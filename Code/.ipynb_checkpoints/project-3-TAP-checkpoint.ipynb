{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "69b9a648-bcc7-490d-9f9b-ea244d156bd6"
   },
   "source": [
    "# Web Scraping for Indeed.com & Predicting Salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "34681254-c802-462f-829d-8894d0772d08"
   },
   "source": [
    "In this project, we will practice two major skills: collecting data by scraping a website and then building a binary classifier.\n",
    "\n",
    "We are going to collect salary information on data science jobs in a variety of markets. Then using the location, title, and summary of the job we will attempt to predict the salary of the job. For job posting sites, this would be extraordinarily useful. While most listings DO NOT come with salary information (as you will see in this exercise), being to able extrapolate or predict the expected salaries from other listings can help guide negotiations.\n",
    "\n",
    "Normally, we could use regression for this task; however, we will convert this problem into classification and use a random forest classifier, as well as another classifier of your choice; either logistic regression, SVM, or KNN. \n",
    "\n",
    "- **Question**: Why would we want this to be a classification problem?\n",
    "- **Answer**: While more precision may be better, there is a fair amount of natural variance in job salaries - predicting a range be may be useful.\n",
    "\n",
    "Therefore, the first part of the assignment will be focused on scraping Indeed.com. In the second, we'll focus on using listings with salary information to build a model and predict additional salaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a948d79c-5527-4c0d-ab23-f5d43ce72056"
   },
   "source": [
    "### Scraping job listings from Indeed.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": true,
    "id": "7203e0c9-e437-4802-a6ad-7dc464f94436"
   },
   "source": [
    "We will be scraping job listings from Indeed.com using BeautifulSoup. Luckily, Indeed.com is a simple text page where we can easily find relevant entries.\n",
    "\n",
    "First, look at the source of an Indeed.com page: (http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\")\n",
    "\n",
    "Notice, each job listing is underneath a `div` tag with a class name of `result`. We can use BeautifulSoup to extract those. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up a request (using requests) to the URL below. Use BeautifulSoup to parse the page and extract all results (HINT: Look for div tags with class name result)\n",
    "The URL here has many query parameters\n",
    "- q for the job search\n",
    "- This is followed by \"+20,000\" to return results with salaries (or expected salaries >$20,000)\n",
    "- l for a location\n",
    "- start for what result number to start on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "URL = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      " <head>\n",
      "  <meta content=\"text/html;charset=utf-8\" http-equiv=\"content-type\"/>\n",
      "  <!-- pll -->\n",
      "  <script src=\"/s/c17916f/en_US.js\" type=\"text/javascript\">\n",
      "  </script>\n",
      "  <link href=\"/s/97410d0/jobsearch_all.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "  <link href=\"http://rss.indeed.com/rss?q=data+scientist+%2420%2C000&amp;l=New+York\" rel=\"alternate\" title=\"Data Scientist $20,000 Jobs, Employment in New York State\" type=\"application/rss+xml\"/>\n",
      "  <link href=\"/m/jobs?q=data+scientist+%2420%2C000&amp;l=New+York\" media=\"only screen and (max-width: 640px)\" rel=\"alternate\"/>\n",
      "  <link href=\"/m/jobs?q=data+scientist+%2420%2C000&amp;l=New+York\" media=\"handheld\" rel=\"alternate\"/>\n",
      "  <script type=\"text/javascript\">\n",
      "   if (typeof window['closureReadyCallbacks'] == 'undefined') {\n",
      "        window['closureReadyCallbacks'] = [];\n",
      "    }\n",
      "\n",
      "    function call_when_jsall_loaded(cb) {\n",
      "        if (window['closureReady']) {\n",
      "            cb();\n",
      "        } else {\n",
      "            window['closureReadyCallbacks'].push(cb);\n",
      "        }\n",
      "    }\n",
      "  </script>\n",
      "  <script src=\"/s/e96089c/jobsearch-all-compiled.js\" type=\"text/javascript\">\n",
      "  </script>\n",
      "  <script type=\"text/javascript\">\n",
      "   var pingUrlsForGA = [];\n",
      "\n",
      "var searchUID = '1bll9fe210m9b3ng';\n",
      "var tk = '1bll9fe210m9b3ng';\n",
      "\n",
      "var loggedIn = false;\n",
      "var myindeed = true;\n",
      "var userEmail = '';\n",
      "var tellFriendEmail = '';\n",
      "var globalLoginURL = 'http:\\/\\/www.indeed.com\\/account\\/login?dest=%2Fjobs%3Fq%3Ddata%2Bscientist%2B%2420%2C000%26l%3DNew%2BYork%26start%3D10';\n",
      "var globalRegisterURL = 'http:\\/\\/www.indeed.com\\/account\\/register?dest=%2Fjobs%3Fq%3Ddata%2Bscientist%2B%2420%2C000%26l%3DNew%2BYork%26start%3D10';\n",
      "var searchKey = '60e10e972da47133';\n",
      "var searchState = 'q=data+scientist+%2420%2C000&amp;l=New+York&amp;start=10';\n",
      "var searchQS = 'q=data+scientist+$20,000&l=New+York&start=10';\n",
      "var eventType = 'jobsearch';\n",
      "var locale = 'en_US';\n",
      "function clk(id) { var a = document.getElementById(id); var hr = a.href; var si = a.href.indexOf('&jsa='); if (si > 0) return; var jsh = hr + '&tk=1bll9fe210m9b3ng&jsa=4305'; a.href = jsh; }\n",
      "function sjomd(id) { var a = document.getElementById(id); var hr = a.href; var ocs = hr.indexOf('&oc=1'); if (ocs < 0) return; var oce = ocs + 5; a.href = hr.substring(0, ocs) + hr.substring(oce); }\n",
      "function sjoc(id, sal) { var a = document.getElementById(id); a.href = a.href + '&oc=1&sal='+sal; }\n",
      "function ptk(st,p) {document.cookie = 'PTK=\"tk=1bll9fe210m9b3ng&type=jobsearch&subtype='+st+(p?'&'+p:'')+'\"; path=/';}\n",
      "function rbptk(st, c, p) { ptk(st, 'cat='+c+(p?'&p='+p:''));}\n",
      "  </script>\n",
      "  <script type=\"text/javascript\">\n",
      "   function loadJSAsync( ) {\n",
      "for ( var i = 0; i < arguments.length; i++ ) {\n",
      "var url = arguments[i];\n",
      "(function() {\n",
      "var s = document.createElement(\"script\"), el = document.getElementsByTagName(\"script\")[0];\n",
      "s.async = true;\n",
      "s.src = url;\n",
      "el.parentNode.insertBefore(s, el);\n",
      "})();\n",
      "}\n",
      "}\n",
      "  </script>\n",
      "  <meta content=\"2,735  Data Scientist $20,000 Jobs available in New York State on Indeed.com.  one search.  all jobs.\" name=\"description\"/>\n",
      "  <meta content=\"Data Scientist $20,000 Jobs, Employment in New York State, New York State careers, New York State employment, New York State job listings, New York State job search, New York State search engine, work in New York State\" name=\"keywords\"/>\n",
      "  <meta content=\"origin\" name=\"referrer\"/>\n",
      "  <link href=\"/jobs?q=Data+Scientist+$20,000&amp;l=New+York+State&amp;start=10\" rel=\"canonical\"/>\n",
      "  <link href=\"/jobs?q=data+scientist+%2420%2C000&amp;l=New+York\" rel=\"prev\">\n",
      "   <link href=\"/jobs?q=data+scientist+%2420%2C000&amp;l=New+York&amp;start=20\" rel=\"next\">\n",
      "    <style type=\"text/css\">\n",
      "     #recPromoDisplay { margin-bottom: 3em;margin-left: 0.5em; }\n",
      "#recPromoDisplayPageLast { font-size: 16px; margin: 1.5em 0; }\n",
      "    </style>\n",
      "    <script type=\"text/javascript\">\n",
      "     var indeedCsrfToken = '2ugSumymFuh4lTyhoQfGF7ihBsUNnBVq';\n",
      "var hashedCsrfToken = '70e62f766a6d43c62701b11cdf42bf3d';\n",
      "    </script>\n",
      "    <style type=\"text/css\">\n",
      "     .jasxcustomfonttst-useCustomHostedFontFullPage *{font-family:\"Open Sans\", sans-serif !important}.jasxcustomfonttst-useLato *{font-family:\"Lato\", sans-serif !important}.jasxcustomfonttst-useFira *{font-family:\"Fira Sans\", sans-serif !important}.jasxcustomfonttst-useGibson *{font-family:\"Gibson\", sans-serif !important}.jasxcustomfonttst-useAvenir *{font-family:\"Avenir Next\", sans-serif !important}\n",
      "    </style>\n",
      "    <style type=\"text/css\">\n",
      "     #resultsCol { padding-top: 0; }\n",
      ".searchCount { margin-top: 6px; }\n",
      ".showing { padding-top: 9px; padding-bottom: 9px; }\n",
      "\n",
      ".brdr { height: 1px; overflow: hidden; background-color: #ccc; }\n",
      "\n",
      "#bjobalerts { margin-top: 0; }\n",
      "\n",
      "/* Tall window sizes */\n",
      "@media only screen and (min-height:780px){\n",
      ".showing { padding-bottom: 0; }\n",
      "}\n",
      "\n",
      "/* Wide window sizes */\n",
      "@media only screen and (min-width:1125px){\n",
      ".brdr  { margin-left: 12px; margin-right: 12px; }\n",
      "}\n",
      "\n",
      "a,a:link,.link,.btn,.btn:hover{text-decoration:none}a:hover,.link:hover{text-decoration:underline}.dya-container a{text-decoration:underline !important}\n",
      "    </style>\n",
      "    <script>\n",
      "     function onLoadHandler() {\n",
      "\n",
      "document.js.reset();\n",
      "jobSeenInit('1bll9fe210m9b3ng');\n",
      "\n",
      "if ( document.radius_update ) { document.radius_update.reset(); }\n",
      "\n",
      "}\n",
      "\n",
      "initLogInitialUserInteraction('1bll9fe210m9b3ng', 'serp');\n",
      "\n",
      "window.onload = onLoadHandler;\n",
      "    </script>\n",
      "    <link href=\"android-app://com.indeed.android.jobsearch/http/www.indeed.com/m/jobs?q=data+scientist+%2420%2C000&amp;l=New+York&amp;start=10\" rel=\"alternate\"/>\n",
      "    <title>\n",
      "     Apply for Data Scientist $20,000 Jobs, Careers in New York State | Indeed.com\n",
      "    </title>\n",
      "    <style type=\"text/css\">\n",
      "     .btn,.sg-btn{display:inline-block;padding:9px 15px;border:1px solid #9a99ac;border-bottom-color:#a2a2a2;-webkit-border-radius:6px;-moz-border-radius:6px;-ms-border-radius:6px;-o-border-radius:6px;border-radius:6px;background-color:#D9D9E2;background-image:-moz-linear-gradient(top, #f8f8f9, #D9D9E2);background-image:-webkit-gradient(linear, 0 0, 0 100%, from(#f8f8f9), to(#D9D9E2));background-image:-webkit-linear-gradient(top, #f8f8f9, #D9D9E2);background-image:linear-gradient(to bottom, #f8f8f9, #D9D9E2);background-repeat:repeat-x;-webkit-box-shadow:0 1px 5px rgba(0,0,0,0.2);-moz-box-shadow:0 1px 5px rgba(0,0,0,0.2);-ms-box-shadow:0 1px 5px rgba(0,0,0,0.2);-o-box-shadow:0 1px 5px rgba(0,0,0,0.2);box-shadow:0 1px 5px rgba(0,0,0,0.2);color:#333;vertical-align:middle;text-align:center;text-decoration:none;text-shadow:0 1px #fff;font-weight:700;font-size:16px;font-family:\"Helvetica Neue\",Helvetica,Arial,\"Lucida Grande\",sans-serif;line-height:22px;filter:progid:DXImageTransform.Microsoft.gradient(startColorstr='#fff8f8f9', endColorstr='#ffe6e6e6', GradientType=0);cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;-o-user-select:none;user-select:none;-webkit-touch-callout:none;-webkit-highlight:none;-webkit-tap-highlight-color:transparent;text-overflow:ellipsis;white-space:nowrap;overflow:hidden}.btn.active,.btn.sg-active,.btn:active,.btn.disabled,.btn.sg-disabled,.btn[disabled],.sg-btn.active,.sg-btn.sg-active,.sg-btn:active,.sg-btn.disabled,.sg-btn.sg-disabled,.sg-btn[disabled]{outline:none;background-color:#f8f8f9;color:#333}.btn:focus,.sg-btn:focus{outline:0;box-shadow:0 0 1px 0 #1642bb;-webkit-transition:box-shadow 0.2s linear;-moz-transition:box-shadow 0.2s linear;transition:box-shadow 0.2s linear}.btn.active,.btn.sg-active,.btn:active,.sg-btn.active,.sg-btn.sg-active,.sg-btn:active{background-color:#f8f8f9;background-image:none;-webkit-box-shadow:inset 0 2px 4px rgba(0,0,0,0.15),0 1px 2px rgba(0,0,0,0.05);-moz-box-shadow:inset 0 2px 4px rgba(0,0,0,0.15),0 1px 2px rgba(0,0,0,0.05);box-shadow:inset 0 2px 4px rgba(0,0,0,0.15),0 1px 2px rgba(0,0,0,0.05)}.btn.disabled,.btn.sg-disabled,.btn[disabled],.sg-btn.disabled,.sg-btn.sg-disabled,.sg-btn[disabled]{background-color:#f8f8f9;background-image:none;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;opacity:.65;filter:alpha(opacity=65);cursor:default}.btn-primary,.sg-btn-primary{border-color:#1642bb;background-color:#5585f2;background-image:-moz-linear-gradient(top, #6598ff, #2e5ad7);background-image:-webkit-gradient(linear, 0 0, 0 100%, from(#6598ff), to(#2e5ad7));background-image:-webkit-linear-gradient(top, #6598ff, #2e5ad7);background-image:linear-gradient(to bottom, #6598ff, #2e5ad7);background-repeat:repeat-x;color:#F8F8F9;text-shadow:0 -1px #0f2299;-ms-filter:progid:DXImageTransform.Microsoft.dropshadow(OffX=0, OffY=-1, Color=#e80f2299, Positive=true);filter:progid:DXImageTransform.Microsoft.dropshadow(OffX=0, OffY=-1, Color=#e80f2299, Positive=true);filter:progid:DXImageTransform.Microsoft.gradient(startColorstr='#ff6598fe', endColorstr='#ff3c69e0', GradientType=0);zoom:1}.btn-primary.active,.btn-primary.sg-active,.btn-primary:active,.btn-primary.disabled,.btn-primary.sg-disabled,.btn-primary[disabled],.sg-btn-primary.active,.sg-btn-primary.sg-active,.sg-btn-primary:active,.sg-btn-primary.disabled,.sg-btn-primary.sg-disabled,.sg-btn-primary[disabled]{background-color:#2e5ad7;color:#F8F8F9}.btn-primary:focus,.sg-btn-primary:focus{box-shadow:0 0 1px 0 #000}.btn-special,.sg-btn-special{border-color:#ba3200;background-color:#5585f2;background-image:-moz-linear-gradient(top, #f60, #f14200);background-image:-webkit-gradient(linear, 0 0, 0 100%, from(#f60), to(#f14200));background-image:-webkit-linear-gradient(top, #f60, #f14200);background-image:linear-gradient(to bottom, #f60, #f14200);background-repeat:repeat-x;color:#F8F8F9;text-shadow:0 -1px #000;-ms-filter:progid:DXImageTransform.Microsoft.dropshadow(OffX=0, OffY=-1, Color=#e80f2299, Positive=true);filter:progid:DXImageTransform.Microsoft.dropshadow(OffX=0, OffY=-1, Color=#e80f2299, Positive=true);filter:progid:DXImageTransform.Microsoft.gradient(startColorstr='#ff6598fe', endColorstr='#ff3c69e0', GradientType=0);zoom:1}.btn-special.active,.btn-special.sg-active,.btn-special:active,.btn-special.disabled,.btn-special.sg-disabled,.btn-special[disabled],.sg-btn-special.active,.sg-btn-special.sg-active,.sg-btn-special:active,.sg-btn-special.disabled,.sg-btn-special.sg-disabled,.sg-btn-special[disabled]{background-color:#f14200;color:#F8F8F9}.btn-special:focus,.sg-btn-special:focus{box-shadow:0 0 1px 0 #000}.btn-danger,.sg-btn-danger{border-color:#83121b;background-color:#5585f2;background-image:-moz-linear-gradient(top, #d1787f, #b01825);background-image:-webkit-gradient(linear, 0 0, 0 100%, from(#d1787f), to(#b01825));background-image:-webkit-linear-gradient(top, #d1787f, #b01825);background-image:linear-gradient(to bottom, #d1787f, #b01825);background-repeat:repeat-x;color:#F8F8F9;text-shadow:0 -1px #000;-ms-filter:progid:DXImageTransform.Microsoft.dropshadow(OffX=0, OffY=-1, Color=#e80f2299, Positive=true);filter:progid:DXImageTransform.Microsoft.dropshadow(OffX=0, OffY=-1, Color=#e80f2299, Positive=true);filter:progid:DXImageTransform.Microsoft.gradient(startColorstr='#ff6598fe', endColorstr='#ff3c69e0', GradientType=0);zoom:1}.btn-danger.active,.btn-danger.sg-active,.btn-danger:active,.btn-danger.disabled,.btn-danger.sg-disabled,.btn-danger[disabled],.sg-btn-danger.active,.sg-btn-danger.sg-active,.sg-btn-danger:active,.sg-btn-danger.disabled,.sg-btn-danger.sg-disabled,.sg-btn-danger[disabled]{background-color:#b01825;color:#F8F8F9}.btn-danger:focus,.sg-btn-danger:focus{box-shadow:0 0 1px 0 #000}input.btn,input.sg-btn{-webkit-appearance:none}button.btn::-moz-focus-inner,button.sg-btn::-moz-focus-inner{border:0}.btn-sm,.sg-btn-sm,.btn-xs,.sg-bt-xs{padding:6px 12px}.btn-xs,.sg-btn-xs{padding:3px 6px;line-height:15px}.btn-md,.sg-btn-md{padding:6px 6px}.btn-lg,.sg-btn-lg{padding:9px 18px;border-radius:6px;font-size:18px}.btn-block,.sg-btn-block{display:block;margin:9px auto;-webkit-box-sizing:border-box !important;-moz-box-sizing:border-box !important;box-sizing:border-box !important;max-width:352px}.btn-block-compact,.sg-btn-block-compact{margin:2px auto}input.btn-block,input.sg-btn-block,button.btn-block,button.sg-btn-block{width:100%;max-width:351px}.btn-block+.btn-block,.sg-btn-block+.sg-btn-block{margin-top:5px}#buttonContainer .btn,#buttonContainer .sg-btn{margin:0}.btn-icon .cssImage{margin-bottom:-40px;position:relative;top:-27px}.btn-pair{-webkit-box-sizing:border-box !important;-moz-box-sizing:border-box !important;box-sizing:border-box !important;width:49%}#refineresultscol{width:184px}#refineresults{width:180px}#branding-td{width:186px;text-align:center}.ltr #searchCount{margin-right:4px;margin-left:4px}.ltr #resultsCol .sorting{padding-right:4px}.ltr #resultsCol .showing{padding-left:4px}.ltr #jobsearch{padding-left:4px}.rtl #searchCount{margin-left:4px;margin-right:4px}.rtl #resultsCol .sorting{padding-left:4px}.rtl #resultsCol .showing{padding-right:4px}.rtl #jobsearch{padding-right:4px}.jaui,.hasu .gasc,.row,.message,.oocs{padding-left:4px;padding-right:4px}#resumePromo{padding-left:4px;padding-right:4px}#primePromo{padding-left:4px;padding-right:4px}@media only screen and (min-width: 1125px){.ltr #refineresults{padding-left:15px}.ltr #branding img{margin-left:16px;margin-right:28px}.rtl #refineresults{padding-right:15px}.rtl #branding img{margin-right:16px;margin-left:28px}.ltr #searchCount{margin-right:12px;margin-left:12px}.ltr #resultsCol .sorting{padding-right:12px}.ltr #resultsCol .showing{padding-left:12px}.ltr #jobsearch{padding-left:12px}.rtl #searchCount{margin-left:12px;margin-right:12px}.rtl #resultsCol .sorting{padding-left:12px}.rtl #resultsCol .showing{padding-right:12px}.rtl #jobsearch{padding-right:12px}.jaui,.hasu .gasc,.row,.message,.oocs{padding-left:12px;padding-right:12px}#resumePromo{padding-left:12px;padding-right:12px}#primePromo{padding-left:12px;padding-right:12px}#resultsBody{width:1125px}#refineresultscol,#branding-td{width:225px}#refineresults{width:210px}}@media only screen and (min-width: 1250px){#resultsBody{width:1250px}#auxCol{width:315px}#refineresultscol,#branding-td{width:275px}#refineresults{width:260px}.ltr #refineresults{padding-left:15px}.ltr #branding img{margin-left:16px;margin-right:28px}.rtl #refineresults{padding-right:15px}.rtl #branding img{margin-right:16px;margin-left:28px}.ltr #searchCount{margin-right:12px;margin-left:12px}.ltr #resultsCol .sorting{padding-right:12px}.ltr #resultsCol .showing{padding-left:12px}.ltr #jobsearch{padding-left:12px}.rtl #searchCount{margin-left:12px;margin-right:12px}.rtl #resultsCol .sorting{padding-left:12px}.rtl #resultsCol .showing{padding-right:12px}.rtl #jobsearch{padding-right:12px}.jaui,.hasu .gasc,.row,.message,.oocs{padding-left:12px;padding-right:12px}#resumePromo{padding-left:12px;padding-right:12px}#primePromo{padding-left:12px;padding-right:12px}}#branding-td{padding:5px 0 5px 0px}.resultsTop{padding-top:9px}\n",
      "    </style>\n",
      "   </link>\n",
      "  </link>\n",
      " </head>\n",
      " <body class=\"ltr jasxcustomfonttst-inactive\" data-tn-application=\"jasx\" data-tn-olth=\"41be357fa1c7dc26c5ee98836f8950b3\" data-tn-originlogid=\"1bll9fe210m9b3ng\" data-tn-originlogtype=\"jobsearch\">\n",
      "  <div id=\"accessibilityBanner\">\n",
      "   <span id=\"accessibilityText\">\n",
      "    Skip to\n",
      "    <!-- This is translated before reaching this state -->\n",
      "    <a class=\"accessibilityMenu\" href=\"#jobPostingsAnchor\" id=\"skipToJobs\">\n",
      "     Job Postings\n",
      "    </a>\n",
      "    ,\n",
      "    <!-- This is translated before reaching this state -->\n",
      "    <a class=\"accessibilityMenu\" href=\"#what\" id=\"skipToSearch\">\n",
      "     Search\n",
      "    </a>\n",
      "   </span>\n",
      "   <a id=\"accessibilityClose\">\n",
      "    Close\n",
      "   </a>\n",
      "  </div>\n",
      "  <link href=\"/s/36397a3/accessibility.css\" rel=\"stylesheet\" type=\"text/css\">\n",
      "   <script type=\"text/javascript\">\n",
      "    createTabBar('1bll9fe210m9b3ng');\n",
      "   </script>\n",
      "   <style type=\"text/css\">\n",
      "    body { margin-top: 0; margin-left: 0; margin-right: 0; padding-top: 0; padding-right: 0; padding-left: 0; }\n",
      "\n",
      "#g_nav { border-bottom:1px solid #ccc; margin-bottom:9px; }\n",
      "\n",
      "#g_nav a,\n",
      "#g_nav a:visited { color: #00c; }\n",
      "\n",
      ".navBi { display: -moz-inline-box; display: inline-block; padding: 9px 12px; margin: 0; list-style-type: none; }\n",
      "   </style>\n",
      "   <div class=\"left\" data-tn-section=\"globalNav\" id=\"g_nav\" role=\"navigation\">\n",
      "    <table cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "     <tr>\n",
      "      <td nowrap=\"\">\n",
      "       <style type=\"text/css\">\n",
      "        #p_nav a.selected { font-weight: bold; text-decoration:none; color: #000 !important; }\n",
      "       </style>\n",
      "       <div id=\"p_nav\">\n",
      "        <span class=\"navBi\">\n",
      "         <a class=\"selected\" href=\"/\" id=\"jobsLink\" title=\"Jobs\">\n",
      "          Find Jobs\n",
      "         </a>\n",
      "        </span>\n",
      "        <span class=\"navBi\">\n",
      "         <a href=\"/Best-Places-to-Work\" onmousedown=\"this.href = appendParamsOnce(this.href, '?from=headercmplink&amp;attributionid=jobsearch')\">\n",
      "          Company Reviews\n",
      "         </a>\n",
      "        </span>\n",
      "        <span class=\"navBi\">\n",
      "         <a href=\"/salaries\" onmousedown=\"this.href = appendParamsOnce(this.href, '?from=headercmplink&amp;attributionid=jobsearch')\">\n",
      "          Find Salaries\n",
      "         </a>\n",
      "        </span>\n",
      "        <span class=\"navBi\">\n",
      "         <a href=\"/resumes?isid=find-resumes&amp;ikw=SERPtop&amp;co=US&amp;hl=en\" id=\"rezLink\">\n",
      "          Find Resumes\n",
      "         </a>\n",
      "        </span>\n",
      "        <span class=\"navBi\">\n",
      "         <a href=\"/hire?hl=en&amp;cc=US\" id=\"empLink\" onclick=\"if ( this.href.match('&amp;isid=employerlink-US-control&amp;ikw=SERPtop') == null ) { this.href += '&amp;isid=employerlink-US-control&amp;ikw=SERPtop' };\">\n",
      "          Employers / Post Job\n",
      "         </a>\n",
      "        </span>\n",
      "       </div>\n",
      "      </td>\n",
      "      <td align=\"right\" nowrap=\"\">\n",
      "       <style type=\"text/css\">\n",
      "        #navpromo a,\n",
      "#navpromo a:visited {\n",
      "color: #f60;\n",
      "}\n",
      "\n",
      "\n",
      "#u_nav .login_unconfirmed,\n",
      "#u_nav .login_unconfirmed a,\n",
      "#u_nav .login_unconfirmed a:visited {\n",
      "color: #c00\n",
      "}\n",
      "\n",
      "#u_nav .resume_pending,\n",
      "#u_nav .resume_pending a,\n",
      "#u_nav .resume_pending a:visited {\n",
      "color: #c00\n",
      "}\n",
      "\n",
      "#userOptionsLabel {\n",
      "position: relative;\n",
      "z-index: 5;\n",
      "}\n",
      "\n",
      "#userOptionsLabel b {\n",
      "cursor: pointer;\n",
      "text-decoration: underline;\n",
      "position: relative;\n",
      "z-index: 5;\n",
      "}\n",
      "\n",
      "#userOptionsLabel:active {\n",
      "outline: none;\n",
      "}\n",
      "\n",
      "#userOptionsLabel.active {\n",
      "padding: 9px 11px;\n",
      "margin-bottom: -1px;\n",
      "_margin-bottom: 0px;\n",
      "border: 1px solid #ccc;\n",
      "border-top: 0;\n",
      "}\n",
      "\n",
      "#userOptionsLabel.active .arrowStub {\n",
      "border-width: 0 3px 3px;\n",
      "_border-width: 0px 3px 4px;\n",
      "border-color: transparent;\n",
      "border-bottom-color: #666;\n",
      "top: -2px;\n",
      "border-style: dashed dashed solid;\n",
      "}\n",
      "\n",
      "#userOptionsLabel.active .halfPxlFix {\n",
      "background: #fff;\n",
      "bottom: -3px;\n",
      "height: 6px;\n",
      "left: 0;\n",
      "position: absolute;\n",
      "right: 0;\n",
      "border: 1px solid #fff;\n",
      "}\n",
      "\n",
      ".arrowStub {\n",
      "position: relative;\n",
      "border-style: solid dashed dashed;\n",
      "border-color: transparent;\n",
      "border-top-color: #666;\n",
      "display: -moz-inline-box;\n",
      "display: inline-block;\n",
      "font-size: 0;\n",
      "height: 0;\n",
      "line-height: 0;\n",
      "width: 0;\n",
      "left: 4px;\n",
      "border-top-width: 3px;\n",
      "border-bottom-width: 0;\n",
      "border-right-width: 3px;\n",
      "padding-top: 1px;\n",
      "top: -1px;\n",
      "}\n",
      "\n",
      "#userOptions {\n",
      "z-index: 2;\n",
      "visibility: hidden;\n",
      "position: absolute;\n",
      "right: 0;\n",
      "x_right: -1px;\n",
      "top: 100%;\n",
      "padding: 9px 15px;\n",
      "border: 1px solid #ccc;\n",
      "background: #fff;\n",
      "min-width: 150px;\n",
      "_width: 150px;\n",
      "text-align: left;\n",
      "}\n",
      "\n",
      "#userOptions.open {\n",
      "visibility: visible;\n",
      "}\n",
      "\n",
      ".userOptionItem {\n",
      "margin: 6px 0;\n",
      "}\n",
      "\n",
      ".userOptionItem a {\n",
      "white-space: nowrap;\n",
      "}\n",
      "\n",
      ".userOptionGroup {\n",
      "border-top: 1px solid #e8e8e8;\n",
      "margin-top: 12px;\n",
      "}\n",
      "\n",
      ".userNameRepeat {\n",
      "color: #a8a8a8;\n",
      "padding-right: 48px;\n",
      "font-weight: bold;\n",
      "}\n",
      "\n",
      ".userOptionGroupHeader {\n",
      "font-weight: bold;\n",
      "margin: 6px 0;\n",
      "}\n",
      "       </style>\n",
      "       <div id=\"u_nav\">\n",
      "        <script>\n",
      "         function regExpEscape(s) {\n",
      "    return String(s).replace(/([-()\\[\\]{}+?*.$\\^|,:#<!\\\\])/g, '\\\\$1').\n",
      "            replace(/\\x08/g, '\\\\x08');\n",
      "}\n",
      "\n",
      "\n",
      "function appendParamsOnce(url, params) {\n",
      "    var useParams = params.replace(/^(\\?|\\&)/, '');\n",
      "    if (url.match(new RegExp('[\\\\?|\\\\&]' + regExpEscape(useParams))) == null) {\n",
      "        return url += (url.indexOf('?') > 0 ? '&' : '?' ) + useParams;\n",
      "    }\n",
      "    return url;\n",
      "}\n",
      "        </script>\n",
      "        <div id=\"user_actions\">\n",
      "         <span class=\"navBi\">\n",
      "          <span class=\"resume-promo\" id=\"navpromo\">\n",
      "           <a href=\"/promo/resume\" onclick=\"window.location=this.href + '?from=nav&amp;subfrom=rezprmstd&amp;trk.origin=jobsearch&amp;trk.variant=rezprmstd&amp;trk.pos=nav&amp;trk.tk=1bll9fe210m9b3ng'; return false;\">\n",
      "            Upload your resume\n",
      "           </a>\n",
      "          </span>\n",
      "         </span>\n",
      "         <span class=\"navBi\">\n",
      "          <a href=\"http://www.indeed.com/account/login?dest=%2Fjobs%3Fq%3Ddata%2Bscientist%2B%2420%2C000%26l%3DNew%2BYork%26start%3D10\" id=\"userOptionsLabel\" rel=\"nofollow\">\n",
      "           Sign in\n",
      "          </a>\n",
      "         </span>\n",
      "        </div>\n",
      "       </div>\n",
      "      </td>\n",
      "     </tr>\n",
      "    </table>\n",
      "   </div>\n",
      "   <style type=\"text/css\">\n",
      "    .indeedLogo {\n",
      "background: url(/images/medium_logo.png) no-repeat;\n",
      "\n",
      "margin: 8px 0 0 9px;\n",
      "border: 0;\n",
      "width: 166px;\n",
      "height: 64px;\n",
      "-webkit-background-size: 155px 43px;\n",
      "background-size: 155px 43px;\n",
      "}\n",
      "@media (-webkit-min-device-pixel-ratio: 2),\n",
      "(   min--moz-device-pixel-ratio: 2),\n",
      "(     -o-min-device-pixel-ratio: 2/1),\n",
      "(        min-device-pixel-ratio: 2),\n",
      "(                min-resolution: 192dpi),\n",
      "(                min-resolution: 2dppx) {\n",
      ".indeedLogo {\n",
      "background: url(/images/medium_logo@2x.png) no-repeat;\n",
      "-webkit-background-size: 155px 43px;\n",
      "background-size: 155px 43px;\n",
      "}\n",
      "}\n",
      "#branding img { border: 0; }\n",
      "#jobsearch { margin: 0 }\n",
      ".inwrap { border-right: 1px solid #e8e8e8;border-bottom: 1px solid #e8e8e8;display:inline-block; }\n",
      ".inwrap input { box-sizing: border-box; margin:0; height: 30px; font-family:Arial,sans-serif;border:1px solid #ccc; border-bottom-color:#aaa;border-right-color:#aaa; -webkit-border-radius: 0; -webkit-appearance: none; }\n",
      ".inwrap .input_text { font-size:18px;padding:3px 6px;_margin: -1px 0; }\n",
      ".inwrap .input_submit {color:#614041;font-size:15px;height:30px;background: #e8e8e8; padding:3px 9px;cursor:pointer;_padding:3px;}\n",
      ".inwrap .input_submit:active { background: #ccc; }\n",
      ".lnav  {width:100%;line-height:1;;font-size:10pt;}\n",
      ".jsf .label {font-size:12px; line-height:1.2;padding-top:0;color:#aaa;font-weight:normal;white-space:nowrap;padding-right:1.5em}\n",
      ".jsf .label label {font-weight:normal}\n",
      ".jsf .sl { font-size: 11px; color: #77c; white-space: nowrap; }\n",
      ".npb { padding-bottom: 0; color: #f60; text-transform: lowercase;font-weight:bold; }\n",
      ".npl { padding-left: 0 }\n",
      "iframe { display:block; }\n",
      "\n",
      ".acd { border: 1px solid #333; background: #fff; position:absolute; width:100%; z-index: 1; }\n",
      ".aci { font-size: 18px; padding:1px 6px; cursor:pointer; }\n",
      ".acis { background:#36c; color:#fff; }\n",
      "\n",
      "#tjobalerts .ws_label,\n",
      "#bjobalerts .ws_label,\n",
      "#tjobalerts .member,\n",
      "#bjobalerts .member{ z-index: 1; }\n",
      "#acr td { padding-top:0; padding-bottom:0; }\n",
      "#acr td .h { display:none; }\n",
      "\n",
      "#what { width: 280px; }\n",
      "#where { width: 260px; }\n",
      ".inwrapBorder{border:1px solid #1c4ed9;border-top-color:#2f62f1;border-bottom-color:#133fbb;display:inline-block;width:auto}.inwrapBorderTop{border-top:1px solid #69F;display:inline-block;background-color:#3163f2;filter:progid:DXImageTransform.Microsoft.gradient(startColorstr='#3163F2',endColorstr='#2B57D5');background:-webkit-gradient(linear,left top,left bottom,from(#3163f2),to(#2b57d5));background:-moz-linear-gradient(top,#3163f2,#2b57d5);background:linear-gradient(top,#3163f2,#2b57d5)}.inwrapBorder .input_submit{background:transparent;border:0;color:#fff;font-family:Arial;font-size:15px;margin:0;padding:4px 9px;cursor:pointer;_padding:3px}.inwrapBorder a.input_submit{text-decoration:none;display:block}.inwrapBorder:hover{border-color:#235af6;border-top-color:#4072ff;border-bottom-color:#1e4fd9}.inwrapBorderTop:hover{border-top-color:#7ba7ff;background-color:#4273ff;filter:progid:DXImageTransform.Microsoft.gradient(startColorstr='#4273ff',endColorstr='#3364f1');background:-webkit-gradient(linear,left top,left bottom,from(#4273ff),to(#3364f1));background:-moz-linear-gradient(top,#4273ff,#3364f1);background:linear-gradient(top,#4273ff,#3364f1)}.inwrapBorder:active{border-color:#536db7;border-top-color:#4b69c1;border-bottom-color:#3753a6}.inwrapBorder:active .inwrapBorderTop{border-top-color:#6c82c1;background-color:#4b69c1;filter:progid:DXImageTransform.Microsoft.gradient(startColorstr='#4b69c1',endColorstr='#3753a6');background:-webkit-gradient(linear,left top,left bottom,from(#4b69c1),to(#3753a6));background:-moz-linear-gradient(top,#4b69c1,#3753a6);background:linear-gradient(top,#4b69c1,#3753a6)}.roundedCorner{display:inline-block;zoom:1;*display:inline;vertical-align:baseline;margin:0 2px;outline:0;cursor:pointer;text-align:center;text-decoration:none;font:15px/100% Arial,Helvetica,sans-serif;padding:.5em 2em .55em;text-shadow:0 1px 1px rgba(0,0,0,.3);-webkit-border-radius:.5em;-moz-border-radius:.5em;border-radius:.5em;-webkit-box-shadow:0 1px 2px rgba(0,0,0,.2);-moz-box-shadow:0 1px 2px rgba(0,0,0,.2);box-shadow:0 1px 2px rgba(0,0,0,.2)}.roundedCorner:hover{text-decoration:none}.roundedCorner:active{position:relative;top:1px}.bigrounded{-webkit-border-radius:2em;-moz-border-radius:2em;border-radius:2em}.medium{font-size:12px;padding:.4em 1.5em .42em}.small{font-size:11px;padding:.2em 1em .275em}.indeedblue{color:#d9eef7;border:solid 1px #1c4ed9;background:#3163f2;background:-webkit-gradient(linear,left top,left bottom,from(#2f62f1),to(#133fbb));background:-moz-linear-gradient(top,#2f62f1,#133fbb);filter:progid:DXImageTransform.Microsoft.gradient(startColorstr='#2F62F1',endColorstr='#133FBB')}.indeedblue:hover,.indeedblue:focus{background:#235af6;background:-webkit-gradient(linear,left top,left bottom,from(#4072ff),to(#1e4fd9));background:-moz-linear-gradient(top,#4072ff,#1e4fd9);filter:progid:DXImageTransform.Microsoft.gradient(startColorstr='#4072ff',endColorstr='#1e4fd9')}.indeedblue:active{color:#d9eef7;background:-webkit-gradient(linear,left top,left bottom,from(#4b69c1),to(#3753a6));background:-moz-linear-gradient(top,#4b69c1,#3753a6);filter:progid:DXImageTransform.Microsoft.gradient(startColorstr='#4b69c1',endColorstr='#3753a6')}\n",
      "   </style>\n",
      "   <span id=\"hidden_colon\" style=\"display:none\">\n",
      "    :\n",
      "   </span>\n",
      "   <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" role=\"banner\">\n",
      "    <tr>\n",
      "     <td width=\"1125\">\n",
      "      <table cellpadding=\"0\" cellspacing=\"0\" class=\"lnav\">\n",
      "       <tr>\n",
      "        <td id=\"branding-td\" style=\"vertical-align:top;\">\n",
      "         <a href=\"/\" id=\"branding\" onmousedown=\"ptk('logo');\">\n",
      "          <img alt=\"one search. all jobs. Indeed\" class=\"indeedLogo\" src=\"data:image/gif;base64,R0lGODlhAQABAJEAAAAAAP///////wAAACH5BAEHAAIALAAAAAABAAEAAAICVAEAOw==\" style=\"margin-bottom:6px;display:block;\" title=\"one search. all jobs. Indeed\"/>\n",
      "         </a>\n",
      "        </td>\n",
      "        <td style=\"padding-top:3px;\" valign=\"top\">\n",
      "         <form action=\"/jobs\" class=\"jsf\" id=\"jobsearch\" method=\"get\" name=\"js\" onsubmit=\"formptk('topsearch','where_ac','',['where_ac','what_ac'], ptk);formptk('topsearch','what_ac','w',['where_ac','what_ac'], ptk);\">\n",
      "          <table align=\"left\" cellpadding=\"3\" cellspacing=\"0\">\n",
      "           <tr>\n",
      "            <td class=\"npb\">\n",
      "             <label for=\"what\" id=\"what_label_top\">\n",
      "              What\n",
      "             </label>\n",
      "            </td>\n",
      "            <td class=\"npb\" colspan=\"3\">\n",
      "             <label for=\"where\" id=\"where_label_top\">\n",
      "              Where\n",
      "             </label>\n",
      "            </td>\n",
      "           </tr>\n",
      "           <tr role=\"search\">\n",
      "            <td class=\"npl epr\">\n",
      "             <span class=\"inwrap\">\n",
      "              <input aria-labelledby=\"what_label_top hidden_colon what_label\" class=\"input_text\" id=\"what\" maxlength=\"512\" name=\"q\" size=\"31\" value=\"data scientist $20,000\"/>\n",
      "             </span>\n",
      "             <div style=\"width:250px\">\n",
      "              <!-- -->\n",
      "             </div>\n",
      "            </td>\n",
      "            <td class=\"npl epr\">\n",
      "             <span class=\"inwrap\">\n",
      "              <input aria-labelledby=\"where_label_top hidden_colon where_label\" class=\"input_text\" id=\"where\" maxlength=\"45\" name=\"l\" size=\"27\" value=\"New York\"/>\n",
      "             </span>\n",
      "             <div style=\"width:200px\">\n",
      "              <!-- -->\n",
      "             </div>\n",
      "            </td>\n",
      "            <td class=\"npl\" style=\"width:1px\">\n",
      "             <span class=\"inwrapBorder\" style=\"width:auto;padding-right:0;\">\n",
      "              <span class=\"inwrapBorderTop\">\n",
      "               <input class=\"input_submit\" id=\"fj\" type=\"submit\" value=\"Find Jobs\"/>\n",
      "              </span>\n",
      "             </span>\n",
      "            </td>\n",
      "            <td class=\"npl advanced-search\" style=\"width:240px;\">\n",
      "             <div style=\"margin-left:12px; display:flex;\">\n",
      "              <a class=\"sl\" href=\"/advanced_search?q=data+scientist+%2420%2C000&amp;l=New+York\">\n",
      "               Advanced Job Search\n",
      "              </a>\n",
      "             </div>\n",
      "            </td>\n",
      "           </tr>\n",
      "           <tr id=\"acr\">\n",
      "            <td>\n",
      "             <span class=\"h\">\n",
      "             </span>\n",
      "            </td>\n",
      "            <td class=\"npl\" colspan=\"2\">\n",
      "             <div style=\"position:relative;z-index:2\">\n",
      "              <div class=\"acd\" id=\"acdiv\" style=\"display:none;\">\n",
      "              </div>\n",
      "             </div>\n",
      "            </td>\n",
      "            <td>\n",
      "             <span class=\"h\">\n",
      "             </span>\n",
      "            </td>\n",
      "           </tr>\n",
      "           <tr id=\"acr\">\n",
      "            <td class=\"npl\" colspan=\"3\">\n",
      "             <div style=\"position:relative;z-index:2\">\n",
      "              <div class=\"acd\" id=\"what_acdiv\" style=\"display:none;\">\n",
      "              </div>\n",
      "             </div>\n",
      "            </td>\n",
      "            <td>\n",
      "             <span class=\"h\">\n",
      "             </span>\n",
      "            </td>\n",
      "           </tr>\n",
      "           <tr valign=\"baseline\">\n",
      "            <td class=\"label\" id=\"what_label_cell\">\n",
      "             <label aria-hidden=\"true\" for=\"what\" id=\"what_label\">\n",
      "              job title, keywords or company\n",
      "             </label>\n",
      "            </td>\n",
      "            <td class=\"label\" colspan=\"3\" id=\"where_label_cell\">\n",
      "             <label aria-hidden=\"true\" for=\"where\" id=\"where_label\">\n",
      "              city, state, or zip\n",
      "             </label>\n",
      "            </td>\n",
      "           </tr>\n",
      "          </table>\n",
      "         </form>\n",
      "        </td>\n",
      "       </tr>\n",
      "      </table>\n",
      "     </td>\n",
      "    </tr>\n",
      "   </table>\n",
      "   <script type=\"text/javascript\">\n",
      "    initAutocomplete('where_ac', gbid('where'), gbid('acdiv'), '/rpc/suggest?from=serp&tk=1bll9fe210m9b3ng', function() { formptk('topsearch','where_ac', '', ['where_ac','what_ac'], ptk); }, gbid('where'));\n",
      "        \n",
      "        initAutocomplete('what_ac', gbid('what'), gbid('what_acdiv'), '/rpc/suggest?what=true&tk=1bll9fe210m9b3ng', function () {formptk('topsearch', 'what_ac', 'w', ['where_ac','what_ac'], ptk);}, gbid('what'));\n",
      "   </script>\n",
      "   <script type=\"text/javascript\">\n",
      "    function rclk(el,jobdata,oc,sal) { var ocstr = oc ? '&onclick=1' : ''; document.cookie='RCLK=\"jk='+jobdata.jk+'&tk=1bll9fe210m9b3ng&from=web&rd='+jobdata.rd+'&qd=7tdTJLF8oc4dPpT7T_zGvPNb6L1Ut5KgfhN1tIlu8MGsllFlTeURo2sZc2R1Y4xRV3eCeUmQGU3ztUik3-Gy_R6CEMRbgwtK5AEvvRLSBdyLn0RBw_pXbkbmWEpfhoo3rDosy-d9U20qw7o-WT45LA&ts=1500731914305&sal='+sal+ocstr+'\"; path=/'; return true;}\n",
      "function zrprclk(el,jobdata,oc) { var ocstr = oc ? '&onclick=1' : ''; document.cookie='RCLK=\"jk='+jobdata.jk+'&tk=1bll9fe210m9b3ng&from=reconzrp&rd='+jobdata.rd+'&qd=7tdTJLF8oc4dPpT7T_zGvPNb6L1Ut5KgfhN1tIlu8MGsllFlTeURo2sZc2R1Y4xRV3eCeUmQGU3ztUik3-Gy_R6CEMRbgwtK5AEvvRLSBdyLn0RBw_pXbkbmWEpfhoo3rDosy-d9U20qw7o-WT45LA&ts=1500731914305'+ocstr+'\"; path=/'; return true;}\n",
      "function prjbottomclk(el,jobdata,oc) { var ocstr = oc ? '&onclick=1' : ''; document.cookie='RCLK=\"jk='+jobdata.jk+'&tk=1bll9fe210m9b3ng&from=reconserp&rd='+jobdata.rd+'&qd=7tdTJLF8oc4dPpT7T_zGvPNb6L1Ut5KgfhN1tIlu8MGsllFlTeURo2sZc2R1Y4xRV3eCeUmQGU3ztUik3-Gy_R6CEMRbgwtK5AEvvRLSBdyLn0RBw_pXbkbmWEpfhoo3rDosy-d9U20qw7o-WT45LA&ts=1500731914305'+ocstr+'\"; path=/'; return true;}\n",
      "\n",
      "\n",
      "var jobmap = {};\n",
      "\n",
      "jobmap[0]= {jk:'5b1f58efbf2e7458',efccid: '7742c109cbf2990f',srcid:'b015d12f075f7dcd',cmpid:'1dec991c3c01c67d',num:'0',srcname:'Tumblr',cmp:'Tumblr',cmpesc:'Tumblr',cmplnk:'/q-Tumblr-l-New-York-jobs.html',loc:'New York, NY',country:'US',zip:'',city:'New York',title:'Data Scientist, Personalization and Recommendation',locid:'45f6c4ded55c00bf',rd:'kS44jnW3ZVPAybGozCXHO6ZM22n6iTqaU6nPqTLU8J8EGaNE-Myob6IiekfKkVAB'};\n",
      "\n",
      "jobmap[1]= {jk:'97293997165757e6',efccid: 'b7ec60b3deb9e1d3',srcid:'13c5e79641e65d90',cmpid:'4a9b8c61a3e17d38',num:'1',srcname:'Schireson Associates',cmp:'Schireson Associates',cmpesc:'Schireson Associates',cmplnk:'/q-Schireson-Associates-l-New-York-jobs.html',loc:'New York, NY 10018',country:'US',zip:'10018',city:'New York',title:'Data Analyst',locid:'45f6c4ded55c00bf',rd:'47ADd3TeFmBFomfqtn1uA3ujl6864H9IMjQoO3UOHZM'};\n",
      "\n",
      "jobmap[2]= {jk:'81e50490c3e0204a',efccid: '91a59336653b47e4',srcid:'2b88f3eaf110b8ed',cmpid:'d9a36a1771c05d30',num:'2',srcname:'Enterprise Select',cmp:'Enterprise Select',cmpesc:'Enterprise Select',cmplnk:'/q-Enterprise-Select-l-New-York-jobs.html',loc:'New York, NY 10005',country:'US',zip:'10005',city:'New York',title:'Data Scientist',locid:'45f6c4ded55c00bf',rd:'oFk8XG6o9EugLQJgglM85Xujl6864H9IMjQoO3UOHZM'};\n",
      "\n",
      "jobmap[3]= {jk:'c577bc95d49af6cd',efccid: '190f9406da32f8fb',srcid:'05bdb93933321805',cmpid:'5673861b9f61c6bf',num:'3',srcname:'J. Crew Group, Inc.',cmp:'J.Crew Group, Inc.',cmpesc:'J.Crew Group, Inc.',cmplnk:'/q-J.Crew-Group-l-New-York-jobs.html',loc:'New York, NY 10003',country:'US',zip:'10003',city:'New York',title:'Data Scientist - Pricing',locid:'45f6c4ded55c00bf',rd:'dsrCoTCYcSFG9et58ob3BqZM22n6iTqaU6nPqTLU8J_5hB5X7MOJSBVxdPC1TKQQ'};\n",
      "\n",
      "jobmap[4]= {jk:'8f5ef42de1f8aa48',efccid: '80fcaaf2c7cdb3d8',srcid:'3556a109037b5959',cmpid:'e127f4594cdf24f4',num:'4',srcname:'Credit Suisse',cmp:'Credit Suisse',cmpesc:'Credit Suisse',cmplnk:'/q-Credit-Suisse-l-New-York-jobs.html',loc:'New York, NY 10022',country:'US',zip:'',city:'New York',title:'AVP - Machine Learning &amp; Advance Analytics',locid:'45f6c4ded55c00bf',rd:'ziq64uvQavf9TYJ9mmOQmaZM22n6iTqaU6nPqTLU8J8KwV79vAlYf1WVRfndRjZP'};\n",
      "\n",
      "jobmap[5]= {jk:'c43b6d66f2b6426b',efccid: '2dfde961b89073b1',srcid:'c492a1aa5674275a',cmpid:'feb484a8aef310be',num:'5',srcname:'GroupM',cmp:'GroupM',cmpesc:'GroupM',cmplnk:'/q-GroupM-l-New-York-jobs.html',loc:'New York, NY',country:'US',zip:'',city:'New York',title:'Gain Theory \\u2013 Data Scientist\\/Statistical Modeler',locid:'45f6c4ded55c00bf',rd:'c7OXduHgNZCrcieHB33zE6ZM22n6iTqaU6nPqTLU8J8KwV79vAlYf1WVRfndRjZP'};\n",
      "\n",
      "jobmap[6]= {jk:'c93c1fc625849021',efccid: 'b9f6ecb2b3e5bd9b',srcid:'c32cbe5199ffa53d',cmpid:'f50f3d8ac53574f7',num:'6',srcname:'Indeed',cmp:'Amazon Web Services',cmpesc:'Amazon Web Services',cmplnk:'/q-Amazon-Web-Services-l-New-York-jobs.html',loc:'New York, NY',country:'US',zip:'',city:'New York',title:'Machine Learning Artificial Intelligence',locid:'45f6c4ded55c00bf',rd:'npA8CxsEMio2NHell9VhE3ujl6864H9IMjQoO3UOHZM'};\n",
      "\n",
      "jobmap[7]= {jk:'d862f9d88d33e634',efccid: '5b6336aa2e5a3ce3',srcid:'7026bea7ec8b75ad',cmpid:'ea25315ee9da22e5',num:'7',srcname:'Comcast',cmp:'Comcast',cmpesc:'Comcast',cmplnk:'/q-Comcast-l-New-York-jobs.html',loc:'New York, NY 10112',country:'US',zip:'10112',city:'New York',title:'Data Scientist II',locid:'45f6c4ded55c00bf',rd:'-OOCGezWKwMDhSp6FmR8faZM22n6iTqaU6nPqTLU8J9Y-AeFmrYmLfZlommaQjts'};\n",
      "\n",
      "jobmap[8]= {jk:'818c820ec89a73e5',efccid: '28783576b41f8803',srcid:'81781007164582ca',cmpid:'4abc9395281256b9',num:'8',srcname:'Indeed',cmp:'Radiator Labs',cmpesc:'Radiator Labs',cmplnk:'/q-Radiator-Labs-l-New-York-jobs.html',loc:'Brooklyn, NY',country:'US',zip:'',city:'Brooklyn',title:'Postdoctoral Position, Data Science\\/IoT',locid:'e69692d64317994a',rd:'UA-NO8pWDwSnYxlZLTQWV3ujl6864H9IMjQoO3UOHZM'};\n",
      "\n",
      "jobmap[9]= {jk:'b5772f35061f7eee',efccid: '9622c077f83da8d3',srcid:'a514ea2a244463eb',cmpid:'cf79f96fb3ec99fe',num:'9',srcname:'Slice',cmp:'Slice',cmpesc:'Slice',cmplnk:'/q-Slice-l-New-York-jobs.html',loc:'New York, NY',country:'US',zip:'',city:'New York',title:'Marketing Data Scientist',locid:'45f6c4ded55c00bf',rd:'GsevTgE0ARTrDQSV3z5vcnujl6864H9IMjQoO3UOHZM'};\n",
      "   </script>\n",
      "   <style type=\"text/css\">\n",
      "    .jobtitle {\n",
      "font-weight: bold;\n",
      "}\n",
      "td.snip b, span.company b, #femp_list .jobtitle, #cmpinfo_list .jobtitle, .jobtitle .new {\n",
      "font-weight: normal;\n",
      "}\n",
      "div.result-link-bar b {\n",
      "font-weight: bold;\n",
      "}\n",
      "   </style>\n",
      "   <style type=\"text/css\">\n",
      "    div.row table tr td.snip { line-height: 1.4; }\n",
      "   </style>\n",
      "   <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" id=\"resultsBody\" role=\"main\">\n",
      "    <tr>\n",
      "     <td>\n",
      "      <script type=\"text/javascript\">\n",
      "       window['ree'] = \"pdsssps\";\n",
      "window['jas'] = \"B2vGPQO\";\n",
      "      </script>\n",
      "      <style type=\"text/css\">\n",
      "       .basePromo{margin-top:8px;margin-bottom:13px;padding-left:12px;padding-right:12px}.redText{color:red}.bold{font-weight:bold}.basePromo.resume{font-size:14px;margin-top:5px}.basePromo.resume>img{height:20px;margin-right:5px;margin-bottom:3px;width:16px}\n",
      "      </style>\n",
      "      <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" id=\"pageContent\" width=\"100%\">\n",
      "       <tr valign=\"top\">\n",
      "        <td data-tn-section=\"refineBy\" id=\"refineresultscol\">\n",
      "         <div id=\"refineresults\">\n",
      "          <h1>\n",
      "           <font size=\"+1\">\n",
      "            data scientist $20,000 jobs in New York State\n",
      "           </font>\n",
      "          </h1>\n",
      "          <div id=\"recPromoDisplay\" style=\"display:none;\">\n",
      "          </div>\n",
      "          <script type=\"text/javascript\">\n",
      "           call_when_jsall_loaded(function() {\n",
      "            var recJobLink = new RecJobLink(\"Recommended Jobs\", \"recPromoDisplay\", \"1bll9fe0p0m9b3hl\", \"\",\n",
      "                    \"US\", \"en\", \"\",\n",
      "                    \"\", null, true);\n",
      "            recJobLink.onLoad();\n",
      "        });\n",
      "          </script>\n",
      "          <span aria-level=\"2\" role=\"heading\" style=\"height: 0; overflow: hidden; position: absolute;\">\n",
      "           Filter results by:\n",
      "          </span>\n",
      "          <div style=\"margin-left: 6px; margin-bottom: 1em;\">\n",
      "           SortÂ by:\n",
      "           <span class=\"no-wrap\">\n",
      "            <b>\n",
      "             relevance\n",
      "            </b>\n",
      "            -\n",
      "            <a href=\"/jobs?q=data+scientist+%2420%2C000&amp;l=New+York&amp;sort=date\" rel=\"nofollow\">\n",
      "             date\n",
      "            </a>\n",
      "           </span>\n",
      "          </div>\n",
      "          <div id=\"activefilters\">\n",
      "           <span>\n",
      "            You refined by:\n",
      "           </span>\n",
      "           <span class=\"item\">\n",
      "            <b>\n",
      "             $20,000+\n",
      "            </b>\n",
      "            (\n",
      "            <a class=\"undo\" href=\"/q-data-scientist-l-New-York-jobs.html\" onmousedown=\"rbptk('rbundo', 'salest');\" rel=\"nofollow\">\n",
      "             undo\n",
      "            </a>\n",
      "            )\n",
      "            <span class=\"se_prompt\">\n",
      "             <a class=\"se_label\" href=\"http://support.indeed.com/hc/en-us/articles/204489020-What-is-a-Salary-Estimate-\" onclick=\"showInPopup( '/jsp/about_salary_estimate.jsp' ); return false;\">\n",
      "              Salaries estimated if unavailable\n",
      "             </a>\n",
      "            </span>\n",
      "           </span>\n",
      "          </div>\n",
      "          <div class=\"rbSection rbOpen\" id=\"rb_Job Type\">\n",
      "           <div class=\"rbHeader\">\n",
      "            <span aria-level=\"3\" class=\"ws_bold\" role=\"heading\">\n",
      "             Job Type\n",
      "            </span>\n",
      "           </div>\n",
      "           <div class=\"rbsrbo\" id=\"JOB_TYPE_rbo\">\n",
      "            <ul class=\"rbList\">\n",
      "             <li onmousedown=\"rbptk('rb', 'jobtype', '1');\">\n",
      "              <a href=\"/jobs?q=data+scientist+$20,000&amp;l=New+York&amp;jt=fulltime\" rel=\"nofollow\" title=\"Full-time (2528)\">\n",
      "               Full-time\n",
      "              </a>\n",
      "              (2528)\n",
      "             </li>\n",
      "             <li onmousedown=\"rbptk('rb', 'jobtype', '2');\">\n",
      "              <a href=\"/jobs?q=data+scientist+$20,000&amp;l=New+York&amp;jt=contract\" rel=\"nofollow\" title=\"Contract (109)\">\n",
      "               Contract\n",
      "              </a>\n",
      "              (109)\n",
      "             </li>\n",
      "             <li onmousedown=\"rbptk('rb', 'jobtype', '3');\">\n",
      "              <a href=\"/jobs?q=data+scientist+$20,000&amp;l=New+York&amp;jt=temporary\" rel=\"nofollow\" title=\"Temporary (84)\">\n",
      "               Temporary\n",
      "              </a>\n",
      "              (84)\n",
      "             </li>\n",
      "             <li onmousedown=\"rbptk('rb', 'jobtype', '4');\">\n",
      "              <a href=\"/jobs?q=data+scientist+$20,000&amp;l=New+York&amp;jt=parttime\" rel=\"nofollow\" title=\"Part-time (70)\">\n",
      "               Part-time\n",
      "              </a>\n",
      "              (70)\n",
      "             </li>\n",
      "             <li onmousedown=\"rbptk('rb', 'jobtype', '5');\">\n",
      "              <a href=\"/jobs?q=data+scientist+$20,000&amp;l=New+York&amp;jt=internship\" rel=\"nofollow\" title=\"Internship (22)\">\n",
      "               Internship\n",
      "              </a>\n",
      "              (22)\n",
      "             </li>\n",
      "             <li onmousedown=\"rbptk('rb', 'jobtype', '6');\">\n",
      "              <a href=\"/jobs?q=data+scientist+$20,000&amp;l=New+York&amp;jt=commission\" rel=\"nofollow\" title=\"Commission (2)\">\n",
      "               Commission\n",
      "              </a>\n",
      "              (2)\n",
      "             </li>\n",
      "            </ul>\n",
      "           </div>\n",
      "          </div>\n",
      "          <div class=\"rbSection rbOpen\" id=\"rb_Location\">\n",
      "           <div class=\"rbHeader\">\n",
      "            <span aria-level=\"3\" class=\"ws_bold\" role=\"heading\">\n",
      "             Location\n",
      "            </span>\n",
      "           </div>\n",
      "           <div class=\"rbsrbo\" id=\"LOCATION_rbo\">\n",
      "            <ul class=\"rbList\">\n",
      "             <li onmousedown=\"rbptk('rb', 'loc', '1');\">\n",
      "              <a href=\"/jobs?q=data+scientist+$20,000&amp;l=New+York&amp;rbl=New+York,+NY&amp;jlid=45f6c4ded55c00bf\" rel=\"nofollow\" title=\"New York, NY (2173)\">\n",
      "               New York, NY\n",
      "              </a>\n",
      "              (2173)\n",
      "             </li>\n",
      "             <li onmousedown=\"rbptk('rb', 'loc', '2');\">\n",
      "              <a href=\"/jobs?q=data+scientist+$20,000&amp;l=New+York&amp;rbl=Brooklyn,+NY&amp;jlid=e69692d64317994a\" rel=\"nofollow\" title=\"Brooklyn, NY (57)\">\n",
      "               Brooklyn, NY\n",
      "              </a>\n",
      "              (57)\n",
      "             </li>\n",
      "             <li onmousedown=\"rbptk('rb', 'loc', '3');\">\n",
      "              <a href=\"/jobs?q=data+scientist+$20,000&amp;l=New+York&amp;rbl=Queens,+NY&amp;jlid=a036f550dfd81ea4\" rel=\"nofollow\" title=\"Queens, NY (50)\">\n",
      "               Queens, NY\n",
      "              </a>\n",
      "              (50)\n",
      "             </li>\n",
      "             <li onmousedown=\"rbptk('rb', 'loc', '4');\">\n",
      "              <a href=\"/jobs?q=data+scientist+$20,000&amp;l=New+York&amp;rbl=Manhattan,+NY&amp;jlid=ea5405905f293f14\" rel=\"nofollow\" title=\"Manhattan, NY (41)\">\n",
      "               Manhattan, NY\n",
      "              </a>\n",
      "              (41)\n",
      "             </li>\n",
      "             <li onmousedown=\"rbptk('rb', 'loc', '5');\">\n",
      "              <a href=\"/jobs?q=data+scientist+$20,000&amp;l=New+York&amp;rbl=Bronx,+NY&amp;jlid=609f72bcaf2fb185\" rel=\"nofollow\" title=\"Bronx, NY (38)\">\n",
      "               Bronx, NY\n",
      "              </a>\n",
      "              (38)\n",
      "             </li>\n",
      "             <li class=\"moreLi\" onmousedown=\"rbptk('rb', 'loc', '6');\">\n",
      "              <a href=\"/jobs?q=data+scientist+$20,000&amp;l=New+York&amp;rbl=Pearl+River,+NY&amp;jlid=c8ad3d6cdd6166bc\" rel=\"nofollow\" title=\"Pearl River, NY (26)\">\n",
      "               Pearl River, NY\n",
      "              </a>\n",
      "              (26)\n",
      "             </li>\n",
      "             <li class=\"moreLi\" onmousedown=\"rbptk('rb', 'loc', '7');\">\n",
      "              <a href=\"/jobs?q=data+scientist+$20,000&amp;l=New+York&amp;rbl=Huntington,+NY&amp;jlid=1495dc6bb28a707a\" rel=\"nofollow\" title=\"Huntington, NY (25)\">\n",
      "               Huntington, NY\n",
      "              </a>\n",
      "              (25)\n",
      "             </li>\n",
      "             <li class=\"moreLi\" onmousedown=\"rbptk('rb', 'loc', '8');\">\n",
      "              <a href=\"/jobs?q=data+scientist+$20,000&amp;l=New+York&amp;rbl=Upton,+NY&amp;jlid=926a9ce02f5610a2\" rel=\"nofollow\" title=\"Upton, NY (24)\">\n",
      "               Upton, NY\n",
      "              </a>\n",
      "              (24)\n",
      "             </li>\n",
      "             <li class=\"moreLi\" onmousedown=\"rbptk('rb', 'loc', '9');\">\n",
      "              <a href=\"/jobs?q=data+scientist+$20,000&amp;l=New+York&amp;rbl=Albany,+NY&amp;jlid=aa8fc4f0507fa94e\" rel=\"nofollow\" title=\"Albany, NY (22)\">\n",
      "               Albany, NY\n",
      "              </a>\n",
      "              (22)\n",
      "             </li>\n",
      "             <li class=\"moreLi\" onmousedown=\"rbptk('rb', 'loc', '10');\">\n",
      "              <a href=\"/jobs?q=data+scientist+$20,000&amp;l=New+York&amp;rbl=New+York+State&amp;jlid=9b6391d9b7d93788\" rel=\"nofollow\" title=\"New York State (19)\">\n",
      "               New York State\n",
      "              </a>\n",
      "              (19)\n",
      "             </li>\n",
      "             <li class=\"moreLi\" onmousedown=\"rbptk('rb', 'loc', '11');\">\n",
      "              <a href=\"/jobs?q=data+scientist+$20,000&amp;l=New+York&amp;rbl=Buffalo,+NY&amp;jlid=1cae56636b867d19\" rel=\"nofollow\" title=\"Buffalo, NY (17)\">\n",
      "               Buffalo, NY\n",
      "              </a>\n",
      "              (17)\n",
      "             </li>\n",
      "             <li class=\"moreLi\" onmousedown=\"rbptk('rb', 'loc', '12');\">\n",
      "              <a href=\"/jobs?q=data+scientist+$20,000&amp;l=New+York&amp;rbl=Syracuse,+NY&amp;jlid=bba15db4d8763697\" rel=\"nofollow\" title=\"Syracuse, NY (15)\">\n",
      "               Syracuse, NY\n",
      "              </a>\n",
      "              (15)\n",
      "             </li>\n",
      "             <li class=\"moreLi\" onmousedown=\"rbptk('rb', 'loc', '13');\">\n",
      "              <a href=\"/jobs?q=data+scientist+$20,000&amp;l=New+York&amp;rbl=Rochester,+NY&amp;jlid=e8a03471e5809517\" rel=\"nofollow\" title=\"Rochester, NY (14)\">\n",
      "               Rochester, NY\n",
      "              </a>\n",
      "              (14)\n",
      "             </li>\n",
      "             <li class=\"moreLi\" onmousedown=\"rbptk('rb', 'loc', '14');\">\n",
      "              <a href=\"/jobs?q=data+scientist+$20,000&amp;l=New+York&amp;rbl=Corning,+NY&amp;jlid=b1f06b0a33656a57\" rel=\"nofollow\" title=\"Corning, NY (13)\">\n",
      "               Corning, NY\n",
      "              </a>\n",
      "              (13)\n",
      "             </li>\n",
      "             <li class=\"moreLi\" onmousedown=\"rbptk('rb', 'loc', '15');\">\n",
      "              <a href=\"/jobs?q=data+scientist+$20,000&amp;l=New+York&amp;rbl=Manhasset,+NY&amp;jlid=71daa0d0b90308b6\" rel=\"nofollow\" title=\"Manhasset, NY (12)\">\n",
      "               Manhasset, NY\n",
      "              </a>\n",
      "              (12)\n",
      "             </li>\n",
      "             <li class=\"moreLi\" onmousedown=\"rbptk('rb', 'loc', '16');\">\n",
      "              <a href=\"/q-Data-Scientist-$20,000-jobs.html\">\n",
      "               Data Scientist $20,000 jobs\n",
      "              </a>\n",
      "              nationwide\n",
      "             </li>\n",
      "            </ul>\n",
      "            <div class=\"more_link\">\n",
      "             <span onclick=\"showAllRefinements('rb_Location'); return false;\" onkeyup=\"if (event.keyCode == 13) showAllRefinements('rb_Location'); return false;\" tabindex=\"0\">\n",
      "              more Â»\n",
      "             </span>\n",
      "            </div>\n",
      "           </div>\n",
      "          </div>\n",
      "          <div class=\"rbSection rbOpen\" id=\"rb_Company\">\n",
      "           <div class=\"rbHeader\">\n",
      "            <span aria-level=\"3\" class=\"ws_bold\" role=\"heading\">\n",
      "             Company\n",
      "            </span>\n",
      "           </div>\n",
      "           <div class=\"rbsrbo\" id=\"COMPANY_rbo\">\n",
      "            <ul class=\"rbList\">\n",
      "             <li onmousedown=\"rbptk('rb', 'cmp', '1');\">\n",
      "              <a href=\"/jobs?q=data+scientist+$20,000&amp;l=New+York&amp;rbc=NYU+Langone+Health&amp;jcid=00a4dc973a1d04f5\" rel=\"nofollow\" title=\"NYU Langone Health (444)\">\n",
      "               NYU Langone Health\n",
      "              </a>\n",
      "              (444)\n",
      "             </li>\n",
      "             <li onmousedown=\"rbptk('rb', 'cmp', '2');\">\n",
      "              <a href=\"/jobs?q=data+scientist+$20,000&amp;l=New+York&amp;rbc=NYU+School+of+Medicine&amp;jcid=fb8afb99610b0769\" rel=\"nofollow\" title=\"NYU School of Medicine (156)\">\n",
      "               NYU School of Medicine\n",
      "              </a>\n",
      "              (156)\n",
      "             </li>\n",
      "             <li onmousedown=\"rbptk('rb', 'cmp', '3');\">\n",
      "              <a href=\"/jobs?q=data+scientist+$20,000&amp;l=New+York&amp;rbc=Mount+Sinai+Health+System&amp;jcid=c007936ceb766fe5\" rel=\"nofollow\" title=\"Mount Sinai Health System (152)\">\n",
      "               Mount Sinai Health System\n",
      "              </a>\n",
      "              (152)\n",
      "             </li>\n",
      "             <li onmousedown=\"rbptk('rb', 'cmp', '4');\">\n",
      "              <a href=\"/jobs?q=data+scientist+$20,000&amp;l=New+York&amp;rbc=NYU+Langone+Hospitals&amp;jcid=3e2918d2d141ae37\" rel=\"nofollow\" title=\"NYU Langone Hospitals (116)\">\n",
      "               NYU Langone Hospitals\n",
      "              </a>\n",
      "              (116)\n",
      "             </li>\n",
      "             <li onmousedown=\"rbptk('rb', 'cmp', '5');\">\n",
      "              <a href=\"/jobs?q=data+scientist+$20,000&amp;l=New+York&amp;rbc=DEPT+OF+HEALTH%2FMENTAL+HYGIENE&amp;jcid=2a757335b4200fbc\" rel=\"nofollow\" title=\"DEPT OF HEALTH/MENTAL HYGIENE (66)\">\n",
      "               DEPT OF HEALTH/MENTAL HYGIENE\n",
      "              </a>\n",
      "              (66)\n",
      "             </li>\n",
      "             <li class=\"moreLi\" onmousedown=\"rbptk('rb', 'cmp', '6');\">\n",
      "              <a href=\"/jobs?q=data+scientist+$20,000&amp;l=New+York&amp;rbc=Weill+Cornell+Medicine&amp;jcid=0f6657068ec189d0\" rel=\"nofollow\" title=\"Weill Cornell Medicine (55)\">\n",
      "               Weill Cornell Medicine\n",
      "              </a>\n",
      "              (55)\n",
      "             </li>\n",
      "             <li class=\"moreLi\" onmousedown=\"rbptk('rb', 'cmp', '7');\">\n",
      "              <a href=\"/jobs?q=data+scientist+$20,000&amp;l=New+York&amp;rbc=Ambulatory%2FOutpatient+NYU+School+of+Medicine&amp;jcid=4b8b92c33c447c01\" rel=\"nofollow\" title=\"Ambulatory/Outpatient NYU School of Medicine (53)\">\n",
      "               Ambulatory/Outpatient NYU School of Medicine\n",
      "              </a>\n",
      "              (53)\n",
      "             </li>\n",
      "             <li class=\"moreLi\" onmousedown=\"rbptk('rb', 'cmp', '8');\">\n",
      "              <a href=\"/jobs?q=data+scientist+$20,000&amp;l=New+York&amp;rbc=BuzzFeed&amp;jcid=aadc8cd1bc50c192\" rel=\"nofollow\" title=\"BuzzFeed (39)\">\n",
      "               BuzzFeed\n",
      "              </a>\n",
      "              (39)\n",
      "             </li>\n",
      "             <li class=\"moreLi\" onmousedown=\"rbptk('rb', 'cmp', '9');\">\n",
      "              <a href=\"/jobs?q=data+scientist+$20,000&amp;l=New+York&amp;rbc=JP+Morgan+Chase&amp;jcid=11ba90543b779766\" rel=\"nofollow\" title=\"JP Morgan Chase (39)\">\n",
      "               JP Morgan Chase\n",
      "              </a>\n",
      "              (39)\n",
      "             </li>\n",
      "             <li class=\"moreLi\" onmousedown=\"rbptk('rb', 'cmp', '10');\">\n",
      "              <a href=\"/jobs?q=data+scientist+$20,000&amp;l=New+York&amp;rbc=Albert+Einstein+College+of+Medicine&amp;jcid=65ce85f45facac9b\" rel=\"nofollow\" title=\"Albert Einstein College of Medicine (36)\">\n",
      "               Albert Einstein College of Medicine\n",
      "              </a>\n",
      "              (36)\n",
      "             </li>\n",
      "             <li class=\"moreLi\" onmousedown=\"rbptk('rb', 'cmp', '11');\">\n",
      "              <a href=\"/jobs?q=data+scientist+$20,000&amp;l=New+York&amp;rbc=Columbia+University&amp;jcid=bd976cc171c690e0\" rel=\"nofollow\" title=\"Columbia University (35)\">\n",
      "               Columbia University\n",
      "              </a>\n",
      "              (35)\n",
      "             </li>\n",
      "             <li class=\"moreLi\" onmousedown=\"rbptk('rb', 'cmp', '12');\">\n",
      "              <a href=\"/jobs?q=data+scientist+$20,000&amp;l=New+York&amp;rbc=Capital+One&amp;jcid=b85c5070c3d3d8c8\" rel=\"nofollow\" title=\"Capital One (31)\">\n",
      "               Capital One\n",
      "              </a>\n",
      "              (31)\n",
      "             </li>\n",
      "             <li class=\"moreLi\" onmousedown=\"rbptk('rb', 'cmp', '13');\">\n",
      "              <a href=\"/jobs?q=data+scientist+$20,000&amp;l=New+York&amp;rbc=Pfizer+Inc.&amp;jcid=5e118f74384e090a\" rel=\"nofollow\" title=\"Pfizer Inc. (26)\">\n",
      "               Pfizer Inc.\n",
      "              </a>\n",
      "              (26)\n",
      "             </li>\n",
      "             <li class=\"moreLi\" onmousedown=\"rbptk('rb', 'cmp', '14');\">\n",
      "              <a href=\"/jobs?q=data+scientist+$20,000&amp;l=New+York&amp;rbc=Ambulatory%2FOutpatient+NYU+Langone+Hospitals&amp;jcid=064cb6f780ca3f7d\" rel=\"nofollow\" title=\"Ambulatory/Outpatient NYU Langone Hospitals (26)\">\n",
      "               Ambulatory/Outpatient NYU Langone Hospitals\n",
      "              </a>\n",
      "              (26)\n",
      "             </li>\n",
      "             <li class=\"moreLi\" onmousedown=\"rbptk('rb', 'cmp', '15');\">\n",
      "              <a href=\"/jobs?q=data+scientist+$20,000&amp;l=New+York&amp;rbc=Brookhaven+National+Laboratory&amp;jcid=e3775e5ec8ee0d6e\" rel=\"nofollow\" title=\"Brookhaven National Laboratory (24)\">\n",
      "               Brookhaven National Laboratory\n",
      "              </a>\n",
      "              (24)\n",
      "             </li>\n",
      "            </ul>\n",
      "            <div class=\"more_link\">\n",
      "             <span onclick=\"showAllRefinements('rb_Company'); return false;\" onkeyup=\"if (event.keyCode == 13) showAllRefinements('rb_Company'); return false;\" tabindex=\"0\">\n",
      "              more Â»\n",
      "             </span>\n",
      "            </div>\n",
      "           </div>\n",
      "          </div>\n",
      "          <div class=\"rbSection rbOpen\" id=\"rb_Experience Level\">\n",
      "           <div class=\"rbHeader\">\n",
      "            <span aria-level=\"3\" class=\"ws_bold\" role=\"heading\">\n",
      "             Experience Level\n",
      "            </span>\n",
      "           </div>\n",
      "           <div class=\"rbsrbo\" id=\"EXP_LVL_rbo\">\n",
      "            <ul class=\"rbList\">\n",
      "             <li onmousedown=\"rbptk('rb', 'explvl', '1');\">\n",
      "              <a href=\"/jobs?q=data+scientist+$20,000&amp;l=New+York&amp;explvl=mid_level\" rel=\"nofollow\" title=\"Mid Level (1238)\">\n",
      "               Mid Level\n",
      "              </a>\n",
      "              (1238)\n",
      "             </li>\n",
      "             <li onmousedown=\"rbptk('rb', 'explvl', '2');\">\n",
      "              <a href=\"/jobs?q=data+scientist+$20,000&amp;l=New+York&amp;explvl=entry_level\" rel=\"nofollow\" title=\"Entry Level (861)\">\n",
      "               Entry Level\n",
      "              </a>\n",
      "              (861)\n",
      "             </li>\n",
      "             <li onmousedown=\"rbptk('rb', 'explvl', '3');\">\n",
      "              <a href=\"/jobs?q=data+scientist+$20,000&amp;l=New+York&amp;explvl=senior_level\" rel=\"nofollow\" title=\"Senior Level (222)\">\n",
      "               Senior Level\n",
      "              </a>\n",
      "              (222)\n",
      "             </li>\n",
      "            </ul>\n",
      "           </div>\n",
      "          </div>\n",
      "         </div>\n",
      "        </td>\n",
      "        <td id=\"resultsCol\">\n",
      "         <div class=\"messageContainer\">\n",
      "          <script type=\"text/javascript\">\n",
      "           function setJaPromoCookie() {\n",
      "var expires = new Date();\n",
      "expires.setTime(expires.getTime() + (5 * 365 * 24 * 60 * 60 * 1000));\n",
      "setCookie(\"showJaPromo\", \"1\", expires);\n",
      "}\n",
      "function setRefineByCookie(refineByTypes) {\n",
      "var expires = new Date();\n",
      "expires.setTime(expires.getTime() + (10 * 1000));\n",
      "for (var i = 0; i < refineByTypes.length; i++) {\n",
      "setCookie(refineByTypes[i], \"1\", expires);\n",
      "}\n",
      "}\n",
      "          </script>\n",
      "         </div>\n",
      "         <style type=\"text/css\">\n",
      "          #increased_radius_result {\n",
      "font-size: 16px;\n",
      "font-style: italic;\n",
      "}\n",
      "#original_radius_result{\n",
      "font-size: 13px;\n",
      "font-style: italic;\n",
      "color: #666666;\n",
      "}\n",
      "         </style>\n",
      "         <div class=\"resultsTop\">\n",
      "          <div id=\"searchCount\">\n",
      "           Jobs 11 to 20 of 2,735\n",
      "          </div>\n",
      "          <div data-tn-section=\"primePromo\" id=\"primePromo\">\n",
      "           <span class=\"new\">\n",
      "            New!\n",
      "           </span>\n",
      "           <a href=\"/promo/prime\" onclick=\"this.href = appendParamsOnce( this.href, '?from=serptop&amp;subfrom=primeprmtop&amp;trk.origin=jobsearch&amp;trk.variant=primeprmtop&amp;trk.tk=1bll9fe210m9b3ng&amp;vertical=TECH&amp;x_isid=serptop&amp;x_ikw=data+scientist+%2420%2C000&amp;x_sid=serptop&amp;x_kw=data+scientist+%2420%2C000')\">\n",
      "            Join Indeed Prime\n",
      "           </a>\n",
      "           - Get offers from great tech companies\n",
      "          </div>\n",
      "         </div>\n",
      "         <script type=\"text/javascript\">\n",
      "          window['sjl'] = \"ri80fX3wjQI\";\n",
      "         </script>\n",
      "         <style type=\"text/css\">\n",
      "          .ri80fX3wjQI { margin: 0 0 6px 0; padding: 0; _zoom:100%; border: 0; background-color: #fff; }\n",
      ".ri80fX3wjQI .jobtitle { white-space: nowrap; float:left; _float: none; }\n",
      ".ri80fX3wjQI .sdn { color: #CD29C0; }\n",
      ".pa7hYk1 .brdr { margin-top: 12px; }\n",
      ".eFbWmP8Mkeu .brdr { margin-bottom: 12px; }\n",
      "@media only screen and (min-height:780px) {\n",
      ".pa7hYk1 { margin-bottom: 9px; }\n",
      ".eFbWmP8Mkeu .brdr,\n",
      ".LMxFwkLjH,\n",
      ".pa7hYk1 .brdr { margin-bottom: 9px; margin-top: 9px; }\n",
      "}\n",
      "         </style>\n",
      "         <style type=\"text/css\">\n",
      "          .result-tab:empty {margin-top: 0;}\n",
      ".pa7hYk1 {\n",
      "margin-bottom: 0;\n",
      "}\n",
      "@media only screen and (min-height:780px) {\n",
      ".pa7hYk1 {\n",
      "margin-bottom: 0;\n",
      "}\n",
      "}\n",
      "         </style>\n",
      "         <div>\n",
      "         </div>\n",
      "         <a id=\"jobPostingsAnchor\" tabindex=\"-1\">\n",
      "         </a>\n",
      "         <div class=\"ri80fX3wjQI pa7hYk1\">\n",
      "          <div class=\"row result\" data-jk=\"6cf2326a94f93666\" id=\"pj_6cf2326a94f93666\">\n",
      "           <!-- Previously this variable was used to indicate job board jobs, we have replaced that with a more accurate source type check -->\n",
      "           <a class=\"jobtitle turnstileLink\" data-tn-element=\"jobTitle\" href=\"/pagead/clk?mo=r&amp;ad=-6NYlbfkN0DAgAc92q6iRaEfcJAuaSGKVeICOvW3P0dpzElS8ir45AVr2KnXyohmCH6uVD67Lw5S6JDi1LHjUjNkLzYXEIusOUGGznSKNvFRXzGPzc3N3_gmmTVugLq169su-9XMHewtHF6oxwvBgSSAFhDlgV2F0K4rgoC5ZNahM8N-d7lG_obtJzaPpnQViO9bN3m_3dTRtxLhMBc68tVp6JAkxuzSIZwtBoImzRfP7AoUZuW-BHEBHgjRRf5df7Ed_VSnByewfGpX-qc6vAtVwRXfelVGenehBWmAL5anibiWM318tGgxrlVY6BgyttZKqp0ZN9P-4R4BKoE9NRcB25zP_5wuO_H7ZE9qpqsL_JWcCkI94RQdJHKaHjzkWz320yPN0USPPgxARG5rq0KC0r8cHYko&amp;p=1&amp;sk=&amp;fvj=0\" id=\"sja1\" onclick=\"setRefineByCookie(['salest']); sjoc('sja1',0); convCtr('SJ', pingUrlsForGA)\" onmousedown=\"sjomd('sja1'); clk('sja1');\" rel=\"noopener nofollow\" target=\"_blank\" title=\"Data Scientist - Big Data &amp; Analytics\">\n",
      "            <b>\n",
      "             Data\n",
      "            </b>\n",
      "            <b>\n",
      "             Scientist\n",
      "            </b>\n",
      "            - Big\n",
      "            <b>\n",
      "             Data\n",
      "            </b>\n",
      "            &amp; Analytics\n",
      "           </a>\n",
      "           <br/>\n",
      "           <div class=\"sjcl\">\n",
      "            <span class=\"company\">\n",
      "             <a class=\"turnstileLink\" data-tn-element=\"companyName\" href=\"/cmp/Kpmg\" onmousedown=\"this.href = appendParamsOnce(this.href, 'from=SERP&amp;campaignid=serp-linkcompanyname&amp;fromjk=6cf2326a94f93666&amp;jcid=2dd390c3a48a7ed0')\" rel=\"noopener\" target=\"_blank\">\n",
      "              KPMG\n",
      "             </a>\n",
      "            </span>\n",
      "            -\n",
      "            <a class=\"ratingsLabel\" data-tn-element=\"reviewStars\" data-tn-variant=\"cmplinktst2\" href=\"/cmp/Kpmg/reviews\" onmousedown=\"this.href = appendParamsOnce(this.href, '?campaignid=cmplinktst2&amp;from=SERP&amp;jt=Data+Scientist+-+Big+Data+%26+Analytics&amp;fromjk=6cf2326a94f93666&amp;jcid=2dd390c3a48a7ed0');\" rel=\"noopener\" target=\"_blank\" title=\"Kpmg reviews\">\n",
      "             <span class=\"ratings\">\n",
      "              <span class=\"rating\" style=\"width:51.0px\">\n",
      "               <!-- -->\n",
      "              </span>\n",
      "             </span>\n",
      "             <span class=\"slNoUnderline\">\n",
      "              3,272 reviews\n",
      "             </span>\n",
      "            </a>\n",
      "            -\n",
      "            <span class=\"location\">\n",
      "             New York, NY 10154\n",
      "            </span>\n",
      "           </div>\n",
      "           <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n",
      "            <tr>\n",
      "             <td class=\"snip\">\n",
      "              <span class=\"summary\">\n",
      "               KPMG is currently seeking a\n",
      "               <b>\n",
      "                Data\n",
      "               </b>\n",
      "               <b>\n",
      "                Scientist\n",
      "               </b>\n",
      "               - Big\n",
      "               <b>\n",
      "                Data\n",
      "               </b>\n",
      "               &amp; Analytics, to join our Advanced\n",
      "               <b>\n",
      "                Data\n",
      "               </b>\n",
      "               &amp; Analytics Organization....\n",
      "              </span>\n",
      "             </td>\n",
      "            </tr>\n",
      "           </table>\n",
      "           <div class=\"sjCapt\">\n",
      "            <div class=\"result-link-bar-container\">\n",
      "             <div class=\"result-link-bar\">\n",
      "              <span class=\" sponsoredGray \">\n",
      "               Sponsored by\n",
      "               <b>\n",
      "                KPMG LLP\n",
      "               </b>\n",
      "              </span>\n",
      "              -\n",
      "              <span class=\"tt_set\" id=\"tt_set_10\">\n",
      "               <a class=\"sl resultLink save-job-link \" href=\"#\" id=\"sj_6cf2326a94f93666\" onclick=\"changeJobState('6cf2326a94f93666', 'save', 'linkbar', true); return false;\" title=\"Save this job to my.indeed\">\n",
      "                save job\n",
      "               </a>\n",
      "              </span>\n",
      "              <div class=\"edit_note_content\" id=\"editsaved2_6cf2326a94f93666\" style=\"display:none;\">\n",
      "              </div>\n",
      "              <script>\n",
      "               window['sj_result_6cf2326a94f93666'] = {\"showSource\": false, \"source\": \"KPMG LLP\", \"loggedIn\": false, \"showMyJobsLinks\": false,\"undoAction\": \"unsave\",\"jobKey\": \"6cf2326a94f93666\", \"myIndeedAvailable\": true, \"showMoreActionsLink\": false, \"resultNumber\": 10, \"jobStateChangedToSaved\": false, \"searchState\": \"q=data scientist $20,000&amp;l=New+York&amp;start=10\", \"basicPermaLink\": \"http://www.indeed.com\", \"saveJobFailed\": false, \"removeJobFailed\": false, \"requestPending\": false, \"notesEnabled\": false, \"currentPage\" : \"serp\", \"sponsored\" : true,\"showSponsor\" : true,\"sponsorName\" : \"KPMG LLP\",\"reportJobButtonEnabled\": false, \"showMyJobsHired\": false, \"showSaveForSponsored\": true, \"showJobAge\": true};\n",
      "              </script>\n",
      "             </div>\n",
      "            </div>\n",
      "            <div class=\"tab-container\">\n",
      "             <div class=\"sign-in-container result-tab\">\n",
      "             </div>\n",
      "             <div class=\"tellafriend-container result-tab email_job_content\">\n",
      "             </div>\n",
      "            </div>\n",
      "           </div>\n",
      "          </div>\n",
      "          <div class=\"row sjlast result\" data-jk=\"35b2886767297d33\" id=\"pj_35b2886767297d33\">\n",
      "           <!-- Previously this variable was used to indicate job board jobs, we have replaced that with a more accurate source type check -->\n",
      "           <a class=\"jobtitle turnstileLink\" data-tn-element=\"jobTitle\" href=\"/pagead/clk?mo=r&amp;ad=-6NYlbfkN0AX1ncGInrSzTnYoDfW2nBFvG36K9Iw1rOQj0E1I2spOVM3AlHsIlKH9OnjhV7NbWrriYiLEvW8wCjsUqxrlccl-o8KMrEe4kgHYa4zMIkxvsw5m5D5MrbGgQW2CZr3wI7U-QD1kNpQElZcdKVle8tkdA-Y15BagjSrteh-UuT_Q0X47bL8Y58TS287IXU2mec6FcXwIW3Gi7N0cbV94Q1IuHlwr_QaxYeJjt8wQNvMifilKFXSPjO2LczdhYwDIH4NR6-ZRg0sWXdKAzREMTBDuM35vSNsEUuh89sgpHxuZzopMBKnQEx6kZRHAz9ZQGCyA0UEu2EqSIBI6Bv0E5pJpRV5p6ENGW0umvELdYrjus857cLfch21q1pEhIjSN7xCGTwAthea55Kbf64j92PS7cA7YhLYSk8nQcFvI6GF4QGMIwTmNulNg1_QNVPZ0QfE1dpdVOHh_OM-SOuEOiOc_ZnbNVb1CaeBY2-u-V6RPA==&amp;p=2&amp;sk=&amp;fvj=0\" id=\"sja2\" onclick=\"setRefineByCookie(['salest']); sjoc('sja2',1); convCtr('SJ', pingUrlsForGA)\" onmousedown=\"sjomd('sja2'); clk('sja2');\" rel=\"noopener nofollow\" target=\"_blank\" title=\"Senior NLP Data Scientist\">\n",
      "            Senior NLP\n",
      "            <b>\n",
      "             Data\n",
      "            </b>\n",
      "            <b>\n",
      "             Scientist\n",
      "            </b>\n",
      "           </a>\n",
      "           <br/>\n",
      "           <div class=\"sjcl\">\n",
      "            <span class=\"company\">\n",
      "             Elevano\n",
      "            </span>\n",
      "            -\n",
      "            <span class=\"location\">\n",
      "             New York, NY\n",
      "            </span>\n",
      "            <div>\n",
      "             $140,000 - $190,000 a year\n",
      "            </div>\n",
      "           </div>\n",
      "           <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n",
      "            <tr>\n",
      "             <td class=\"snip\">\n",
      "              <span class=\"summary\">\n",
      "               Parsing of structured/unstructured\n",
      "               <b>\n",
      "                data\n",
      "               </b>\n",
      "               . Our client is looking for a Senior\n",
      "               <b>\n",
      "                Data\n",
      "               </b>\n",
      "               <b>\n",
      "                Scientist\n",
      "               </b>\n",
      "               with a strong background in NLP....\n",
      "              </span>\n",
      "             </td>\n",
      "            </tr>\n",
      "           </table>\n",
      "           <div class=\"sjCapt\">\n",
      "            <div class=\"iaP\">\n",
      "             <span class=\"iaLabel\">\n",
      "              Easily apply\n",
      "             </span>\n",
      "            </div>\n",
      "            <div class=\"result-link-bar-container\">\n",
      "             <div class=\"result-link-bar\">\n",
      "              <span class=\" sponsoredGray \">\n",
      "               Sponsored\n",
      "              </span>\n",
      "              -\n",
      "              <span class=\"tt_set\" id=\"tt_set_11\">\n",
      "               <a class=\"sl resultLink save-job-link \" href=\"#\" id=\"sj_35b2886767297d33\" onclick=\"changeJobState('35b2886767297d33', 'save', 'linkbar', true); return false;\" title=\"Save this job to my.indeed\">\n",
      "                save job\n",
      "               </a>\n",
      "              </span>\n",
      "              <div class=\"edit_note_content\" id=\"editsaved2_35b2886767297d33\" style=\"display:none;\">\n",
      "              </div>\n",
      "              <script>\n",
      "               window['sj_result_35b2886767297d33'] = {\"showSource\": false, \"source\": \"Elevano\", \"loggedIn\": false, \"showMyJobsLinks\": false,\"undoAction\": \"unsave\",\"jobKey\": \"35b2886767297d33\", \"myIndeedAvailable\": true, \"showMoreActionsLink\": false, \"resultNumber\": 11, \"jobStateChangedToSaved\": false, \"searchState\": \"q=data scientist $20,000&amp;l=New+York&amp;start=10\", \"basicPermaLink\": \"http://www.indeed.com\", \"saveJobFailed\": false, \"removeJobFailed\": false, \"requestPending\": false, \"notesEnabled\": false, \"currentPage\" : \"serp\", \"sponsored\" : true,\"showSponsor\" : true,\"reportJobButtonEnabled\": false, \"showMyJobsHired\": false, \"showSaveForSponsored\": true, \"showJobAge\": true};\n",
      "              </script>\n",
      "             </div>\n",
      "            </div>\n",
      "            <div class=\"tab-container\">\n",
      "             <div class=\"sign-in-container result-tab\">\n",
      "             </div>\n",
      "             <div class=\"tellafriend-container result-tab email_job_content\">\n",
      "             </div>\n",
      "            </div>\n",
      "           </div>\n",
      "          </div>\n",
      "         </div>\n",
      "         <div class=\" row result\" data-jk=\"5b1f58efbf2e7458\" data-tn-component=\"organicJob\" id=\"p_5b1f58efbf2e7458\" itemscope=\"\" itemtype=\"http://schema.org/JobPosting\">\n",
      "          <h2 class=\"jobtitle\" id=\"jl_5b1f58efbf2e7458\">\n",
      "           <a class=\"turnstileLink\" data-tn-element=\"jobTitle\" href=\"/rc/clk?jk=5b1f58efbf2e7458&amp;fccid=1dec991c3c01c67d\" itemprop=\"title\" onclick=\"setRefineByCookie(['salest']); return rclk(this,jobmap[0],true,0);\" onmousedown=\"return rclk(this,jobmap[0],0);\" rel=\"noopener nofollow\" target=\"_blank\" title=\"Data Scientist, Personalization and Recommendation\">\n",
      "            <b>\n",
      "             Data\n",
      "            </b>\n",
      "            <b>\n",
      "             Scientist\n",
      "            </b>\n",
      "            , Personalization and Recommendation\n",
      "           </a>\n",
      "          </h2>\n",
      "          <span class=\"company\" itemprop=\"hiringOrganization\" itemtype=\"http://schema.org/Organization\">\n",
      "           <span itemprop=\"name\">\n",
      "            <a href=\"/cmp/Tumblr\" onmousedown=\"this.href = appendParamsOnce(this.href, 'from=SERP&amp;campaignid=serp-linkcompanyname&amp;fromjk=5b1f58efbf2e7458&amp;jcid=1dec991c3c01c67d')\" rel=\"noopener\" target=\"_blank\">\n",
      "             Tumblr\n",
      "            </a>\n",
      "           </span>\n",
      "          </span>\n",
      "          -\n",
      "          <a class=\"ratingsLabel\" data-tn-element=\"reviewStars\" data-tn-variant=\"cmplinktst2\" href=\"/cmp/Tumblr/reviews\" onmousedown=\"this.href = appendParamsOnce(this.href, '?campaignid=cmplinktst2&amp;from=SERP&amp;jt=Data+Scientist%2C+Personalization+and+Recommendation&amp;fromjk=5b1f58efbf2e7458&amp;jcid=1dec991c3c01c67d');\" rel=\"noopener\" target=\"_blank\" title=\"Tumblr reviews\">\n",
      "           <span class=\"ratings\">\n",
      "            <span class=\"rating\" style=\"width:52.8px\">\n",
      "             <!-- -->\n",
      "            </span>\n",
      "           </span>\n",
      "           <span class=\"slNoUnderline\">\n",
      "            9 reviews\n",
      "           </span>\n",
      "          </a>\n",
      "          -\n",
      "          <span itemprop=\"jobLocation\" itemscope=\"\" itemtype=\"http://schema.org/Place\">\n",
      "           <span class=\"location\" itemprop=\"address\" itemscope=\"\" itemtype=\"http://schema.org/Postaladdress\">\n",
      "            <span itemprop=\"addressLocality\">\n",
      "             New York, NY\n",
      "            </span>\n",
      "           </span>\n",
      "          </span>\n",
      "          <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n",
      "           <tr>\n",
      "            <td class=\"snip\">\n",
      "             <div>\n",
      "              <span class=\"summary\" itemprop=\"description\">\n",
      "               <b>\n",
      "                Data\n",
      "               </b>\n",
      "               <b>\n",
      "                Scientist\n",
      "               </b>\n",
      "               , Personalization and Recommendation. We are seeking a veteran\n",
      "               <b>\n",
      "                Data\n",
      "               </b>\n",
      "               <b>\n",
      "                Scientist\n",
      "               </b>\n",
      "               , well-versed in\n",
      "               <b>\n",
      "                data\n",
      "               </b>\n",
      "               analysis and algorithm implementation, ready to...\n",
      "              </span>\n",
      "             </div>\n",
      "             <div class=\"iaP\">\n",
      "              <span class=\"iaLabel\">\n",
      "               Easily apply\n",
      "              </span>\n",
      "             </div>\n",
      "             <div class=\"result-link-bar-container\">\n",
      "              <div class=\"result-link-bar\">\n",
      "               <span class=\"date\">\n",
      "                27 days ago\n",
      "               </span>\n",
      "               <span class=\"tt_set\" id=\"tt_set_0\">\n",
      "                -\n",
      "                <a class=\"sl resultLink save-job-link \" href=\"#\" id=\"sj_5b1f58efbf2e7458\" onclick=\"changeJobState('5b1f58efbf2e7458', 'save', 'linkbar', false); return false;\" title=\"Save this job to my.indeed\">\n",
      "                 save job\n",
      "                </a>\n",
      "                -\n",
      "                <a class=\"sl resultLink more-link \" href=\"#\" id=\"tog_0\" onclick=\"toggleMoreLinks('5b1f58efbf2e7458'); return false;\">\n",
      "                 more...\n",
      "                </a>\n",
      "               </span>\n",
      "               <div class=\"edit_note_content\" id=\"editsaved2_5b1f58efbf2e7458\" style=\"display:none;\">\n",
      "               </div>\n",
      "               <script>\n",
      "                window['result_5b1f58efbf2e7458'] = {\"showSource\": false, \"source\": \"Tumblr\", \"loggedIn\": false, \"showMyJobsLinks\": false,\"undoAction\": \"unsave\",\"relativeJobAge\": \"27 days ago\",\"jobKey\": \"5b1f58efbf2e7458\", \"myIndeedAvailable\": true, \"showMoreActionsLink\": true, \"resultNumber\": 0, \"jobStateChangedToSaved\": false, \"searchState\": \"q=data scientist $20,000&amp;l=New+York&amp;start=10\", \"basicPermaLink\": \"http://www.indeed.com\", \"saveJobFailed\": false, \"removeJobFailed\": false, \"requestPending\": false, \"notesEnabled\": true, \"currentPage\" : \"serp\", \"sponsored\" : false,\"reportJobButtonEnabled\": false, \"showMyJobsHired\": false, \"showSaveForSponsored\": false, \"showJobAge\": true};\n",
      "               </script>\n",
      "              </div>\n",
      "             </div>\n",
      "             <div class=\"tab-container\">\n",
      "              <div class=\"more-links-container result-tab\" id=\"tt_display_0\" style=\"display:none;\">\n",
      "               <a class=\"close-link closeLink\" href=\"#\" onclick=\"toggleMoreLinks('5b1f58efbf2e7458'); return false;\" title=\"Close\">\n",
      "               </a>\n",
      "               <div class=\"more_actions\" id=\"more_0\">\n",
      "                <ul>\n",
      "                 <li>\n",
      "                  <span class=\"mat\">\n",
      "                   View all\n",
      "                   <a href=\"/q-Tumblr-l-New-York,-NY-jobs.html\" rel=\"nofollow\">\n",
      "                    Tumblr jobs in New York, NY\n",
      "                   </a>\n",
      "                   -\n",
      "                   <a href=\"/l-New-York,-NY-jobs.html\">\n",
      "                    New York jobs\n",
      "                   </a>\n",
      "                  </span>\n",
      "                 </li>\n",
      "                 <li>\n",
      "                  <span class=\"mat\">\n",
      "                   Salary Search:\n",
      "                   <a href=\"/salaries/Data-Scientist-Salaries,-New-York-NY\" onmousedown=\"this.href = appendParamsOnce(this.href, '?campaignid=serp-more&amp;fromjk=5b1f58efbf2e7458&amp;from=serp-more');\">\n",
      "                    Data Scientist salaries in New York, NY\n",
      "                   </a>\n",
      "                  </span>\n",
      "                 </li>\n",
      "                 <li>\n",
      "                  <span class=\"mat\">\n",
      "                   Learn more about working at\n",
      "                   <a href=\"/cmp/Tumblr\" onmousedown=\"this.href = appendParamsOnce(this.href, '?fromjk=5b1f58efbf2e7458&amp;from=serp-more&amp;campaignid=serp-more&amp;jcid=1dec991c3c01c67d');\">\n",
      "                    Tumblr\n",
      "                   </a>\n",
      "                  </span>\n",
      "                 </li>\n",
      "                 <li>\n",
      "                  <span class=\"mat\">\n",
      "                   Related forums:\n",
      "                   <a href=\"/forum/cmp/Tumblr.html\">\n",
      "                    Tumblr\n",
      "                   </a>\n",
      "                   -\n",
      "                   <a href=\"/forum/loc/New-York-New-York.html\">\n",
      "                    New York, New York\n",
      "                   </a>\n",
      "                  </span>\n",
      "                 </li>\n",
      "                </ul>\n",
      "               </div>\n",
      "              </div>\n",
      "              <div class=\"dya-container result-tab\">\n",
      "              </div>\n",
      "              <div class=\"tellafriend-container result-tab email_job_content\">\n",
      "              </div>\n",
      "              <div class=\"sign-in-container result-tab\">\n",
      "              </div>\n",
      "              <div class=\"notes-container result-tab\">\n",
      "              </div>\n",
      "             </div>\n",
      "            </td>\n",
      "           </tr>\n",
      "          </table>\n",
      "         </div>\n",
      "         <div class=\" row result\" data-jk=\"97293997165757e6\" data-tn-component=\"organicJob\" id=\"p_97293997165757e6\" itemscope=\"\" itemtype=\"http://schema.org/JobPosting\">\n",
      "          <h2 class=\"jobtitle\" id=\"jl_97293997165757e6\">\n",
      "           <a class=\"turnstileLink\" data-tn-element=\"jobTitle\" href=\"/rc/clk?jk=97293997165757e6&amp;fccid=4a9b8c61a3e17d38\" itemprop=\"title\" onclick=\"setRefineByCookie(['salest']); return rclk(this,jobmap[1],true,0);\" onmousedown=\"return rclk(this,jobmap[1],0);\" rel=\"noopener nofollow\" target=\"_blank\" title=\"Data Analyst\">\n",
      "            <b>\n",
      "             Data\n",
      "            </b>\n",
      "            Analyst\n",
      "           </a>\n",
      "          </h2>\n",
      "          <span class=\"company\" itemprop=\"hiringOrganization\" itemtype=\"http://schema.org/Organization\">\n",
      "           <span itemprop=\"name\">\n",
      "            Schireson Associates\n",
      "           </span>\n",
      "          </span>\n",
      "          -\n",
      "          <span itemprop=\"jobLocation\" itemscope=\"\" itemtype=\"http://schema.org/Place\">\n",
      "           <span class=\"location\" itemprop=\"address\" itemscope=\"\" itemtype=\"http://schema.org/Postaladdress\">\n",
      "            <span itemprop=\"addressLocality\">\n",
      "             New York, NY 10018\n",
      "             <span style=\"font-size: smaller\">\n",
      "              (Clinton area)\n",
      "             </span>\n",
      "            </span>\n",
      "           </span>\n",
      "          </span>\n",
      "          <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n",
      "           <tr>\n",
      "            <td class=\"snip\">\n",
      "             <div>\n",
      "              <span class=\"summary\" itemprop=\"description\">\n",
      "               We are looking for an analytically-oriented\n",
      "               <b>\n",
      "                data\n",
      "               </b>\n",
      "               analyst to join our growing team and assist our\n",
      "               <b>\n",
      "                data\n",
      "               </b>\n",
      "               <b>\n",
      "                scientists\n",
      "               </b>\n",
      "               in the creation of cutting edge analyses and...\n",
      "              </span>\n",
      "             </div>\n",
      "             <div class=\"iaP\">\n",
      "              <span class=\"iaLabel\">\n",
      "               Easily apply\n",
      "              </span>\n",
      "             </div>\n",
      "             <div class=\"result-link-bar-container\">\n",
      "              <div class=\"result-link-bar\">\n",
      "               <span class=\"date\">\n",
      "                10 days ago\n",
      "               </span>\n",
      "               <span class=\"tt_set\" id=\"tt_set_1\">\n",
      "                -\n",
      "                <a class=\"sl resultLink save-job-link \" href=\"#\" id=\"sj_97293997165757e6\" onclick=\"changeJobState('97293997165757e6', 'save', 'linkbar', false); return false;\" title=\"Save this job to my.indeed\">\n",
      "                 save job\n",
      "                </a>\n",
      "                -\n",
      "                <a class=\"sl resultLink more-link \" href=\"#\" id=\"tog_1\" onclick=\"toggleMoreLinks('97293997165757e6'); return false;\">\n",
      "                 more...\n",
      "                </a>\n",
      "               </span>\n",
      "               <div class=\"edit_note_content\" id=\"editsaved2_97293997165757e6\" style=\"display:none;\">\n",
      "               </div>\n",
      "               <script>\n",
      "                window['result_97293997165757e6'] = {\"showSource\": false, \"source\": \"Schireson Associates\", \"loggedIn\": false, \"showMyJobsLinks\": false,\"undoAction\": \"unsave\",\"relativeJobAge\": \"10 days ago\",\"jobKey\": \"97293997165757e6\", \"myIndeedAvailable\": true, \"showMoreActionsLink\": true, \"resultNumber\": 1, \"jobStateChangedToSaved\": false, \"searchState\": \"q=data scientist $20,000&amp;l=New+York&amp;start=10\", \"basicPermaLink\": \"http://www.indeed.com\", \"saveJobFailed\": false, \"removeJobFailed\": false, \"requestPending\": false, \"notesEnabled\": true, \"currentPage\" : \"serp\", \"sponsored\" : false,\"reportJobButtonEnabled\": false, \"showMyJobsHired\": false, \"showSaveForSponsored\": false, \"showJobAge\": true};\n",
      "               </script>\n",
      "              </div>\n",
      "             </div>\n",
      "             <div class=\"tab-container\">\n",
      "              <div class=\"more-links-container result-tab\" id=\"tt_display_1\" style=\"display:none;\">\n",
      "               <a class=\"close-link closeLink\" href=\"#\" onclick=\"toggleMoreLinks('97293997165757e6'); return false;\" title=\"Close\">\n",
      "               </a>\n",
      "               <div class=\"more_actions\" id=\"more_1\">\n",
      "                <ul>\n",
      "                 <li>\n",
      "                  <span class=\"mat\">\n",
      "                   View all\n",
      "                   <a href=\"/q-Schireson-Associates-l-New-York,-NY-jobs.html\" rel=\"nofollow\">\n",
      "                    Schireson Associates jobs in New York, NY\n",
      "                   </a>\n",
      "                   -\n",
      "                   <a href=\"/l-New-York,-NY-jobs.html\">\n",
      "                    New York jobs\n",
      "                   </a>\n",
      "                  </span>\n",
      "                 </li>\n",
      "                 <li>\n",
      "                  <span class=\"mat\">\n",
      "                   Salary Search:\n",
      "                   <a href=\"/salaries/Data-Analyst-Salaries,-New-York-NY\" onmousedown=\"this.href = appendParamsOnce(this.href, '?campaignid=serp-more&amp;fromjk=97293997165757e6&amp;from=serp-more');\">\n",
      "                    Data Analyst salaries in New York, NY\n",
      "                   </a>\n",
      "                  </span>\n",
      "                 </li>\n",
      "                 <li>\n",
      "                  <span class=\"mat\">\n",
      "                   Related forums:\n",
      "                   <a href=\"/forum/cmp/Schireson-Associates.html\">\n",
      "                    Schireson Associates\n",
      "                   </a>\n",
      "                   -\n",
      "                   <a href=\"/forum/job/Data-Analyst.html\">\n",
      "                    Data Analyst\n",
      "                   </a>\n",
      "                   -\n",
      "                   <a href=\"/forum/loc/New-York-New-York.html\">\n",
      "                    New York, New York\n",
      "                   </a>\n",
      "                  </span>\n",
      "                 </li>\n",
      "                </ul>\n",
      "               </div>\n",
      "              </div>\n",
      "              <div class=\"dya-container result-tab\">\n",
      "              </div>\n",
      "              <div class=\"tellafriend-container result-tab email_job_content\">\n",
      "              </div>\n",
      "              <div class=\"sign-in-container result-tab\">\n",
      "              </div>\n",
      "              <div class=\"notes-container result-tab\">\n",
      "              </div>\n",
      "             </div>\n",
      "            </td>\n",
      "           </tr>\n",
      "          </table>\n",
      "         </div>\n",
      "         <div class=\" row result\" data-jk=\"81e50490c3e0204a\" data-tn-component=\"organicJob\" id=\"p_81e50490c3e0204a\" itemscope=\"\" itemtype=\"http://schema.org/JobPosting\">\n",
      "          <h2 class=\"jobtitle\" id=\"jl_81e50490c3e0204a\">\n",
      "           <a class=\"turnstileLink\" data-tn-element=\"jobTitle\" href=\"/rc/clk?jk=81e50490c3e0204a&amp;fccid=d9a36a1771c05d30\" itemprop=\"title\" onclick=\"setRefineByCookie(['salest']); return rclk(this,jobmap[2],true,1);\" onmousedown=\"return rclk(this,jobmap[2],1);\" rel=\"noopener nofollow\" target=\"_blank\" title=\"Data Scientist\">\n",
      "            <b>\n",
      "             Data\n",
      "            </b>\n",
      "            <b>\n",
      "             Scientist\n",
      "            </b>\n",
      "           </a>\n",
      "          </h2>\n",
      "          <span class=\"company\" itemprop=\"hiringOrganization\" itemtype=\"http://schema.org/Organization\">\n",
      "           <span itemprop=\"name\">\n",
      "            Enterprise Select\n",
      "           </span>\n",
      "          </span>\n",
      "          -\n",
      "          <span itemprop=\"jobLocation\" itemscope=\"\" itemtype=\"http://schema.org/Place\">\n",
      "           <span class=\"location\" itemprop=\"address\" itemscope=\"\" itemtype=\"http://schema.org/Postaladdress\">\n",
      "            <span itemprop=\"addressLocality\">\n",
      "             New York, NY 10005\n",
      "             <span style=\"font-size: smaller\">\n",
      "              (Financial District area)\n",
      "             </span>\n",
      "            </span>\n",
      "           </span>\n",
      "          </span>\n",
      "          <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n",
      "           <tr>\n",
      "            <td class=\"snip\">\n",
      "             <span class=\"no-wrap\">\n",
      "              $185,000 a year\n",
      "             </span>\n",
      "             <div>\n",
      "              <span class=\"summary\" itemprop=\"description\">\n",
      "               Financial Services\n",
      "               <b>\n",
      "                data\n",
      "               </b>\n",
      "               such as transactions, payments, customer\n",
      "               <b>\n",
      "                data\n",
      "               </b>\n",
      "               etc. 3yrs+ experience in a\n",
      "               <b>\n",
      "                data\n",
      "               </b>\n",
      "               <b>\n",
      "                scientist\n",
      "               </b>\n",
      "               role - working in the field....\n",
      "              </span>\n",
      "             </div>\n",
      "             <div class=\"iaP\">\n",
      "              <span class=\"iaLabel\">\n",
      "               Easily apply\n",
      "              </span>\n",
      "             </div>\n",
      "             <div class=\"result-link-bar-container\">\n",
      "              <div class=\"result-link-bar\">\n",
      "               <span class=\"date\">\n",
      "                30+ days ago\n",
      "               </span>\n",
      "               <span class=\"tt_set\" id=\"tt_set_2\">\n",
      "                -\n",
      "                <a class=\"sl resultLink save-job-link \" href=\"#\" id=\"sj_81e50490c3e0204a\" onclick=\"changeJobState('81e50490c3e0204a', 'save', 'linkbar', false); return false;\" title=\"Save this job to my.indeed\">\n",
      "                 save job\n",
      "                </a>\n",
      "                -\n",
      "                <a class=\"sl resultLink more-link \" href=\"#\" id=\"tog_2\" onclick=\"toggleMoreLinks('81e50490c3e0204a'); return false;\">\n",
      "                 more...\n",
      "                </a>\n",
      "               </span>\n",
      "               <div class=\"edit_note_content\" id=\"editsaved2_81e50490c3e0204a\" style=\"display:none;\">\n",
      "               </div>\n",
      "               <script>\n",
      "                window['result_81e50490c3e0204a'] = {\"showSource\": false, \"source\": \"Enterprise Select\", \"loggedIn\": false, \"showMyJobsLinks\": false,\"undoAction\": \"unsave\",\"relativeJobAge\": \"30+ days ago\",\"jobKey\": \"81e50490c3e0204a\", \"myIndeedAvailable\": true, \"showMoreActionsLink\": true, \"resultNumber\": 2, \"jobStateChangedToSaved\": false, \"searchState\": \"q=data scientist $20,000&amp;l=New+York&amp;start=10\", \"basicPermaLink\": \"http://www.indeed.com\", \"saveJobFailed\": false, \"removeJobFailed\": false, \"requestPending\": false, \"notesEnabled\": true, \"currentPage\" : \"serp\", \"sponsored\" : false,\"reportJobButtonEnabled\": false, \"showMyJobsHired\": false, \"showSaveForSponsored\": false, \"showJobAge\": true};\n",
      "               </script>\n",
      "              </div>\n",
      "             </div>\n",
      "             <div class=\"tab-container\">\n",
      "              <div class=\"more-links-container result-tab\" id=\"tt_display_2\" style=\"display:none;\">\n",
      "               <a class=\"close-link closeLink\" href=\"#\" onclick=\"toggleMoreLinks('81e50490c3e0204a'); return false;\" title=\"Close\">\n",
      "               </a>\n",
      "               <div class=\"more_actions\" id=\"more_2\">\n",
      "                <ul>\n",
      "                 <li>\n",
      "                  <span class=\"mat\">\n",
      "                   View all\n",
      "                   <a href=\"/q-Enterprise-Select-l-New-York,-NY-jobs.html\" rel=\"nofollow\">\n",
      "                    Enterprise Select jobs in New York, NY\n",
      "                   </a>\n",
      "                   -\n",
      "                   <a href=\"/l-New-York,-NY-jobs.html\">\n",
      "                    New York jobs\n",
      "                   </a>\n",
      "                  </span>\n",
      "                 </li>\n",
      "                 <li>\n",
      "                  <span class=\"mat\">\n",
      "                   Salary Search:\n",
      "                   <a href=\"/salaries/Data-Scientist-Salaries,-New-York-NY\" onmousedown=\"this.href = appendParamsOnce(this.href, '?campaignid=serp-more&amp;fromjk=81e50490c3e0204a&amp;from=serp-more');\">\n",
      "                    Data Scientist salaries in New York, NY\n",
      "                   </a>\n",
      "                  </span>\n",
      "                 </li>\n",
      "                 <li>\n",
      "                  <span class=\"mat\">\n",
      "                   Related forums:\n",
      "                   <a href=\"/forum/cmp/Enterprise-Select.html\">\n",
      "                    Enterprise Select\n",
      "                   </a>\n",
      "                   -\n",
      "                   <a href=\"/forum/loc/New-York-New-York.html\">\n",
      "                    New York, New York\n",
      "                   </a>\n",
      "                  </span>\n",
      "                 </li>\n",
      "                </ul>\n",
      "               </div>\n",
      "              </div>\n",
      "              <div class=\"dya-container result-tab\">\n",
      "              </div>\n",
      "              <div class=\"tellafriend-container result-tab email_job_content\">\n",
      "              </div>\n",
      "              <div class=\"sign-in-container result-tab\">\n",
      "              </div>\n",
      "              <div class=\"notes-container result-tab\">\n",
      "              </div>\n",
      "             </div>\n",
      "            </td>\n",
      "           </tr>\n",
      "          </table>\n",
      "         </div>\n",
      "         <div class=\" row result\" data-jk=\"c577bc95d49af6cd\" data-tn-component=\"organicJob\" id=\"p_c577bc95d49af6cd\" itemscope=\"\" itemtype=\"http://schema.org/JobPosting\">\n",
      "          <h2 class=\"jobtitle\" id=\"jl_c577bc95d49af6cd\">\n",
      "           <a class=\"turnstileLink\" data-tn-element=\"jobTitle\" href=\"/rc/clk?jk=c577bc95d49af6cd&amp;fccid=2152cf83e9c8d7cd\" itemprop=\"title\" onclick=\"setRefineByCookie(['salest']); return rclk(this,jobmap[3],true,0);\" onmousedown=\"return rclk(this,jobmap[3],0);\" rel=\"noopener nofollow\" target=\"_blank\" title=\"Data Scientist - Pricing\">\n",
      "            <b>\n",
      "             Data\n",
      "            </b>\n",
      "            <b>\n",
      "             Scientist\n",
      "            </b>\n",
      "            - Pricing\n",
      "           </a>\n",
      "          </h2>\n",
      "          <span class=\"company\" itemprop=\"hiringOrganization\" itemtype=\"http://schema.org/Organization\">\n",
      "           <span itemprop=\"name\">\n",
      "            <a href=\"/cmp/J.-Crew-Group,-Inc.\" onmousedown=\"this.href = appendParamsOnce(this.href, 'from=SERP&amp;campaignid=serp-linkcompanyname&amp;fromjk=c577bc95d49af6cd&amp;jcid=5673861b9f61c6bf')\" rel=\"noopener\" target=\"_blank\">\n",
      "             J.Crew Group, Inc.\n",
      "            </a>\n",
      "           </span>\n",
      "          </span>\n",
      "          -\n",
      "          <a class=\"ratingsLabel\" data-tn-element=\"reviewStars\" data-tn-variant=\"cmplinktst2\" href=\"/cmp/J.-Crew-Group,-Inc./reviews\" onmousedown=\"this.href = appendParamsOnce(this.href, '?campaignid=cmplinktst2&amp;from=SERP&amp;jt=Data+Scientist+-+Pricing&amp;fromjk=c577bc95d49af6cd&amp;jcid=5673861b9f61c6bf');\" rel=\"noopener\" target=\"_blank\" title=\"J.crew Group reviews\">\n",
      "           <span class=\"ratings\">\n",
      "            <span class=\"rating\" style=\"width:44.4px\">\n",
      "             <!-- -->\n",
      "            </span>\n",
      "           </span>\n",
      "           <span class=\"slNoUnderline\">\n",
      "            568 reviews\n",
      "           </span>\n",
      "          </a>\n",
      "          -\n",
      "          <span itemprop=\"jobLocation\" itemscope=\"\" itemtype=\"http://schema.org/Place\">\n",
      "           <span class=\"location\" itemprop=\"address\" itemscope=\"\" itemtype=\"http://schema.org/Postaladdress\">\n",
      "            <span itemprop=\"addressLocality\">\n",
      "             New York, NY 10003\n",
      "             <span style=\"font-size: smaller\">\n",
      "              (Greenwich Village area)\n",
      "             </span>\n",
      "            </span>\n",
      "           </span>\n",
      "          </span>\n",
      "          <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n",
      "           <tr>\n",
      "            <td class=\"snip\">\n",
      "             <div>\n",
      "              <span class=\"summary\" itemprop=\"description\">\n",
      "               J.Crew is seeking a\n",
      "               <b>\n",
      "                Data\n",
      "               </b>\n",
      "               <b>\n",
      "                Scientist\n",
      "               </b>\n",
      "               with an emphasis on Pricing Analytics to join our team of highly successful predictive analysts....\n",
      "              </span>\n",
      "             </div>\n",
      "             <div class=\"result-link-bar-container\">\n",
      "              <div class=\"result-link-bar\">\n",
      "               <span class=\"result-link-source\">\n",
      "                J. Crew Group, Inc.\n",
      "               </span>\n",
      "               -\n",
      "               <span class=\"date\">\n",
      "                6 days ago\n",
      "               </span>\n",
      "               <span class=\"tt_set\" id=\"tt_set_3\">\n",
      "                -\n",
      "                <a class=\"sl resultLink save-job-link \" href=\"#\" id=\"sj_c577bc95d49af6cd\" onclick=\"changeJobState('c577bc95d49af6cd', 'save', 'linkbar', false); return false;\" title=\"Save this job to my.indeed\">\n",
      "                 save job\n",
      "                </a>\n",
      "                -\n",
      "                <a class=\"sl resultLink more-link \" href=\"#\" id=\"tog_3\" onclick=\"toggleMoreLinks('c577bc95d49af6cd'); return false;\">\n",
      "                 more...\n",
      "                </a>\n",
      "               </span>\n",
      "               <div class=\"edit_note_content\" id=\"editsaved2_c577bc95d49af6cd\" style=\"display:none;\">\n",
      "               </div>\n",
      "               <script>\n",
      "                window['result_c577bc95d49af6cd'] = {\"showSource\": true, \"source\": \"J. Crew Group, Inc.\", \"loggedIn\": false, \"showMyJobsLinks\": false,\"undoAction\": \"unsave\",\"relativeJobAge\": \"6 days ago\",\"jobKey\": \"c577bc95d49af6cd\", \"myIndeedAvailable\": true, \"showMoreActionsLink\": true, \"resultNumber\": 3, \"jobStateChangedToSaved\": false, \"searchState\": \"q=data scientist $20,000&amp;l=New+York&amp;start=10\", \"basicPermaLink\": \"http://www.indeed.com\", \"saveJobFailed\": false, \"removeJobFailed\": false, \"requestPending\": false, \"notesEnabled\": true, \"currentPage\" : \"serp\", \"sponsored\" : false,\"reportJobButtonEnabled\": false, \"showMyJobsHired\": false, \"showSaveForSponsored\": false, \"showJobAge\": true};\n",
      "               </script>\n",
      "              </div>\n",
      "             </div>\n",
      "             <div class=\"tab-container\">\n",
      "              <div class=\"more-links-container result-tab\" id=\"tt_display_3\" style=\"display:none;\">\n",
      "               <a class=\"close-link closeLink\" href=\"#\" onclick=\"toggleMoreLinks('c577bc95d49af6cd'); return false;\" title=\"Close\">\n",
      "               </a>\n",
      "               <div class=\"more_actions\" id=\"more_3\">\n",
      "                <ul>\n",
      "                 <li>\n",
      "                  <span class=\"mat\">\n",
      "                   View all\n",
      "                   <a href=\"/jobs?q=J+Crew+Group,+Inc&amp;l=New+York,+NY&amp;nc=jasx\" rel=\"nofollow\">\n",
      "                    J.Crew Group, Inc. jobs in New York, NY\n",
      "                   </a>\n",
      "                   -\n",
      "                   <a href=\"/l-New-York,-NY-jobs.html\">\n",
      "                    New York jobs\n",
      "                   </a>\n",
      "                  </span>\n",
      "                 </li>\n",
      "                 <li>\n",
      "                  <span class=\"mat\">\n",
      "                   Salary Search:\n",
      "                   <a href=\"/salaries/Data-Scientist-Salaries,-New-York-NY\" onmousedown=\"this.href = appendParamsOnce(this.href, '?campaignid=serp-more&amp;fromjk=c577bc95d49af6cd&amp;from=serp-more');\">\n",
      "                    Data Scientist salaries in New York, NY\n",
      "                   </a>\n",
      "                  </span>\n",
      "                 </li>\n",
      "                 <li>\n",
      "                  <span class=\"mat\">\n",
      "                   Learn more about working at\n",
      "                   <a href=\"/cmp/J.-Crew-Group,-Inc.\" onmousedown=\"this.href = appendParamsOnce(this.href, '?fromjk=c577bc95d49af6cd&amp;from=serp-more&amp;campaignid=serp-more&amp;jcid=5673861b9f61c6bf');\">\n",
      "                    J.crew Group, Inc.\n",
      "                   </a>\n",
      "                  </span>\n",
      "                 </li>\n",
      "                 <li>\n",
      "                  <span class=\"mat\">\n",
      "                   <a href=\"/cmp/J.-Crew-Group,-Inc./faq\" onmousedown=\"this.href = appendParamsOnce(this.href, '?from=serp-more&amp;campaignid=serp-more&amp;fromjk=c577bc95d49af6cd&amp;jcid=5673861b9f61c6bf');\">\n",
      "                    J.crew Group, Inc. questions about work, benefits, interviews and hiring process:\n",
      "                   </a>\n",
      "                   <ul>\n",
      "                    <li>\n",
      "                     <a href=\"/cmp/J.-Crew-Group,-Inc./faq/what-is-the-interview-process-like?quid=1acmoa5ol52vgabm\" onmousedown=\"this.href = appendParamsOnce(this.href, '?from=serp-more&amp;campaignid=serp-more&amp;fromjk=c577bc95d49af6cd&amp;jcid=5673861b9f61c6bf');\">\n",
      "                      What is the interview process like?\n",
      "                     </a>\n",
      "                    </li>\n",
      "                    <li>\n",
      "                     <a href=\"/cmp/J.-Crew-Group,-Inc./faq/what-is-the-dress-code-at-jcrew-i-have-training-tomorrow-and-i-m-not-sure-what-to-wear?quid=1apck4vgoak52brt\" onmousedown=\"this.href = appendParamsOnce(this.href, '?from=serp-more&amp;campaignid=serp-more&amp;fromjk=c577bc95d49af6cd&amp;jcid=5673861b9f61c6bf');\">\n",
      "                      What is the dress code at Jcrew. I have training tomorrow and I'm not su...\n",
      "                     </a>\n",
      "                    </li>\n",
      "                   </ul>\n",
      "                  </span>\n",
      "                 </li>\n",
      "                 <li>\n",
      "                  <span class=\"mat\">\n",
      "                   Related forums:  -\n",
      "                   <a href=\"/forum/loc/New-York-New-York.html\">\n",
      "                    New York, New York\n",
      "                   </a>\n",
      "                  </span>\n",
      "                 </li>\n",
      "                </ul>\n",
      "               </div>\n",
      "              </div>\n",
      "              <div class=\"dya-container result-tab\">\n",
      "              </div>\n",
      "              <div class=\"tellafriend-container result-tab email_job_content\">\n",
      "              </div>\n",
      "              <div class=\"sign-in-container result-tab\">\n",
      "              </div>\n",
      "              <div class=\"notes-container result-tab\">\n",
      "              </div>\n",
      "             </div>\n",
      "            </td>\n",
      "           </tr>\n",
      "          </table>\n",
      "         </div>\n",
      "         <div class=\" row result\" data-jk=\"8f5ef42de1f8aa48\" data-tn-component=\"organicJob\" id=\"p_8f5ef42de1f8aa48\" itemscope=\"\" itemtype=\"http://schema.org/JobPosting\">\n",
      "          <h2 class=\"jobtitle\" id=\"jl_8f5ef42de1f8aa48\">\n",
      "           <a class=\"turnstileLink\" data-tn-element=\"jobTitle\" href=\"/rc/clk?jk=8f5ef42de1f8aa48&amp;fccid=e127f4594cdf24f4\" itemprop=\"title\" onclick=\"setRefineByCookie(['salest']); return rclk(this,jobmap[4],true,0);\" onmousedown=\"return rclk(this,jobmap[4],0);\" rel=\"noopener nofollow\" target=\"_blank\" title=\"AVP - Machine Learning &amp; Advance Analytics\">\n",
      "            AVP - Machine Learning &amp; Advance Analytics\n",
      "           </a>\n",
      "          </h2>\n",
      "          <span class=\"company\" itemprop=\"hiringOrganization\" itemtype=\"http://schema.org/Organization\">\n",
      "           <span itemprop=\"name\">\n",
      "            <a href=\"/cmp/Credit-Suisse\" onmousedown=\"this.href = appendParamsOnce(this.href, 'from=SERP&amp;campaignid=serp-linkcompanyname&amp;fromjk=8f5ef42de1f8aa48&amp;jcid=e127f4594cdf24f4')\" rel=\"noopener\" target=\"_blank\">\n",
      "             Credit Suisse\n",
      "            </a>\n",
      "           </span>\n",
      "          </span>\n",
      "          -\n",
      "          <a class=\"ratingsLabel\" data-tn-element=\"reviewStars\" data-tn-variant=\"cmplinktst2\" href=\"/cmp/Credit-Suisse/reviews\" onmousedown=\"this.href = appendParamsOnce(this.href, '?campaignid=cmplinktst2&amp;from=SERP&amp;jt=AVP+-+Machine+Learning+%26+Advance+Analytics&amp;fromjk=8f5ef42de1f8aa48&amp;jcid=e127f4594cdf24f4');\" rel=\"noopener\" target=\"_blank\" title=\"Credit Suisse reviews\">\n",
      "           <span class=\"ratings\">\n",
      "            <span class=\"rating\" style=\"width:51.0px\">\n",
      "             <!-- -->\n",
      "            </span>\n",
      "           </span>\n",
      "           <span class=\"slNoUnderline\">\n",
      "            881 reviews\n",
      "           </span>\n",
      "          </a>\n",
      "          -\n",
      "          <span itemprop=\"jobLocation\" itemscope=\"\" itemtype=\"http://schema.org/Place\">\n",
      "           <span class=\"location\" itemprop=\"address\" itemscope=\"\" itemtype=\"http://schema.org/Postaladdress\">\n",
      "            <span itemprop=\"addressLocality\">\n",
      "             New York, NY 10022\n",
      "             <span style=\"font-size: smaller\">\n",
      "              (Midtown area)\n",
      "             </span>\n",
      "            </span>\n",
      "           </span>\n",
      "          </span>\n",
      "          <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n",
      "           <tr>\n",
      "            <td class=\"snip\">\n",
      "             <div>\n",
      "              <span class=\"summary\" itemprop=\"description\">\n",
      "               As a\n",
      "               <b>\n",
      "                data\n",
      "               </b>\n",
      "               <b>\n",
      "                scientist\n",
      "               </b>\n",
      "               , you will join a growing, high-visibility machine learning team that is developing and deploying solutions to some of Credit Suisseâs most...\n",
      "              </span>\n",
      "             </div>\n",
      "             <div class=\"result-link-bar-container\">\n",
      "              <div class=\"result-link-bar\">\n",
      "               <span class=\"date\">\n",
      "                30+ days ago\n",
      "               </span>\n",
      "               <span class=\"tt_set\" id=\"tt_set_4\">\n",
      "                -\n",
      "                <a class=\"sl resultLink save-job-link \" href=\"#\" id=\"sj_8f5ef42de1f8aa48\" onclick=\"changeJobState('8f5ef42de1f8aa48', 'save', 'linkbar', false); return false;\" title=\"Save this job to my.indeed\">\n",
      "                 save job\n",
      "                </a>\n",
      "                -\n",
      "                <a class=\"sl resultLink more-link \" href=\"#\" id=\"tog_4\" onclick=\"toggleMoreLinks('8f5ef42de1f8aa48'); return false;\">\n",
      "                 more...\n",
      "                </a>\n",
      "               </span>\n",
      "               <div class=\"edit_note_content\" id=\"editsaved2_8f5ef42de1f8aa48\" style=\"display:none;\">\n",
      "               </div>\n",
      "               <script>\n",
      "                window['result_8f5ef42de1f8aa48'] = {\"showSource\": false, \"source\": \"Credit Suisse\", \"loggedIn\": false, \"showMyJobsLinks\": false,\"undoAction\": \"unsave\",\"relativeJobAge\": \"30+ days ago\",\"jobKey\": \"8f5ef42de1f8aa48\", \"myIndeedAvailable\": true, \"showMoreActionsLink\": true, \"resultNumber\": 4, \"jobStateChangedToSaved\": false, \"searchState\": \"q=data scientist $20,000&amp;l=New+York&amp;start=10\", \"basicPermaLink\": \"http://www.indeed.com\", \"saveJobFailed\": false, \"removeJobFailed\": false, \"requestPending\": false, \"notesEnabled\": true, \"currentPage\" : \"serp\", \"sponsored\" : false,\"reportJobButtonEnabled\": false, \"showMyJobsHired\": false, \"showSaveForSponsored\": false, \"showJobAge\": true};\n",
      "               </script>\n",
      "              </div>\n",
      "             </div>\n",
      "             <div class=\"tab-container\">\n",
      "              <div class=\"more-links-container result-tab\" id=\"tt_display_4\" style=\"display:none;\">\n",
      "               <a class=\"close-link closeLink\" href=\"#\" onclick=\"toggleMoreLinks('8f5ef42de1f8aa48'); return false;\" title=\"Close\">\n",
      "               </a>\n",
      "               <div class=\"more_actions\" id=\"more_4\">\n",
      "                <ul>\n",
      "                 <li>\n",
      "                  <span class=\"mat\">\n",
      "                   View all\n",
      "                   <a href=\"/q-Credit-Suisse-l-New-York,-NY-jobs.html\" rel=\"nofollow\">\n",
      "                    Credit Suisse jobs in New York, NY\n",
      "                   </a>\n",
      "                   -\n",
      "                   <a href=\"/l-New-York,-NY-jobs.html\">\n",
      "                    New York jobs\n",
      "                   </a>\n",
      "                  </span>\n",
      "                 </li>\n",
      "                 <li>\n",
      "                  <span class=\"mat\">\n",
      "                   Salary Search:\n",
      "                   <a href=\"/salaries/Machine-Learning-Engineer-Salaries,-New-York-NY\" onmousedown=\"this.href = appendParamsOnce(this.href, '?campaignid=serp-more&amp;fromjk=8f5ef42de1f8aa48&amp;from=serp-more');\">\n",
      "                    Machine Learning Engineer salaries in New York, NY\n",
      "                   </a>\n",
      "                  </span>\n",
      "                 </li>\n",
      "                 <li>\n",
      "                  <span class=\"mat\">\n",
      "                   Learn more about working at\n",
      "                   <a href=\"/cmp/Credit-Suisse\" onmousedown=\"this.href = appendParamsOnce(this.href, '?fromjk=8f5ef42de1f8aa48&amp;from=serp-more&amp;campaignid=serp-more&amp;jcid=e127f4594cdf24f4');\">\n",
      "                    Credit Suisse\n",
      "                   </a>\n",
      "                  </span>\n",
      "                 </li>\n",
      "                 <li>\n",
      "                  <span class=\"mat\">\n",
      "                   <a href=\"/cmp/Credit-Suisse/faq\" onmousedown=\"this.href = appendParamsOnce(this.href, '?from=serp-more&amp;campaignid=serp-more&amp;fromjk=8f5ef42de1f8aa48&amp;jcid=e127f4594cdf24f4');\">\n",
      "                    Credit Suisse questions about work, benefits, interviews and hiring process:\n",
      "                   </a>\n",
      "                   <ul>\n",
      "                    <li>\n",
      "                     <a href=\"/cmp/Credit-Suisse/faq/how-long-does-it-take-to-get-hired-from-start-to-finish-what-are-the-steps-along-the-way?quid=1arduoser0kbo4or\" onmousedown=\"this.href = appendParamsOnce(this.href, '?from=serp-more&amp;campaignid=serp-more&amp;fromjk=8f5ef42de1f8aa48&amp;jcid=e127f4594cdf24f4');\">\n",
      "                      How long does it take to get hired from start to finish? What are the st...\n",
      "                     </a>\n",
      "                    </li>\n",
      "                    <li>\n",
      "                     <a href=\"/cmp/Credit-Suisse/faq/what-tips-or-advice-would-you-give-to-someone-interviewing-at-credit-suisse?quid=1arecq98g0mtr6dn\" onmousedown=\"this.href = appendParamsOnce(this.href, '?from=serp-more&amp;campaignid=serp-more&amp;fromjk=8f5ef42de1f8aa48&amp;jcid=e127f4594cdf24f4');\">\n",
      "                      What tips or advice would you give to someone interviewing at Credit Sui...\n",
      "                     </a>\n",
      "                    </li>\n",
      "                   </ul>\n",
      "                  </span>\n",
      "                 </li>\n",
      "                 <li>\n",
      "                  <span class=\"mat\">\n",
      "                   Related forums:\n",
      "                   <a href=\"/forum/cmp/Credit-Suisse.html\">\n",
      "                    Credit Suisse\n",
      "                   </a>\n",
      "                   -\n",
      "                   <a href=\"/forum/loc/New-York-New-York.html\">\n",
      "                    New York, New York\n",
      "                   </a>\n",
      "                  </span>\n",
      "                 </li>\n",
      "                </ul>\n",
      "               </div>\n",
      "              </div>\n",
      "              <div class=\"dya-container result-tab\">\n",
      "              </div>\n",
      "              <div class=\"tellafriend-container result-tab email_job_content\">\n",
      "              </div>\n",
      "              <div class=\"sign-in-container result-tab\">\n",
      "              </div>\n",
      "              <div class=\"notes-container result-tab\">\n",
      "              </div>\n",
      "             </div>\n",
      "            </td>\n",
      "           </tr>\n",
      "          </table>\n",
      "         </div>\n",
      "         <div class=\" row result\" data-jk=\"c43b6d66f2b6426b\" data-tn-component=\"organicJob\" id=\"p_c43b6d66f2b6426b\" itemscope=\"\" itemtype=\"http://schema.org/JobPosting\">\n",
      "          <h2 class=\"jobtitle\" id=\"jl_c43b6d66f2b6426b\">\n",
      "           <a class=\"turnstileLink\" data-tn-element=\"jobTitle\" href=\"/rc/clk?jk=c43b6d66f2b6426b&amp;fccid=feb484a8aef310be\" itemprop=\"title\" onclick=\"setRefineByCookie(['salest']); return rclk(this,jobmap[5],true,0);\" onmousedown=\"return rclk(this,jobmap[5],0);\" rel=\"noopener nofollow\" target=\"_blank\" title=\"Gain Theory â Data Scientist/Statistical Modeler\">\n",
      "            Gain Theory â\n",
      "            <b>\n",
      "             Data\n",
      "            </b>\n",
      "            <b>\n",
      "             Scientist\n",
      "            </b>\n",
      "            /Statistical Modeler\n",
      "           </a>\n",
      "          </h2>\n",
      "          <span class=\"company\" itemprop=\"hiringOrganization\" itemtype=\"http://schema.org/Organization\">\n",
      "           <span itemprop=\"name\">\n",
      "            <a href=\"/cmp/Groupm\" onmousedown=\"this.href = appendParamsOnce(this.href, 'from=SERP&amp;campaignid=serp-linkcompanyname&amp;fromjk=c43b6d66f2b6426b&amp;jcid=feb484a8aef310be')\" rel=\"noopener\" target=\"_blank\">\n",
      "             GroupM\n",
      "            </a>\n",
      "           </span>\n",
      "          </span>\n",
      "          -\n",
      "          <a class=\"ratingsLabel\" data-tn-element=\"reviewStars\" data-tn-variant=\"cmplinktst2\" href=\"/cmp/Groupm/reviews\" onmousedown=\"this.href = appendParamsOnce(this.href, '?campaignid=cmplinktst2&amp;from=SERP&amp;jt=Gain+Theory+%5Cu2013+Data+Scientist%5C%2FStatistical+Modeler&amp;fromjk=c43b6d66f2b6426b&amp;jcid=feb484a8aef310be');\" rel=\"noopener\" target=\"_blank\" title=\"Groupm reviews\">\n",
      "           <span class=\"ratings\">\n",
      "            <span class=\"rating\" style=\"width:51.0px\">\n",
      "             <!-- -->\n",
      "            </span>\n",
      "           </span>\n",
      "           <span class=\"slNoUnderline\">\n",
      "            67 reviews\n",
      "           </span>\n",
      "          </a>\n",
      "          -\n",
      "          <span itemprop=\"jobLocation\" itemscope=\"\" itemtype=\"http://schema.org/Place\">\n",
      "           <span class=\"location\" itemprop=\"address\" itemscope=\"\" itemtype=\"http://schema.org/Postaladdress\">\n",
      "            <span itemprop=\"addressLocality\">\n",
      "             New York, NY\n",
      "            </span>\n",
      "           </span>\n",
      "          </span>\n",
      "          <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n",
      "           <tr>\n",
      "            <td class=\"snip\">\n",
      "             <div>\n",
      "              <span class=\"summary\" itemprop=\"description\">\n",
      "               Gain Theory has an opening in New York City, USA for a\n",
      "               <b>\n",
      "                Data\n",
      "               </b>\n",
      "               <b>\n",
      "                Scientist\n",
      "               </b>\n",
      "               or Statistical Modeler. Gain Theory â\n",
      "               <b>\n",
      "                Data\n",
      "               </b>\n",
      "               <b>\n",
      "                Scientist\n",
      "               </b>\n",
      "               /Statistical Modeler....\n",
      "              </span>\n",
      "             </div>\n",
      "             <div class=\"result-link-bar-container\">\n",
      "              <div class=\"result-link-bar\">\n",
      "               <span class=\"date\">\n",
      "                9 days ago\n",
      "               </span>\n",
      "               <span class=\"tt_set\" id=\"tt_set_5\">\n",
      "                -\n",
      "                <a class=\"sl resultLink save-job-link \" href=\"#\" id=\"sj_c43b6d66f2b6426b\" onclick=\"changeJobState('c43b6d66f2b6426b', 'save', 'linkbar', false); return false;\" title=\"Save this job to my.indeed\">\n",
      "                 save job\n",
      "                </a>\n",
      "                -\n",
      "                <a class=\"sl resultLink more-link \" href=\"#\" id=\"tog_5\" onclick=\"toggleMoreLinks('c43b6d66f2b6426b'); return false;\">\n",
      "                 more...\n",
      "                </a>\n",
      "               </span>\n",
      "               <div class=\"edit_note_content\" id=\"editsaved2_c43b6d66f2b6426b\" style=\"display:none;\">\n",
      "               </div>\n",
      "               <script>\n",
      "                window['result_c43b6d66f2b6426b'] = {\"showSource\": false, \"source\": \"GroupM\", \"loggedIn\": false, \"showMyJobsLinks\": false,\"undoAction\": \"unsave\",\"relativeJobAge\": \"9 days ago\",\"jobKey\": \"c43b6d66f2b6426b\", \"myIndeedAvailable\": true, \"showMoreActionsLink\": true, \"resultNumber\": 5, \"jobStateChangedToSaved\": false, \"searchState\": \"q=data scientist $20,000&amp;l=New+York&amp;start=10\", \"basicPermaLink\": \"http://www.indeed.com\", \"saveJobFailed\": false, \"removeJobFailed\": false, \"requestPending\": false, \"notesEnabled\": true, \"currentPage\" : \"serp\", \"sponsored\" : false,\"reportJobButtonEnabled\": false, \"showMyJobsHired\": false, \"showSaveForSponsored\": false, \"showJobAge\": true};\n",
      "               </script>\n",
      "              </div>\n",
      "             </div>\n",
      "             <div class=\"tab-container\">\n",
      "              <div class=\"more-links-container result-tab\" id=\"tt_display_5\" style=\"display:none;\">\n",
      "               <a class=\"close-link closeLink\" href=\"#\" onclick=\"toggleMoreLinks('c43b6d66f2b6426b'); return false;\" title=\"Close\">\n",
      "               </a>\n",
      "               <div class=\"more_actions\" id=\"more_5\">\n",
      "                <ul>\n",
      "                 <li>\n",
      "                  <span class=\"mat\">\n",
      "                   View all\n",
      "                   <a href=\"/q-Groupm-l-New-York,-NY-jobs.html\" rel=\"nofollow\">\n",
      "                    GroupM jobs in New York, NY\n",
      "                   </a>\n",
      "                   -\n",
      "                   <a href=\"/l-New-York,-NY-jobs.html\">\n",
      "                    New York jobs\n",
      "                   </a>\n",
      "                  </span>\n",
      "                 </li>\n",
      "                 <li>\n",
      "                  <span class=\"mat\">\n",
      "                   Salary Search:\n",
      "                   <a href=\"/salaries/Data-Modeler-Salaries,-New-York-NY\" onmousedown=\"this.href = appendParamsOnce(this.href, '?campaignid=serp-more&amp;fromjk=c43b6d66f2b6426b&amp;from=serp-more');\">\n",
      "                    Data Modeler salaries in New York, NY\n",
      "                   </a>\n",
      "                  </span>\n",
      "                 </li>\n",
      "                 <li>\n",
      "                  <span class=\"mat\">\n",
      "                   Learn more about working at\n",
      "                   <a href=\"/cmp/Groupm\" onmousedown=\"this.href = appendParamsOnce(this.href, '?fromjk=c43b6d66f2b6426b&amp;from=serp-more&amp;campaignid=serp-more&amp;jcid=feb484a8aef310be');\">\n",
      "                    Groupm\n",
      "                   </a>\n",
      "                  </span>\n",
      "                 </li>\n",
      "                 <li>\n",
      "                  <span class=\"mat\">\n",
      "                   Related forums:\n",
      "                   <a href=\"/forum/cmp/Groupm.html\">\n",
      "                    GroupM\n",
      "                   </a>\n",
      "                   -\n",
      "                   <a href=\"/forum/loc/New-York-New-York.html\">\n",
      "                    New York, New York\n",
      "                   </a>\n",
      "                  </span>\n",
      "                 </li>\n",
      "                </ul>\n",
      "               </div>\n",
      "              </div>\n",
      "              <div class=\"dya-container result-tab\">\n",
      "              </div>\n",
      "              <div class=\"tellafriend-container result-tab email_job_content\">\n",
      "              </div>\n",
      "              <div class=\"sign-in-container result-tab\">\n",
      "              </div>\n",
      "              <div class=\"notes-container result-tab\">\n",
      "              </div>\n",
      "             </div>\n",
      "            </td>\n",
      "           </tr>\n",
      "          </table>\n",
      "         </div>\n",
      "         <div class=\" row result\" data-jk=\"c93c1fc625849021\" data-tn-component=\"organicJob\" id=\"p_c93c1fc625849021\" itemscope=\"\" itemtype=\"http://schema.org/JobPosting\">\n",
      "          <h2 class=\"jobtitle\" id=\"jl_c93c1fc625849021\">\n",
      "           <a class=\"turnstileLink\" data-tn-element=\"jobTitle\" href=\"/company/Amazon-Web-Services/jobs/Machine-Learning-Artificial-Intelligence-c93c1fc625849021?fccid=e20f28ac00e9ef0e\" itemprop=\"title\" onclick=\"setRefineByCookie(['salest']); return rclk(this,jobmap[6],true,0);\" onmousedown=\"return rclk(this,jobmap[6],0);\" rel=\"noopener nofollow\" target=\"_blank\" title=\"Machine Learning Artificial Intelligence\">\n",
      "            Machine Learning Artificial Intelligence\n",
      "           </a>\n",
      "          </h2>\n",
      "          <span class=\"company\" itemprop=\"hiringOrganization\" itemtype=\"http://schema.org/Organization\">\n",
      "           <span itemprop=\"name\">\n",
      "            Amazon Web Services\n",
      "           </span>\n",
      "          </span>\n",
      "          -\n",
      "          <span itemprop=\"jobLocation\" itemscope=\"\" itemtype=\"http://schema.org/Place\">\n",
      "           <span class=\"location\" itemprop=\"address\" itemscope=\"\" itemtype=\"http://schema.org/Postaladdress\">\n",
      "            <span itemprop=\"addressLocality\">\n",
      "             New York, NY\n",
      "            </span>\n",
      "           </span>\n",
      "          </span>\n",
      "          <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n",
      "           <tr>\n",
      "            <td class=\"snip\">\n",
      "             <div>\n",
      "              <span class=\"summary\" itemprop=\"description\">\n",
      "               SENIOR\n",
      "               <b>\n",
      "                Data\n",
      "               </b>\n",
      "               <b>\n",
      "                scientist\n",
      "               </b>\n",
      "               â AWS Professional services*. Our\n",
      "               <b>\n",
      "                Data\n",
      "               </b>\n",
      "               <b>\n",
      "                Scientists\n",
      "               </b>\n",
      "               can live in any location where we have a Professional Service office....\n",
      "              </span>\n",
      "             </div>\n",
      "             <div class=\"iaP\">\n",
      "              <span class=\"iaLabel\">\n",
      "               Easily apply\n",
      "              </span>\n",
      "             </div>\n",
      "             <div class=\"result-link-bar-container\">\n",
      "              <div class=\"result-link-bar\">\n",
      "               <span class=\"date\">\n",
      "                10 days ago\n",
      "               </span>\n",
      "               <span class=\"tt_set\" id=\"tt_set_6\">\n",
      "                -\n",
      "                <a class=\"sl resultLink save-job-link \" href=\"#\" id=\"sj_c93c1fc625849021\" onclick=\"changeJobState('c93c1fc625849021', 'save', 'linkbar', false); return false;\" title=\"Save this job to my.indeed\">\n",
      "                 save job\n",
      "                </a>\n",
      "                -\n",
      "                <a class=\"sl resultLink more-link \" href=\"#\" id=\"tog_6\" onclick=\"toggleMoreLinks('c93c1fc625849021'); return false;\">\n",
      "                 more...\n",
      "                </a>\n",
      "               </span>\n",
      "               <div class=\"edit_note_content\" id=\"editsaved2_c93c1fc625849021\" style=\"display:none;\">\n",
      "               </div>\n",
      "               <script>\n",
      "                window['result_c93c1fc625849021'] = {\"showSource\": false, \"source\": \"Indeed\", \"loggedIn\": false, \"showMyJobsLinks\": false,\"undoAction\": \"unsave\",\"relativeJobAge\": \"10 days ago\",\"jobKey\": \"c93c1fc625849021\", \"myIndeedAvailable\": true, \"showMoreActionsLink\": true, \"resultNumber\": 6, \"jobStateChangedToSaved\": false, \"searchState\": \"q=data scientist $20,000&amp;l=New+York&amp;start=10\", \"basicPermaLink\": \"http://www.indeed.com\", \"saveJobFailed\": false, \"removeJobFailed\": false, \"requestPending\": false, \"notesEnabled\": true, \"currentPage\" : \"serp\", \"sponsored\" : false,\"reportJobButtonEnabled\": false, \"showMyJobsHired\": false, \"showSaveForSponsored\": false, \"showJobAge\": true};\n",
      "               </script>\n",
      "              </div>\n",
      "             </div>\n",
      "             <div class=\"tab-container\">\n",
      "              <div class=\"more-links-container result-tab\" id=\"tt_display_6\" style=\"display:none;\">\n",
      "               <a class=\"close-link closeLink\" href=\"#\" onclick=\"toggleMoreLinks('c93c1fc625849021'); return false;\" title=\"Close\">\n",
      "               </a>\n",
      "               <div class=\"more_actions\" id=\"more_6\">\n",
      "                <ul>\n",
      "                 <li>\n",
      "                  <span class=\"mat\">\n",
      "                   View all\n",
      "                   <a href=\"/q-Amazon-Web-Services-l-New-York,-NY-jobs.html\" rel=\"nofollow\">\n",
      "                    Amazon Web Services jobs in New York, NY\n",
      "                   </a>\n",
      "                   -\n",
      "                   <a href=\"/l-New-York,-NY-jobs.html\">\n",
      "                    New York jobs\n",
      "                   </a>\n",
      "                  </span>\n",
      "                 </li>\n",
      "                 <li>\n",
      "                  <span class=\"mat\">\n",
      "                   Salary Search:\n",
      "                   <a href=\"/salaries/Machine-Learning-Engineer-Salaries,-New-York-NY\" onmousedown=\"this.href = appendParamsOnce(this.href, '?campaignid=serp-more&amp;fromjk=c93c1fc625849021&amp;from=serp-more');\">\n",
      "                    Machine Learning Engineer salaries in New York, NY\n",
      "                   </a>\n",
      "                  </span>\n",
      "                 </li>\n",
      "                 <li>\n",
      "                  <span class=\"mat\">\n",
      "                   Related forums:\n",
      "                   <a href=\"/forum/cmp/Amazon-Web-Services-8c0e3741.html\">\n",
      "                    Amazon Web Services\n",
      "                   </a>\n",
      "                   -\n",
      "                   <a href=\"/forum/loc/New-York-New-York.html\">\n",
      "                    New York, New York\n",
      "                   </a>\n",
      "                  </span>\n",
      "                 </li>\n",
      "                </ul>\n",
      "               </div>\n",
      "              </div>\n",
      "              <div class=\"dya-container result-tab\">\n",
      "              </div>\n",
      "              <div class=\"tellafriend-container result-tab email_job_content\">\n",
      "              </div>\n",
      "              <div class=\"sign-in-container result-tab\">\n",
      "              </div>\n",
      "              <div class=\"notes-container result-tab\">\n",
      "              </div>\n",
      "             </div>\n",
      "            </td>\n",
      "           </tr>\n",
      "          </table>\n",
      "         </div>\n",
      "         <div class=\" row result\" data-jk=\"d862f9d88d33e634\" data-tn-component=\"organicJob\" id=\"p_d862f9d88d33e634\" itemscope=\"\" itemtype=\"http://schema.org/JobPosting\">\n",
      "          <h2 class=\"jobtitle\" id=\"jl_d862f9d88d33e634\">\n",
      "           <a class=\"turnstileLink\" data-tn-element=\"jobTitle\" href=\"/rc/clk?jk=d862f9d88d33e634&amp;fccid=ea25315ee9da22e5\" itemprop=\"title\" onclick=\"setRefineByCookie(['salest']); return rclk(this,jobmap[7],true,0);\" onmousedown=\"return rclk(this,jobmap[7],0);\" rel=\"noopener nofollow\" target=\"_blank\" title=\"Data Scientist II\">\n",
      "            <b>\n",
      "             Data\n",
      "            </b>\n",
      "            <b>\n",
      "             Scientist\n",
      "            </b>\n",
      "            II\n",
      "           </a>\n",
      "          </h2>\n",
      "          <span class=\"company\" itemprop=\"hiringOrganization\" itemtype=\"http://schema.org/Organization\">\n",
      "           <span itemprop=\"name\">\n",
      "            <a href=\"/cmp/Comcast\" onmousedown=\"this.href = appendParamsOnce(this.href, 'from=SERP&amp;campaignid=serp-linkcompanyname&amp;fromjk=d862f9d88d33e634&amp;jcid=ea25315ee9da22e5')\" rel=\"noopener\" target=\"_blank\">\n",
      "             Comcast\n",
      "            </a>\n",
      "           </span>\n",
      "          </span>\n",
      "          -\n",
      "          <a class=\"ratingsLabel\" data-tn-element=\"reviewStars\" data-tn-variant=\"cmplinktst2\" href=\"/cmp/Comcast/reviews\" onmousedown=\"this.href = appendParamsOnce(this.href, '?campaignid=cmplinktst2&amp;from=SERP&amp;jt=Data+Scientist+II&amp;fromjk=d862f9d88d33e634&amp;jcid=ea25315ee9da22e5');\" rel=\"noopener\" target=\"_blank\" title=\"Comcast reviews\">\n",
      "           <span class=\"ratings\">\n",
      "            <span class=\"rating\" style=\"width:43.8px\">\n",
      "             <!-- -->\n",
      "            </span>\n",
      "           </span>\n",
      "           <span class=\"slNoUnderline\">\n",
      "            8,013 reviews\n",
      "           </span>\n",
      "          </a>\n",
      "          -\n",
      "          <span itemprop=\"jobLocation\" itemscope=\"\" itemtype=\"http://schema.org/Place\">\n",
      "           <span class=\"location\" itemprop=\"address\" itemscope=\"\" itemtype=\"http://schema.org/Postaladdress\">\n",
      "            <span itemprop=\"addressLocality\">\n",
      "             New York, NY 10112\n",
      "             <span style=\"font-size: smaller\">\n",
      "              (Midtown area)\n",
      "             </span>\n",
      "            </span>\n",
      "           </span>\n",
      "          </span>\n",
      "          <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n",
      "           <tr>\n",
      "            <td class=\"snip\">\n",
      "             <div>\n",
      "              <span class=\"summary\" itemprop=\"description\">\n",
      "               Solid background and practical experience in relational and non-relational databases,\n",
      "               <b>\n",
      "                data\n",
      "               </b>\n",
      "               architecting,\n",
      "               <b>\n",
      "                data\n",
      "               </b>\n",
      "               management and complex\n",
      "               <b>\n",
      "                data\n",
      "               </b>\n",
      "               processing in...\n",
      "              </span>\n",
      "             </div>\n",
      "             <div class=\"result-link-bar-container\">\n",
      "              <div class=\"result-link-bar\">\n",
      "               <span class=\"date\">\n",
      "                29 days ago\n",
      "               </span>\n",
      "               <span class=\"tt_set\" id=\"tt_set_7\">\n",
      "                -\n",
      "                <a class=\"sl resultLink save-job-link \" href=\"#\" id=\"sj_d862f9d88d33e634\" onclick=\"changeJobState('d862f9d88d33e634', 'save', 'linkbar', false); return false;\" title=\"Save this job to my.indeed\">\n",
      "                 save job\n",
      "                </a>\n",
      "                -\n",
      "                <a class=\"sl resultLink more-link \" href=\"#\" id=\"tog_7\" onclick=\"toggleMoreLinks('d862f9d88d33e634'); return false;\">\n",
      "                 more...\n",
      "                </a>\n",
      "               </span>\n",
      "               <div class=\"edit_note_content\" id=\"editsaved2_d862f9d88d33e634\" style=\"display:none;\">\n",
      "               </div>\n",
      "               <script>\n",
      "                window['result_d862f9d88d33e634'] = {\"showSource\": false, \"source\": \"Comcast\", \"loggedIn\": false, \"showMyJobsLinks\": false,\"undoAction\": \"unsave\",\"relativeJobAge\": \"29 days ago\",\"jobKey\": \"d862f9d88d33e634\", \"myIndeedAvailable\": true, \"showMoreActionsLink\": true, \"resultNumber\": 7, \"jobStateChangedToSaved\": false, \"searchState\": \"q=data scientist $20,000&amp;l=New+York&amp;start=10\", \"basicPermaLink\": \"http://www.indeed.com\", \"saveJobFailed\": false, \"removeJobFailed\": false, \"requestPending\": false, \"notesEnabled\": true, \"currentPage\" : \"serp\", \"sponsored\" : false,\"reportJobButtonEnabled\": false, \"showMyJobsHired\": false, \"showSaveForSponsored\": false, \"showJobAge\": true};\n",
      "               </script>\n",
      "              </div>\n",
      "             </div>\n",
      "             <div class=\"tab-container\">\n",
      "              <div class=\"more-links-container result-tab\" id=\"tt_display_7\" style=\"display:none;\">\n",
      "               <a class=\"close-link closeLink\" href=\"#\" onclick=\"toggleMoreLinks('d862f9d88d33e634'); return false;\" title=\"Close\">\n",
      "               </a>\n",
      "               <div class=\"more_actions\" id=\"more_7\">\n",
      "                <ul>\n",
      "                 <li>\n",
      "                  <span class=\"mat\">\n",
      "                   View all\n",
      "                   <a href=\"/q-Comcast-l-New-York,-NY-jobs.html\" rel=\"nofollow\">\n",
      "                    Comcast jobs in New York, NY\n",
      "                   </a>\n",
      "                   -\n",
      "                   <a href=\"/l-New-York,-NY-jobs.html\">\n",
      "                    New York jobs\n",
      "                   </a>\n",
      "                  </span>\n",
      "                 </li>\n",
      "                 <li>\n",
      "                  <span class=\"mat\">\n",
      "                   Salary Search:\n",
      "                   <a href=\"/salaries/Data-Scientist-Salaries,-New-York-NY\" onmousedown=\"this.href = appendParamsOnce(this.href, '?campaignid=serp-more&amp;fromjk=d862f9d88d33e634&amp;from=serp-more');\">\n",
      "                    Data Scientist salaries in New York, NY\n",
      "                   </a>\n",
      "                  </span>\n",
      "                 </li>\n",
      "                 <li>\n",
      "                  <span class=\"mat\">\n",
      "                   Learn more about working at\n",
      "                   <a href=\"/cmp/Comcast\" onmousedown=\"this.href = appendParamsOnce(this.href, '?fromjk=d862f9d88d33e634&amp;from=serp-more&amp;campaignid=serp-more&amp;jcid=ea25315ee9da22e5');\">\n",
      "                    Comcast\n",
      "                   </a>\n",
      "                  </span>\n",
      "                 </li>\n",
      "                 <li>\n",
      "                  <span class=\"mat\">\n",
      "                   <a href=\"/cmp/Comcast/faq\" onmousedown=\"this.href = appendParamsOnce(this.href, '?from=serp-more&amp;campaignid=serp-more&amp;fromjk=d862f9d88d33e634&amp;jcid=ea25315ee9da22e5');\">\n",
      "                    Comcast questions about work, benefits, interviews and hiring process:\n",
      "                   </a>\n",
      "                   <ul>\n",
      "                    <li>\n",
      "                     <a href=\"/cmp/Comcast/faq/how-are-the-working-hours?quid=1acd4c8r5ak9699j\" onmousedown=\"this.href = appendParamsOnce(this.href, '?from=serp-more&amp;campaignid=serp-more&amp;fromjk=d862f9d88d33e634&amp;jcid=ea25315ee9da22e5');\">\n",
      "                      How are the working hours?\n",
      "                     </a>\n",
      "                    </li>\n",
      "                    <li>\n",
      "                     <a href=\"/cmp/Comcast/faq/what-is-the-work-environment-and-culture-like-at-comcast?quid=1acdg56atb84odag\" onmousedown=\"this.href = appendParamsOnce(this.href, '?from=serp-more&amp;campaignid=serp-more&amp;fromjk=d862f9d88d33e634&amp;jcid=ea25315ee9da22e5');\">\n",
      "                      What is the work environment and culture like at Comcast?\n",
      "                     </a>\n",
      "                    </li>\n",
      "                   </ul>\n",
      "                  </span>\n",
      "                 </li>\n",
      "                 <li>\n",
      "                  <span class=\"mat\">\n",
      "                   Related forums:\n",
      "                   <a href=\"/forum/cmp/Comcast.html\">\n",
      "                    Comcast\n",
      "                   </a>\n",
      "                   -\n",
      "                   <a href=\"/forum/loc/New-York-New-York.html\">\n",
      "                    New York, New York\n",
      "                   </a>\n",
      "                  </span>\n",
      "                 </li>\n",
      "                </ul>\n",
      "               </div>\n",
      "              </div>\n",
      "              <div class=\"dya-container result-tab\">\n",
      "              </div>\n",
      "              <div class=\"tellafriend-container result-tab email_job_content\">\n",
      "              </div>\n",
      "              <div class=\"sign-in-container result-tab\">\n",
      "              </div>\n",
      "              <div class=\"notes-container result-tab\">\n",
      "              </div>\n",
      "             </div>\n",
      "            </td>\n",
      "           </tr>\n",
      "          </table>\n",
      "         </div>\n",
      "         <div class=\" row result\" data-jk=\"818c820ec89a73e5\" data-tn-component=\"organicJob\" id=\"p_818c820ec89a73e5\" itemscope=\"\" itemtype=\"http://schema.org/JobPosting\">\n",
      "          <h2 class=\"jobtitle\" id=\"jl_818c820ec89a73e5\">\n",
      "           <a class=\"turnstileLink\" data-tn-element=\"jobTitle\" href=\"/company/Radiator-Labs/jobs/Postdoctoral-Position-818c820ec89a73e5?fccid=781a2e4c231be33b\" itemprop=\"title\" onclick=\"setRefineByCookie(['salest']); return rclk(this,jobmap[8],true,0);\" onmousedown=\"return rclk(this,jobmap[8],0);\" rel=\"noopener nofollow\" target=\"_blank\" title=\"Postdoctoral Position, Data Science/IoT\">\n",
      "            Postdoctoral Position,\n",
      "            <b>\n",
      "             Data\n",
      "            </b>\n",
      "            Science/IoT\n",
      "           </a>\n",
      "          </h2>\n",
      "          <span class=\"company\" itemprop=\"hiringOrganization\" itemtype=\"http://schema.org/Organization\">\n",
      "           <span itemprop=\"name\">\n",
      "            Radiator Labs\n",
      "           </span>\n",
      "          </span>\n",
      "          -\n",
      "          <span itemprop=\"jobLocation\" itemscope=\"\" itemtype=\"http://schema.org/Place\">\n",
      "           <span class=\"location\" itemprop=\"address\" itemscope=\"\" itemtype=\"http://schema.org/Postaladdress\">\n",
      "            <span itemprop=\"addressLocality\">\n",
      "             Brooklyn, NY\n",
      "            </span>\n",
      "           </span>\n",
      "          </span>\n",
      "          <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n",
      "           <tr>\n",
      "            <td class=\"snip\">\n",
      "             <div>\n",
      "              <span class=\"summary\" itemprop=\"description\">\n",
      "               Candidates with experience accessing\n",
      "               <b>\n",
      "                data\n",
      "               </b>\n",
      "               stored in cloud databases,\n",
      "               <b>\n",
      "                data\n",
      "               </b>\n",
      "               modeling and processing, as well as the presentation of results....\n",
      "              </span>\n",
      "             </div>\n",
      "             <div class=\"iaP\">\n",
      "              <span class=\"iaLabel\">\n",
      "               Easily apply\n",
      "              </span>\n",
      "             </div>\n",
      "             <div class=\"result-link-bar-container\">\n",
      "              <div class=\"result-link-bar\">\n",
      "               <span class=\"date\">\n",
      "                2 hours ago\n",
      "               </span>\n",
      "               <span class=\"tt_set\" id=\"tt_set_8\">\n",
      "                -\n",
      "                <a class=\"sl resultLink save-job-link \" href=\"#\" id=\"sj_818c820ec89a73e5\" onclick=\"changeJobState('818c820ec89a73e5', 'save', 'linkbar', false); return false;\" title=\"Save this job to my.indeed\">\n",
      "                 save job\n",
      "                </a>\n",
      "                -\n",
      "                <a class=\"sl resultLink more-link \" href=\"#\" id=\"tog_8\" onclick=\"toggleMoreLinks('818c820ec89a73e5'); return false;\">\n",
      "                 more...\n",
      "                </a>\n",
      "               </span>\n",
      "               <div class=\"edit_note_content\" id=\"editsaved2_818c820ec89a73e5\" style=\"display:none;\">\n",
      "               </div>\n",
      "               <script>\n",
      "                window['result_818c820ec89a73e5'] = {\"showSource\": false, \"source\": \"Indeed\", \"loggedIn\": false, \"showMyJobsLinks\": false,\"undoAction\": \"unsave\",\"relativeJobAge\": \"2 hours ago\",\"jobKey\": \"818c820ec89a73e5\", \"myIndeedAvailable\": true, \"showMoreActionsLink\": true, \"resultNumber\": 8, \"jobStateChangedToSaved\": false, \"searchState\": \"q=data scientist $20,000&amp;l=New+York&amp;start=10\", \"basicPermaLink\": \"http://www.indeed.com\", \"saveJobFailed\": false, \"removeJobFailed\": false, \"requestPending\": false, \"notesEnabled\": true, \"currentPage\" : \"serp\", \"sponsored\" : false,\"reportJobButtonEnabled\": false, \"showMyJobsHired\": false, \"showSaveForSponsored\": false, \"showJobAge\": true};\n",
      "               </script>\n",
      "              </div>\n",
      "             </div>\n",
      "             <div class=\"tab-container\">\n",
      "              <div class=\"more-links-container result-tab\" id=\"tt_display_8\" style=\"display:none;\">\n",
      "               <a class=\"close-link closeLink\" href=\"#\" onclick=\"toggleMoreLinks('818c820ec89a73e5'); return false;\" title=\"Close\">\n",
      "               </a>\n",
      "               <div class=\"more_actions\" id=\"more_8\">\n",
      "                <ul>\n",
      "                 <li>\n",
      "                  <span class=\"mat\">\n",
      "                   View all\n",
      "                   <a href=\"/q-Radiator-Labs-l-Brooklyn,-NY-jobs.html\" rel=\"nofollow\">\n",
      "                    Radiator Labs jobs in Brooklyn, NY\n",
      "                   </a>\n",
      "                   -\n",
      "                   <a href=\"/l-Brooklyn,-NY-jobs.html\">\n",
      "                    Brooklyn jobs\n",
      "                   </a>\n",
      "                  </span>\n",
      "                 </li>\n",
      "                 <li>\n",
      "                  <span class=\"mat\">\n",
      "                   Salary Search:\n",
      "                   <a href=\"/salaries/Data-Scientist-Salaries,-Brooklyn-NY\" onmousedown=\"this.href = appendParamsOnce(this.href, '?campaignid=serp-more&amp;fromjk=818c820ec89a73e5&amp;from=serp-more');\">\n",
      "                    Data Scientist salaries in Brooklyn, NY\n",
      "                   </a>\n",
      "                  </span>\n",
      "                 </li>\n",
      "                 <li>\n",
      "                  <span class=\"mat\">\n",
      "                   Related forums:\n",
      "                   <a href=\"/forum/cmp/Radiator-Labs.html\">\n",
      "                    Radiator Labs\n",
      "                   </a>\n",
      "                   -\n",
      "                   <a href=\"/forum/loc/Brooklyn-New-York.html\">\n",
      "                    Brooklyn, New York\n",
      "                   </a>\n",
      "                  </span>\n",
      "                 </li>\n",
      "                </ul>\n",
      "               </div>\n",
      "              </div>\n",
      "              <div class=\"dya-container result-tab\">\n",
      "              </div>\n",
      "              <div class=\"tellafriend-container result-tab email_job_content\">\n",
      "              </div>\n",
      "              <div class=\"sign-in-container result-tab\">\n",
      "              </div>\n",
      "              <div class=\"notes-container result-tab\">\n",
      "              </div>\n",
      "             </div>\n",
      "            </td>\n",
      "           </tr>\n",
      "          </table>\n",
      "         </div>\n",
      "         <div class=\"lastRow row result\" data-jk=\"b5772f35061f7eee\" data-tn-component=\"organicJob\" id=\"p_b5772f35061f7eee\" itemscope=\"\" itemtype=\"http://schema.org/JobPosting\">\n",
      "          <h2 class=\"jobtitle\" id=\"jl_b5772f35061f7eee\">\n",
      "           <a class=\"turnstileLink\" data-tn-element=\"jobTitle\" href=\"/rc/clk?jk=b5772f35061f7eee&amp;fccid=cf79f96fb3ec99fe\" itemprop=\"title\" onclick=\"setRefineByCookie(['salest']); return rclk(this,jobmap[9],true,0);\" onmousedown=\"return rclk(this,jobmap[9],0);\" rel=\"noopener nofollow\" target=\"_blank\" title=\"Marketing Data Scientist\">\n",
      "            Marketing\n",
      "            <b>\n",
      "             Data\n",
      "            </b>\n",
      "            <b>\n",
      "             Scientist\n",
      "            </b>\n",
      "           </a>\n",
      "          </h2>\n",
      "          <span class=\"company\" itemprop=\"hiringOrganization\" itemtype=\"http://schema.org/Organization\">\n",
      "           <span itemprop=\"name\">\n",
      "            Slice\n",
      "           </span>\n",
      "          </span>\n",
      "          -\n",
      "          <span itemprop=\"jobLocation\" itemscope=\"\" itemtype=\"http://schema.org/Place\">\n",
      "           <span class=\"location\" itemprop=\"address\" itemscope=\"\" itemtype=\"http://schema.org/Postaladdress\">\n",
      "            <span itemprop=\"addressLocality\">\n",
      "             New York, NY\n",
      "            </span>\n",
      "           </span>\n",
      "          </span>\n",
      "          <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n",
      "           <tr>\n",
      "            <td class=\"snip\">\n",
      "             <div>\n",
      "              <span class=\"summary\" itemprop=\"description\">\n",
      "               Experience with\n",
      "               <b>\n",
      "                data\n",
      "               </b>\n",
      "               visualization tools (e.g. Familiarity with leveraging APIs for\n",
      "               <b>\n",
      "                data\n",
      "               </b>\n",
      "               extraction purposes. Experience in translating business challenges into...\n",
      "              </span>\n",
      "             </div>\n",
      "             <div class=\"iaP\">\n",
      "              <span class=\"iaLabel\">\n",
      "               Easily apply\n",
      "              </span>\n",
      "             </div>\n",
      "             <div class=\"result-link-bar-container\">\n",
      "              <div class=\"result-link-bar\">\n",
      "               <span class=\"date\">\n",
      "                21 days ago\n",
      "               </span>\n",
      "               <span class=\"tt_set\" id=\"tt_set_9\">\n",
      "                -\n",
      "                <a class=\"sl resultLink save-job-link \" href=\"#\" id=\"sj_b5772f35061f7eee\" onclick=\"changeJobState('b5772f35061f7eee', 'save', 'linkbar', false); return false;\" title=\"Save this job to my.indeed\">\n",
      "                 save job\n",
      "                </a>\n",
      "                -\n",
      "                <a class=\"sl resultLink more-link \" href=\"#\" id=\"tog_9\" onclick=\"toggleMoreLinks('b5772f35061f7eee'); return false;\">\n",
      "                 more...\n",
      "                </a>\n",
      "               </span>\n",
      "               <div class=\"edit_note_content\" id=\"editsaved2_b5772f35061f7eee\" style=\"display:none;\">\n",
      "               </div>\n",
      "               <script>\n",
      "                window['result_b5772f35061f7eee'] = {\"showSource\": false, \"source\": \"Slice\", \"loggedIn\": false, \"showMyJobsLinks\": false,\"undoAction\": \"unsave\",\"relativeJobAge\": \"21 days ago\",\"jobKey\": \"b5772f35061f7eee\", \"myIndeedAvailable\": true, \"showMoreActionsLink\": true, \"resultNumber\": 9, \"jobStateChangedToSaved\": false, \"searchState\": \"q=data scientist $20,000&amp;l=New+York&amp;start=10\", \"basicPermaLink\": \"http://www.indeed.com\", \"saveJobFailed\": false, \"removeJobFailed\": false, \"requestPending\": false, \"notesEnabled\": true, \"currentPage\" : \"serp\", \"sponsored\" : false,\"reportJobButtonEnabled\": false, \"showMyJobsHired\": false, \"showSaveForSponsored\": false, \"showJobAge\": true};\n",
      "               </script>\n",
      "              </div>\n",
      "             </div>\n",
      "             <div class=\"tab-container\">\n",
      "              <div class=\"more-links-container result-tab\" id=\"tt_display_9\" style=\"display:none;\">\n",
      "               <a class=\"close-link closeLink\" href=\"#\" onclick=\"toggleMoreLinks('b5772f35061f7eee'); return false;\" title=\"Close\">\n",
      "               </a>\n",
      "               <div class=\"more_actions\" id=\"more_9\">\n",
      "                <ul>\n",
      "                 <li>\n",
      "                  <span class=\"mat\">\n",
      "                   View all\n",
      "                   <a href=\"/q-Slice-l-New-York,-NY-jobs.html\" rel=\"nofollow\">\n",
      "                    Slice jobs in New York, NY\n",
      "                   </a>\n",
      "                   -\n",
      "                   <a href=\"/l-New-York,-NY-jobs.html\">\n",
      "                    New York jobs\n",
      "                   </a>\n",
      "                  </span>\n",
      "                 </li>\n",
      "                 <li>\n",
      "                  <span class=\"mat\">\n",
      "                   Salary Search:\n",
      "                   <a href=\"/salaries/Data-Scientist-Salaries,-New-York-NY\" onmousedown=\"this.href = appendParamsOnce(this.href, '?campaignid=serp-more&amp;fromjk=b5772f35061f7eee&amp;from=serp-more');\">\n",
      "                    Data Scientist salaries in New York, NY\n",
      "                   </a>\n",
      "                  </span>\n",
      "                 </li>\n",
      "                 <li>\n",
      "                  <span class=\"mat\">\n",
      "                   <a href=\"/cmp/Slice/faq\" onmousedown=\"this.href = appendParamsOnce(this.href, '?from=serp-more&amp;campaignid=serp-more&amp;fromjk=b5772f35061f7eee&amp;jcid=cf79f96fb3ec99fe');\">\n",
      "                    Slice questions about work, benefits, interviews and hiring process:\n",
      "                   </a>\n",
      "                   <ul>\n",
      "                    <li>\n",
      "                     <a href=\"/cmp/Slice/faq/what-is-the-sick-leave-policy-like-how-many-sick-days-do-you-get-per-year?quid=1bdf4bevq5n9mbe6\" onmousedown=\"this.href = appendParamsOnce(this.href, '?from=serp-more&amp;campaignid=serp-more&amp;fromjk=b5772f35061f7eee&amp;jcid=cf79f96fb3ec99fe');\">\n",
      "                      What is the sick leave policy like? How many sick days do you get per year?\n",
      "                     </a>\n",
      "                    </li>\n",
      "                    <li>\n",
      "                     <a href=\"/cmp/Slice/faq/what-advice-would-you-give-the-ceo-of-slice-about-how-to-improve-it?quid=1bgi0d6m1brcv9sa\" onmousedown=\"this.href = appendParamsOnce(this.href, '?from=serp-more&amp;campaignid=serp-more&amp;fromjk=b5772f35061f7eee&amp;jcid=cf79f96fb3ec99fe');\">\n",
      "                      What advice would you give the CEO of Slice about how to improve it?\n",
      "                     </a>\n",
      "                    </li>\n",
      "                   </ul>\n",
      "                  </span>\n",
      "                 </li>\n",
      "                 <li>\n",
      "                  <span class=\"mat\">\n",
      "                   Related forums:\n",
      "                   <a href=\"/forum/cmp/Slice.html\">\n",
      "                    Slice\n",
      "                   </a>\n",
      "                   -\n",
      "                   <a href=\"/forum/loc/New-York-New-York.html\">\n",
      "                    New York, New York\n",
      "                   </a>\n",
      "                  </span>\n",
      "                 </li>\n",
      "                </ul>\n",
      "               </div>\n",
      "              </div>\n",
      "              <div class=\"dya-container result-tab\">\n",
      "              </div>\n",
      "              <div class=\"tellafriend-container result-tab email_job_content\">\n",
      "              </div>\n",
      "              <div class=\"sign-in-container result-tab\">\n",
      "              </div>\n",
      "              <div class=\"notes-container result-tab\">\n",
      "              </div>\n",
      "             </div>\n",
      "            </td>\n",
      "           </tr>\n",
      "          </table>\n",
      "         </div>\n",
      "         <div>\n",
      "         </div>\n",
      "         <div class=\"ri80fX3wjQI eFbWmP8Mkeu\">\n",
      "          <div class=\"row result\" data-jk=\"ef76da781e876d41\" id=\"pj_ef76da781e876d41\">\n",
      "           <!-- Previously this variable was used to indicate job board jobs, we have replaced that with a more accurate source type check -->\n",
      "           <a class=\"jobtitle turnstileLink\" data-tn-element=\"jobTitle\" href=\"/pagead/clk?mo=r&amp;ad=-6NYlbfkN0DAgAc92q6iRaEfcJAuaSGKVeICOvW3P0dpzElS8ir45AVr2KnXyohmCH6uVD67Lw7-jm9pD1Dy8WkuDMDi4BoqKGSgXXjI709k9NeQx8ezf2Vjg_BQ2p9a0Sv201T5WiyKwf2qutSPCWvziJSYlxqToHiOmA6ez4CMMe76T06f1N-1dutdRLvTzZLPbRhZbmxPRL5TgthSFM8fdEod130jUKOAGMOrw4Fx2ghn5Gxv61CUOnjeNW4sIZOJXPkwEptNx5Rb5KN9kib52sFS_2Si3M2K4ODDlpZOXjrCNwvrRraBWITbjWOs2QcuzOiG7Uc6jze-DUaG9PYT3dUF13aJmLAeyIgE8_q9jm2xaOuETNa_rZBToSeouRfjQCcjqMw8JbZicVFE52KPoWXUiLs8&amp;p=3&amp;sk=&amp;fvj=0\" id=\"sja3\" onclick=\"setRefineByCookie(['salest']); sjoc('sja3',0); convCtr('SJ', pingUrlsForGA)\" onmousedown=\"sjomd('sja3'); clk('sja3');\" rel=\"noopener nofollow\" target=\"_blank\" title=\"Healthcare &amp; Life Sciences - Data Scientist\">\n",
      "            Healthcare &amp; Life Sciences -\n",
      "            <b>\n",
      "             Data\n",
      "            </b>\n",
      "            <b>\n",
      "             Scientist\n",
      "            </b>\n",
      "           </a>\n",
      "           <br/>\n",
      "           <div class=\"sjcl\">\n",
      "            <span class=\"company\">\n",
      "             <a class=\"turnstileLink\" data-tn-element=\"companyName\" href=\"/cmp/Kpmg\" onmousedown=\"this.href = appendParamsOnce(this.href, 'from=SERP&amp;campaignid=serp-linkcompanyname&amp;fromjk=ef76da781e876d41&amp;jcid=2dd390c3a48a7ed0')\" rel=\"noopener\" target=\"_blank\">\n",
      "              KPMG\n",
      "             </a>\n",
      "            </span>\n",
      "            -\n",
      "            <a class=\"ratingsLabel\" data-tn-element=\"reviewStars\" data-tn-variant=\"cmplinktst2\" href=\"/cmp/Kpmg/reviews\" onmousedown=\"this.href = appendParamsOnce(this.href, '?campaignid=cmplinktst2&amp;from=SERP&amp;jt=Healthcare+%26+Life+Sciences+-+Data+Scientist&amp;fromjk=ef76da781e876d41&amp;jcid=2dd390c3a48a7ed0');\" rel=\"noopener\" target=\"_blank\" title=\"Kpmg reviews\">\n",
      "             <span class=\"ratings\">\n",
      "              <span class=\"rating\" style=\"width:51.0px\">\n",
      "               <!-- -->\n",
      "              </span>\n",
      "             </span>\n",
      "             <span class=\"slNoUnderline\">\n",
      "              3,272 reviews\n",
      "             </span>\n",
      "            </a>\n",
      "            -\n",
      "            <span class=\"location\">\n",
      "             New York, NY 10154\n",
      "            </span>\n",
      "           </div>\n",
      "           <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n",
      "            <tr>\n",
      "             <td class=\"snip\">\n",
      "              <span class=\"summary\">\n",
      "               KPMG is currently seeking a Healthcare &amp; Life Sciences -\n",
      "               <b>\n",
      "                Data\n",
      "               </b>\n",
      "               <b>\n",
      "                Scientist\n",
      "               </b>\n",
      "               , to join our Advanced Analytics Organization....\n",
      "              </span>\n",
      "             </td>\n",
      "            </tr>\n",
      "           </table>\n",
      "           <div class=\"sjCapt\">\n",
      "            <div class=\"result-link-bar-container\">\n",
      "             <div class=\"result-link-bar\">\n",
      "              <span class=\" sponsoredGray \">\n",
      "               Sponsored by\n",
      "               <b>\n",
      "                KPMG LLP\n",
      "               </b>\n",
      "              </span>\n",
      "              -\n",
      "              <span class=\"tt_set\" id=\"tt_set_12\">\n",
      "               <a class=\"sl resultLink save-job-link \" href=\"#\" id=\"sj_ef76da781e876d41\" onclick=\"changeJobState('ef76da781e876d41', 'save', 'linkbar', true); return false;\" title=\"Save this job to my.indeed\">\n",
      "                save job\n",
      "               </a>\n",
      "              </span>\n",
      "              <div class=\"edit_note_content\" id=\"editsaved2_ef76da781e876d41\" style=\"display:none;\">\n",
      "              </div>\n",
      "              <script>\n",
      "               window['sj_result_ef76da781e876d41'] = {\"showSource\": false, \"source\": \"KPMG LLP\", \"loggedIn\": false, \"showMyJobsLinks\": false,\"undoAction\": \"unsave\",\"jobKey\": \"ef76da781e876d41\", \"myIndeedAvailable\": true, \"showMoreActionsLink\": false, \"resultNumber\": 12, \"jobStateChangedToSaved\": false, \"searchState\": \"q=data scientist $20,000&amp;l=New+York&amp;start=10\", \"basicPermaLink\": \"http://www.indeed.com\", \"saveJobFailed\": false, \"removeJobFailed\": false, \"requestPending\": false, \"notesEnabled\": false, \"currentPage\" : \"serp\", \"sponsored\" : true,\"showSponsor\" : true,\"sponsorName\" : \"KPMG LLP\",\"reportJobButtonEnabled\": false, \"showMyJobsHired\": false, \"showSaveForSponsored\": true, \"showJobAge\": true};\n",
      "              </script>\n",
      "             </div>\n",
      "            </div>\n",
      "            <div class=\"tab-container\">\n",
      "             <div class=\"sign-in-container result-tab\">\n",
      "             </div>\n",
      "             <div class=\"tellafriend-container result-tab email_job_content\">\n",
      "             </div>\n",
      "            </div>\n",
      "           </div>\n",
      "          </div>\n",
      "          <div class=\"row result\" data-jk=\"d2c181ae32990a35\" id=\"pj_d2c181ae32990a35\">\n",
      "           <!-- Previously this variable was used to indicate job board jobs, we have replaced that with a more accurate source type check -->\n",
      "           <a class=\"jobtitle turnstileLink\" data-tn-element=\"jobTitle\" href=\"/pagead/clk?mo=r&amp;ad=-6NYlbfkN0DAgAc92q6iRaEfcJAuaSGKVeICOvW3P0dpzElS8ir45AVr2KnXyohmCH6uVD67Lw4eErW6N8oByL9r_AhoWji6LHpuxaB_kyxjLUVUvdNTNM1MhhZr_o6HfAtk5BQP01RzPxwFD943DkvCQK7BrfE8OY3N_ewtvJJgz0kyr5ZtM3_oeD9rx6p2UVUHNxAA91LlVedbncsLsdS2MnXMaXjf2qb_R5Hp24FHEl37TvgXKGcXJozsvzPPL8G7t5hNYVTZesjehZxXGrPaxEpZHHuCE7QG4ifcZapv8iBIx6wb4zIWXRl6_A_aw5g4Eo6uptHmN8TIBTRHlYY6f9hPHrlyKS04nXLN3Srfa_yTGVjWF-HNlwnJ2TuBW_tFHBE4e70fgAMV1G6aXGd-CkwduWes&amp;p=4&amp;sk=&amp;fvj=0\" id=\"sja4\" onclick=\"setRefineByCookie(['salest']); sjoc('sja4',0); convCtr('SJ', pingUrlsForGA)\" onmousedown=\"sjomd('sja4'); clk('sja4');\" rel=\"noopener nofollow\" target=\"_blank\" title=\"Data Scientist\">\n",
      "            <b>\n",
      "             Data\n",
      "            </b>\n",
      "            <b>\n",
      "             Scientist\n",
      "            </b>\n",
      "           </a>\n",
      "           <br/>\n",
      "           <div class=\"sjcl\">\n",
      "            <span class=\"company\">\n",
      "             <a class=\"turnstileLink\" data-tn-element=\"companyName\" href=\"/cmp/Kpmg\" onmousedown=\"this.href = appendParamsOnce(this.href, 'from=SERP&amp;campaignid=serp-linkcompanyname&amp;fromjk=d2c181ae32990a35&amp;jcid=2dd390c3a48a7ed0')\" rel=\"noopener\" target=\"_blank\">\n",
      "              KPMG\n",
      "             </a>\n",
      "            </span>\n",
      "            -\n",
      "            <a class=\"ratingsLabel\" data-tn-element=\"reviewStars\" data-tn-variant=\"cmplinktst2\" href=\"/cmp/Kpmg/reviews\" onmousedown=\"this.href = appendParamsOnce(this.href, '?campaignid=cmplinktst2&amp;from=SERP&amp;jt=Data+Scientist&amp;fromjk=d2c181ae32990a35&amp;jcid=2dd390c3a48a7ed0');\" rel=\"noopener\" target=\"_blank\" title=\"Kpmg reviews\">\n",
      "             <span class=\"ratings\">\n",
      "              <span class=\"rating\" style=\"width:51.0px\">\n",
      "               <!-- -->\n",
      "              </span>\n",
      "             </span>\n",
      "             <span class=\"slNoUnderline\">\n",
      "              3,272 reviews\n",
      "             </span>\n",
      "            </a>\n",
      "            -\n",
      "            <span class=\"location\">\n",
      "             New York, NY 10154\n",
      "            </span>\n",
      "           </div>\n",
      "           <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n",
      "            <tr>\n",
      "             <td class=\"snip\">\n",
      "              <span class=\"summary\">\n",
      "               KPMG is currently seeking a\n",
      "               <b>\n",
      "                Data\n",
      "               </b>\n",
      "               <b>\n",
      "                Scientist\n",
      "               </b>\n",
      "               to join our Advanced\n",
      "               <b>\n",
      "                Data\n",
      "               </b>\n",
      "               &amp; Analytics Organization. Retrieve, prepare, and process a rich\n",
      "               <b>\n",
      "                data\n",
      "               </b>\n",
      "               variety of\n",
      "               <b>\n",
      "                data\n",
      "               </b>\n",
      "               ...\n",
      "              </span>\n",
      "             </td>\n",
      "            </tr>\n",
      "           </table>\n",
      "           <div class=\"sjCapt\">\n",
      "            <div class=\"result-link-bar-container\">\n",
      "             <div class=\"result-link-bar\">\n",
      "              <span class=\" sponsoredGray \">\n",
      "               Sponsored by\n",
      "               <b>\n",
      "                KPMG LLP\n",
      "               </b>\n",
      "              </span>\n",
      "              -\n",
      "              <span class=\"tt_set\" id=\"tt_set_13\">\n",
      "               <a class=\"sl resultLink save-job-link \" href=\"#\" id=\"sj_d2c181ae32990a35\" onclick=\"changeJobState('d2c181ae32990a35', 'save', 'linkbar', true); return false;\" title=\"Save this job to my.indeed\">\n",
      "                save job\n",
      "               </a>\n",
      "              </span>\n",
      "              <div class=\"edit_note_content\" id=\"editsaved2_d2c181ae32990a35\" style=\"display:none;\">\n",
      "              </div>\n",
      "              <script>\n",
      "               window['sj_result_d2c181ae32990a35'] = {\"showSource\": false, \"source\": \"KPMG LLP\", \"loggedIn\": false, \"showMyJobsLinks\": false,\"undoAction\": \"unsave\",\"jobKey\": \"d2c181ae32990a35\", \"myIndeedAvailable\": true, \"showMoreActionsLink\": false, \"resultNumber\": 13, \"jobStateChangedToSaved\": false, \"searchState\": \"q=data scientist $20,000&amp;l=New+York&amp;start=10\", \"basicPermaLink\": \"http://www.indeed.com\", \"saveJobFailed\": false, \"removeJobFailed\": false, \"requestPending\": false, \"notesEnabled\": false, \"currentPage\" : \"serp\", \"sponsored\" : true,\"showSponsor\" : true,\"sponsorName\" : \"KPMG LLP\",\"reportJobButtonEnabled\": false, \"showMyJobsHired\": false, \"showSaveForSponsored\": true, \"showJobAge\": true};\n",
      "              </script>\n",
      "             </div>\n",
      "            </div>\n",
      "            <div class=\"tab-container\">\n",
      "             <div class=\"sign-in-container result-tab\">\n",
      "             </div>\n",
      "             <div class=\"tellafriend-container result-tab email_job_content\">\n",
      "             </div>\n",
      "            </div>\n",
      "           </div>\n",
      "          </div>\n",
      "          <div class=\"row sjlast result\" data-jk=\"6144a1ed913a082d\" id=\"pj_6144a1ed913a082d\">\n",
      "           <!-- Previously this variable was used to indicate job board jobs, we have replaced that with a more accurate source type check -->\n",
      "           <a class=\"jobtitle turnstileLink\" data-tn-element=\"jobTitle\" href=\"/pagead/clk?mo=r&amp;ad=-6NYlbfkN0AcKrCDQ_eChMN_hHoeVwk0t6ouhlvRsMi3bqSMrWgRh45cvUDcYHB8JyliDTuggW9uRVzljqa7c7VjP24oev1ffZtxZbcp1pm4qrLAYyCA6gN5h4Ho21cuuVlw2ySUZbb5k2Bl0_kZfka7VWLBG7hy0RHGL3Gk4aCAncBCSGTYrUaYuGLby__eylUR9US5FAmLy0WrmBxXAV-r3DyOxfOryONEWXIZoeG4nEpw8e-LSACdrRpGCayYQSxNCzpUHV1TETSsSpgh8YdJSFRIb63V4yGRHRbHOAue8V2niwNoJ6zpIsFx4l_0YljO9pRx-AYFcvfiqhB0-kv1pGHh5uwOn02UI1Svhwc_WPwOBZE1WGcy7sl3ujvGuiKeRfuF9exNMldf2Qh0UT4mohtEj6NXI-lvp8W7bv9EpASdwSbJxedbg6EH7N6zAzg-CkgslBrKaZNgs6F0VT0ptKX2yabjV33fVzzz4GkE31yNvy-osvPcStD6r2UsaE3ZQLMQj4DwrsDK_TKixTvjEYqvlyTPVhFrrJWTcsjldi6JIBTlOKUcBtGaKT11tih__lgWJDe4XGWk_P_v4XCQEuKrbEBJd_9IKv3fh9qcpuW0a7ptXi-oEOem448R43JYctelVUtV-hqGtDA72bPt2DhbaPO1bDZ8Q_vVJ1OZRREneYbBFRSAk-wRcLR1&amp;p=5&amp;sk=&amp;fvj=0\" id=\"sja5\" onclick=\"setRefineByCookie(['salest']); sjoc('sja5',0); convCtr('SJ', pingUrlsForGA)\" onmousedown=\"sjomd('sja5'); clk('sja5');\" rel=\"noopener nofollow\" target=\"_blank\" title=\"Data Scientist - Worldwide Advanced Analytics Team\">\n",
      "            <b>\n",
      "             Data\n",
      "            </b>\n",
      "            <b>\n",
      "             Scientist\n",
      "            </b>\n",
      "            - Worldwide Advanced Analytics Team\n",
      "           </a>\n",
      "           <br/>\n",
      "           <div class=\"sjcl\">\n",
      "            <span class=\"company\">\n",
      "             <a class=\"turnstileLink\" data-tn-element=\"companyName\" href=\"/cmp/IBM\" onmousedown=\"this.href = appendParamsOnce(this.href, 'from=SERP&amp;campaignid=serp-linkcompanyname&amp;fromjk=6144a1ed913a082d&amp;jcid=de71a49b535e21cb')\" rel=\"noopener\" target=\"_blank\">\n",
      "              IBM\n",
      "             </a>\n",
      "            </span>\n",
      "            -\n",
      "            <a class=\"ratingsLabel\" data-tn-element=\"reviewStars\" data-tn-variant=\"cmplinktst2\" href=\"/cmp/IBM/reviews\" onmousedown=\"this.href = appendParamsOnce(this.href, '?campaignid=cmplinktst2&amp;from=SERP&amp;jt=Data+Scientist+-+Worldwide+Advanced+Analytics+Team&amp;fromjk=6144a1ed913a082d&amp;jcid=de71a49b535e21cb');\" rel=\"noopener\" target=\"_blank\" title=\"IBM reviews\">\n",
      "             <span class=\"ratings\">\n",
      "              <span class=\"rating\" style=\"width:51.0px\">\n",
      "               <!-- -->\n",
      "              </span>\n",
      "             </span>\n",
      "             <span class=\"slNoUnderline\">\n",
      "              16,657 reviews\n",
      "             </span>\n",
      "            </a>\n",
      "            -\n",
      "            <span class=\"location\">\n",
      "             New York, NY\n",
      "            </span>\n",
      "           </div>\n",
      "           <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n",
      "            <tr>\n",
      "             <td class=\"snip\">\n",
      "              <span class=\"summary\">\n",
      "               The Worldwide Advanced Analytics Center of Competency is the top-of-the-spear of IBMâs consulting organization when it comes to Machine Learning &amp; Big\n",
      "               <b>\n",
      "                Data\n",
      "               </b>\n",
      "               ....\n",
      "              </span>\n",
      "             </td>\n",
      "            </tr>\n",
      "           </table>\n",
      "           <div class=\"sjCapt\">\n",
      "            <div class=\"result-link-bar-container\">\n",
      "             <div class=\"result-link-bar\">\n",
      "              <span class=\" sponsoredGray \">\n",
      "               Sponsored\n",
      "              </span>\n",
      "              -\n",
      "              <span class=\"tt_set\" id=\"tt_set_14\">\n",
      "               <a class=\"sl resultLink save-job-link \" href=\"#\" id=\"sj_6144a1ed913a082d\" onclick=\"changeJobState('6144a1ed913a082d', 'save', 'linkbar', true); return false;\" title=\"Save this job to my.indeed\">\n",
      "                save job\n",
      "               </a>\n",
      "              </span>\n",
      "              <div class=\"edit_note_content\" id=\"editsaved2_6144a1ed913a082d\" style=\"display:none;\">\n",
      "              </div>\n",
      "              <script>\n",
      "               window['sj_result_6144a1ed913a082d'] = {\"showSource\": false, \"source\": \"IBM\", \"loggedIn\": false, \"showMyJobsLinks\": false,\"undoAction\": \"unsave\",\"jobKey\": \"6144a1ed913a082d\", \"myIndeedAvailable\": true, \"showMoreActionsLink\": false, \"resultNumber\": 14, \"jobStateChangedToSaved\": false, \"searchState\": \"q=data scientist $20,000&amp;l=New+York&amp;start=10\", \"basicPermaLink\": \"http://www.indeed.com\", \"saveJobFailed\": false, \"removeJobFailed\": false, \"requestPending\": false, \"notesEnabled\": false, \"currentPage\" : \"serp\", \"sponsored\" : true,\"showSponsor\" : true,\"reportJobButtonEnabled\": false, \"showMyJobsHired\": false, \"showSaveForSponsored\": true, \"showJobAge\": true};\n",
      "              </script>\n",
      "             </div>\n",
      "            </div>\n",
      "            <div class=\"tab-container\">\n",
      "             <div class=\"sign-in-container result-tab\">\n",
      "             </div>\n",
      "             <div class=\"tellafriend-container result-tab email_job_content\">\n",
      "             </div>\n",
      "            </div>\n",
      "           </div>\n",
      "          </div>\n",
      "         </div>\n",
      "         <style>\n",
      "          .fixed_ja_link_x { color:#00C; float: right; font-size: 22px; margin-top: -8px; font-weight: bold;}\n",
      ".fixed_ja_link_x:hover { cursor:pointer;}\n",
      ".fixed_ja_link { color:#00C; cursor: pointer;}\n",
      ".fixed_ja_link:hover { text-decoration: underline;}\n",
      ".fixed_ja_background { background-color: #ebebeb;}\n",
      "         </style>\n",
      "         <div id=\"bjobalertswrapper\">\n",
      "          <div class=\"open jaui B2vGPQO\" id=\"bjobalerts\">\n",
      "           <div class=\"jobalertlabel\">\n",
      "            <span class=\"jobalerts_title\" id=\"bjobalertlabel\">\n",
      "             <span aria-label=\"alert icon\" class=\"ico\" role=\"img\">\n",
      "             </span>\n",
      "             Be the first to see new\n",
      "             <b>\n",
      "              data scientist $20,000 jobs in New York\n",
      "             </b>\n",
      "            </span>\n",
      "           </div>\n",
      "           <div class=\"jaform\" id=\"bjobalertform\">\n",
      "            <span id=\"bjobalerttext\">\n",
      "            </span>\n",
      "            <span id=\"bjobalertsending\">\n",
      "            </span>\n",
      "            <div id=\"bjobalertmessage\">\n",
      "             <form action=\"/alert\" method=\"POST\" onsubmit=\"return addalertdelegate('data+scientist+%2420%2C000','New+York','b','',this.email.value,'1bll9fe210m9b3ng', this.verified.value, true, '661982', 'US', '70e62f766a6d43c62701b11cdf42bf3d', this.recjobalert.checked, false, false);\">\n",
      "              <input name=\"a\" type=\"hidden\" value=\"add\"/>\n",
      "              <input name=\"q\" type=\"hidden\" value=\"data scientist $20,000\"/>\n",
      "              <input name=\"l\" type=\"hidden\" value=\"New York\"/>\n",
      "              <input name=\"radius\" type=\"hidden\" value=\"25\"/>\n",
      "              <input name=\"noscript\" type=\"hidden\" value=\"1\"/>\n",
      "              <input name=\"fr\" type=\"hidden\" value=\"b\"/>\n",
      "              <input name=\"tk\" type=\"hidden\" value=\"1bll9fe210m9b3ng\"/>\n",
      "              <input id=\"balertverified\" name=\"verified\" type=\"hidden\" value=\"0\"/>\n",
      "              <input name=\"alertparams\" type=\"hidden\" value=\"\"/>\n",
      "              <label for=\"balertemail\">\n",
      "               My email:\n",
      "              </label>\n",
      "              <input id=\"balertemail\" maxlength=\"100\" name=\"email\" size=\"25\" type=\"text\" value=\"\"/>\n",
      "              <span class=\"indeed-apply-button\">\n",
      "               <span class=\"indeed-apply-button-inner\">\n",
      "                <input class=\"indeed-apply-button-label\" id=\"balertsubmit\" type=\"submit\" value=\"Activate\"/>\n",
      "               </span>\n",
      "              </span>\n",
      "              <style type=\"text/css\">\n",
      "               .indeed-apply-button { cursor : pointer !important; display : inline-block !important; padding : 1px !important; height : 31px !important; -moz-border-radius : 7px !important; border-radius : 7px !important; position : relative !important; text-decoration : none !important;background-color:#79788B; filter:progid:DXImageTransform.Microsoft.gradient(startColorstr='#BCBBCD', endColorstr='#79788B', GradientType=0);background-image: -webkit-gradient(linear, center top, center bottom, from(#BCBBCD), to(#79788B)) !important;background-image: -webkit-linear-gradient(top, #BCBBCD, #79788B) !important;background-image: -moz-linear-gradient(top, #BCBBCD, #79788B) !important;background-image: -o-linear-gradient(top, #BCBBCD, #79788B) !important;background-image: -ms-linear-gradient(top, #BCBBCD, #79788B) !important;background-image: linear-gradient(top, #BCBBCD, #79788B) !important;-webkit-box-shadow: 0 1px 2px rgba(0,0,0,0.2) !important;-moz-box-shadow: 0 1px 2px rgba(0,0,0,0.2) !important;box-shadow: 0 1px 2px rgba(0,0,0,0.2) !important; } #indeed-ia-1329175190441-0:link, #indeed-ia-1329175190441-0:visited, #indeed-ia-1329175190441-0:hover, #indeed-ia-1329175190441-0:active { border : 0 !important; text-decoration : none !important; }\n",
      "\n",
      "    .indeed-apply-button:hover { filter:progid:DXImageTransform.Microsoft.gradient(startColorstr='#6D99F6', endColorstr='#1B45A3', GradientType=0);background-image: -webkit-gradient(linear, center top, center bottom, from(#6D99F6), to(#1B45A3)) !important;background-image: -webkit-linear-gradient(top, #6D99F6, #1B45A3) !important;background-image: -moz-linear-gradient(top, #6D99F6, #1B45A3) !important;background-image: -o-linear-gradient(top, #6D99F6, #1B45A3) !important;background-image: -ms-linear-gradient(top, #6D99F6, #1B45A3) !important;background-image: linear-gradient(top, #6D99F6, #1B45A3) !important; }\n",
      "\n",
      "    .indeed-apply-state-clicked .indeed-apply-button,\n",
      "    .indeed-apply-button:active { filter:progid:DXImageTransform.Microsoft.gradient(startColorstr='#B3BACA', endColorstr='#7C8493', GradientType=0);background-image: -webkit-gradient(linear, center top, center bottom, from(#B3BACA), to(#7C8493)) !important;background-image: -webkit-linear-gradient(top, #B3BACA, #7C8493) !important;background-image: -moz-linear-gradient(top, #B3BACA, #7C8493) !important;background-image: -o-linear-gradient(top, #B3BACA, #7C8493) !important;background-image: -ms-linear-gradient(top, #B3BACA, #7C8493) !important;background-image: linear-gradient(top, #B3BACA, #7C8493) !important;-webkit-box-shadow: none !important;-moz-box-shadow: none !important;box-shadow: none !important; }\n",
      "\n",
      "    .indeed-apply-button-inner { display : inline-block !important; height : 31px !important; -moz-border-radius : 6px !important; border-radius : 6px !important; font : 18px 'Helvetica Neue','Helvetica',Arial !important; font-weight : 200 !important; text-decoration : none !important; text-shadow : 0px 1px #F1F1F4 !important;background-color:#D9D9E2;  color: #FF6703;filter:progid:DXImageTransform.Microsoft.gradient(startColorstr='#FAFAFB', endColorstr='#D9D9E2', GradientType=0);background-image: -webkit-gradient(linear, center top, center bottom, from(#FAFAFB), to(#D9D9E2)) !important;background-image: -webkit-linear-gradient(top, #FAFAFB, #D9D9E2) !important;background-image: -moz-linear-gradient(top, #FAFAFB, #D9D9E2) !important;background-image: -o-linear-gradient(top, #FAFAFB, #D9D9E2) !important;background-image: -ms-linear-gradient(top, #FAFAFB, #D9D9E2) !important;background-image: linear-gradient(top, #FAFAFB, #D9D9E2) !important; }\n",
      "\n",
      "    .indeed-apply-button:active .indeed-apply-button-inner { filter:progid:DXImageTransform.Microsoft.gradient(startColorstr='#E8E8E9', endColorstr='#CBCBD3', GradientType=0);background-image: -webkit-gradient(linear, center top, center bottom, from(#E8E8E9), to(#CBCBD3)) !important;background-image: -webkit-linear-gradient(top, #E8E8E9, #CBCBD3) !important;background-image: -moz-linear-gradient(top, #E8E8E9, #CBCBD3) !important;background-image: -o-linear-gradient(top, #E8E8E9, #CBCBD3) !important;background-image: -ms-linear-gradient(top, #E8E8E9, #CBCBD3) !important;background-image: linear-gradient(top, #E8E8E9, #CBCBD3) !important; }\n",
      "\n",
      "    .indeed-apply-button-label {cursor: pointer; text-align : center !important; border:0; background: transparent;font-size: 12px; font-family: Arial, sans-serif; padding:3px 14px 2px 12px; margin:0; line-height: 26px; }\n",
      "\n",
      "    .indeed-apply-button:active .indeed-apply-button-label,\n",
      "    .indeed-apply-state-clicked .indeed-apply-button-label { -ms-filter: \"progid:DXImageTransform.Microsoft.Alpha(Opacity=0.75)\" !important;filter: alpha(opacity=75) !important;-moz-opacity: 0.75 !important;-khtml-opacity: 0.75 !important;opacity: 0.75 !important; }\n",
      "\n",
      "    #talertemail, #balertemail {  height: 27px; line-height: 24px; padding-left: 6px; padding-right: 6px; font-size: 14px; font-family: Arial, sans-serif; }\n",
      "\n",
      "    .jobalertform-terms-outer-wrapper label {  position: fixed;  font-size: 1px;  transform: scale(0.3);  }\n",
      "\n",
      "    .jobalertform-terms-inner-wrapper {  position: relative;  z-index: 20;  width: 50%;  background: #ebebeb;  height: 12px;  }\n",
      "              </style>\n",
      "              <label for=\"brecjobalert\" id=\"brecjobalertlabel\">\n",
      "               <input checked=\"\" id=\"brecjobalert\" name=\"recjobalert\" type=\"checkbox\"/>\n",
      "               <span>\n",
      "                Also get an email with jobs recommended just for me\n",
      "               </span>\n",
      "              </label>\n",
      "             </form>\n",
      "             <span class=\"caption\">\n",
      "              You can cancel email alerts at any time.\n",
      "             </span>\n",
      "            </div>\n",
      "           </div>\n",
      "          </div>\n",
      "         </div>\n",
      "         <script type=\"text/javascript\">\n",
      "          function ptk(st,p) {\n",
      "document.cookie = 'PTK=\"tk=&type=jobsearch&subtype=' + st + (p ? '&' + p : '')\n",
      " + (st == 'pagination' ? '&fp=2' : '')\n",
      "+'\"; path=/';\n",
      "}\n",
      "         </script>\n",
      "         <script type=\"text/javascript\">\n",
      "          function pclk(event) {\n",
      "var evt = event || window.event;\n",
      "var target = evt.target || evt.srcElement;\n",
      "var el = target.nodeType == 1 ? target : target.parentNode;\n",
      "var tag = el.tagName.toLowerCase();\n",
      "if (tag == 'span' || tag == 'a') {\n",
      "ptk('pagination');\n",
      "}\n",
      "return true;\n",
      "}\n",
      "function addPPUrlParam(obj) {\n",
      "var pp = obj.getAttribute('data-pp');\n",
      "var href = obj.getAttribute('href');\n",
      "if (pp && href) {\n",
      "obj.setAttribute('href', href + '&pp=' + pp);\n",
      "}\n",
      "}\n",
      "         </script>\n",
      "         <div class=\"pagination\" onmousedown=\"pclk(event);\">\n",
      "          ResultsÂ Page:\n",
      "          <a href=\"/jobs?q=data+scientist+%2420%2C000&amp;l=New+York\">\n",
      "           <span class=\"pn\">\n",
      "            <span class=\"np\">\n",
      "             Â«Â Previous\n",
      "            </span>\n",
      "           </span>\n",
      "          </a>\n",
      "          <a href=\"/jobs?q=data+scientist+%2420%2C000&amp;l=New+York\">\n",
      "           <span class=\"pn\">\n",
      "            1\n",
      "           </span>\n",
      "          </a>\n",
      "          <b>\n",
      "           2\n",
      "          </b>\n",
      "          <a data-pp=\"ABQAAAAAAAAAAAAAAAEVFVA8AQACSR2sjRuoBV6AcoG_umzrJaubJY5_xpn1gGczKk79Ia06sNVhLOBEr-uBkxb_pO5S\" href=\"/jobs?q=data+scientist+%2420%2C000&amp;l=New+York&amp;start=20\" onmousedown=\"addPPUrlParam &amp;&amp; addPPUrlParam(this);\">\n",
      "           <span class=\"pn\">\n",
      "            3\n",
      "           </span>\n",
      "          </a>\n",
      "          <a data-pp=\"AB4AAAAAAAAAAAAAAAEVFVA8AQEBCwFZRIulDna3MhXIdM6LCE0mz2u_SpnYqxbBmItbrlV4IRSOEiPURzb5IyZ78gnVXPndtiuv6CjLv5ss_JU\" href=\"/jobs?q=data+scientist+%2420%2C000&amp;l=New+York&amp;start=30\" onmousedown=\"addPPUrlParam &amp;&amp; addPPUrlParam(this);\">\n",
      "           <span class=\"pn\">\n",
      "            4\n",
      "           </span>\n",
      "          </a>\n",
      "          <a data-pp=\"ACgAAAAAAAAAAAAAAAEVFVA8AQEBDDH86HCYjHMpZzmo5K-H_viYGO6dPUrQtdh1njusCYTdczTNF2KZPi1SsN195ufB5zK_KUGMOJnveoEmsNnjVXH2p7OqNnA6Fqja\" href=\"/jobs?q=data+scientist+%2420%2C000&amp;l=New+York&amp;start=40\" onmousedown=\"addPPUrlParam &amp;&amp; addPPUrlParam(this);\">\n",
      "           <span class=\"pn\">\n",
      "            5\n",
      "           </span>\n",
      "          </a>\n",
      "          <a data-pp=\"ADIAAAAAAAAAAAAAAAEVFVA8AQEBE2v7NJOlGq2PkHISPL6AZTk7wyk9vXCWTTazbbCOqFKuL7bzksQTPf7qT6zXLqgvkop0hscaOWQ26h4PQgQYBkPu1zlI4d24jRqDJl075toQmOl7A5ZsOwjXrw\" href=\"/jobs?q=data+scientist+%2420%2C000&amp;l=New+York&amp;start=50\" onmousedown=\"addPPUrlParam &amp;&amp; addPPUrlParam(this);\">\n",
      "           <span class=\"pn\">\n",
      "            6\n",
      "           </span>\n",
      "          </a>\n",
      "          <a data-pp=\"ABQAAAAAAAAAAAAAAAEVFVA8AQACSR2sjRuoBV6AcoG_umzrJaubJY5_xpn1gGczKk79Ia06sNVhLOBEr-uBkxb_pO5S\" href=\"/jobs?q=data+scientist+%2420%2C000&amp;l=New+York&amp;start=20\" onmousedown=\"addPPUrlParam &amp;&amp; addPPUrlParam(this);\">\n",
      "           <span class=\"pn\">\n",
      "            <span class=\"np\">\n",
      "             NextÂ Â»\n",
      "            </span>\n",
      "           </span>\n",
      "          </a>\n",
      "         </div>\n",
      "        </td>\n",
      "        <td id=\"auxCol\" role=\"complementary\">\n",
      "         <div id=\"tjobalertswrapper\">\n",
      "          <div class=\"open jaui \" id=\"tjobalerts\">\n",
      "           <div class=\"jobalertlabel\">\n",
      "            <span class=\"jobalerts_title\" id=\"tjobalertlabel\">\n",
      "             <span aria-label=\"alert icon\" class=\"ico\" role=\"img\">\n",
      "             </span>\n",
      "             Be the first to see new\n",
      "             <b>\n",
      "              data scientist $20,000 jobs in New York\n",
      "             </b>\n",
      "            </span>\n",
      "           </div>\n",
      "           <div class=\"jaform\" id=\"tjobalertform\">\n",
      "            <span id=\"tjobalerttext\">\n",
      "            </span>\n",
      "            <span id=\"tjobalertsending\">\n",
      "            </span>\n",
      "            <div id=\"tjobalertmessage\">\n",
      "             <form action=\"/alert\" method=\"POST\" onsubmit=\"return addalertdelegate('data+scientist+%2420%2C000','New+York','t','',this.email.value,'1bll9fe210m9b3ng', this.verified.value, true, '661982', 'US', '70e62f766a6d43c62701b11cdf42bf3d', this.recjobalert.checked, false, false);\">\n",
      "              <input name=\"a\" type=\"hidden\" value=\"add\"/>\n",
      "              <input name=\"q\" type=\"hidden\" value=\"data scientist $20,000\"/>\n",
      "              <input name=\"l\" type=\"hidden\" value=\"New York\"/>\n",
      "              <input name=\"radius\" type=\"hidden\" value=\"25\"/>\n",
      "              <input name=\"noscript\" type=\"hidden\" value=\"1\"/>\n",
      "              <input name=\"fr\" type=\"hidden\" value=\"t\"/>\n",
      "              <input name=\"tk\" type=\"hidden\" value=\"1bll9fe210m9b3ng\"/>\n",
      "              <input id=\"talertverified\" name=\"verified\" type=\"hidden\" value=\"0\"/>\n",
      "              <input name=\"alertparams\" type=\"hidden\" value=\"\"/>\n",
      "              <label for=\"talertemail\">\n",
      "               My email:\n",
      "              </label>\n",
      "              <input id=\"talertemail\" maxlength=\"100\" name=\"email\" size=\"25\" type=\"text\" value=\"\"/>\n",
      "              <label for=\"trecjobalert\" id=\"trecjobalertlabel\">\n",
      "               <input checked=\"\" id=\"trecjobalert\" name=\"recjobalert\" type=\"checkbox\"/>\n",
      "               <span>\n",
      "                Also get an email with jobs recommended just for me\n",
      "               </span>\n",
      "              </label>\n",
      "              <span class=\"indeed-apply-button\">\n",
      "               <span class=\"indeed-apply-button-inner\">\n",
      "                <input class=\"indeed-apply-button-label\" id=\"talertsubmit\" type=\"submit\" value=\"Activate\"/>\n",
      "               </span>\n",
      "              </span>\n",
      "              <style type=\"text/css\">\n",
      "               .indeed-apply-button { cursor : pointer !important; display : inline-block !important; padding : 1px !important; height : 31px !important; -moz-border-radius : 7px !important; border-radius : 7px !important; position : relative !important; text-decoration : none !important;background-color:#79788B; filter:progid:DXImageTransform.Microsoft.gradient(startColorstr='#BCBBCD', endColorstr='#79788B', GradientType=0);background-image: -webkit-gradient(linear, center top, center bottom, from(#BCBBCD), to(#79788B)) !important;background-image: -webkit-linear-gradient(top, #BCBBCD, #79788B) !important;background-image: -moz-linear-gradient(top, #BCBBCD, #79788B) !important;background-image: -o-linear-gradient(top, #BCBBCD, #79788B) !important;background-image: -ms-linear-gradient(top, #BCBBCD, #79788B) !important;background-image: linear-gradient(top, #BCBBCD, #79788B) !important;-webkit-box-shadow: 0 1px 2px rgba(0,0,0,0.2) !important;-moz-box-shadow: 0 1px 2px rgba(0,0,0,0.2) !important;box-shadow: 0 1px 2px rgba(0,0,0,0.2) !important; } #indeed-ia-1329175190441-0:link, #indeed-ia-1329175190441-0:visited, #indeed-ia-1329175190441-0:hover, #indeed-ia-1329175190441-0:active { border : 0 !important; text-decoration : none !important; }\n",
      "\n",
      "    .indeed-apply-button:hover { filter:progid:DXImageTransform.Microsoft.gradient(startColorstr='#6D99F6', endColorstr='#1B45A3', GradientType=0);background-image: -webkit-gradient(linear, center top, center bottom, from(#6D99F6), to(#1B45A3)) !important;background-image: -webkit-linear-gradient(top, #6D99F6, #1B45A3) !important;background-image: -moz-linear-gradient(top, #6D99F6, #1B45A3) !important;background-image: -o-linear-gradient(top, #6D99F6, #1B45A3) !important;background-image: -ms-linear-gradient(top, #6D99F6, #1B45A3) !important;background-image: linear-gradient(top, #6D99F6, #1B45A3) !important; }\n",
      "\n",
      "    .indeed-apply-state-clicked .indeed-apply-button,\n",
      "    .indeed-apply-button:active { filter:progid:DXImageTransform.Microsoft.gradient(startColorstr='#B3BACA', endColorstr='#7C8493', GradientType=0);background-image: -webkit-gradient(linear, center top, center bottom, from(#B3BACA), to(#7C8493)) !important;background-image: -webkit-linear-gradient(top, #B3BACA, #7C8493) !important;background-image: -moz-linear-gradient(top, #B3BACA, #7C8493) !important;background-image: -o-linear-gradient(top, #B3BACA, #7C8493) !important;background-image: -ms-linear-gradient(top, #B3BACA, #7C8493) !important;background-image: linear-gradient(top, #B3BACA, #7C8493) !important;-webkit-box-shadow: none !important;-moz-box-shadow: none !important;box-shadow: none !important; }\n",
      "\n",
      "    .indeed-apply-button-inner { display : inline-block !important; height : 31px !important; -moz-border-radius : 6px !important; border-radius : 6px !important; font : 18px 'Helvetica Neue','Helvetica',Arial !important; font-weight : 200 !important; text-decoration : none !important; text-shadow : 0px 1px #F1F1F4 !important;background-color:#D9D9E2;  color: #FF6703;filter:progid:DXImageTransform.Microsoft.gradient(startColorstr='#FAFAFB', endColorstr='#D9D9E2', GradientType=0);background-image: -webkit-gradient(linear, center top, center bottom, from(#FAFAFB), to(#D9D9E2)) !important;background-image: -webkit-linear-gradient(top, #FAFAFB, #D9D9E2) !important;background-image: -moz-linear-gradient(top, #FAFAFB, #D9D9E2) !important;background-image: -o-linear-gradient(top, #FAFAFB, #D9D9E2) !important;background-image: -ms-linear-gradient(top, #FAFAFB, #D9D9E2) !important;background-image: linear-gradient(top, #FAFAFB, #D9D9E2) !important; }\n",
      "\n",
      "    .indeed-apply-button:active .indeed-apply-button-inner { filter:progid:DXImageTransform.Microsoft.gradient(startColorstr='#E8E8E9', endColorstr='#CBCBD3', GradientType=0);background-image: -webkit-gradient(linear, center top, center bottom, from(#E8E8E9), to(#CBCBD3)) !important;background-image: -webkit-linear-gradient(top, #E8E8E9, #CBCBD3) !important;background-image: -moz-linear-gradient(top, #E8E8E9, #CBCBD3) !important;background-image: -o-linear-gradient(top, #E8E8E9, #CBCBD3) !important;background-image: -ms-linear-gradient(top, #E8E8E9, #CBCBD3) !important;background-image: linear-gradient(top, #E8E8E9, #CBCBD3) !important; }\n",
      "\n",
      "    .indeed-apply-button-label {cursor: pointer; text-align : center !important; border:0; background: transparent;font-size: 12px; font-family: Arial, sans-serif; padding:3px 14px 2px 12px; margin:0; line-height: 26px; }\n",
      "\n",
      "    .indeed-apply-button:active .indeed-apply-button-label,\n",
      "    .indeed-apply-state-clicked .indeed-apply-button-label { -ms-filter: \"progid:DXImageTransform.Microsoft.Alpha(Opacity=0.75)\" !important;filter: alpha(opacity=75) !important;-moz-opacity: 0.75 !important;-khtml-opacity: 0.75 !important;opacity: 0.75 !important; }\n",
      "\n",
      "    #talertemail, #balertemail {  height: 27px; line-height: 24px; padding-left: 6px; padding-right: 6px; font-size: 14px; font-family: Arial, sans-serif; }\n",
      "\n",
      "    .jobalertform-terms-outer-wrapper label {  position: fixed;  font-size: 1px;  transform: scale(0.3);  }\n",
      "\n",
      "    .jobalertform-terms-inner-wrapper {  position: relative;  z-index: 20;  width: 50%;  background: #ebebeb;  height: 12px;  }\n",
      "              </style>\n",
      "             </form>\n",
      "             <span class=\"caption\">\n",
      "              You can cancel email alerts at any time.\n",
      "             </span>\n",
      "            </div>\n",
      "           </div>\n",
      "          </div>\n",
      "         </div>\n",
      "         <div id=\"femp_list\">\n",
      "          <div class=\"femp_header\">\n",
      "           Company with data scientist $20,000 jobs\n",
      "          </div>\n",
      "          <div class=\"femp_item\">\n",
      "           <div class=\"femp_logo\">\n",
      "            <a href=\"/cmp/Kpmg\" onmousedown=\"this.href = appendParamsOnce(this.href, 'tk=1bll9fe210m9b3ng&amp;campaignid=femp&amp;from=femp');\" rel=\"noopener\" target=\"_blank\">\n",
      "             <img alt=\"KPMG\" src=\"https://d2q79iu7y748jz.cloudfront.net/s/_logo/935de59a14e73fdf8bbaefe2837a7817\" width=\"120\"/>\n",
      "            </a>\n",
      "           </div>\n",
      "           <div class=\"femp_cmp\">\n",
      "            <a class=\"femp_cmp_link\" href=\"/cmp/Kpmg\" onmousedown=\"this.href = appendParamsOnce(this.href, 'tk=1bll9fe210m9b3ng&amp;campaignid=femp&amp;from=femp');\" rel=\"noopener\" target=\"_blank\">\n",
      "             KPMG\n",
      "            </a>\n",
      "           </div>\n",
      "           <div class=\"femp_desc\">\n",
      "            With passion and purpose we work shoulder-to-shoulder with you, integrating innovative approaches and deep expertise to deliver real results\n",
      "           </div>\n",
      "           <div class=\"featemp_sjl\" id=\"featemp_sj\" style=\"display: none\">\n",
      "            <div id=\"indJobContent\">\n",
      "            </div>\n",
      "           </div>\n",
      "           <script type=\"text/javascript\">\n",
      "            var ind_nr = true;\n",
      "        var ind_pub = '8772657697788355';\n",
      "        var ind_el = 'indJobContent';\n",
      "        var ind_pf = '';\n",
      "        var ind_q = '';\n",
      "        var ind_fcckey = 'ecbee8f621ec09f2';\n",
      "        var ind_l = 'New York';\n",
      "        var ind_chnl = 'KPMG';\n",
      "        var ind_n = 3;\n",
      "        var ind_d = '';\n",
      "        var ind_t = 60;\n",
      "        var ind_c = 30;\n",
      "        var ind_rq = 'data scientist $20,000';\n",
      "           </script>\n",
      "           <script src=\"//jobroll.indeed.com/jobroll-widget-v3-fc2.js\" type=\"text/javascript\">\n",
      "           </script>\n",
      "           <script type=\"text/javascript\">\n",
      "            window.indeedJobroll.origJobsCallback = window.indeedJobroll.jobsCallback;\n",
      "        window.indeedJobroll.jobsCallback=function(contentId, content) {\n",
      "            var sjDiv = document.getElementById('featemp_sj');\n",
      "            if (content.length <= 33 && sjDiv) {\n",
      "                sjDiv.style.display = 'none';\n",
      "            } else {\n",
      "                if (sjDiv) { sjDiv.style.display = 'block'; }\n",
      "                window.indeedJobroll.origJobsCallback(contentId, content);\n",
      "            }\n",
      "        };\n",
      "           </script>\n",
      "           <div class=\"femp_links\">\n",
      "            <div class=\"jobs\">\n",
      "             <a href=\"/jobs?q=company%3A%22KPMG%22&amp;l=New+York\" onmousedown=\"this.href = appendParamsOnce(this.href, '&amp;from=femp');\">\n",
      "              Jobs (165)\n",
      "             </a>\n",
      "            </div>\n",
      "            <div class=\"reviews\">\n",
      "             <a href=\"/cmp/Kpmg/reviews\" onmousedown=\"this.href = appendParamsOnce(this.href, '&amp;campaignid=femp&amp;from=femp');\">\n",
      "              Reviews (3,272)\n",
      "             </a>\n",
      "             <span class=\"ratings\">\n",
      "              <span class=\"rating\" style=\"width:51.0px\">\n",
      "               <!-- -->\n",
      "              </span>\n",
      "             </span>\n",
      "            </div>\n",
      "            <div class=\"photos\">\n",
      "             <a href=\"/cmp/Kpmg/photos\" onmousedown=\"this.href = appendParamsOnce(this.href, '&amp;campaignid=femp&amp;from=femp');\">\n",
      "              Photos (29)\n",
      "             </a>\n",
      "            </div>\n",
      "            <div class=\"salaries\">\n",
      "             <a href=\"/cmp/Kpmg/salaries\" onmousedown=\"this.href = appendParamsOnce(this.href, '&amp;campaignid=femp&amp;from=femp');\">\n",
      "              Salaries (4,943)\n",
      "             </a>\n",
      "            </div>\n",
      "           </div>\n",
      "          </div>\n",
      "         </div>\n",
      "        </td>\n",
      "       </tr>\n",
      "      </table>\n",
      "      <div class=\"prime-popover\" id=\"prime-popover-background\">\n",
      "      </div>\n",
      "      <div class=\"prime-popover\" id=\"prime-popover-div\">\n",
      "       <div id=\"prime-popover-x\">\n",
      "        <button aria-label=\"close\" id=\"prime-popover-close-button\">\n",
      "         <span>\n",
      "          Ã\n",
      "         </span>\n",
      "        </button>\n",
      "       </div>\n",
      "       <style type=\"text/css\">\n",
      "        #prime_promo_logos {\n",
      "        width: 620px;\n",
      "        height: 436px;\n",
      "    }\n",
      "\n",
      "    #prime_promo_logos .heading_logo_div {\n",
      "        margin: 30px 0 24px 0;\n",
      "        text-align: center;\n",
      "    }\n",
      "\n",
      "    #prime_promo_logos .heading_logo_div .heading_logo {\n",
      "        max-height: 50px;\n",
      "        vertical-align: middle;\n",
      "    }\n",
      "\n",
      "    #prime_promo_logos .heading {\n",
      "        font-size: 24px;\n",
      "        color: #ff6600;\n",
      "        text-align: center;\n",
      "        line-height: 26px;\n",
      "    }\n",
      "\n",
      "    #prime_promo_logos .subheading {\n",
      "        font-size: 15px;\n",
      "        color: #666666;\n",
      "        text-align: center;\n",
      "        margin-top: 15px;\n",
      "        margin-bottom: 25px;\n",
      "    }\n",
      "\n",
      "    #prime_promo_logos .content {\n",
      "        background: #F8F8F8;\n",
      "    }\n",
      "\n",
      "    #prime_promo_logos .content .legal {\n",
      "        font-size: 11px;\n",
      "        color: #666666;\n",
      "        padding-top: 15px;\n",
      "        padding-bottom: 20px;\n",
      "        text-align: center;\n",
      "    }\n",
      "\n",
      "    #prime_promo_logos .apply_div {\n",
      "        margin-top: 22px;\n",
      "        margin-bottom: 31px;\n",
      "    }\n",
      "\n",
      "    #learnMore {\n",
      "        color: #FFFFFF;\n",
      "        text-decoration: none !important;\n",
      "        font-size: 18px;\n",
      "        font-weight: bold;\n",
      "    }\n",
      "\n",
      "    #learnMore:hover,  #learnMore:focus {\n",
      "        text-decoration: none !important;\n",
      "    }\n",
      "\n",
      "    #prime_promo_logos .logo_div div {\n",
      "        display: inline-block;\n",
      "        width: 144px;\n",
      "        height: 35px;\n",
      "        text-align: center;\n",
      "    }\n",
      "\n",
      "    #prime_promo_logos .logo {\n",
      "        padding: 0 22.5px 0 22.5px;\n",
      "        max-width: 576px;\n",
      "        max-height: 94px;\n",
      "    }\n",
      "\n",
      "    #prime_promo_logos .logo_center_helper {\n",
      "        display: inline-block;\n",
      "        height: 100%;\n",
      "        vertical-align: middle;\n",
      "    }\n",
      "\n",
      "    #learnMore_div {\n",
      "        text-align: center;\n",
      "    }\n",
      "    #hiddenPrimeButton {\n",
      "        height: 0;\n",
      "        border: 0;\n",
      "        width: 0;\n",
      "        padding: 0;\n",
      "    }\n",
      "       </style>\n",
      "       <div id=\"prime_promo_logos\">\n",
      "        <div class=\"heading_logo_div\">\n",
      "         <span class=\"logo_center_helper\">\n",
      "         </span>\n",
      "         <img alt=\"Indeed Prime\" class=\"heading_logo\" src=\"/images/prime/indeed_prime_logo.png\"/>\n",
      "        </div>\n",
      "        <div class=\"heading\">\n",
      "         <b>\n",
      "          3 minutes\n",
      "         </b>\n",
      "         could get you\n",
      "        </div>\n",
      "        <div class=\"heading\">\n",
      "         <b>\n",
      "          10 offers\n",
      "         </b>\n",
      "         from top tech companies\n",
      "        </div>\n",
      "        <div class=\"apply_div\" id=\"learnMore_div\">\n",
      "         <button autofocus=\"\" id=\"hiddenPrimeButton\" tabindex=\"-1\">\n",
      "         </button>\n",
      "         <a class=\"roundedCorner indeedblue\" href=\"/promo/prime\" id=\"learnMore\" onclick=\"this.href = appendParamsOnce( this.href, '?from=primepopover&amp;subfrom=primepopover&amp;trk.origin=jobsearch&amp;trk.variant=primepopover&amp;trk.tk=1bll9fe0p0m9b3hl&amp;vertical=TECH&amp;x_isid=primepopover&amp;x_ikw=data+scientist+%2420%2C000&amp;x_sid=primepopover&amp;x_kw=data+scientist+%2420%2C000')\" role=\"button\">\n",
      "          Learn More\n",
      "         </a>\n",
      "        </div>\n",
      "        <div class=\"content\">\n",
      "         <div class=\"logo_div\">\n",
      "          <div>\n",
      "           <span class=\"logo_center_helper\">\n",
      "           </span>\n",
      "           <img alt=\"Dropbox, Evernote, Facebook, Redfin, Twilio, Uber, Slack... and more!\" class=\"logo\" src=\"/images/prime/cmp-logos.png\"/>\n",
      "          </div>\n",
      "         </div>\n",
      "         <div class=\"legal\">\n",
      "          Representative Companies Using Indeed Prime\n",
      "         </div>\n",
      "        </div>\n",
      "       </div>\n",
      "       <img height=\"1\" src=\"/imgping?type=primepromo&amp;keyword=data scientist $20,000&amp;location=New York&amp;vertical=TECH&amp;promo=primepopover\" width=\"1\"/>\n",
      "      </div>\n",
      "      <style type=\"text/css\">\n",
      "       #prime-popover-background {\n",
      "        z-index: 2;\n",
      "        background: #000000;\n",
      "        width: 100%;\n",
      "        height: 100%;\n",
      "        opacity: .30;\n",
      "        filter: alpha(opacity=30);\n",
      "        top: 0;\n",
      "    }\n",
      "    #prime-popover-x {\n",
      "        float: right;\n",
      "        margin: 1px 1px 0 0;\n",
      "        cursor: pointer;\n",
      "        font-weight: bold;\n",
      "        font-size: 18px;\n",
      "        color: #666;\n",
      "    }\n",
      "    #prime-popover-close-button {\n",
      "        background:none;\n",
      "        border:none;\n",
      "        font-weight: bold;\n",
      "        font-size: 18px;\n",
      "        color: #666;\n",
      "    }\n",
      "    #prime-popover-close-button:hover {\n",
      "        cursor: pointer;\n",
      "    }\n",
      "    .prime-popover {\n",
      "        position: fixed;\n",
      "        display: none;\n",
      "    }\n",
      "    #prime-popover-div {\n",
      "        z-index: 3;\n",
      "        height: auto;\n",
      "        width: auto;\n",
      "        background: #ffffff;\n",
      "        display: none; /*hide before the cookie check*/\n",
      "        max-width: 620px;\n",
      "    }\n",
      "    \n",
      "    #prime_promo {\n",
      "        background:#ffffff\n",
      "    }\n",
      "      </style>\n",
      "      <script type=\"text/javascript\">\n",
      "       window['primePopoverShown'] = 'popover';\n",
      "      </script>\n",
      "      <script>\n",
      "       var focusHandlers = [];\n",
      "var linkHighlighter = new LinkHighlighter();\n",
      "focusHandlers.push(googBind(linkHighlighter.fadeToOriginalColor, linkHighlighter));\n",
      "var lostFocusHandlers = [];\n",
      "lostFocusHandlers.push(googBind(linkHighlighter.clickedAway, linkHighlighter, \"#551a8b\"));\n",
      "\n",
      "var didYouApplyPrompt = new DidYouApplyPrompt('1bll9fe210m9b3ng', 60, 'serp',\n",
      "false);\n",
      "focusHandlers.push(googBind(didYouApplyPrompt.returnedToPage, didYouApplyPrompt));\n",
      "lostFocusHandlers.push(googBind(didYouApplyPrompt.leftPage, didYouApplyPrompt));\n",
      "didYouApplyPrompt.dyaChangeFromCookie();\n",
      "var clickTime = new ClickTime(window.tk, 'serp', 'jobtitle', focusHandlers, lostFocusHandlers);\n",
      "      </script>\n",
      "      <script>\n",
      "       enableAdometry();\n",
      "      </script>\n",
      "      <style type=\"text/css\">\n",
      "       #secondary_nav a,#secondary_nav a:link,#secondary_nav a:visited{color:#77c;text-decoration:none}#secondary_nav a:hover{text-decoration:underline}\n",
      "      </style>\n",
      "      <!-- jobs -->\n",
      "      <div id=\"footerWrapper\" role=\"contentinfo\" style=\"text-align:center;\">\n",
      "       <div id=\"footer\" style=\"text-align:left;\">\n",
      "        <div class=\"separator_bottom\">\n",
      "        </div>\n",
      "        <div id=\"secondary_nav\">\n",
      "         <div style=\"margin: 1em;\">\n",
      "          <span class=\"gaj_heading\">\n",
      "           Indeed helps people get jobs:\n",
      "          </span>\n",
      "          <a class=\"sl\" href=\"/promo/gotajob\" onmousedown=\"null\">\n",
      "           Over 10 million stories shared\n",
      "          </a>\n",
      "         </div>\n",
      "         <a href=\"/\" id=\"jobs_product_link\" title=\"Jobs\">\n",
      "          Jobs\n",
      "         </a>\n",
      "         -\n",
      "         <a href=\"/Best-Places-to-Work\" id=\"companies_product_link\" title=\"Browse Companies\">\n",
      "          Browse Companies\n",
      "         </a>\n",
      "         -\n",
      "         <a href=\"/salaries\" id=\"salaries_product_link\" title=\"Salary Search\">\n",
      "          Salaries\n",
      "         </a>\n",
      "         -\n",
      "         <a href=\"/jobtrends/category-trends\">\n",
      "          Job Category Trends\n",
      "         </a>\n",
      "         -\n",
      "         <a href=\"/forum\" id=\"forums_product_link\" title=\"Employment Forums\">\n",
      "          Forums\n",
      "         </a>\n",
      "         -\n",
      "         <script type=\"text/javascript\">\n",
      "          var jobsProductLink = document.getElementById('jobs_product_link');\n",
      "document.getElementById('forums_product_link').onclick = function() { if ( !document.js ) { return; } var q = document.js.q.value; if ( q ) { window.location = '/forum/?q=' + urlencode( q ) + '&l=' + urlencode( document.js.l.value ); return false; } };document.getElementById('companies_product_link').onclick = function() { window.location = '/Best-Places-to-Work?campaignid=jobs'; return false;};\n",
      "         </script>\n",
      "         <a href=\"/find-jobs.jsp\">\n",
      "          Browse Jobs\n",
      "         </a>\n",
      "         -\n",
      "         <a href=\"/tools/jobseeker/\">\n",
      "          Tools\n",
      "         </a>\n",
      "         -\n",
      "         <a href=\"http://www.indeed.jobs\">\n",
      "          Work at Indeed\n",
      "         </a>\n",
      "         -\n",
      "         <a href=\"/publisher\">\n",
      "          API\n",
      "         </a>\n",
      "         -\n",
      "         <a href=\"/intl/en/about.html\">\n",
      "          <span style=\"white-space: nowrap;\">\n",
      "           About\n",
      "          </span>\n",
      "         </a>\n",
      "         -\n",
      "         <a href=\"https://indeed.zendesk.com/hc/en-us\">\n",
      "          Help Center\n",
      "         </a>\n",
      "         <style type=\"text/css\">\n",
      "          #footer-legal {\n",
      "margin-top: 10px;\n",
      "font-size: 9pt;\n",
      "}\n",
      "         </style>\n",
      "         <div id=\"footer-legal\">\n",
      "          <div class=\"legal-footer\">\n",
      "           Â©2017 Indeed -\n",
      "           <a href=\"/legal\">\n",
      "            Cookies, Privacy and Terms\n",
      "           </a>\n",
      "          </div>\n",
      "         </div>\n",
      "        </div>\n",
      "       </div>\n",
      "      </div>\n",
      "      <script defer=\"\" src=\"/tos/banner.js?ctk=1bll9fe0p0m9b3hl\">\n",
      "      </script>\n",
      "     </td>\n",
      "    </tr>\n",
      "   </table>\n",
      "   <script type=\"text/javascript\">\n",
      "    function sm_cv_tag(activityId) {\n",
      "            var ebRand = Math.random()+'';\n",
      "            ebRand = ebRand * 1000000;\n",
      "\n",
      "            var tagContainer = document.body.appendChild(document.createElement(\"div\"));\n",
      "            tagContainer.style.position=\"absolute\";\n",
      "            tagContainer.style.top=\"0\";\n",
      "            tagContainer.style.left=\"0\";\n",
      "            tagContainer.style.width=\"1px\";\n",
      "            tagContainer.style.height=\"1px\";\n",
      "            tagContainer.style.display=\"none\";\n",
      "\n",
      "            var jsTag = document.createElement('script');\n",
      "            jsTag.src = '//bs.serving-sys.com/Serving/ActivityServer.bs?cn=as&ActivityID=' + activityId + '&rnd=' + ebRand;\n",
      "            jsTag.setAttribute('crossorigin', 'anonymous');\n",
      "            jsTag.style.width=\"1px\";\n",
      "            jsTag.style.height=\"1px\";\n",
      "            jsTag.style.border=\"0\";\n",
      "            jsTag.async = 1;\n",
      "\n",
      "            var noScript = document.createElement(\"noscript\");\n",
      "            var noScriptText = '<img width=\"1\" height=\"1\" style=\"border:0\" src=\"//bs.serving-sys.com/Serving/ActivityServer.bs?cn=as&ActivityID=' + activityId + '&ns=1\"/>';\n",
      "\n",
      "            // IE less than 9 and RCs do not support innerHTML on some DOM elements, but supports .text for it\n",
      "            if (((typeof noScript.canHaveHTML) === \"boolean\") && (noScript.canHaveHTML === false)) { // canHaveHTML only exists for IE\n",
      "                noScript.text = noScriptText;\n",
      "            } else {\n",
      "                noScript.innerHTML = noScriptText;\n",
      "            }\n",
      "\n",
      "            tagContainer.appendChild(jsTag);\n",
      "            tagContainer.appendChild(noScript);\n",
      "        }\n",
      "   </script>\n",
      "   <script type=\"text/javascript\">\n",
      "    <!--\n",
      "(function ( tk ) { if ( tk && document.images ) { var s=\"/\", q=\"?\", a=\"&\", e=\"=\"; rpc(s+\"rpc\"+s+\"log\"+q+\"a\"+e+\"jsv\"+a+\"tk\"+e+tk); } })('1bll9fe210m9b3ng');\n",
      "function jsall_loaded() {\n",
      "\n",
      "\n",
      "initProcessLeftoverDwellEntries();\n",
      "\n",
      "    detectBrowserState('jobsearch', '1bll9fe210m9b3ng');\n",
      "\n",
      "attachSjBlock('');\n",
      "attachJaBlock('');\n",
      "}\n",
      "if (window['closureReady'] === true) {\n",
      "jsall_loaded();\n",
      "}\n",
      "//-->\n",
      "   </script>\n",
      "   <script type=\"text/javascript\">\n",
      "    PENDING_ANALYTICS_VARS = window.PENDING_ANALYTICS_VARS || [];\n",
      "PENDING_ANALYTICS_VARS[PENDING_ANALYTICS_VARS.length] = ['_setCustomVar', 5, 'loggedIn', 'false', 3];\n",
      "   </script>\n",
      "   <script type=\"text/javascript\">\n",
      "    var ga_domains = [];\n",
      "        ga_domains.push('indeed.co.in');ga_domains.push('indeed.lu');ga_domains.push('indeed.fr');ga_domains.push('indeed.de');ga_domains.push('indeed.com.br');ga_domains.push('indeed.co.uk');ga_domains.push('indeed.hk');ga_domains.push('indeed.fi');ga_domains.push('indeed.pt');ga_domains.push('indeed.jp');ga_domains.push('indeed.com');ga_domains.push('indeed.com.sg');ga_domains.push('indeed.nl');ga_domains.push('indeed.com.pk');ga_domains.push('indeed.cl');ga_domains.push('indeed.es');ga_domains.push('indeed.co.ve');ga_domains.push('indeed.ae');ga_domains.push('indeed.com.mx');ga_domains.push('indeed.com.my');ga_domains.push('indeed.ch');ga_domains.push('indeed.com.co');ga_domains.push('indeed.com.ph');ga_domains.push('indeed.co.za');ga_domains.push('indeed.ie');ga_domains.push('indeed.com.au');ga_domains.push('indeed.ca');ga_domains.push('indeed.com.pe');\n",
      "\n",
      "        (function (i, s, o, g, r, a, m) {\n",
      "            i['GoogleAnalyticsObject'] = r;\n",
      "            i[r] = i[r] || function () {\n",
      "                (i[r].q = i[r].q || []).push(arguments)\n",
      "            }, i[r].l = 1 * new Date();\n",
      "            a = s.createElement(o),\n",
      "                    m = s.getElementsByTagName(o)[0];\n",
      "            a.async = 1;\n",
      "            a.src = g;\n",
      "            m.parentNode.insertBefore(a, m)\n",
      "        })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');\n",
      "\n",
      "        var ga = ga || [];\n",
      "        ga('create', 'UA-90780-1', 'auto', {\n",
      "            'allowLinker': true\n",
      "        });\n",
      "        ga('require', 'linkid');\n",
      "        ga('require', 'linker');\n",
      "        ga('linker:autoLink', ga_domains, false, true);\n",
      "        ga('require', 'displayfeatures');\n",
      "        ga('send', 'pageview');\n",
      "\n",
      "        \n",
      "        (function () {\n",
      "            if (window.PENDING_ANALYTICS_VARS && window.PENDING_ANALYTICS_VARS.length > 0) {\n",
      "                for (var i in PENDING_ANALYTICS_VARS) {\n",
      "                    ga('set', PENDING_ANALYTICS_VARS[i][2], PENDING_ANALYTICS_VARS[i][3]);\n",
      "                }\n",
      "            }\n",
      "        })();\n",
      "   </script>\n",
      "   <script>\n",
      "    !function(f,b,e,v,n,t,s){if(f.fbq)return;n=f.fbq=function(){n.callMethod?\n",
      "            n.callMethod.apply(n,arguments):n.queue.push(arguments)};if(!f._fbq)f._fbq=n;\n",
      "        n.push=n;n.loaded=!0;n.version='2.0';n.queue=[];t=b.createElement(e);t.async=!0;\n",
      "        t.src=v;s=b.getElementsByTagName(e)[0];s.parentNode.insertBefore(t,s)}(window,\n",
      "            document,'script','https://connect.facebook.net/en_US/fbevents.js');\n",
      "\n",
      "    fbq('init', '579216298929618');\n",
      "    fbq('track', \"PageView\");\n",
      "   </script>\n",
      "   <noscript>\n",
      "    <img height=\"1\" src=\"https://www.facebook.com/tr?id=579216298929618&amp;ev=PageView&amp;noscript=1\" style=\"display:none\" width=\"1\"/>\n",
      "   </noscript>\n",
      "   <script>\n",
      "    var _comscore = _comscore || [];\n",
      "_comscore.push({ c1: \"2\", c2: \"6486505\", c4:\"www.indeed.com/jobs\", c15:\"1bll9fe0p0m9b3hl\"});\n",
      "(function() { var s = document.createElement(\"script\"), el = document.getElementsByTagName(\"script\")[0]; s.async = true; s.src = (document.location.protocol == \"https:\" ? \"https://sb\" : \"http://b\") + \".scorecardresearch.com/beacon.js\"; el.parentNode.insertBefore(s, el); })();\n",
      "   </script>\n",
      "   <noscript>\n",
      "    <img alt=\"\" height=\"0\" src=\"http://b.scorecardresearch.com/p?c1=2&amp;c2=6486505&amp;c4=www.indeed.com%2Fjobs&amp;c15=1bll9fe0p0m9b3hl&amp;cv=2.0&amp;cj=1\" style=\"display:none\" width=\"0\"/>\n",
      "   </noscript>\n",
      "   <img height=\"0\" src=\"//log.dmtry.com/redir/1/0/4102/1011464/0/1/189/0/1017/1.ver?at=v&amp;d=PxConv\" width=\"0\"/>\n",
      "  </link>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#grab html of the page\n",
    "html=requests.get(URL)\n",
    "#convert into soup object\n",
    "soup=BeautifulSoup(html.text,'html.parser')\n",
    "print (soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at one result more closely. A single result looks like\n",
    "```JSON\n",
    "<div class=\" row result\" data-jk=\"2480d203f7e97210\" data-tn-component=\"organicJob\" id=\"p_2480d203f7e97210\" itemscope=\"\" itemtype=\"http://schema.org/JobPosting\">\n",
    "<h2 class=\"jobtitle\" id=\"jl_2480d203f7e97210\">\n",
    "<a class=\"turnstileLink\" data-tn-element=\"jobTitle\" onmousedown=\"return rclk(this,jobmap[0],1);\" rel=\"nofollow\" target=\"_blank\" title=\"AVP/Quantitative Analyst\">AVP/Quantitative Analyst</a>\n",
    "</h2>\n",
    "<span class=\"company\" itemprop=\"hiringOrganization\" itemtype=\"http://schema.org/Organization\">\n",
    "<span itemprop=\"name\">\n",
    "<a href=\"/cmp/Alliancebernstein?from=SERP&campaignid=serp-linkcompanyname&fromjk=2480d203f7e97210&jcid=b374f2a780e04789\" target=\"_blank\">\n",
    "    AllianceBernstein</a></span>\n",
    "</span>\n",
    "<tr>\n",
    "<td class=\"snip\">\n",
    "<nobr>$117,500 - $127,500 a year</nobr>\n",
    "<div>\n",
    "<span class=\"summary\" itemprop=\"description\">\n",
    "C onduct quantitative and statistical research as well as portfolio management for various investment portfolios. Collaborate with Quantitative Analysts and</span>\n",
    "</div>\n",
    "</div>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "</div>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this has some more verbose elements removed, we can see that there is some structure to the above:\n",
    "- The salary is available in a nobr element inside of a td element with class='snip.\n",
    "- The title of a job is in a link with class set to jobtitle and a data-tn-element=\"jobTitle.\n",
    "- The location is set in a span with class='location'.\n",
    "- The company is set in a span with class='company'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write 4 functions to extract these items (one function for each): location, company, job title, and salary.Â¶\n",
    "Example\n",
    "```python\n",
    "def extract_location_from_result(result):\n",
    "    return result.find ...\n",
    "```\n",
    "\n",
    "##### - Make sure these functions are robust and can handle cases where the data/field may not be available.\n",
    ">- Remember to check if a field is empty or None for attempting to call methods on it\n",
    ">- Remember to use try/except if you anticipate errors.\n",
    "\n",
    "- **Test** the functions on the results above and simple examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'IBM\\n\\n - \\n\\n16,657 reviews\\n - New York, NY']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def salary_from_result(soup):                                                     #initialize salary list\n",
    "#     for div in soup.find_all(name='div', attrs={'class':'row'}):     #iterate through infor in div\n",
    "#         salary = []   \n",
    "#         try:\n",
    "#             salary.append(div.find('nobr').text)                     #appending to salary list with div using .find to determine if string nobr occrs in div.class.row \n",
    "#         except:\n",
    "#             try:\n",
    "#                 div_two = div.find(name='div', attrs={'class':'sjcl'}) #also check if salary listed under sjcl as it is for a few salaries \n",
    "#                 salary.append(div_two.text.strip())\n",
    "#             except:\n",
    "#                 salary.append('Not Listed')     #if nothing listed show Not listed\n",
    "#     return(salary)\n",
    "# salary_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<span class=\"no-wrap\"><b>relevance</b> -\\n            <a href=\"/jobs?q=data+scientist+%2420%2C000&amp;l=New+York&amp;sort=date\" rel=\"nofollow\">date</a></span>,\n",
       "  <span class=\"no-wrap\">$185,000 a year</span>]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def salary_result(soup):\n",
    "#     salary = []\n",
    "#     for div in soup.find_all(name='div', attrs={'class':'row'}): \n",
    "#         for x in soup.find_all('span',{'class':'no-wrap'}):\n",
    "#             salary.append(soup.find_all('span',{'class':'no-wrap'}))\n",
    "#             return salary\n",
    "# salary_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my function\n",
    "def salary_from_result(result):\n",
    "    for a in soup.find_all('span',{'class':'nobr'}):\n",
    "        print a.text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print salary_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is Baurs Code.I would usually use this as a reference and work to create my own , but due to the impending due date,\n",
    "#the time it takes to scrape from the web, and what remains to do in the project. I did create a function to process\n",
    "#the salary, but I later(too late), realized in order to properly process salaries and adjusted them so calculations \n",
    "#are possible from the dataframe the parsing and resetting of salaries had to be done during the scrapper and not in the dataframe. \n",
    "#If this is an unacceptable move,please let me know and I will spend the weekend working to create my own.\n",
    "def salary(div):\n",
    "    if div.find(\"span\", {\"class\":\"no-wrap\"}) != None:\n",
    "        js = str(div.find(\"span\", {\"class\":\"no-wrap\"}).text.strip()).split()\n",
    "        #print js\n",
    "        #print float(re.sub(\",\", \"\",re.findall(r\"\\d+\\,\\d+|\\d+\\.\\d+\",js[0])[0]))\n",
    "        if js[-1] == 'year':\n",
    "            if js[1] == '-':\n",
    "                js1 = float(re.sub(\",\",\"\",(re.findall(r\"\\d+\\,\\d+|\\d+\\.\\d+\",js[0])[0])))\n",
    "                #print js1\n",
    "                js2 = float(re.sub(\",\",\"\",(re.findall(r\"\\d+\\,\\d+|\\d+\\.\\d+\",js[2])[0])))\n",
    "                #print js2\n",
    "                js = (js1+js2)/2\n",
    "                #print js\n",
    "            else: js = float(re.sub(\",\",\"\",(re.findall(r\"\\d+\\,\\d+|\\d+\\.\\d+\",js[0])[0])))\n",
    "            #print js\n",
    "        elif js[-1] == 'hour':\n",
    "            if js[1] == '-':\n",
    "                #print js[0], js[1], js[2]\n",
    "                js1 = float(re.findall(r\"\\d+\",js[0])[0])\n",
    "                #print js1\n",
    "                js2 = float(re.findall(r\"\\d+\",js[2])[0])\n",
    "                #print js2\n",
    "                js = (js1+js2)/2*1600\n",
    "                #print js\n",
    "            else: js = float(re.findall(r\"\\d+\",js[0])[0])*1600\n",
    "        elif js[-1] == 'day':\n",
    "            if js[1] == '-':\n",
    "                #print js[0], js[1], js[2]\n",
    "                js1 = float(re.findall(r\"\\d+\",js[0])[0])\n",
    "                #print js1\n",
    "                js2 = float(re.findall(r\"\\d+\",js[2])[0])\n",
    "                #print js2\n",
    "                js = (js1+js2)/2*200\n",
    "                #print js\n",
    "            else: js = float(re.findall(r\"\\d+\",js[0])[0])*200\n",
    "        elif js[-1] == 'month':\n",
    "            if js[1] == '-':\n",
    "                #print js[0], js[1], js[2]\n",
    "                js1 = float(re.sub(\",\",\"\",(re.findall(r\"\\d+\\,\\d+|\\d+\\.\\d+\",js[0])[0])))\n",
    "                #print js1\n",
    "                js2 = float(re.sub(\",\",\"\",(re.findall(r\"\\d+\\,\\d+|\\d+\\.\\d+\",js[2])[0])))\n",
    "                #print js2\n",
    "                js = (js1+js2)/2*12\n",
    "                #print js\n",
    "            else: js = float(re.sub(\",\",\"\",(re.findall(r\"\\d+\\,\\d+|\\d+\\.\\d+\",js[0])[0])))*12\n",
    "    else: js = str('NaN')\n",
    "    #print js\n",
    "    return js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Data Scientist - Big Data & Analytics',\n",
       " u'Senior NLP Data Scientist',\n",
       " u'Data Scientist, Personalization and Recommendation',\n",
       " u'Data Analyst',\n",
       " u'Data Scientist',\n",
       " u'Data Scientist - Pricing',\n",
       " u'AVP - Machine Learning & Advance Analytics',\n",
       " u'Gain Theory \\u2013 Data Scientist/Statistical Modeler',\n",
       " u'Machine Learning Artificial Intelligence',\n",
       " u'Data Scientist II',\n",
       " u'Postdoctoral Position, Data Science/IoT',\n",
       " u'Marketing Data Scientist',\n",
       " u'Healthcare & Life Sciences - Data Scientist',\n",
       " u'Data Scientist',\n",
       " u'Data Scientist - Worldwide Advanced Analytics Team']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#function to find job titles located in class row sub class data-ten-element under jobTitle\n",
    "def title_from_result(soup): \n",
    "    title = []\n",
    "    for div in soup.find_all(name='div', attrs={'class':'row'}):\n",
    "        for a in div.find_all(name='a', attrs={'data-tn-element':'jobTitle'}): \n",
    "            title.append(a['title'])\n",
    "    return(title)\n",
    "title_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'New York, NY 10154',\n",
       " u'New York, NY',\n",
       " u'New York, NY',\n",
       " u'New York, NY 10018 (Clinton area)',\n",
       " u'New York, NY 10005 (Financial District area)',\n",
       " u'New York, NY 10003 (Greenwich Village area)',\n",
       " u'New York, NY 10022 (Midtown area)',\n",
       " u'New York, NY',\n",
       " u'New York, NY',\n",
       " u'New York, NY 10112 (Midtown area)',\n",
       " u'Brooklyn, NY',\n",
       " u'New York, NY',\n",
       " u'New York, NY 10154',\n",
       " u'New York, NY 10154',\n",
       " u'New York, NY']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list created from function looking for location\n",
    "def location_result(soup):\n",
    "    location = []\n",
    "    for x in soup.find_all(name='span', attrs={'class':'location'}):\n",
    "        location.append(x.text)\n",
    "    return location\n",
    "location_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Same list but cleaner\n",
    "def location_from_result(result):\n",
    "    for location in  soup.find_all('span',{'class':'location'}):\n",
    "        print location.text                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York, NY 10154\n",
      "New York, NY\n",
      "New York, NY\n",
      "New York, NY 10018 (Clinton area)\n",
      "New York, NY 10005 (Financial District area)\n",
      "New York, NY 10003 (Greenwich Village area)\n",
      "New York, NY 10022 (Midtown area)\n",
      "New York, NY\n",
      "New York, NY\n",
      "New York, NY 10112 (Midtown area)\n",
      "Brooklyn, NY\n",
      "New York, NY\n",
      "New York, NY 10154\n",
      "New York, NY 10154\n",
      "New York, NY\n"
     ]
    }
   ],
   "source": [
    "location_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'\\n\\n    KPMG',\n",
       " u'\\n    Elevano',\n",
       " u'\\n\\n\\n    Tumblr\\n',\n",
       " u'\\n\\n    Schireson Associates\\n',\n",
       " u'\\n\\n    Enterprise Select\\n',\n",
       " u'\\n\\n\\n    J.Crew Group, Inc.\\n',\n",
       " u'\\n\\n\\n    Credit Suisse\\n',\n",
       " u'\\n\\n\\n    GroupM\\n',\n",
       " u'\\n\\n    Amazon Web Services\\n',\n",
       " u'\\n\\n\\n    Comcast\\n',\n",
       " u'\\n\\n    Radiator Labs\\n',\n",
       " u'\\n\\n    Slice\\n',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n\\n    IBM',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n    Elevano',\n",
       " u'\\n\\n\\n    Tumblr\\n',\n",
       " u'\\n\\n    Schireson Associates\\n',\n",
       " u'\\n\\n    Enterprise Select\\n',\n",
       " u'\\n\\n\\n    J.Crew Group, Inc.\\n',\n",
       " u'\\n\\n\\n    Credit Suisse\\n',\n",
       " u'\\n\\n\\n    GroupM\\n',\n",
       " u'\\n\\n    Amazon Web Services\\n',\n",
       " u'\\n\\n\\n    Comcast\\n',\n",
       " u'\\n\\n    Radiator Labs\\n',\n",
       " u'\\n\\n    Slice\\n',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n\\n    IBM',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n    Elevano',\n",
       " u'\\n\\n\\n    Tumblr\\n',\n",
       " u'\\n\\n    Schireson Associates\\n',\n",
       " u'\\n\\n    Enterprise Select\\n',\n",
       " u'\\n\\n\\n    J.Crew Group, Inc.\\n',\n",
       " u'\\n\\n\\n    Credit Suisse\\n',\n",
       " u'\\n\\n\\n    GroupM\\n',\n",
       " u'\\n\\n    Amazon Web Services\\n',\n",
       " u'\\n\\n\\n    Comcast\\n',\n",
       " u'\\n\\n    Radiator Labs\\n',\n",
       " u'\\n\\n    Slice\\n',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n\\n    IBM',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n    Elevano',\n",
       " u'\\n\\n\\n    Tumblr\\n',\n",
       " u'\\n\\n    Schireson Associates\\n',\n",
       " u'\\n\\n    Enterprise Select\\n',\n",
       " u'\\n\\n\\n    J.Crew Group, Inc.\\n',\n",
       " u'\\n\\n\\n    Credit Suisse\\n',\n",
       " u'\\n\\n\\n    GroupM\\n',\n",
       " u'\\n\\n    Amazon Web Services\\n',\n",
       " u'\\n\\n\\n    Comcast\\n',\n",
       " u'\\n\\n    Radiator Labs\\n',\n",
       " u'\\n\\n    Slice\\n',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n\\n    IBM',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n    Elevano',\n",
       " u'\\n\\n\\n    Tumblr\\n',\n",
       " u'\\n\\n    Schireson Associates\\n',\n",
       " u'\\n\\n    Enterprise Select\\n',\n",
       " u'\\n\\n\\n    J.Crew Group, Inc.\\n',\n",
       " u'\\n\\n\\n    Credit Suisse\\n',\n",
       " u'\\n\\n\\n    GroupM\\n',\n",
       " u'\\n\\n    Amazon Web Services\\n',\n",
       " u'\\n\\n\\n    Comcast\\n',\n",
       " u'\\n\\n    Radiator Labs\\n',\n",
       " u'\\n\\n    Slice\\n',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n\\n    IBM',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n    Elevano',\n",
       " u'\\n\\n\\n    Tumblr\\n',\n",
       " u'\\n\\n    Schireson Associates\\n',\n",
       " u'\\n\\n    Enterprise Select\\n',\n",
       " u'\\n\\n\\n    J.Crew Group, Inc.\\n',\n",
       " u'\\n\\n\\n    Credit Suisse\\n',\n",
       " u'\\n\\n\\n    GroupM\\n',\n",
       " u'\\n\\n    Amazon Web Services\\n',\n",
       " u'\\n\\n\\n    Comcast\\n',\n",
       " u'\\n\\n    Radiator Labs\\n',\n",
       " u'\\n\\n    Slice\\n',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n\\n    IBM',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n    Elevano',\n",
       " u'\\n\\n\\n    Tumblr\\n',\n",
       " u'\\n\\n    Schireson Associates\\n',\n",
       " u'\\n\\n    Enterprise Select\\n',\n",
       " u'\\n\\n\\n    J.Crew Group, Inc.\\n',\n",
       " u'\\n\\n\\n    Credit Suisse\\n',\n",
       " u'\\n\\n\\n    GroupM\\n',\n",
       " u'\\n\\n    Amazon Web Services\\n',\n",
       " u'\\n\\n\\n    Comcast\\n',\n",
       " u'\\n\\n    Radiator Labs\\n',\n",
       " u'\\n\\n    Slice\\n',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n\\n    IBM',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n    Elevano',\n",
       " u'\\n\\n\\n    Tumblr\\n',\n",
       " u'\\n\\n    Schireson Associates\\n',\n",
       " u'\\n\\n    Enterprise Select\\n',\n",
       " u'\\n\\n\\n    J.Crew Group, Inc.\\n',\n",
       " u'\\n\\n\\n    Credit Suisse\\n',\n",
       " u'\\n\\n\\n    GroupM\\n',\n",
       " u'\\n\\n    Amazon Web Services\\n',\n",
       " u'\\n\\n\\n    Comcast\\n',\n",
       " u'\\n\\n    Radiator Labs\\n',\n",
       " u'\\n\\n    Slice\\n',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n\\n    IBM',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n    Elevano',\n",
       " u'\\n\\n\\n    Tumblr\\n',\n",
       " u'\\n\\n    Schireson Associates\\n',\n",
       " u'\\n\\n    Enterprise Select\\n',\n",
       " u'\\n\\n\\n    J.Crew Group, Inc.\\n',\n",
       " u'\\n\\n\\n    Credit Suisse\\n',\n",
       " u'\\n\\n\\n    GroupM\\n',\n",
       " u'\\n\\n    Amazon Web Services\\n',\n",
       " u'\\n\\n\\n    Comcast\\n',\n",
       " u'\\n\\n    Radiator Labs\\n',\n",
       " u'\\n\\n    Slice\\n',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n\\n    IBM',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n    Elevano',\n",
       " u'\\n\\n\\n    Tumblr\\n',\n",
       " u'\\n\\n    Schireson Associates\\n',\n",
       " u'\\n\\n    Enterprise Select\\n',\n",
       " u'\\n\\n\\n    J.Crew Group, Inc.\\n',\n",
       " u'\\n\\n\\n    Credit Suisse\\n',\n",
       " u'\\n\\n\\n    GroupM\\n',\n",
       " u'\\n\\n    Amazon Web Services\\n',\n",
       " u'\\n\\n\\n    Comcast\\n',\n",
       " u'\\n\\n    Radiator Labs\\n',\n",
       " u'\\n\\n    Slice\\n',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n\\n    IBM',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n    Elevano',\n",
       " u'\\n\\n\\n    Tumblr\\n',\n",
       " u'\\n\\n    Schireson Associates\\n',\n",
       " u'\\n\\n    Enterprise Select\\n',\n",
       " u'\\n\\n\\n    J.Crew Group, Inc.\\n',\n",
       " u'\\n\\n\\n    Credit Suisse\\n',\n",
       " u'\\n\\n\\n    GroupM\\n',\n",
       " u'\\n\\n    Amazon Web Services\\n',\n",
       " u'\\n\\n\\n    Comcast\\n',\n",
       " u'\\n\\n    Radiator Labs\\n',\n",
       " u'\\n\\n    Slice\\n',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n\\n    IBM',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n    Elevano',\n",
       " u'\\n\\n\\n    Tumblr\\n',\n",
       " u'\\n\\n    Schireson Associates\\n',\n",
       " u'\\n\\n    Enterprise Select\\n',\n",
       " u'\\n\\n\\n    J.Crew Group, Inc.\\n',\n",
       " u'\\n\\n\\n    Credit Suisse\\n',\n",
       " u'\\n\\n\\n    GroupM\\n',\n",
       " u'\\n\\n    Amazon Web Services\\n',\n",
       " u'\\n\\n\\n    Comcast\\n',\n",
       " u'\\n\\n    Radiator Labs\\n',\n",
       " u'\\n\\n    Slice\\n',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n\\n    IBM',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n    Elevano',\n",
       " u'\\n\\n\\n    Tumblr\\n',\n",
       " u'\\n\\n    Schireson Associates\\n',\n",
       " u'\\n\\n    Enterprise Select\\n',\n",
       " u'\\n\\n\\n    J.Crew Group, Inc.\\n',\n",
       " u'\\n\\n\\n    Credit Suisse\\n',\n",
       " u'\\n\\n\\n    GroupM\\n',\n",
       " u'\\n\\n    Amazon Web Services\\n',\n",
       " u'\\n\\n\\n    Comcast\\n',\n",
       " u'\\n\\n    Radiator Labs\\n',\n",
       " u'\\n\\n    Slice\\n',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n\\n    IBM',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n    Elevano',\n",
       " u'\\n\\n\\n    Tumblr\\n',\n",
       " u'\\n\\n    Schireson Associates\\n',\n",
       " u'\\n\\n    Enterprise Select\\n',\n",
       " u'\\n\\n\\n    J.Crew Group, Inc.\\n',\n",
       " u'\\n\\n\\n    Credit Suisse\\n',\n",
       " u'\\n\\n\\n    GroupM\\n',\n",
       " u'\\n\\n    Amazon Web Services\\n',\n",
       " u'\\n\\n\\n    Comcast\\n',\n",
       " u'\\n\\n    Radiator Labs\\n',\n",
       " u'\\n\\n    Slice\\n',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n\\n    IBM',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n    Elevano',\n",
       " u'\\n\\n\\n    Tumblr\\n',\n",
       " u'\\n\\n    Schireson Associates\\n',\n",
       " u'\\n\\n    Enterprise Select\\n',\n",
       " u'\\n\\n\\n    J.Crew Group, Inc.\\n',\n",
       " u'\\n\\n\\n    Credit Suisse\\n',\n",
       " u'\\n\\n\\n    GroupM\\n',\n",
       " u'\\n\\n    Amazon Web Services\\n',\n",
       " u'\\n\\n\\n    Comcast\\n',\n",
       " u'\\n\\n    Radiator Labs\\n',\n",
       " u'\\n\\n    Slice\\n',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n\\n    KPMG',\n",
       " u'\\n\\n    IBM']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#function to find company jobs listings\n",
    "def company_from_result(soup):\n",
    "    orgs = []\n",
    "    for div in soup.find_all(name='div', attrs={'class':'row'}):\n",
    "        for company in soup.find_all(name='span',attrs={'class':'company'}):\n",
    "            orgs.append(company.text)\n",
    "    return (orgs)\n",
    "company_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cleaner company name search\n",
    "def company(result):\n",
    "    for company in  soup.find_all('span',{'class':'company'}):\n",
    "        print company.text.strip()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KPMG\n",
      "Elevano\n",
      "Tumblr\n",
      "Schireson Associates\n",
      "Enterprise Select\n",
      "J.Crew Group, Inc.\n",
      "Credit Suisse\n",
      "GroupM\n",
      "Amazon Web Services\n",
      "Comcast\n",
      "Radiator Labs\n",
      "Slice\n",
      "KPMG\n",
      "KPMG\n",
      "IBM\n"
     ]
    }
   ],
   "source": [
    "company(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KPMG is currently seeking a Data Scientist - Big Data & Analytics, to join our Advanced Data & Analytics Organization....\n",
      "Parsing of structured/unstructured data. Our client is looking for a Senior Data Scientist with a strong background in NLP....\n",
      "\n",
      "Data Scientist, Personalization and Recommendation. We are seeking a veteran Data Scientist, well-versed in data analysis and algorithm implementation, ready to...\n",
      "\n",
      "We are looking for an analytically-oriented data analyst to join our growing team and assist our data scientists in the creation of cutting edge analyses and...\n",
      "\n",
      "Financial Services data such as transactions, payments, customer data etc. 3yrs+ experience in a data scientist role - working in the field....\n",
      "\n",
      "J.Crew is seeking a Data Scientist with an emphasis on Pricing Analytics to join our team of highly successful predictive analysts....\n",
      "\n",
      "As a data scientist, you will join a growing, high-visibility machine learning team that is developing and deploying solutions to some of Credit Suisseâs most...\n",
      "\n",
      "Gain Theory has an opening in New York City, USA for a Data Scientist or Statistical Modeler. Gain Theory â Data Scientist/Statistical Modeler....\n",
      "\n",
      "SENIOR Data scientist â AWS Professional services*. Our Data Scientists can live in any location where we have a Professional Service office....\n",
      "\n",
      "Solid background and practical experience in relational and non-relational databases, data architecting, data management and complex data processing in...\n",
      "\n",
      "Candidates with experience accessing data stored in cloud databases, data modeling and processing, as well as the presentation of results....\n",
      "\n",
      "Experience with data visualization tools (e.g. Familiarity with leveraging APIs for data extraction purposes. Experience in translating business challenges into...\n",
      "KPMG is currently seeking a Healthcare & Life Sciences - Data Scientist, to join our Advanced Analytics Organization....\n",
      "KPMG is currently seeking a Data Scientist to join our Advanced Data & Analytics Organization. Retrieve, prepare, and process a rich data variety of data...\n",
      "The Worldwide Advanced Analytics Center of Competency is the top-of-the-spear of IBMâs consulting organization when it comes to Machine Learning & Big Data....\n"
     ]
    }
   ],
   "source": [
    "#job description search function for listings\n",
    "def description_from_result(result):\n",
    "    for description in soup.find_all('span',{'class':'summary'}):\n",
    "        print description.text\n",
    "description_from_result(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to scale up our scraping, we need to accumulate more results. We can do this by examining the URL above.\n",
    "- \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\"\n",
    "\n",
    "There are two query parameters here we can alter to collect more results, the l=New+York and the start=10. The first controls the location of the results (so we can try a different city). The second controls where in the results to start and gives 10 results (thus, we can keep incrementing by 10 to go further in the list).\n",
    "##### Complete the following code to collect results from multiple cities and starting points.\n",
    "- Enter your city below to add it to the search\n",
    "- Remember to convert your salary to U.S. Dollars to match the other cities if the currency is different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "YOUR_CITY = 'Boston'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist_Entry Level',\n",
       "  u'GS5',\n",
       "  u'Washington, DC',\n",
       "  u'The Data Scientist_Entry Level is expected to:. GS5, LLC is looking for a TS/SCI Cleared Data Scientist_Entry Level....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Junior Data Scientist / Visualist',\n",
       "  u'Assured Consulting Solutions',\n",
       "  u'Washington, DC',\n",
       "  u'We are seeking a highly motivated Junior Data Scientist. Create executive level reports and briefings on data architecture, data management, and data analytics...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist, Junior',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'Alexandria, VA',\n",
       "  u'Data Scientist, Junior. Perform as a data scientist with a focus on computer science to apply knowledge of and expertise in distributed, scalable Big Data store...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Machine Learning Algorithm Developer - US Citizens Only',\n",
       "  u'Naval Research Lab',\n",
       "  u'Washington, DC 20375 (AU-Tenleytown area)',\n",
       "  u'Develop machine learning algorithms for a variety of applications involving the RF spectrum. The ideal candidate should have knowledge ranging from the',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Statistical Analyst',\n",
       "  u'eGlobalTech',\n",
       "  u'Washington, DC',\n",
       "  u'Volumes of data (e.g. Coordinate with Data Analysts and other team members throughout the project. In this role, the Statistical Analyst will support a...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist/Developer/Engineer',\n",
       "  u'ByteCubed',\n",
       "  u'Arlington, VA',\n",
       "  u'ByteCubed is seeking a Data Scientist/Developer/Engineer to join our rapidly growing Data Science team. At ByteCubed, the data science team mostly does data...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Statistician',\n",
       "  u'Ukpeagvik I\\xf1upiat Corporation/Bowhead Family of Co...',\n",
       "  u'Washington, DC',\n",
       "  u'- Provide statistical support for sample design, data collection, weighting procedures, handling missing data, business intelligence, and data analytics;...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Machine Learning Engineer',\n",
       "  u'Development Seed',\n",
       "  u'Washington, DC',\n",
       "  u'Remotely sensed data and associated libraries (GDAL, QGIS). Here, you will work with us to build tools that extract insights from large datasets, especially...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Statistician',\n",
       "  u'International Cotton Advisory Committee',\n",
       "  u'Washington, DC',\n",
       "  u'Analysis, compilation, presentation and dissemination of statistical data. Maintaining the main database of the ICAC via research, collection and cleaning of...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Statistician',\n",
       "  u'Leidos',\n",
       "  u'Washington, DC 20001 (Shaw area)',\n",
       "  u'Assist DEA statisticians and scientists in tracking phases or steps in cocaine production and transportation cycle within South America, Central America, Mexico...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist, Mid',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'Washington, DC',\n",
       "  u'Data Scientist, Mid. Apply expertise in CS, software development, and the latest technologies to analyze and implement analysis infrastructure and tools,...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Federal - Business Analytics Consultant',\n",
       "  u'Accenture',\n",
       "  u'Washington, DC 20006 (Foggy Bottom area)',\n",
       "  u'Individuals in this role are expected to work with clients as a data scientist and problem solver to construct enduring and innovative solutions....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Analyst, Evaluation and Analysis',\n",
       "  u'PCORI',\n",
       "  u'Washington, DC',\n",
       "  u'Demonstrated data cleaning, data management, and data presentation skills. Knowledge of sampling, data modeling, matching, data mining, and data analytics...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Intelligence Research Analyst',\n",
       "  u'DAWSON',\n",
       "  u'Washington, DC 20001 (Shaw area)',\n",
       "  u'(Note: This position is contingent upon a successful proposal submission and subsequent contract award. Work is expected to begin in September/October 2017)',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Undergraduate Internship/Co-op Program - Data Scientist',\n",
       "  u'Central Intelligence Agency',\n",
       "  u'Washington, DC',\n",
       "  u'Students serving as Data Scientist interns work side-by-side with other data scientists using advanced hardware and software to create and develop computational...',\n",
       "  36800.0],\n",
       " ['Washington D.C.',\n",
       "  u'Public Affairs - Research Analyst, Public Polling (Entry-Lev...',\n",
       "  u'Ipsos North America',\n",
       "  u'Washington, DC',\n",
       "  u'Data analysis planning and data verification including creating cross-tabulation plans, verifying datasets, and providing basic dataset manipulation....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Statistician',\n",
       "  u'Extreme Data Technologies',\n",
       "  u'Washington, DC',\n",
       "  u'This type of study could involve data simulations as well as analysis using SOI data. For example, a review might be requested of the possible effect of missing...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Associate Research Scientist',\n",
       "  u'Vencore',\n",
       "  u'Washington, DC',\n",
       "  u'From smart grid to smart phones, intelligent highways to intelligent battlefields, Vencore Labs\\u2019 200 scientists, engineers and analysts are consistently...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data and Policy Analyst - Statistical Programmer',\n",
       "  u'Acumen LLC',\n",
       "  u'Washington, DC',\n",
       "  u'Data and Policy Analysts perform a wide array of functions as part of the research process. This position is responsible for managing and analyzing data,...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Business Analytics Consultant',\n",
       "  u'PNC',\n",
       "  u'Washington, DC 20022 (Brentwood area)',\n",
       "  u'Providing business clients with detailed, actionable reports documenting the findings from, data processing, and data analysis....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Data Scientist',\n",
       "  u'Altamira Technologies Corporation',\n",
       "  u'Washington, DC',\n",
       "  u'Handles raw data (e.g. Experienced in working with and exploiting big data; Experience in working with travel and identity data sets....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Junior Data Scientist',\n",
       "  u'Coverent',\n",
       "  u'Springfield, VA',\n",
       "  u'Coverent is seeking a Junior Data Scientist to work as part of a high performing, collaborative team providing support to critical, time sensitive assignments....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst',\n",
       "  u'DAWSON',\n",
       "  u'Washington, DC 20001 (Shaw area)',\n",
       "  u'(Note: This position is contingent upon a successful proposal submission and subsequent contract award. Work is expected to begin in September/October 2017)',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Statistical Modeling Scientist',\n",
       "  u'Nestle USA',\n",
       "  u'Arlington, VA',\n",
       "  u'Lead small scale projects under the guidance of statistical forecast scientist and business management. Participate in the design process and integration...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Intern',\n",
       "  u'Mid-Atlantic Permanente Medical Group',\n",
       "  u'Rockville, MD',\n",
       "  u'Creates presentations for scientists and physician executives. The Intern will support project managers and/or research scientists across multiple initiatives,...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Head of Data Science',\n",
       "  u'Vox Media',\n",
       "  u'Washington, DC',\n",
       "  u'You will ultimately drive a shift in deepening and broadening our data informed culture enabling data as a true currency....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Data Scientist, Data Science',\n",
       "  u'The Advisory Board Company',\n",
       "  u'Washington, DC',\n",
       "  u'Senior Data Scientist. The Education Advisory Board (EAB) Data Science Team is looking for a broadly-talented Data Scientist with quantitative research skills....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst',\n",
       "  u'GBTA',\n",
       "  u'Alexandria, VA 22314 (Southwest Quadrant area)',\n",
       "  u'Perform data analysis on member and vendor supplied data via the GBTA Foundation Benchmarking Tools. Analyze data, and author reports....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Statistician',\n",
       "  u'Onyx Government Services, LLC',\n",
       "  u'Washington, DC',\n",
       "  u'5+ years of experience in SAS, data processing, ETL, database programming and/or data analytics. Strong knowledge of data analysis methodology, SAS stored...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Big Data Architect (Manager, Sr. Manager)',\n",
       "  u'Sumeru Solutions',\n",
       "  u'Washington, DC',\n",
       "  u\"Experience working with Business Intelligence teams, Data Integration developers, Data Scientists, Analysts and DBA's to deliver well-architected and scalable...\",\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Big Data Architect (Manager, Sr. Manager)',\n",
       "  u'Sumeru Solutions',\n",
       "  u'Washington, DC',\n",
       "  u\"Experience working with Business Intelligence teams, Data Integration developers, Data Scientists, Analysts and DBA's to deliver well-architected and scalable...\",\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'R / Python Developer',\n",
       "  u'ANALYTICA',\n",
       "  u'Washington, DC 20036 (Downtown area)',\n",
       "  u'Analytica is seeking a talented Data Scientist with strong quantitative research and analytics capabilities to support federal government consulting engagements...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst',\n",
       "  u'Monument Economics Group',\n",
       "  u'Arlington, VA',\n",
       "  u'Logically grasps underlying data and work flow of a case. We are seeking a Research Analyst possessing strong analytical and qualitative skills with an interest...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'J.P. Morgan Chase Institute Research Analyst',\n",
       "  u'JP Morgan Chase',\n",
       "  u'Washington, DC 20004 (Downtown area)',\n",
       "  u'1,000,000 data points and more). Experience working with big data (e.g. Work alongside other analysts, Research Directors, PhD fellows, academic advisors, and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Intelligence Research Analyst',\n",
       "  u'Vencore',\n",
       "  u'Washington, DC',\n",
       "  u'Vencore is a proven provider of information solutions, engineering and analytics for the U.S. Government. With more than 40 years of experience working in the',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Sr Data Scientist',\n",
       "  u'Leidos',\n",
       "  u'Suitland, MD 20752',\n",
       "  u'3+ yrs practical work experience with geospatial data or imagery data. Perform exploratory and targeted data analyses;...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Analyst, Research',\n",
       "  u'JLL',\n",
       "  u'Washington, DC',\n",
       "  u'Track, maintain and disseminate detailed data for critical retail market indicators, including. Respond to all internal and external client requests for data...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Machine Learning Engineer',\n",
       "  u'Capital One',\n",
       "  u'McLean, VA',\n",
       "  u'Construct data staging layers and fast real-time systems to feed machine learning algorithms. Capital One maintains a full stack of technology solutions...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Statistician/Econometrician',\n",
       "  u'American Institutes for Research',\n",
       "  u'Washington, DC',\n",
       "  u'The American Institutes for Research (AIR) is a leading professional services firm specializing in all aspects of education and other social policy issues.',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Risk Analyst',\n",
       "  u'Prevalent Inc.',\n",
       "  u'Tysons Corner, VA',\n",
       "  u'Risk analyst, data scientist, and cyber threat analyst to join our Vendor Threat Intelligence Team. BA or BS in relevant areas, including Math, Economics,...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Analyst - Business Transformation',\n",
       "  u'Verizon',\n",
       "  u'Ashburn, VA 20147',\n",
       "  u'The successful candidate will help in Data analysis, data interpretations, and turn data into meaningful information, which gives insight into business....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Statistical Analyst',\n",
       "  u'Vanda Pharmaceuticals Inc.',\n",
       "  u'Washington, DC 20037 (Foggy Bottom area)',\n",
       "  u'Produce and/or validate datasets, analyses, tabulations, graphics and listings of clinical trials data. Expertise in the production and reviewing of datasets,...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Data Scientist',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'Washington, DC',\n",
       "  u'Research Data Scientist. Experience with building complex data extraction, transformation, and loading, including ETL into structured databases, data warehouses...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Statistical Programmer',\n",
       "  u'Social & Scientific Systems Inc.',\n",
       "  u'Silver Spring, MD 20910',\n",
       "  u'Participates in a highly collaborative environment as an integral member of a clinical project team to create data displays and data summaries for studies...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Scientist',\n",
       "  u'Vencore',\n",
       "  u'Washington, DC',\n",
       "  u'From smart grid to smart phones, intelligent highways to intelligent battlefields, Vencore Labs\\u2019 200 scientists, engineers and analysts are consistently...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'IBM Watson Health - Research Analyst 1 - Truven',\n",
       "  u'IBM',\n",
       "  u'Bethesda, MD 20817',\n",
       "  u'Extract data from various sources to support the development of research proposals, project analysis plans, project specifications, and client deliverables....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Analyst (Statistical Analysis)',\n",
       "  u'Teracore',\n",
       "  u'Washington, DC',\n",
       "  u'Experience managing small data analytics teams. Previous experience working on DHS data systems. The Data Analyst will work on a small project team to provide...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Analytical Chemist',\n",
       "  u'Applied Research Associates, Inc',\n",
       "  u'Alexandria, VA',\n",
       "  u'And subsequent data analysis, interpretation, and report writing under the guidance of a senior scientist....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Data Scientist',\n",
       "  u'American Institutes for Research',\n",
       "  u'Washington, DC',\n",
       "  u'The Senior Data Scientist will also be called upon to:. Analyze and interpret experimental data. Data scientists at AIR use a blend of technology skills and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst',\n",
       "  u'University of Maryland',\n",
       "  u'College Park, MD',\n",
       "  u'The Research Analyst is responsible for supporting the data reporting needs of the Office of Enrollment Management, including data related to Undergraduate...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Statistician',\n",
       "  u'Goldbelt, Inc.',\n",
       "  u'College Park, MD',\n",
       "  u'Meta-analyses of data using statistically appropriate data analytic methods. Relevant data, developing appropriate statistical analyses of the data to....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst, Environmental Programs Group',\n",
       "  u'The Cadmus Group, Inc.',\n",
       "  u'Arlington, VA',\n",
       "  u'Data preparation and analysis. Mathematics, statistics or data science; Classwork or professional experience with GIS and other environmental data sets, such as...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Marvelous Machine Learning & Analytics Developer (Data Scien...',\n",
       "  u'Parsons Corporation',\n",
       "  u'Fort Meade, MD',\n",
       "  u'We\\u2019re looking for talented individuals to help us crunch lots of data in key threat areas, develop models, and apply the results to the fast-moving world of...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist/SAS Developer',\n",
       "  u'Onyx Government Services, LLC',\n",
       "  u'Washington, DC',\n",
       "  u'5+ years in data analytics, data processing, ETL, database programming and/or data analytics. Experience with ETL and data integration is a plus....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Intern \\u2013 Field Data Analysis and Administration',\n",
       "  u'SP+',\n",
       "  u'Fairfax, VA',\n",
       "  u'The successful candidate should have an aptitude for and enjoy gathering, analyzing and interpreting data. This position will oversee internal projects, act as...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Metrics and Data Analyst - Principle Job',\n",
       "  u'SAIC',\n",
       "  u'Bethesda, MD 20817',\n",
       "  u'Assist with data analytics initiatives to include the development of data formats for identifying IC- wide workforce numbers....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst: Sustainable Public Finance',\n",
       "  u'World Resources Institute',\n",
       "  u'Washington, DC',\n",
       "  u'Reports, briefs, data products). The foundation of our work is delivering high-quality research, data, maps and analysis to solve the world\\u2019s greatest...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst',\n",
       "  u'EurekaFacts, LLC',\n",
       "  u'Rockville, MD',\n",
       "  u'Prepares data sets for analysis using available software tools and previously identified data standards; Uses the statistical reporting and qualitative data...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst',\n",
       "  u'The Cadmus Group, Inc.',\n",
       "  u'Arlington, VA',\n",
       "  u'Code programs for both data analysis and simulation models. The Cadmus Group, Inc....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Science Manager',\n",
       "  u'The Upside Travel Company, LLC',\n",
       "  u'Washington, DC',\n",
       "  u'Help lead small to medium-sized teams of analysts and data scientists on short- and long-term projects. You have proven experience leading teams of three to ten...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Statistician - FAA',\n",
       "  u'Engility Corporation',\n",
       "  u'Washington, DC',\n",
       "  u'Determine and present the pros and cons of using different tools (mainly R, SAS, Python, and SQL) for data transformation, calculation, and analysis....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Scientist - Health Care',\n",
       "  u'National Opinion Research Center (NORC)',\n",
       "  u'Bethesda, MD',\n",
       "  u'Our team includes social scientists that acquire, collect, and analyze data from health care organizations and patients;...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Econ & Stat Research Analyst',\n",
       "  u'NASDAQ',\n",
       "  u'Rockville, MD 20850',\n",
       "  u'Analyze large, complex data sets using the latest big data technologies. Assists with writing computer code for analyzing complex data sets (big data)....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst',\n",
       "  u'The JBG Companies',\n",
       "  u'Chevy Chase, MD 20815',\n",
       "  u'Initial preparation of quarterly statistics for reporting Analysis and summary of third-party reports Maintenance of statistical tracking/models Tracking and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Scientist II',\n",
       "  u'Universities Space Research Association',\n",
       "  u'Greenbelt, MD',\n",
       "  u'The Research Scientist will work to advance land data assimilation within the coupled atmosphere-ocean-land Goddard Earth Observing System (GEOS) model and its...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Mathematical Statistician',\n",
       "  u'Department of Defense',\n",
       "  u'Alexandria, VA',\n",
       "  u'About the Agency If you would like to be a part of a Federal organization dedicated to serving our Nation and those who defend it, consider a career with the',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Analyst',\n",
       "  u'Leidos',\n",
       "  u'McLean, VA 22108',\n",
       "  u'Leidos is looking for Data Scientist with these skills:. Computer science concepts and data content. Ability to build statistical models, test hypotheses,...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst',\n",
       "  u'Public Company Accounting Oversight Board',\n",
       "  u'Washington, DC',\n",
       "  u'Excellent data management skills; Knowledge of econometrics, including panel data techniques; Ensure data quality through review and validation with source...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Machine Learning - R&D TS Clearance',\n",
       "  u'Barone Consulting',\n",
       "  u'Arlington, VA',\n",
       "  u'Apply deep technical knowledge of machine learning techniques and applications to serve as a strategic consultant for government clients leading research and',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Analytical Chemist',\n",
       "  u'The Johns Hopkins Applied Physics Laboratory',\n",
       "  u'Laurel, MD',\n",
       "  u'Experience in performing statistical data analysis, and report generation. The ability to think independently, work well with others, and present unbiased...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Qualitative Research Analyst',\n",
       "  u'Addx',\n",
       "  u'Washington, DC',\n",
       "  u'Proficiency in using qualitative data analysis software such as NVivo or ATLAS.ti. Experience with data visualization tools (Tableau experience a plus) and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst',\n",
       "  u'CBRE',\n",
       "  u'Washington, DC',\n",
       "  u'Ability to handle and manipulate large amounts of data. Reviews and evaluates data results collected by themselves and others within the research team to ensure...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst - Economist',\n",
       "  u'CNA Corp.',\n",
       "  u'Arlington, VA 22201 (Lyon Village area)',\n",
       "  u'RAD supports the Navy and Marine Corps, as well as other DOD sponsors in the development and assessment of policies, programs, and processes affecting the',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Statistician',\n",
       "  u'Apogee Integration, LLC',\n",
       "  u'Arlington, VA',\n",
       "  u'Minimum five (5) years of experience related to job position in OSD or Joint Staff or similar strategic level corporate/governmental analysis experience...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Research Analyst',\n",
       "  u'Vistra Communications',\n",
       "  u'Washington, DC',\n",
       "  u'Supports the team to further enhance process flow for all data collection activities, data collection QA procedures documentation....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Analyst',\n",
       "  u'ABS Consulting',\n",
       "  u'Arlington, VA',\n",
       "  u'Data scientist to help conceptualize and develop ground-breaking solutions for. Data visualization techniques to display and clearly communicate big data and....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Analyst',\n",
       "  u'General Dynamics Information Technology',\n",
       "  u'Washington, DC 20003 (Capitol Hill area)',\n",
       "  u'Ensures the integrity of project data, including data extraction, storage, manipulation, processing and analysis....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst',\n",
       "  u'Sevatec, Inc.',\n",
       "  u'Washington, DC',\n",
       "  u'Identify and correct data quality issues and work with Team Leader to establish a data governance framework to enforce data standards and improve accuracy using...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Machine Learning Developer',\n",
       "  u'The Johns Hopkins Applied Physics Laboratory',\n",
       "  u'Laurel, MD',\n",
       "  u'Perform exploratory analysis and pre-processing of data sources with the intent of visualizing data and discovering statistical properties and other key...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst/Associate',\n",
       "  u'Center for the Study of Services',\n",
       "  u'Washington, DC 20001 (Shaw area)',\n",
       "  u'Understanding of general statistics, Boolean algebraic logic, and data interpretation. Write programs, macros, and queries to process or analyze large data...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Custom Health - Research Analyst',\n",
       "  u'Ipsos North America',\n",
       "  u'Washington, DC',\n",
       "  u'Develop data plan analyses and perform data analysis. Do you have an interest in learning more about medicines, medical technologies and advancements in...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Analysis and Visualization Developer',\n",
       "  u'The Johns Hopkins Applied Physics Laboratory',\n",
       "  u'Laurel, MD',\n",
       "  u'Experience with data management, data analytics development, and database programming. Experience delivering solutions using Big Data tools and technologies....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Intelligence Work Research Analyst',\n",
       "  u'Delta Research Associates, Inc.',\n",
       "  u'Washington, DC',\n",
       "  u'Demonstrated experience in the analysis and evaluation of technical, scientific data related to interagency/intelligence agreements....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Research Scientist - Medicare/Medicaid',\n",
       "  u'National Opinion Research Center (NORC)',\n",
       "  u'Bethesda, MD',\n",
       "  u'Experience with and knowledge of the principles of quantitative and qualitative research design, data collection, and data analysis....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Software Engineer - Machine Learning',\n",
       "  u'IBM',\n",
       "  u'Washington, DC 20005 (Logan Circle area)',\n",
       "  u'Work with a team of scientists and engineers to implement client driven application requirements. IBM is breaking ground in the areas of machine learning and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Supervisory Operations Research Analyst',\n",
       "  u'Department of Health And Human Services',\n",
       "  u'Silver Spring, MD',\n",
       "  u'Develops alternative options to resolve complex data analysis. The Division of Quality Intelligence, Risk Analysis, and Modeling includes components that work...',\n",
       "  146833.5],\n",
       " ['Washington D.C.',\n",
       "  u'Research and Policy Associate- Education and Society',\n",
       "  u'The Aspen Institute',\n",
       "  u'Washington, DC',\n",
       "  u'Facilitating and capturing information from Commissioner convenings as well as meetings of scientists and educators....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Pragmatics, Inc',\n",
       "  u'Suitland, MD',\n",
       "  u'Geospatial Data or Imagery Data:. Data or *imagery*. Is seeking a *Data Scientist*. 3 years\\u2019 experience *integrating data mining, conditioning,*....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Scientist / Senior Research Scientist - Public Heal...',\n",
       "  u'National Opinion Research Center (NORC)',\n",
       "  u'Bethesda, MD',\n",
       "  u'This position is responsible for providing direction and task leadership in all aspects of project work which could include analytic approach, questionnaire...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Machine Learning Research Engineer',\n",
       "  u'BAE Systems Applied Intelligence',\n",
       "  u'Arlington, VA',\n",
       "  u'Enterprise-wide data flow analysis and defense. Seeking Machine learning and Data science expertise for Cutting-edge cyber SECURITY CHALLENGES....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'General Research Analyst, Network Science Initiative',\n",
       "  u'Atlantic Media',\n",
       "  u'Washington, DC 20037 (Foggy Bottom area)',\n",
       "  u'Strategy consulting, business research, government affairs consulting, policy analysis, Capitol Hill, political science research, executive agency policymaking,...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Software Engineer - Machine Learning',\n",
       "  u'IBM',\n",
       "  u'Washington, DC 20005 (Logan Circle area)',\n",
       "  u'Work with a team of scientists and engineers to implement client driven application requirements. IBM is breaking ground in the areas of machine learning and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Management Analyst',\n",
       "  u'Missing Link Security',\n",
       "  u'Washington, DC',\n",
       "  u'Maintain a tracking system to ensure on time, accurate responses to all data calls. Deliver data calls for SAGE input/outputs/updates for the SAGE manager and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Analysis and Visualization Developer',\n",
       "  u'The Johns Hopkins Applied Physics Laboratory',\n",
       "  u'Laurel, MD',\n",
       "  u'Experience with data management, data analytics development, and database programming. Experience delivering solutions using Big Data tools and technologies....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst - MATLAB / Python / C++',\n",
       "  u'The Johns Hopkins Applied Physics Laboratory',\n",
       "  u'Laurel, MD',\n",
       "  u'Proficiency in data analysis and tools such as MATLAB, Python, or equivalent. Experience working with sensor data (IR and/or RF) and related phenomenology...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Scientist, Informatics',\n",
       "  u'N C Q A',\n",
       "  u'Washington, DC',\n",
       "  u'At least 10 years\\x92 experience conducting health services research, quality measure development or HIT data standards development ....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Analyst',\n",
       "  u'Govini',\n",
       "  u'Arlington, VA 22209 (Radnor-Ft Myer Heights area)',\n",
       "  u'Deep research, analysis, data abstraction and data manipulation skills, with a demonstrated ability to solve strategic business questions using data....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Machine Learning Developer',\n",
       "  u'The Johns Hopkins Applied Physics Laboratory',\n",
       "  u'Laurel, MD',\n",
       "  u'Perform exploratory analysis and pre-processing of data sources with the intent of visualizing data and discovering statistical properties and other key...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Research Analyst',\n",
       "  u'REDHORSE CORPORATION',\n",
       "  u'Arlington, VA 22201 (Lyon Village area)',\n",
       "  u'Redhorse is hiring a Senior Research Analyst to provide support for open source research and information relevant to priority programs within the Office of',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Emergency Management Research Analyst',\n",
       "  u'The Cadmus Group, Inc.',\n",
       "  u'Washington, DC',\n",
       "  u'At Cadmus, our Homeland Security Sector provides clients with pragmatic solutions to their most important analytical and policy challenges. We bring together',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Analysis Manager',\n",
       "  u'Capital One',\n",
       "  u'McLean, VA',\n",
       "  u'Data Analysis Manager. Extracting and analyzing data to gauge product offerings. At least 4 years of professional data analysis work experience....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Mid-Level Data Scientist',\n",
       "  u'Altamira Technologies Corporation',\n",
       "  u'Washington, DC',\n",
       "  u'Handles raw data (e.g. Experienced in working with and exploiting big data; Experience in working with travel and identity data sets....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Tobacco Biomarker Research Analyst',\n",
       "  u'WESTAT',\n",
       "  u'Rockville, MD 20850',\n",
       "  u'Conducting data analysis, collaborating with senior scientists and programmers in implementing analysis plans;...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Program Analyst/Operations Research Analyst',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'Washington, DC',\n",
       "  u'5 years of experience with statistical methods, data analysis, and modeling. Gather, relate, and identify data with variables in models by applying personal...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Operational Research Analyst',\n",
       "  u'Grant Thornton',\n",
       "  u'Washington, DC 20036 (Downtown area)',\n",
       "  u'Data Visualization, performance indicators preferred. Operational Research Analyst....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Scientist / Engineer',\n",
       "  u'ENSCO, Inc.',\n",
       "  u'Washington, DC',\n",
       "  u'Strong understanding of data acquisition and analysis. ENSCO is seeking a Research Scientist/Engineer to serve on an integrated team of government and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist Analyst Sr',\n",
       "  u'Lockheed Martin',\n",
       "  u'Herndon, VA 20171',\n",
       "  u'The Data Scientist understands structure and techniques of data analysis and can lead data analysts. To perform these duties, the Data Scientist will:....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Evaluation and Data Analysis VISTA',\n",
       "  u'AmeriCorps',\n",
       "  u'Washington, DC',\n",
       "  u'Review student post-secondary performance data and literature to update trend and outcome data for staff and board members;...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Analytics Developer',\n",
       "  u'Noblis',\n",
       "  u'Lanham, MD',\n",
       "  u'Support the design and implementation of data integration across data analytics infrastructures. As part of the design and implementation effort, the data...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Product Manager - Healthcare Analytics, McKinsey New Venture...',\n",
       "  u'McKinsey & Company',\n",
       "  u'Washington, DC 20036 (Downtown area)',\n",
       "  u'As one of the fastest-growing parts of our firm, New Ventures has more than 1,000 dedicated professionals (including more than 800 analysts and data scientists)...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Quantitative Research Analyst',\n",
       "  u'CEB',\n",
       "  u'Washington, DC',\n",
       "  u'Analyzing large data sets to identify actionable insights for senior executives. Assisting with large-scale data collection efforts across member organizations...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst',\n",
       "  u'ManTech International Corporation',\n",
       "  u'Silver Spring, MD',\n",
       "  u'Conduct quality review, data cleaning, merging, and extraction of relevant information from multiple large data sets....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Financial Data Scientist/Technology Analyst- MA (20449)',\n",
       "  u'Federal Reserve Board',\n",
       "  u'Washington, DC 20006 (Foggy Bottom area)',\n",
       "  u'Knowledge of and affinity with finance/economics or data management is a strong plus, as well as experience working with high-frequency financial data or big...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Manager, Data Solutions',\n",
       "  u'Gannett',\n",
       "  u'McLean, VA',\n",
       "  u'Based on your experience either as a Data Scientist or as a Data Engineer, deliver personal leadership within the team and across the organization in the...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'Washington, DC',\n",
       "  u'Ability to work with data collection and apply appropriate standards, as needed. Experience in working with segmented raw data and analysis to help determine...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Statistician Data Analyst',\n",
       "  u'Cubic Corporation',\n",
       "  u'Springfield, VA',\n",
       "  u'Proficient in analyzing large amounts of data, preferably GEOINT data. Provide statistical and mathematical support to the Business Analytics (BA) COE with...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Statistician Junior',\n",
       "  u'Atlas Research',\n",
       "  u'Washington, DC 20005 (Logan Circle area)',\n",
       "  u'Atlas Research is seeking a Statistician Junior to perform project tasks independently, participate in the development of deliverable content that meets the',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Excella Consulting',\n",
       "  u'Washington, DC 20006 (Foggy Bottom area)',\n",
       "  u'Obtaining data from multiple, disparate data sources including structured, semi-structured and unstructured data....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Lead Data Scientist',\n",
       "  u'Mitre Corporation',\n",
       "  u'McLean, VA',\n",
       "  u'Strong experience with data processing and integration including Extract/Transform/Load (ETL) workflow engineering utilizing various formats (XML, JSON, flat...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist_Senior Level',\n",
       "  u'GS5',\n",
       "  u'Washington, DC',\n",
       "  u'Perform as a data scientist leveraging expertise with distributed scalable Big Data store, including Apache Accumulo, Apache Hadoop, MapReduce programming and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Machine Learning Research Engineer',\n",
       "  u'BAE Systems',\n",
       "  u'Arlington, VA',\n",
       "  u'Enterprise-wide data flow analysis and defense. Seeking Machine learning and Data science expertise for Cutting-edge cyber SECURITY CHALLENGES....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Akima, LLC',\n",
       "  u'Washington, DC',\n",
       "  u'Technical expertise regarding data models, database design and development, data mining and segmentation techniques....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist Principal Job',\n",
       "  u'SAIC',\n",
       "  u'Reston, VA',\n",
       "  u'Data Scientist Principal (Job Number:. SAIC currently has an opening for a Data Scientist Principal based in Reston, VA....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'CleanChoice Energy',\n",
       "  u'Washington, DC 20007 (Georgetown area)',\n",
       "  u'CleanChoice Energy is looking for a Data Scientist to work on predictive models for customer acquisition marketing....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Statistical Analyst',\n",
       "  u'WESTAT',\n",
       "  u'Rockville, MD 20850',\n",
       "  u'This position will also support company-wide efforts to develop new directions and applications in data science....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Health Research Analyst',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'Washington, DC',\n",
       "  u'3 years of experience with quantitative and qualitative data analysis. Booz Allen Hamilton has been at the forefront of strategy and technology for more than...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Research Scientist',\n",
       "  u'Karna LLC',\n",
       "  u'Alexandria, VA 22311 (Alexandria Wrest area)',\n",
       "  u'Data analysis, data collection, data management, SPSS, data quality, quantitative, public health, behavioral health, mental health, military....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Software Engineer',\n",
       "  u'Strategic Data Systems',\n",
       "  u'Bethesda, MD 20817',\n",
       "  u'Strategic Data Systems is looking for a Software Engineer to join our team. The Carderock Division of the Naval Surface Warfare Center supports 3,200 scientists...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Excella Consulting',\n",
       "  u'Washington, DC 20006 (Foggy Bottom area)',\n",
       "  u'Obtaining data from multiple, disparate data sources including structured, semi-structured and unstructured data....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst',\n",
       "  u'Atlantic Media',\n",
       "  u'Washington, DC 20037 (Foggy Bottom area)',\n",
       "  u'Perform quality control checks at all phases of research, including fieldwork, data processing, and reporting....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Engineer/Scientist',\n",
       "  u'Cherokee Nation Businesses',\n",
       "  u'Silver Spring, MD 20910',\n",
       "  u'Support the development of a cross-agency national written program guidance and data calls. NOAA is need of a Social Scientist to provide scientific, technical...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Data Scientist',\n",
       "  u'BAE Systems',\n",
       "  u'Reston, VA 20191',\n",
       "  u'Significant current experience (i.e., within last 2 years) in data science/engineering work. 10 years\\u2019 experience performing data science/engineering work and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Pharmacology/Toxicology Reviewer',\n",
       "  u'Food & Drug Administration',\n",
       "  u'Silver Spring, MD',\n",
       "  u'Their primary responsibility will be the evaluation of preclinical data (e.g., in vitro and animal studies) during premarket review of investigational products....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'Washington, DC',\n",
       "  u'Ability to work with data collection and apply appropriate standards, as needed. Experience in working with segmented raw data and analysis to help determine...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Analyst, Senior',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'Springfield, VA',\n",
       "  u'10+ years of experience as a data analyst or data scientist. Data Analyst, Senior. Ability to manipulate data from multiple structured and unstructured data...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Akima, LLC',\n",
       "  u'Washington, DC',\n",
       "  u'Technical expertise regarding data models, database design and development, data mining and segmentation techniques....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Sr. Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209 (Radnor-Ft Myer Heights area)',\n",
       "  u'Data Modeling, Erwin, DBA. Informatica, ODI, SAP Data Services, SAP BW/HANA, Datastage. Our Federal AIM team helps change the way clients leverage data through...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'The Situs Companies',\n",
       "  u'Washington, DC',\n",
       "  u'Use techniques from statistics, machine learning, and other data sciences to estimate predictive models from numeric, categorical, textual, geographic, and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Engineer/Scientist',\n",
       "  u'Cherokee Nation Businesses',\n",
       "  u'Silver Spring, MD 20910',\n",
       "  u'Support the development of a cross-agency national written program guidance and data calls. NOAA is need of a Social Scientist to provide scientific, technical...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Energy Research and Development Project Management Analyst',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'Washington, DC',\n",
       "  u'Possession of excellent data gathering, analytical, problem-solving, and client service skills. Booz Allen Hamilton has been at the forefront of strategy and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Data Analyst',\n",
       "  u'Wunderman',\n",
       "  u'Washington, DC',\n",
       "  u'Data visualization dash boards. Headquartered in New York, the agency brings together 7,000 creatives, data scientists, strategists and technologists in 175...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Data Analyst',\n",
       "  u'Blast Radius',\n",
       "  u'Washington, DC',\n",
       "  u'Data visualization dash boards. Headquartered in New York, the agency brings together 7,000 creatives, data scientists, strategists and technologists in 175...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Data Analyst',\n",
       "  u'SicolaMartin',\n",
       "  u'Washington, DC',\n",
       "  u'Data visualization dash boards. Headquartered in New York, the agency brings together 7,000 creatives, data scientists, strategists and technologists in 175...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Data Analyst',\n",
       "  u'Young & Rubicam Group',\n",
       "  u'Washington, DC',\n",
       "  u'Data visualization dash boards. Headquartered in New York, the agency brings together 7,000 creatives, data scientists, strategists and technologists in 175...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist Senior',\n",
       "  u'Leidos',\n",
       "  u'Fairfax, VA 22032',\n",
       "  u'This position is a part of the Data Services team providing integration and processing support of data to the applications....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Halfaker and Associates',\n",
       "  u'Washington, DC',\n",
       "  u'Halfaker has an opening for a Data Scientist to join our talented, dynamic team. Understands data warehousing, business intelligence and information management...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Human Capital Research Analyst',\n",
       "  u'Leidos',\n",
       "  u'Springfield, VA 22151',\n",
       "  u'Ability to perform data entry, data collection, ensure data integrity, and clean data as needed. Administer quality control and process improvement activities,...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Data Scientist',\n",
       "  u'BAE Systems Applied Intelligence',\n",
       "  u'Reston, VA',\n",
       "  u'Significant current experience (i.e., within last 2 years) in data science/engineering work. 10 years\\u2019 experience performing data science/engineering work and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Federal Reserve Board of Governors',\n",
       "  u'Washington, DC',\n",
       "  u'Transforms data into actionable information. Utilizes data mining techniques to optimize decisions that support Division strategic objectives....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Principal Data Analyst',\n",
       "  u'General Dynamics Information Technology',\n",
       "  u'Washington, DC 20003 (Capitol Hill area)',\n",
       "  u'Ensures the integrity of project data, including data extraction, storage, manipulation, processing and analysis....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Membership Assistant',\n",
       "  u'Association for Psychological Science',\n",
       "  u'Washington, DC',\n",
       "  u'Support other areas of the organization with reports and data files. With over 33,000 members from around the world, APS membership includes the field\\u2019s leading...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst',\n",
       "  u'Atlantic Media',\n",
       "  u'Washington, DC 20037 (Foggy Bottom area)',\n",
       "  u'Perform quality control checks at all phases of research, including fieldwork, data processing, and reporting....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Data Scientist',\n",
       "  u'BAE Systems',\n",
       "  u'Reston, VA 20191',\n",
       "  u'Significant current experience (i.e., within last 2 years) in data science/engineering work. 10 years\\u2019 experience performing data science/engineering work and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Analyst, Senior',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'Springfield, VA',\n",
       "  u'10+ years of experience as a data analyst or data scientist. Data Analyst, Senior. Ability to manipulate data from multiple structured and unstructured data...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Flow Lead',\n",
       "  u'Dowless & Associates, Inc.',\n",
       "  u'Washington, DC',\n",
       "  u'Deliver DoDIIS and IC ITE data services which increase data enrichment, improve access to DIA data sources and support data analytics and data science....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst, CAP Action War Room',\n",
       "  u'American Progress',\n",
       "  u'Washington, DC',\n",
       "  u'American Progress has an immediate opening for a Research Analyst on the War Room team to conduct investigations into the executive branch and produce rapid',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Metropolitan Police Department',\n",
       "  u'Washington, DC',\n",
       "  u'Or data visualization and interaction. The Data Scientist position is assigned to the Metropolitan Police Department (MPD), Executive Office of the Chief of...',\n",
       "  86711.0],\n",
       " ['Washington D.C.',\n",
       "  u'Market Research Analyst - Analyst Development Program',\n",
       "  u'Ipsos North America',\n",
       "  u'Washington, DC',\n",
       "  u'Love data, consumer decision-making, and puzzles. Would you like to work with a team of passionate problem-solvers dedicated to bringing research insights and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Pharmacology/Toxicology Reviewer',\n",
       "  u'Food & Drug Administration',\n",
       "  u'Silver Spring, MD',\n",
       "  u'Their primary responsibility will be the evaluation of preclinical data (e.g., in vitro and animal studies) during premarket review of investigational products....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist, Senior',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'Arlington, VA',\n",
       "  u'Data Scientist, Senior. Produce data visualizations that provide insight into data set structure and meaning. Develop machine learning, data mining, statistical...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst, Child Welfare',\n",
       "  u'Child Trends',\n",
       "  u'Bethesda, MD 20814',\n",
       "  u'Analyze and interpret data and identify patterns from data collected through qualitative interviews, cognitive interviews, focus groups, or surveys, as well as...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Centra Technology',\n",
       "  u'Arlington, VA',\n",
       "  u'Courage Services, a CENTRA Technology company, is looking for a Data Scientist who:. Provides geospatial intelligence analysis services and data production to...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Copyright Research Analyst',\n",
       "  u'Clarivate Analytics',\n",
       "  u'Alexandria, VA',\n",
       "  u'Researches and extracts data from all applicable sources, ensures accuracy and quality of findings by complying with policies and applicable laws....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Program Coordinator - Cooperative Research Programs',\n",
       "  u'The National Academies',\n",
       "  u'Washington, DC',\n",
       "  u'Performs data collection. Gathers impact data for tracking purposes. Participates in tracking efforts including collection, analysis, and tabulation of data and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Research Analyst',\n",
       "  u'JHNA, Inc.',\n",
       "  u'Alexandria, VA',\n",
       "  u'John H. Northrop & Associates, Inc. (JHNA) seeks a talented Senior Research Analyst for support of its government customer and its need for open source',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist_Journeyman Level',\n",
       "  u'GS5',\n",
       "  u'Washington, DC',\n",
       "  u'The Data Scientist_Journeyman Level is expected to:. GS5, LLC is looking for a TS/SCI Cleared Data Scientist_Journeyman Level....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Junior Ops Research Analyst Job',\n",
       "  u'SAIC',\n",
       "  u'Arlington, VA',\n",
       "  u'The analyst should interpret results and formulates insights and findings underpinned by the data analysis....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Advanced Laser Remote Sensing Project',\n",
       "  u'Oak Ridge Associated Universities',\n",
       "  u'Springfield, VA',\n",
       "  u'Selected scientists will participate with government project scientists and contract experts to collect and analyze data from existing and new U.S....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Software Developer - Earth Science Data Analytics',\n",
       "  u'CSRA',\n",
       "  u'Greenbelt, MD',\n",
       "  u'The NCCS is dedicated to providing scientists and engineers with high-end computing and data resources, simulation tools, and analytics specifically designed to...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Zapata Technology',\n",
       "  u'Washington, DC 20024 (South West area)',\n",
       "  u'Data Scientist - Data Science / Integration / Analytics - Remote. BS or MS in Mathematics, Statistics, or Data Science....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst - Health Care Research',\n",
       "  u'National Opinion Research Center (NORC)',\n",
       "  u'Bethesda, MD',\n",
       "  u'Developing instrumentation for quantitative or qualitative data collection; Quantitative analysis experience including working knowledge of SAS, SPSS (or other...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Research Analyst',\n",
       "  u'Beacon Policy Advisors',\n",
       "  u'Washington, DC 20006 (Foggy Bottom area)',\n",
       "  u'Beacon Policy Advisors is an independent public policy research firm that advises top-tier institutional investment firms. We believe that public policy',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Bioinformatics Scientist',\n",
       "  u'Digicon',\n",
       "  u'McLean, VA',\n",
       "  u'Demonstrated success supporting next-generation sequencing data analysis. Proven experience deploying tools for genomic data analysis, integration and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Federal - Analytics Consultant',\n",
       "  u'Accenture',\n",
       "  u'Suitland, MD',\n",
       "  u'Expected to work with clients as a data scientist and problem solver to. Define data and technology. Drive the exploration of data sources and analytic...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'NOA1771 Science Writer',\n",
       "  u'I.M. Systems Group (IMSG)',\n",
       "  u'Silver Spring, MD',\n",
       "  u'Use technology or data visualizations to communicate scientific information. Work with NOAA scientists and subject matter experts to translate technical and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst Intern',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'McLean, VA',\n",
       "  u'Compile reference and statistical data into standard formats. Leverage knowledge of standard research techniques, statistical analysis and compilation of data,...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist \\u2013 SPSS Guru',\n",
       "  u'AXIS Management Group',\n",
       "  u'McLean, VA',\n",
       "  u'Data Scientist that specializes in SPSS*. This individual must have a solid understanding of data acquisition, data processing, and data lifecycle management...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'COMPUTER SCIENTIST, GS 15/(EX) IT Infrastructure Division/Wa...',\n",
       "  u'Federal Bureau of Investigation',\n",
       "  u'Washington, DC',\n",
       "  u'Data Management System. Computer Scientist, GS 15. The Computer Scientist will evaluate MPO IT project compliance to FBI policies, processes and standards....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'CSA Lead Data Scientist - Vice President - Permanent',\n",
       "  u'Deutsche Bank',\n",
       "  u'McLean, VA',\n",
       "  u'The Lead Data Scientist will turn data into information, information into insight and insight into business decisions....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Research Analyst',\n",
       "  u'CBRE',\n",
       "  u'Washington, DC',\n",
       "  u'Ability to handle and manipulate large amounts of data. Reviews and evaluates data results collected by themselves and others within the research team to ensure...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Media Research Analyst (overnight shifts)',\n",
       "  u'OMNITEC Solutions, Inc.',\n",
       "  u'Arlington, VA 22202 (Aurora Highlands area)',\n",
       "  u'People who thrive on the mechanics and nuances of media research, data gathering, analysis, and interpretation to provide up-to-the-minute situational awareness...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Machine Learning/Advanced Analytics Specialist',\n",
       "  u'Raytheon',\n",
       "  u'Herndon, VA 20170',\n",
       "  u'Write MapReduce jobs, Hive queries, and Pig scripts as appropriate to perform various tasks related to machine learning and data science activities including...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Facilities Intern',\n",
       "  u'Natural Resources Defense Council',\n",
       "  u'Washington, DC',\n",
       "  u\"Maintain data bases, paper and electronic filing systems. The Natural Resources Defense Council (NRDC) is the nation's most effective environmental action group...\",\n",
       "  24000.0],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist Manager',\n",
       "  u'Capital One',\n",
       "  u'McLean, VA',\n",
       "  u'Data Scientist Manager. Writing software to clean and investigate large, messy data sets of numerical and textual data....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst',\n",
       "  u'TAJ Associates LLC',\n",
       "  u'Bowie, MD',\n",
       "  u'Analyzes information and statistical data to prepare reports and studies for use by. TAJ Associates LLC is currently seeking an Research Analyst *.*....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst (Justice Team)',\n",
       "  u'CNA Corp.',\n",
       "  u'Arlington, VA 22201 (Lyon Village area)',\n",
       "  u'The CNA Institute for Public Research (IPR) seeks a research analyst to join the Justice Group. The CNA Justice Group numbers over 20 analysts and project',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Systems Serology Staff Scientist',\n",
       "  u'The Henry M. Jackson Foundation',\n",
       "  u'Silver Spring, MD 20910',\n",
       "  u'Provides data analysis and interpretation. Experience with project planning, implementation and data analysis....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'VP of Data Science & Architecture',\n",
       "  u'R.O.I. Checker',\n",
       "  u'Vienna, VA 22180',\n",
       "  u'VP of Data Science & Architecture*. Identify and evaluate current data management technologies. Implement measures to ensure data accuracy and accessibility....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Ops Research Analyst -Senior',\n",
       "  u'Advanced Concepts and Technologies International',\n",
       "  u'Washington, DC',\n",
       "  u'Career field management for scientists, engineers and acquisition program managers; Analyzing workforce data on size, certification, professional development,...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Technical Writer',\n",
       "  u'CACI',\n",
       "  u'Washington, DC 20001 (Shaw area)',\n",
       "  u'Confers with engineers, scientists and other technical experts to articulate complex concepts; Researches and analyzes technical data from a variety of...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Program Data Management, Analysis and Administration Analyst',\n",
       "  u'CSRA',\n",
       "  u'Arlington, VA',\n",
       "  u'Data analysis and reporting from associated databases and data sources. Comparing/updating our data between multiple Excel files and SharePoint lists - Perform...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist/Operations Research General Management Consul...',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'Washington, DC',\n",
       "  u'Data Scientist/Operations Research General Management Consultant. Knowledge of basic graphics design for presenting complex customer feedback data into easy-to...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Analyst, Disputes and Investigations',\n",
       "  u'DUFF AND PHELPS, LLC',\n",
       "  u'Washington, DC 20004 (Downtown area)',\n",
       "  u'The data rarely. And automatically download data sets. To join our Data Analytics team. Import data tables into a database using an....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'DevOps Data Scientist, Senior',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'Alexandria, VA',\n",
       "  u'DevOps Data Scientist, Senior. Perform as a data scientist to support the practices of continuous integration and continuous delivery and deployment through the...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Data Scientist',\n",
       "  u'GEICO',\n",
       "  u'Chevy Chase, MD 20815',\n",
       "  u'Senior Data Scientist. The Data Scientist team drives strategic business initiatives by researching, analyzing and interpreting data;...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Survey Research Analyst',\n",
       "  u'Deloitte',\n",
       "  u'Washington, DC',\n",
       "  u'Are you interested in working in a dynamic environment that offers opportunities for professional growth and new responsibilities? Are you interested in',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Program Coordinator - Cooperative Research Programs',\n",
       "  u'The National Academies',\n",
       "  u'Washington, DC',\n",
       "  u'Performs data collection. Gathers impact data for tracking purposes. Participates in tracking efforts including collection, analysis, and tabulation of data and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Systems Serology Staff Scientist',\n",
       "  u'The Henry M. Jackson Foundation',\n",
       "  u'Silver Spring, MD 20910',\n",
       "  u'Provides data analysis and interpretation. Experience with project planning, implementation and data analysis....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Media Research Analyst (overnight shifts)',\n",
       "  u'OMNITEC Solutions, Inc.',\n",
       "  u'Arlington, VA 22202 (Aurora Highlands area)',\n",
       "  u'People who thrive on the mechanics and nuances of media research, data gathering, analysis, and interpretation to provide up-to-the-minute situational awareness...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Program Data Management, Analysis and Administration Analyst',\n",
       "  u'CSRA',\n",
       "  u'Arlington, VA',\n",
       "  u'Data analysis and reporting from associated databases and data sources. Comparing/updating our data between multiple Excel files and SharePoint lists - Perform...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Research Analyst',\n",
       "  u'CBRE',\n",
       "  u'Washington, DC',\n",
       "  u'Ability to handle and manipulate large amounts of data. Reviews and evaluates data results collected by themselves and others within the research team to ensure...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Management Lead',\n",
       "  u'CRGT Inc.',\n",
       "  u'Tysons Corner, VA',\n",
       "  u'Experience creating an enterprise data strategy including data management, data governance, data transformation, and data exchanges....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Management Lead',\n",
       "  u'Salient CRGT',\n",
       "  u'Tysons Corner, VA',\n",
       "  u'Experience creating an enterprise data strategy including data management, data governance, data transformation, and data exchanges....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Scientist',\n",
       "  u'Aret\\xe9 Associates',\n",
       "  u'Arlington, VA',\n",
       "  u'Assess algorithm performance on real-world data. Sensor applications including EO/IR and radar, data analysis, signal processing, machine learning, algorithm...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist Research Appointment',\n",
       "  u'Oak Ridge Associated Universities',\n",
       "  u'Springfield, VA',\n",
       "  u'NGA InnoVision is seeking a data scientist with demonstrated ability and R&D experience in statistical/quantitative analysis and model based exploitation of...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Policy Analyst I',\n",
       "  u'Dowless & Associates, Inc.',\n",
       "  u'Washington, DC',\n",
       "  u'Seven years or more years of specialized experience working on complex data/database projects as a data analyst, data architect, data scientist or database...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Physical Scientist, AST, Atmospheric Chemistry and...',\n",
       "  u'National Aeronautics and Space Administration',\n",
       "  u'Greenbelt, MD',\n",
       "  u'Utilization of satellite data to test existing models; As Research Physical Scientist, specializing in Atmospheric, Chemistry and Dynamics, you will conduct...',\n",
       "  120212.5],\n",
       " ['Washington D.C.',\n",
       "  u'Analyst, Disputes and Investigations',\n",
       "  u'DUFF AND PHELPS, LLC',\n",
       "  u'Washington, DC 20004 (Downtown area)',\n",
       "  u'The data rarely. And automatically download data sets. To join our Data Analytics team. Import data tables into a database using an....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Social Sciences, Sr.',\n",
       "  u'Mitre Corporation',\n",
       "  u'McLean, VA',\n",
       "  u\"MITRE's highly skilled, multi-disciplined social and behavioral scientists play a vital role in helping transform government operations and services....\",\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Facilities Intern',\n",
       "  u'Natural Resources Defense Council',\n",
       "  u'Washington, DC',\n",
       "  u\"Maintain data bases, paper and electronic filing systems. The Natural Resources Defense Council (NRDC) is the nation's most effective environmental action group...\",\n",
       "  24000.0],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Zapata Technology',\n",
       "  u'Washington, DC 20024 (South West area)',\n",
       "  u'Data Scientist - Data Science / Integration / Analytics - Remote. BS or MS in Mathematics, Statistics, or Data Science....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Flow Lead',\n",
       "  u'Aveshka, Inc.',\n",
       "  u'Bolling AFB, DC',\n",
       "  u'Deliver DoDIIS and IC ITE data services which increase data enrichment, improve access to DIA data sources and support data analytics and data science....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Technical Writer',\n",
       "  u'CACI',\n",
       "  u'Washington, DC 20001 (Shaw area)',\n",
       "  u'Confers with engineers, scientists and other technical experts to articulate complex concepts; Researches and analyzes technical data from a variety of...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'COMPUTER SCIENTIST, GS 15/(EX) IT Infrastructure Division/Wa...',\n",
       "  u'Federal Bureau of Investigation',\n",
       "  u'Washington, DC',\n",
       "  u'Data Management System. Computer Scientist, GS 15. The Computer Scientist will evaluate MPO IT project compliance to FBI policies, processes and standards....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Climate Fellowship',\n",
       "  u'Development Seed',\n",
       "  u'Washington, DC',\n",
       "  u'Remotely sensed data and associated libraries (GDAL, QGIS). Your main focus will be on one of our open-source projects that supports accessible, open earth data...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Data Scientist',\n",
       "  u'Sevatec, Inc.',\n",
       "  u'Fairfax, VA 22031',\n",
       "  u'The Data Scientist will work closely with clients, data stewards, project/program managers, and other IT teams to turn data into critical information and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Research Analyst, Andean Region',\n",
       "  u'Frontier Strategy Group LLC',\n",
       "  u'Washington, DC 20036 (Downtown area)',\n",
       "  u'Promising candidates will proceed through a phone interview, a data forecasting test, a half-day of in-person interviews, and finally a case study presentation....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'MISSION ANALYST, REAL PROPERTY RESEARCH ANALYST',\n",
       "  u'VERSAR',\n",
       "  u'Arlington, VA',\n",
       "  u'Data anomaly corrections; Development and maintainance of RPI metrics/performance indicators by evaluating and analyzing RPI data IAW those metrics/performance...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Scientist',\n",
       "  u'Aret\\xe9 Associates',\n",
       "  u'Arlington, VA',\n",
       "  u'Assess algorithm performance on real-world data. Sensor applications including EO/IR and radar, data analysis, signal processing, machine learning, algorithm...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst',\n",
       "  u'Armed Forces Services Corporation',\n",
       "  u'Arlington, VA',\n",
       "  u'Experience in managing complex data from multiple sources, including statistical analysis of longitudinal or repeated measurement data;...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist Research Appointment',\n",
       "  u'Oak Ridge Associated Universities',\n",
       "  u'Springfield, VA',\n",
       "  u'NGA InnoVision is seeking a data scientist with demonstrated ability and R&D experience in statistical/quantitative analysis and model based exploitation of...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'IHS Markit',\n",
       "  u'Washington, DC',\n",
       "  u'Demonstrated ability to understand problems and conceptualize solutions through mastery of data manipulation, exploratory data analysis, modeling, and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Flow Lead',\n",
       "  u'Aveshka, Inc.',\n",
       "  u'Bolling AFB, DC',\n",
       "  u'Deliver DoDIIS and IC ITE data services which increase data enrichment, improve access to DIA data sources and support data analytics and data science....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Python / R Programmer',\n",
       "  u'SouthTek Resources',\n",
       "  u'McLean, VA',\n",
       "  u'Partner with Statisticians and Data Scientists to design and implement high quality, production solutions using distributed computing and Big Data technologies....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Scientist',\n",
       "  u'EPM Scientific',\n",
       "  u'Rockville, MD',\n",
       "  u'Scientist | Analytical Chemistry*. Ability to properly evaluate and interpret generated data. Senior Scientist, Analytical Chemistry required for rapidly...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Policy Analyst I',\n",
       "  u'Dowless & Associates, Inc.',\n",
       "  u'Washington, DC',\n",
       "  u'Seven years or more years of specialized experience working on complex data/database projects as a data analyst, data architect, data scientist or database...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Systems Engineer III (Data Analysis Specialist)',\n",
       "  u'CNA Corp.',\n",
       "  u'Arlington, VA 22201 (Lyon Village area)',\n",
       "  u'Applies formal, established engineering and management principles to specifications and documentation of systems developed, with emphasis on data analysis, data...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Strayer University',\n",
       "  u'Herndon, VA 20171',\n",
       "  u'A job opportunity for a data scientist with a passion for solving real world problems using Machine Learning (ML), Artificial Intelligence (AI) and software...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Sr. Director - Data Engineering',\n",
       "  u'Capital One',\n",
       "  u'Vienna, VA',\n",
       "  u'Director - Data Engineering. Utilizing a team of data engineers, data scientists, and other key contributors, this executive will impact every Capital One...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst I',\n",
       "  u'PenFed Credit Union',\n",
       "  u'Alexandria, VA',\n",
       "  u'PenFed is hiring a Research Analyst in our Alexandria, VA office. The primary purpose of this job is to efficiently research and resolve problems in response',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst (Statistics/GIS)',\n",
       "  u'CNA Corp.',\n",
       "  u'Arlington, VA 22201 (Lyon Village area)',\n",
       "  u'6 Generate compelling visualizations of quantitative datasets and qualitative data or process diagrams. Serve as an important contributing team member on...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst/ Sr. Research Analyst',\n",
       "  u'CEB',\n",
       "  u'Washington, DC',\n",
       "  u'Experience analyzing quantitative and qualitative data. By pooling the collective experience of the more than 300,000 business professionals and 10,000...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Technology Analyst - Junior',\n",
       "  u'AECOM',\n",
       "  u'Arlington, VA 22204 (Douglas Park area)',\n",
       "  u'+ responses to data call. The individual must interface with senior ONR scientists and managers while working cooperatively with the FNC Support Staff to...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Analyst',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'Springfield, VA',\n",
       "  u'3+ years of experience as a data analyst or data scientist. Knowledge of statistical methods and standard data mining techniques....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Research Analyst',\n",
       "  u'Vencore',\n",
       "  u'McLean, VA',\n",
       "  u'Vencore is a proven provider of information solutions, engineering and analytics for the U.S. Government. With more than 40 years of experience working in the',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Scientist',\n",
       "  u'EPM Scientific',\n",
       "  u'Rockville, MD',\n",
       "  u'Scientist | Analytical Chemistry*. Ability to properly evaluate and interpret generated data. Senior Scientist, Analytical Chemistry required for rapidly...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst',\n",
       "  u'Leger',\n",
       "  u'Fort Washington, MD',\n",
       "  u'Where? Fort Washington When? Immediately Permanent / full-time position Leger, The Research Intelligence Group, is looking for a Research Analyst to work in',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'SVP, Investment Research Group (Long Term Care Analyst)',\n",
       "  u'Capital One',\n",
       "  u'Bethesda, MD',\n",
       "  u'Bethesda Metro Center (17049), United States of America, Bethesda, Maryland At Capital One, we\\u2019re building a leading information-based technology company.',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Associate Data Scientist',\n",
       "  u'IHS Markit',\n",
       "  u'Washington, DC',\n",
       "  u'Data Scientist, Analytics. Experience writing code and using data science tools such as SQL, Python, Tableau, ArcGIS, and/or Hadoop highly desirable....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Evans & Chambers Technology',\n",
       "  u'Springfield, VA',\n",
       "  u'This position is for a highly-skilled Data Scientist to support the deployment and evolution of a core web application and data workflow....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Software Engineer',\n",
       "  u'Nuna',\n",
       "  u'Washington, DC',\n",
       "  u'Our technology enables data scientists, analysts, benefits officers, and policymakers to understand healthcare data while ensuring its integrity, security and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Sr Data Scientist',\n",
       "  u'Praxis Engineering',\n",
       "  u'Reston, VA',\n",
       "  u'The Senior Data Scientist will be developing highly complex programmatic and quantitative methods to find patterns and relationships in large data sets;...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Delex',\n",
       "  u'Suitland, MD',\n",
       "  u'Interactive Data Language (IDL). 1 year practical work experience with geospatial or imagery data. 3 years of practical work experience integrating data mining,...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Scientific Information Analyst',\n",
       "  u'Leidos',\n",
       "  u'Bethesda, MD 20813',\n",
       "  u'This position provides scientific analysis to support accurate reporting of investments based on categorized research data....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Research Analyst, Andean Region',\n",
       "  u'Frontier Strategy Group LLC',\n",
       "  u'Washington, DC 20036 (Downtown area)',\n",
       "  u'Promising candidates will proceed through a phone interview, a data forecasting test, a half-day of in-person interviews, and finally a case study presentation....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Sr. Data Analysis Manager',\n",
       "  u'Capital One',\n",
       "  u'McLean, VA',\n",
       "  u'5+ years of experience managing or developing enterprise data management, data governance or data quality programs. Data Analysis Manager....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'IHS Markit',\n",
       "  u'Washington, DC',\n",
       "  u'Demonstrated ability to understand problems and conceptualize solutions through mastery of data manipulation, exploratory data analysis, modeling, and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst',\n",
       "  u'CSRA',\n",
       "  u'Merrifield, VA',\n",
       "  u'Plans and conducts scientific testing and prepares comprehensive technical reports, data reports, and other publications....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Market Research Analyst',\n",
       "  u'Council',\n",
       "  u'Washington, DC 20036 (Downtown area)',\n",
       "  u'Focus on expanding data tools and supporting a data driven culture. Provides collaboration and direction for data architecture strategy including overall data...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'OPERATIONS RESEARCH ANALYST, LEAD',\n",
       "  u'CACI',\n",
       "  u'Arlington, VA 22202 (Aurora Highlands area)',\n",
       "  u'The Contractor shall take structured and unstructured data and distill the information into a cohesive analytical product for a senior military audience....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Technology Consultant',\n",
       "  u'Ignyte Group',\n",
       "  u'Washington, DC 20006 (Foggy Bottom area)',\n",
       "  u'Your everyday tasks can range from working with clients to develop their digital strategies, to working with designers to create user interfaces or even working...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Digital Strategy Intern',\n",
       "  u'\\xd8ptimus Consulting',\n",
       "  u'Washington, DC 20005 (Logan Circle area)',\n",
       "  u'\\xd8ptimus Consulting is a family of statisticians, graphic designers, data scientists, programmers, social media marketing analysts, and recovering politicos....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Big Data Engineer - Shared Informaton Support, Prf',\n",
       "  u'Freddie Mac',\n",
       "  u'McLean, VA 22102',\n",
       "  u'Experience working with Data Scientists. The Data Engineer will provide data engineering (ingestion) and data enablement support the provision of analytic ready...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Quantitative Analyst',\n",
       "  u'Capital One',\n",
       "  u'McLean, VA',\n",
       "  u'Collect, organize, and analyze large econometric data sets. Apply mathematical and statistical methods to collect, organize, interpret, and summarize data in...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Biostatistician / Research Analyst',\n",
       "  u'American Red Cross',\n",
       "  u'Rockville, MD 20850',\n",
       "  u'Investigates, analyzes, and evaluates data using accepted statistical techniques. Communicates with data providers internal and external about accuracy and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Compl Prgms Monitor/Assesor',\n",
       "  u'RELX Corporate',\n",
       "  u'Washington, DC',\n",
       "  u'We help scientists make new discoveries, lawyers win cases, doctors save lives, and executives forge commercial relationships with their clients....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Staff Scientist',\n",
       "  u'The Henry M. Jackson Foundation',\n",
       "  u'Bethesda, MD 20814',\n",
       "  u'Processes, analyses, and interprets experimental data. Experience with database development and data management is desirable....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'KPMG',\n",
       "  u'Washington, DC 20036 (Downtown area)',\n",
       "  u'KPMG is currently seeking a Senior Associate Data Scientist to join our Data & Analytics Organization. Five years of professional experience working as a Data...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Washington',\n",
       "  u'Cognitio',\n",
       "  u'Washington, DC',\n",
       "  u'Data Scientist, Expert. Experience with integrating data from multiple data sources. Acquire data from primary or secondary data sources and maintain databases...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist/Analyst',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'McLean, VA',\n",
       "  u'Experience with using R, Perl, Python, SAS, or SPSS for analysis of data. Experience with machine learning, data mining, statistics, or graph algorithms in an...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist with TS/SCI',\n",
       "  u'OneGlobe, LLC',\n",
       "  u'Washington, DC',\n",
       "  u'Handles raw data (e.g. Experienced in working with and exploiting big data; At level 5, supervises, manages, and reviews work outputs of lower level scientists....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Analyst',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'Springfield, VA',\n",
       "  u'3+ years of experience as a data analyst or data scientist. Knowledge of statistical methods and standard data mining techniques....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Behavioral Health Epidemiologist/Sr. Analyst SME',\n",
       "  u'The Tauri Group',\n",
       "  u'Washington, DC',\n",
       "  u'Provide consultative support for ad hoc data. Assure data quality through assisting/leading quality. We are seeking a behavioral health epidemiologist/senior...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Federal - ETL/BI Developer',\n",
       "  u'Accenture',\n",
       "  u'Springfield, VA',\n",
       "  u'In this role, the Developer will work closely with IT Architects, Analysts, Data Scientists, UI/UX designers, functional practitioners, and clients/stakeholders...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Data Scientist Job',\n",
       "  u'Bechtel',\n",
       "  u'Reston, VA',\n",
       "  u'Senior Data Scientist. Bechtel Corporation is seeking a Senior Data Scientist for its highly anticipated Data & Analytics Center of Excellence (COE)....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Analytical Consulting Group, LLC',\n",
       "  u'Springfield, VA',\n",
       "  u'Analytical Consulting Group LLC is looking for data scientists to fill requirements in Springfield, VA. Ensure the confidentiality, integrity, and availability...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst',\n",
       "  u'Leger',\n",
       "  u'Fort Washington, MD',\n",
       "  u'Where? Fort Washington When? Immediately Permanent / full-time position Leger, The Research Intelligence Group, is looking for a Research Analyst to work in',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Genomic Data Scientist',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'Rockville, MD',\n",
       "  u'Genomic Data Scientist. Knowledge of key data analytics techniques and data types used in genomics and biomedical research....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'SENIOR SCIENTIST',\n",
       "  u'VERSAR',\n",
       "  u'Germantown, MD 20874',\n",
       "  u'Strong analytical and data management skills; Proficiency with MS Office applications and ability to conduct data analysis (including statistical analyses) in...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Big Data Engineer - Shared Informaton Support, Prf',\n",
       "  u'Freddie Mac',\n",
       "  u'McLean, VA 22102',\n",
       "  u'Experience working with Data Scientists. The Data Engineer will provide data engineering (ingestion) and data enablement support the provision of analytic ready...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Quantitative Analyst',\n",
       "  u'Capital One',\n",
       "  u'McLean, VA',\n",
       "  u'Collect, organize, and analyze large econometric data sets. Apply mathematical and statistical methods to collect, organize, interpret, and summarize data in...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst',\n",
       "  u'CSRA',\n",
       "  u'Merrifield, VA',\n",
       "  u'Plans and conducts scientific testing and prepares comprehensive technical reports, data reports, and other publications....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Biostatistician / Research Analyst',\n",
       "  u'American Red Cross',\n",
       "  u'Rockville, MD 20850',\n",
       "  u'Investigates, analyzes, and evaluates data using accepted statistical techniques. Communicates with data providers internal and external about accuracy and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Business Analyst',\n",
       "  u'Net ESolutions Corporation (NETE)',\n",
       "  u'Bethesda, MD',\n",
       "  u'Working knowledge of data analysis tools including Excel Pivot tables, and other data analysis skills is a plus....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Staff Scientist - MAR16-02',\n",
       "  u'Human Resources Research Organization',\n",
       "  u'Alexandria, VA',\n",
       "  u'Analyzing data and interpreting results. Human Resources Research Organization (HumRRO) is looking for talented individuals to join our premier research and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Intel Research Analyst',\n",
       "  u'Leidos',\n",
       "  u'Bethesda, MD 20813',\n",
       "  u'Description: Leidos has an exciting opening for an experience Intelligence Researcher. This person will s erve as one of a team of part-time writers for a',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Sr Data Scientist',\n",
       "  u'Praxis Engineering',\n",
       "  u'Reston, VA',\n",
       "  u'The Senior Data Scientist will be developing highly complex programmatic and quantitative methods to find patterns and relationships in large data sets;...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist, Natural Language Processing',\n",
       "  u'KPMG',\n",
       "  u'Washington, DC 20036 (Downtown area)',\n",
       "  u'KPMG is currently seeking a Senior Associate Data Scientist to join our Advanced Data & Analytics Organization....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Research Scientist - Health Marketing/Communications',\n",
       "  u'National Opinion Research Center (NORC)',\n",
       "  u'Bethesda, MD',\n",
       "  u'High level of technical competence in study design, data collection protocol development, data analysis and reporting of findings....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Analyst, EAB Research',\n",
       "  u'The Advisory Board Company',\n",
       "  u'Washington, DC',\n",
       "  u'The Education Advisory Board is the firm\\u2019s higher education practice, with membership programs serving Chief Academic Officers, Chief Business Officers,',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Market Research Analyst',\n",
       "  u'SAGE Publishing',\n",
       "  u'Washington, DC',\n",
       "  u'The Market Research Analyst will collect and store their own research, as well as SAGE\\u2019s data on the academic library market size and trends;...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Big Data Developer / Data Scientist',\n",
       "  u'Noblis',\n",
       "  u'Lanham, MD',\n",
       "  u'The individual must also have a solid understanding of data flow and processing of large data sets. Team members will work collaboratively with the Noblis data...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Scientist/S&T Advisor',\n",
       "  u'Integrity Applications Incorporated',\n",
       "  u'Vienna, VA',\n",
       "  u'Analyze existing IC S&T program data to define programmatic baselines and identify opportunities for synergy;...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Analyst, Financial& Quantitative Analytics',\n",
       "  u'Inovalon',\n",
       "  u'Bowie, MD 20715',\n",
       "  u'Perform root cause analysis to identify data flow issues/ system performance issues and/or data discrepancy issues employing SQL queries and database tools....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Real Estate and Urban Planning Research Analyst (12726, Grad...',\n",
       "  u'The Maryland-National Capital Park and Planning Co...',\n",
       "  u'Silver Spring, MD 20902',\n",
       "  u'Experience with Costar and other real estate data sources. The Research and Special Projects Division (R&SP) is responsible for demographic, land use and...',\n",
       "  79475.0],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'WESTAT',\n",
       "  u'Rockville, MD 20850',\n",
       "  u'Westat is seeking a data scientist to apply advanced statistical solutions to assist in managing and improving survey data collection, design, and methodology....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Behavioral Health Epidemiologist/Sr. Analyst SME',\n",
       "  u'The Tauri Group',\n",
       "  u'Washington, DC',\n",
       "  u'Provide consultative support for ad hoc data. Assure data quality through assisting/leading quality. We are seeking a behavioral health epidemiologist/senior...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Scientist/S&T Advisor',\n",
       "  u'Integrity Applications Incorporated',\n",
       "  u'Vienna, VA',\n",
       "  u'Analyze existing IC S&T program data to define programmatic baselines and identify opportunities for synergy;...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Market Research Analyst',\n",
       "  u'SAGE Publishing',\n",
       "  u'Washington, DC',\n",
       "  u'The Market Research Analyst will collect and store their own research, as well as SAGE\\u2019s data on the academic library market size and trends;...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Research Scientist - Health Marketing/Communications',\n",
       "  u'National Opinion Research Center (NORC)',\n",
       "  u'Bethesda, MD',\n",
       "  u'High level of technical competence in study design, data collection protocol development, data analysis and reporting of findings....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Project Support Specialist',\n",
       "  u'ASRC Federal',\n",
       "  u'Greenbelt, MD',\n",
       "  u'Track data to ensure accuracy and budgetary compliance. Our team of scientists and professional management personnel allows us to bring real-world experience to...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Statistician - Healthcare or Pharma Industry',\n",
       "  u'Contingent/Direct Consultants',\n",
       "  u'Gaithersburg, MD 20877',\n",
       "  u'Experience of Development, program design and data analysis and interpretation. B&I drives good design to generate the data needed for quality decision making....',\n",
       "  150000.0],\n",
       " ['Washington D.C.',\n",
       "  u'Quantitative Analytics Professional A',\n",
       "  u'Freddie Mac',\n",
       "  u'McLean, VA 22102',\n",
       "  u'Visualize data to communicate complex ideas. Use techniques from statistics, machine learning, and other data sciences to estimate predictive models from...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'WESTAT',\n",
       "  u'Rockville, MD 20850',\n",
       "  u'Westat is seeking a data scientist to apply advanced statistical solutions to assist in managing and improving survey data collection, design, and methodology....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist with TS/SCI',\n",
       "  u'OneGlobe, LLC',\n",
       "  u'Washington, DC',\n",
       "  u'Handles raw data (e.g. Experienced in working with and exploiting big data; At level 5, supervises, manages, and reviews work outputs of lower level scientists....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Data Scientist',\n",
       "  u'Freddie Mac',\n",
       "  u'McLean, VA 22102',\n",
       "  u'As a Data Scientist on the Collateral Modeling and Analytics team at Freddie Mac, you will join a group of skilled professionals who use data science to solve...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Junior Analyst, Quantitative Analysis',\n",
       "  u'AMERICAN SYSTEMS',\n",
       "  u'Fort Myer, VA 22211',\n",
       "  u'College graduates with TS/SCI!! Now is your opportunity to turn your internship with a security clearance into an exciting and meaningful full-time position!',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'NOA1771 Science Writer',\n",
       "  u'IMSG, Inc.',\n",
       "  u'Silver Spring, MD',\n",
       "  u'Use technology or data visualizations to communicate scientific information. Work with NOAA scientists and subject matter experts to translate technical and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Junior Technical Writer',\n",
       "  u'Engility Corporation',\n",
       "  u'Silver Spring, MD 20993',\n",
       "  u'Data and System Analysis responsibilities:. Supports the analysis of systems and data. Supports The FDA IDIQ as a junior technical writer\\\\systems and data...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist/Demographer, Senior',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'Springfield, VA',\n",
       "  u'Data Scientist/Demographer, Senior. Produce statistical and computational analysis on a variety of datasets in accordance with industry best practices,...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209 (Radnor-Ft Myer Heights area)',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Analyst/Collection Manager',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'Springfield, VA',\n",
       "  u'3+ years of experience as a data analyst or data scientist. Data Analyst/Collection Manager. Experience with analyzing large sets of data using standard...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Policy - Data Analyst',\n",
       "  u'Eagle Ray Inc',\n",
       "  u'Washington, DC',\n",
       "  u'Seven years or more years of specialized experience working on complex data/database projects as a data analyst, data architect, data scientist or database...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Web Based Research Analyst',\n",
       "  u'Raytheon',\n",
       "  u'Herndon, VA 20170',\n",
       "  u'Raytheon Blackbird Technologies is currently seeking a Web-Based Research Analyst to support current company efforts in Herndon, Virginia. The Web-Based',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'University - Data Analyst/Scientist',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'Washington, DC',\n",
       "  u'University - Data Analyst/Scientist. Experience with using R, Perl, Python, SAS, or SPSS for analysis of data. A Day in the Life of a Data Analyst at Booz Allen...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Quantitative Analytics Professional A',\n",
       "  u'Freddie Mac',\n",
       "  u'McLean, VA 22102',\n",
       "  u'Visualize data to communicate complex ideas. Use techniques from statistics, machine learning, and other data sciences to estimate predictive models from...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Lead Data Scientist/Statistician, Veterans Experience Office',\n",
       "  u'ERPi',\n",
       "  u'Washington, DC',\n",
       "  u'Collecting national customer experience data. Support the integration of disparate data sets based on common data elements using statistical software packages...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist/ Data Modeler',\n",
       "  u'Leidos',\n",
       "  u'Suitland, MD 20752',\n",
       "  u'O Statistical data analysis and use of data analysis tools (e.g. O Data preparation and visualization/presentation....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Operations Research Analyst',\n",
       "  u'DAWSON',\n",
       "  u'Washington, DC 20001 (Shaw area)',\n",
       "  u'(Note: This position is contingent upon a successful proposal submission and subsequent contract award. Work is expected to begin in September/October 2017)',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Operations Research Analyst (Air Traffic Management)',\n",
       "  u'Mitre Corporation',\n",
       "  u'McLean, VA',\n",
       "  u'You will be expected to work with other team members, and work with and further develop a large integrated Oracle data base of aviation data, as well as use...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Software Engineer \\u2013 Big Data/IoT',\n",
       "  u'Select Source Solutions',\n",
       "  u'Alexandria, VA',\n",
       "  u'We work in small, multi-disciplined teams of product managers, hardware engineers, data engineers, data scientists, application engineers, and devops...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'NOA1772 Support Scientist \\u2013 Ensemble Forecasting for sub-sea...',\n",
       "  u'I.M. Systems Group (IMSG)',\n",
       "  u'College Park, MD',\n",
       "  u'Must also have experience with running complex jobs, and processing large amounts of numerical output data on mainframe supercomputers and/or workstations in a...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Marketing Analytics Manager',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'Washington, DC',\n",
       "  u'Serve as a marketer, analyst, and data scientist to transform how the marketing and communications function and firm business leaders consume and use marketing...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Vanda Pharmaceuticals Inc.',\n",
       "  u'Washington, DC 20037 (Foggy Bottom area)',\n",
       "  u'Vanda is seeking a Data Scientist who will primarily be responsible for developing analytical models and providing data driven insights....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Engineer',\n",
       "  u'SRC, Inc.',\n",
       "  u'Fort Belvoir, VA',\n",
       "  u'In addition, you will collaborate with other data engineers, data scientists, software engineers, and other researchers in the DoD and industry....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Billing Analyst - Clinical Research (P)',\n",
       "  u'Huron Consulting Group Inc.',\n",
       "  u'Washington, DC 20036 (Downtown area)',\n",
       "  u'As part of the Research Office team, the Clinical Research Billing Specialist plays an important role in the analytics of billed items and services provided',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'University - Data Analyst/Scientist',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'Washington, DC',\n",
       "  u'University - Data Analyst/Scientist. Experience with using R, Perl, Python, SAS, or SPSS for analysis of data. A Day in the Life of a Data Analyst at Booz Allen...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Energetic and Non-Energetic Materials Chemical Analyst',\n",
       "  u'Bennett Aerospace Inc.',\n",
       "  u'Adelphi, MD',\n",
       "  u'Experience as Scientist and/or Engineer. Currently, ARL scientists and engineers are pioneering research in such areas as neuroergonomics, energetic materials...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Assistant III',\n",
       "  u'The Henry M. Jackson Foundation',\n",
       "  u'Bethesda, MD 20889',\n",
       "  u'Provides data analysis and interpretation. Assists with training laboratory staff, students and visiting scientists as required....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Junior Technical Writer',\n",
       "  u'Engility Corporation',\n",
       "  u'Silver Spring, MD 20993',\n",
       "  u'Data and System Analysis responsibilities:. Supports the analysis of systems and data. Supports The FDA IDIQ as a junior technical writer\\\\systems and data...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Statistician (Journeyman)',\n",
       "  u'Advanced Concepts and Technologies International',\n",
       "  u'Washington, DC',\n",
       "  u'This position is also in support the CBP Data Center Migration (DCM) Program Management Office, currently within EDME....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'NOA1771 Science Writer',\n",
       "  u'IMSG, Inc.',\n",
       "  u'Silver Spring, MD',\n",
       "  u'Use technology or data visualizations to communicate scientific information. Work with NOAA scientists and subject matter experts to translate technical and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist/SW Engineer',\n",
       "  u'Invictus International Consulting, LLC',\n",
       "  u'Reston, VA',\n",
       "  u'Data Scientist/Software Engineer. As a Data Scientist, support the practices of continuous integration, continuous delivery, and deployment through the...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209 (Radnor-Ft Myer Heights area)',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Algorithm Developer in Machine Learning',\n",
       "  u'Expedition Technology, Inc.',\n",
       "  u'Dulles, VA 20166',\n",
       "  u'Data science and analysis. EXP is an employee-owned defense and aerospace technology start-up seeking scientist and engineers who enjoy taking challenging...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Federal - Analytics Senior Analyst',\n",
       "  u'Accenture',\n",
       "  u'Suitland, MD',\n",
       "  u'Expected to work with clients as a data scientist and problem solver to. Define data and technology. Drive the exploration of data sources and analytic...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Database Engineer',\n",
       "  u'Alion Science and Technology',\n",
       "  u'Washington, DC 20003 (Capitol Hill area)',\n",
       "  u'Use predictive modeling, machine learning, data mining, and/or any other data analysis techniques to extract insights from large unstructured or structured data...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Sr. Scientific Researcher',\n",
       "  u'Digicon',\n",
       "  u'McLean, VA',\n",
       "  u'Experience processing unstructured data and manipulating large data sets is desirable. Analyze genomic and clinical data....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Data Scientist',\n",
       "  u'Freddie Mac',\n",
       "  u'McLean, VA 22102',\n",
       "  u'As a Data Scientist on the Collateral Modeling and Analytics team at Freddie Mac, you will join a group of skilled professionals who use data science to solve...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Statistician (Journeyman)',\n",
       "  u'Advanced Concepts and Technologies International',\n",
       "  u'Washington, DC',\n",
       "  u'This position is also in support the CBP Data Center Migration (DCM) Program Management Office, currently within EDME....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Federal - Analytics Senior Analyst',\n",
       "  u'Accenture',\n",
       "  u'Suitland, MD',\n",
       "  u'Expected to work with clients as a data scientist and problem solver to. Define data and technology. Drive the exploration of data sources and analytic...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst',\n",
       "  u'Smart Media Group',\n",
       "  u'Alexandria, VA 22301 (Potomac West area)',\n",
       "  u'Tasks include gathering, analyzing, and visualizing relevant data from a number of external sources; And assisting the Research Director with ad hoc requests...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Defense Research Analyst, Senior',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'Washington, DC',\n",
       "  u'Booz Allen Hamilton has been at the forefront of strategy and technology for more than 100 years Today, the firm provides management and technology consulting',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist/Statistician',\n",
       "  u'Parsons Corporation',\n",
       "  u'Springfield, VA',\n",
       "  u'Data Scientist / Data Analytics / Statistician / Mathematician / Systems Engineer / Systems Analyst. Analyze model data from industrial partners and research...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Science DevOps Engineer, Senior',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'Alexandria, VA',\n",
       "  u'Data Science DevOps Engineer, Senior. Perform as a data scientist to support the practices of continuous integration and continuous delivery and deployment...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Sr Data Scientist with Polygraph',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209 (Radnor-Ft Myer Heights area)',\n",
       "  u'Serve as a \\u201cSubject Matter Expert\\u201d, adding interpretive value to data presented or experienced insight into a functional process or issue....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Analyst / Data Scientist',\n",
       "  u'CALIBRE Systems, Inc.',\n",
       "  u'Alexandria, VA 22310',\n",
       "  u'CALIBRE, an employee-owned management consulting and information technology solutions company is seeking a Senior Analyst/ Data Scientist to support one of the...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Brain Trauma Research Scientist (Neuroscientist) (WRAIR)',\n",
       "  u'General Dynamics Information Technology',\n",
       "  u'Silver Spring, MD',\n",
       "  u'Utilizes established mathematical and scientific techniques to compile and analyze data. Walter Reed Army Institute of Research (WRAIR), in support of its...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Image - Video Analyst',\n",
       "  u'EOIR Technologies',\n",
       "  u'Fort Belvoir, VA',\n",
       "  u'Data Processing/Analysis Skills. Computer Scientist \\u2013 Video Analyst. Candidates will support project leads, scientists, and engineers with video analytics and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst, China Studies',\n",
       "  u'CNA Corp.',\n",
       "  u'Arlington, VA 22201 (Lyon Village area)',\n",
       "  u'Serve as an important contributing team member on projects or lead smaller/less complex activities. Demonstrate analytical competence. 1 Develop sound',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Computer Scientist, Cryptography Technical SETA Job',\n",
       "  u'SAIC',\n",
       "  u'College Park, MD',\n",
       "  u'Computer Scientist, Cryptography Technical SETA (Job Number:. Advise the Government PM in the areas of cryptographic protocols, secure data devices, programming...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Energetic and Non-Energetic Materials Chemical Analyst',\n",
       "  u'Bennett Aerospace Inc.',\n",
       "  u'Adelphi, MD',\n",
       "  u'Experience as Scientist and/or Engineer. Currently, ARL scientists and engineers are pioneering research in such areas as neuroergonomics, energetic materials...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Statistician',\n",
       "  u'ANALYTICA',\n",
       "  u'Washington, DC 20036 (Downtown area)',\n",
       "  u'Experience working with demographic, economic and social statistical data, especially large-scale production of summary statistics....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Engineering Lead',\n",
       "  u'Leidos',\n",
       "  u'Chantilly, VA 20153',\n",
       "  u'Demonstrated experience performing data assessment, data engineering, modeling and analytics to enable new methodologies for end user analysts, data scientists,...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Government Engagements',\n",
       "  u'KPMG',\n",
       "  u'Washington, DC 20036 (Downtown area)',\n",
       "  u'Five years of professional experience working as a Data Scientist. Machine learning, data visualization, statistical modeling, data mining, or information...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Leidos',\n",
       "  u'Suitland, MD 20752',\n",
       "  u'1+ yrs practical work experience with geospatial data or imagery data. Perform exploratory and targeted data analyses;...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Computer Scientist',\n",
       "  u'USC',\n",
       "  u'Arlington, VA',\n",
       "  u'Today, RCG is addressing our nation\\u2019s challenges in big data, hardware cybersecurity, trusted systems, cognitive radio and more....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'ETL Developer/Engineer (Scientist/Engineering Specialist)',\n",
       "  u'Knowesis Inc.',\n",
       "  u'Fairfax, VA 22031',\n",
       "  u'Data profiling experience. ETL, SQL, SSIS, Engineering, Scientist. Deep understanding of Data Warehousing principles with hands on experience including EDW, ODS...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Defense Research Analyst, Senior',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'Washington, DC',\n",
       "  u'Booz Allen Hamilton has been at the forefront of strategy and technology for more than 100 years Today, the firm provides management and technology consulting',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Brain Trauma Research Scientist (Neuroscientist) (WRAIR)',\n",
       "  u'General Dynamics Information Technology',\n",
       "  u'Silver Spring, MD',\n",
       "  u'Utilizes established mathematical and scientific techniques to compile and analyze data. Walter Reed Army Institute of Research (WRAIR), in support of its...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'NOA1772 Support Scientist \\u2013 Ensemble Forecasting for sub-sea...',\n",
       "  u'I.M. Systems Group (IMSG)',\n",
       "  u'College Park, MD',\n",
       "  u'Must also have experience with running complex jobs, and processing large amounts of numerical output data on mainframe supercomputers and/or workstations in a...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Database Engineer',\n",
       "  u'Alion Science and Technology',\n",
       "  u'Washington, DC 20003 (Capitol Hill area)',\n",
       "  u'Use predictive modeling, machine learning, data mining, and/or any other data analysis techniques to extract insights from large unstructured or structured data...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Credit Risk Transfer Research Analyst',\n",
       "  u'Fannie Mae',\n",
       "  u'Washington, DC 20022 (Brentwood area)',\n",
       "  u'Familiarity with Fannie Mae\\u2019s historical credit performance and data. Enthusiasm to analyze large data sets and work on hard, ill-defined problems....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Billing Analyst - Clinical Research (P)',\n",
       "  u'Huron Consulting Group Inc.',\n",
       "  u'Washington, DC 20036 (Downtown area)',\n",
       "  u'As part of the Research Office team, the Clinical Research Billing Specialist plays an important role in the analytics of billed items and services provided',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Business Development Research Analyst',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'McLean, VA',\n",
       "  u'Develop new reports and tools, as needed and organize, analyze, and synthesize data and information using Excel and PowerPoint....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Laulima Government Solutions, LLC.',\n",
       "  u'Falls Church, VA',\n",
       "  u'The Data Scientist will incorporate technology while communicating data findings to both DoD and AF stakeholders, leaders and TEH Office managers to help AFMS...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Water Distribution System Modeler',\n",
       "  u'Arcadis:US',\n",
       "  u'Washington, DC',\n",
       "  u'Assist with water distribution system and asset management data analytics. The Engineer will utilize their technical knowledge of hydraulics and water...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Tobacco Research Analyst',\n",
       "  u'WESTAT',\n",
       "  u'Rockville, MD 20850',\n",
       "  u'Conducting data analysis, collaborating with senior scientists and programmers in implementing analysis plans;...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Government Engagements',\n",
       "  u'KPMG',\n",
       "  u'Washington, DC 20036 (Downtown area)',\n",
       "  u'Five years of professional experience working as a Data Scientist. Machine learning, data visualization, statistical modeling, data mining, or information...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'ETL/BI Developer',\n",
       "  u'Accenture',\n",
       "  u'Springfield, VA',\n",
       "  u'In this role, the Developer will work closely with IT Architects, Analysts, Data Scientists, UI/UX designers, functional practitioners, and clients/stakeholders...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Operations Research Analyst',\n",
       "  u'DAWSON',\n",
       "  u'Washington, DC 20001 (Shaw area)',\n",
       "  u'(Note: This position is contingent upon a successful proposal submission and subsequent contract award. Work is expected to begin in September/October 2017)',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Associate',\n",
       "  u'Dillon Allman & Partners',\n",
       "  u'Bethesda, MD 20814',\n",
       "  u\"He/she will work closely with other Dillon Allman staff in gathering and analyzing data that is relevant to the company's clients along with assisting in...\",\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Data Scientist/Statistician/Predictive Modeler',\n",
       "  u'DataLab USA',\n",
       "  u'Germantown, MD 20876',\n",
       "  u'Strong data mining proficiency. 3-5 years of database marketing and data mining experience. Through the use of data analytics, sourcing, processing, and digital...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Clinical Pharmacology Fellowship - CDER',\n",
       "  u'Oak Ridge Associated Universities',\n",
       "  u'Silver Spring, MD',\n",
       "  u'(1) data collection from literatures; For years, OCP has provided recommendations on the study design, data analysis, and labeling language on these factors....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Quantitative Analyst/Modeler',\n",
       "  u'Leidos',\n",
       "  u'Washington, DC 20001 (Shaw area)',\n",
       "  u'Review and analyze data from research studies and develop reports and conclusions based on the data. Review external models, risk assessments, research data and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Junior Operations Research Analyst',\n",
       "  u'ECS Federal LLC',\n",
       "  u'Washington, DC',\n",
       "  u'ECS Federal, LLC (ECS) is seeking a Junior Operations Research Analyst to work in our Washington, DC office. PLEASE NOTE: This position is contingent upon',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'ESPC Engineer Scientist',\n",
       "  u'Cherokee Nation Businesses',\n",
       "  u'Silver Spring, MD 20910',\n",
       "  u'ESPC Engineer Scientist. CNSP focuses on quality performance in the collection and analysis of data, dissemination of useful information, and actionable real...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'ETL/BI Developer',\n",
       "  u'Accenture',\n",
       "  u'Springfield, VA',\n",
       "  u'In this role, the Developer will work closely with IT Architects, Analysts, Data Scientists, UI/UX designers, functional practitioners, and clients/stakeholders...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Operations Research Analyst',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'Arlington, VA',\n",
       "  u'Ability to analyze highly dimensional survey data. Ability to apply database query languages and pull data from authoritative databases....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Principal Research Analyst - Higher Education Analytics Cent...',\n",
       "  u'National Opinion Research Center (NORC)',\n",
       "  u'Bethesda, MD',\n",
       "  u'Protocol development for qualitative data collection; And data processing and management. The HEAC provides targeted data analysis that informs solutions for...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Computer Scientist / Software Developer',\n",
       "  u'Mitre Corporation',\n",
       "  u'McLean, VA',\n",
       "  u'Experience in data pipeline management, ETL/ELT, and data/system architecture. The candidate will provide development of backend data architectures to support...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Scientist - Computer Vision, Machine Learning, Robo...',\n",
       "  u'Intelligent Automation',\n",
       "  u'Rockville, MD 20855',\n",
       "  u'The successful candidate will join a team of vision and robotics scientists and participate in rewarding research to develop algorithms for image and video...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Program Research Analyst, Senior',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'Washington, DC',\n",
       "  u'Booz Allen Hamilton has been at the forefront of strategy and technology for more than 100 years Today, the firm provides management and technology consulting',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Machine Learning Research Scientist',\n",
       "  u'BAE Systems Applied Intelligence',\n",
       "  u'Reston, VA',\n",
       "  u'And (2) data analysis. BAE Systems is looking for a Research Scientist to join their. (2) creating prototypes (typically in MATLAB) to support demonstration and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Data Analysis and Governance Analyst',\n",
       "  u'Capgemini Government Solutions',\n",
       "  u'Washington, DC',\n",
       "  u'Data quality, data cleansing, data tagging, and metadata management. Conduct and review work products involving data quality, data cleansing, data tagging, and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Scientist - Big Data Analytics',\n",
       "  u'Intelligent Automation',\n",
       "  u'Rockville, MD 20855',\n",
       "  u'Cloud, Big data tools and frameworks such as Openstack, Hadoop, Solr, Hbase and Spark, Dockers, Ansible....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Director, Data Scientist',\n",
       "  u'KPMG',\n",
       "  u'Washington, DC 20036 (Downtown area)',\n",
       "  u'Retrieve, prepare, and process a rich data variety of data sources such as social media, news, internal/external documents, emails, financial data, and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'ETL Developer/Engineer (Scientist/Engineering Specialist)',\n",
       "  u'Knowesis Inc.',\n",
       "  u'Fairfax, VA 22031',\n",
       "  u'Data profiling experience. ETL, SQL, SSIS, Engineering, Scientist. Deep understanding of Data Warehousing principles with hands on experience including EDW, ODS...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Junior Operations Research Analyst',\n",
       "  u'ECS Federal LLC',\n",
       "  u'Washington, DC',\n",
       "  u'ECS Federal, LLC (ECS) is seeking a Junior Operations Research Analyst to work in our Washington, DC office. PLEASE NOTE: This position is contingent upon',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Microsoft BI Data Scientist',\n",
       "  u'Clarus Group',\n",
       "  u'Chantilly, VA',\n",
       "  u'Our Professional Services team is currently looking for a *Microsoft BI Data Scientist*. Practiced in Data Analysis work through use of Microsoft BI tools to...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Supervisor, Reporting & Data Analysis',\n",
       "  u'Federal Services',\n",
       "  u'Arlington, VA',\n",
       "  u'Extracts data and generates reports using Business Objects. The Supervisor provides ongoing support and training for internal and external users of the...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Quantitative Analyst/Modeler',\n",
       "  u'Leidos',\n",
       "  u'Washington, DC 20001 (Shaw area)',\n",
       "  u'Review and analyze data from research studies and develop reports and conclusions based on the data. Review external models, risk assessments, research data and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Contractor',\n",
       "  u'National Institutes of Health - National Heart, Lu...',\n",
       "  u'Bethesda, MD',\n",
       "  u'The Biophysics Core Facility maintains an environment where scientists and physician scientists can work together to address fundamental and translational...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'TSA Statistical Data Analyst',\n",
       "  u'Engility Corporation',\n",
       "  u'Chantilly, VA 20151',\n",
       "  u'Creating test plans and data collection strategies Managing large datasets in relational databases (MS-Access and SQL Server) Conducting statistical analyses...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Clinical Research Associate',\n",
       "  u'CICONIX',\n",
       "  u'Washington, DC',\n",
       "  u'Preparation of a monitoring visit plan and complete agenda, including a checklist of items to be reviewed, data and information to be collected....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Tobacco Research Analyst',\n",
       "  u'WESTAT',\n",
       "  u'Rockville, MD 20850',\n",
       "  u'Conducting data analysis, collaborating with senior scientists and programmers in implementing analysis plans;...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Supervisor, Reporting & Data Analysis',\n",
       "  u'Federal Services',\n",
       "  u'Arlington, VA',\n",
       "  u'Extracts data and generates reports using Business Objects. The Supervisor provides ongoing support and training for internal and external users of the...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Principal Research Scientist',\n",
       "  u'Battelle',\n",
       "  u'Alexandria, VA 22301 (Potomac West area)',\n",
       "  u'We are currently seeking a Principal Research Scientist . This Principal Research Scientist will support the TSWG IDD subgroup by providing technical,...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Developmemt & Integration Data Analyst',\n",
       "  u'Eagle Ray Inc',\n",
       "  u'Washington, DC',\n",
       "  u'Seven years or more years of specialized experience working on complex data/database projects as a data analyst, data architect, data scientist or database...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Machine Learning & Analytics Developer',\n",
       "  u'BrainTrust Holdings',\n",
       "  u'Laurel, MD',\n",
       "  u'We specialize in Cloud Computing, Massive Data Storage/Retrieval, Analysis, Cyber, and Mission Operations....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Operations Research Analyst_Washington DC',\n",
       "  u'Sawdey Solution Services',\n",
       "  u'Washington, DC 20005 (Logan Circle area)',\n",
       "  u'Sawdey Solution Services, Inc. , an ISO 9001 certified company, provides innovative strategic and technical planning, information technology, acquisition,',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Applied Data Science Product Engineer',\n",
       "  u'Esri',\n",
       "  u'Vienna, VA',\n",
       "  u'All work performed in this role is from the perspective of a customer-user in the role of a data scientist working on national security challenges and problems....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'BLH Technologies, Inc.',\n",
       "  u'Rockville, MD 20850',\n",
       "  u'Identify data needs and proper methods for data gathering, integration and preparation, data quality and data governance. And data visualization....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Intelligence Analyst',\n",
       "  u'Wiser',\n",
       "  u'Springfield, VA',\n",
       "  u'\\u2022 Ability to perform administrative tasks, data searches, data input and retrieval. The Contractor services shall include providing situational awareness...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Computational Social Scientist',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'McLean, VA',\n",
       "  u'Computational Social Scientist. Research projects and evaluate published and peer\\u2013reviewed techniques as they apply to client\\u2013specific data....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'BAE Systems Applied Intelligence',\n",
       "  u'Springfield, VA',\n",
       "  u'As a Data Scientist, you will leverage knowledge of data science, methodologies, and processing techniques to perform predictive analytics in the geospatial...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Intelligence Research Analyst',\n",
       "  u'Xator Corporation',\n",
       "  u'Washington, DC 20340',\n",
       "  u'Clearance Requirement: Active Top Secret Level Clearance with SCI Access RESPONSIBILITIES: Perform all-source intelligence research to identify potential',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior System/Data Analyst',\n",
       "  u'Engility Corporation',\n",
       "  u'Silver Spring, MD 20993',\n",
       "  u'Data and System Analysis additional responsibilities:. Data and Systems knowledgeable resources strongly preferred....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Computational Social Scientist',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'McLean, VA',\n",
       "  u'Computational Social Scientist. Research projects and evaluate published and peer\\u2013reviewed techniques as they apply to client\\u2013specific data....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Development & Integration Data Analyst',\n",
       "  u'Dowless & Associates, Inc.',\n",
       "  u'Washington, DC',\n",
       "  u'Seven years or more years of specialized experience working on complex data/database projects as a data analyst, data architect, data scientist or database...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'FireEye',\n",
       "  u'Reston, VA 20190',\n",
       "  u'Maintain a data server used to store large quantities of unstructured data. FireEye iSIGHT Intelligence is seeking a Data Scientist to support one of its cyber...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Surv and Analysis Supp Assoc (Biostatistician 2)',\n",
       "  u'Cherokee Nation Businesses',\n",
       "  u'Silver Spring, MD 20904',\n",
       "  u'Ensure data use agreements are staffed and maintained appropriately. Analyze data using analytic software such SAS, SPSS, or Epi Info....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'OPIR Research Scientist',\n",
       "  u'Leidos',\n",
       "  u'Springfield, VA',\n",
       "  u'The candidate shall provide support to GEOINT analysis and operation support for data processing, data analysis and analytic support....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Public Safety Analyst',\n",
       "  u'Corner Alliance',\n",
       "  u'Washington, DC 20036 (Downtown area)',\n",
       "  u'Evaluating and processing data; Review and analyze gathered qualitative data (i.e., theming, sorting, and categorizing information);...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Geologist/Scientist/Engineer - Environmental Project Task Le...',\n",
       "  u'ARCADIS US',\n",
       "  u'Washington, DC 20011 (Catholic University-Brookland area)',\n",
       "  u'Data analysis, technical reports. And serve as an *Environmental Project Task Leader*....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Statistician',\n",
       "  u'DataTEK, Inc.',\n",
       "  u'Fairfax, VA',\n",
       "  u'Create or provide specifications for analysis databases based on Data Management database. DOE*....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Market Research and Competitive Intelligence Analyst',\n",
       "  u'Volkswagen Group of America, Inc.',\n",
       "  u'Herndon, VA 20171',\n",
       "  u'Ensure pricing data and competitive baskets are kept current; Ensure data submitted to Germany is adequately reviewed by US management for content and impact....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Jr. Systems Engineer / Scientist',\n",
       "  u'Harris Corporation',\n",
       "  u'Herndon, VA',\n",
       "  u'Systems Engineer / Scientist. Predictive models for aircraft trajectories that include integration of aircraft performance models, meteorological data, and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'OWAQ Policy Engineer Scientist',\n",
       "  u'Cherokee Nation Businesses',\n",
       "  u'Silver Spring, MD 20910',\n",
       "  u'OWAQ Policy Engineer Scientist. CNSP focuses on quality performance in the collection and analysis of data, dissemination of useful information, and actionable...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'OWAQ R20 Engineer Scientist',\n",
       "  u'Cherokee Nation Businesses',\n",
       "  u'Silver Spring, MD 20910',\n",
       "  u'OWAQ R20 Engineer Scientist. Support the development of a cross-agency national written program guidance and data calls....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'ESPC Engineer Scientist',\n",
       "  u'Cherokee Nation Businesses',\n",
       "  u'Silver Spring, MD 20910',\n",
       "  u'ESPC Engineer Scientist. CNSP focuses on quality performance in the collection and analysis of data, dissemination of useful information, and actionable real...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'CI/HUMINT Research Analyst',\n",
       "  u'Leidos',\n",
       "  u'Fort George G Meade, MD',\n",
       "  u'Develop graphical presentations of information and data. The Global Services Group of Leidos, Inc....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior System/Data Analyst',\n",
       "  u'Engility Corporation',\n",
       "  u'Silver Spring, MD 20993',\n",
       "  u'Data and System Analysis additional responsibilities:. Data and Systems knowledgeable resources strongly preferred....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Jr. Operations Research/Data Analyst',\n",
       "  u'Engility Corporation',\n",
       "  u'McLean, VA 22101',\n",
       "  u'Competence in large dataset collection including data selection, execution of data collection scripts, conducting statistical analysis of data, and summarizing...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Advanced Analytics Data Scientist',\n",
       "  u'IBM',\n",
       "  u'Washington, DC 20005 (Logan Circle area)',\n",
       "  u\"As an Advanced Analytics Data Scientist, you'll team with some of the best minds in the industry to create innovative world class solutions focused on clients'...\",\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Operations Research Analyst II',\n",
       "  u'Parsons Corporation',\n",
       "  u'Fort Meade, MD',\n",
       "  u'Do you want to be on the front lines of the nation\\u2019s cyber security defenses? Are you a math whiz? If so, Parsons needs you. We are looking for Operations',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst I',\n",
       "  u'Optimal Solutions Group, LLC',\n",
       "  u'College Park, MD',\n",
       "  u'Real-Time Data Collection, Analysis, and Reporting More > Real-Time Data Collection, Analysis, and Reporting More > Real-Time Data Collection, Analysis, and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'ZeniMax Media',\n",
       "  u'Rockville, MD 20850',\n",
       "  u'The Data Scientist will be responsible for validating incoming data, facilitating creation of reports, aiding advanced Data Scientists in analytics, making sure...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst III',\n",
       "  u'Vencore',\n",
       "  u'McLean, VA',\n",
       "  u'Demonstrated ability to extract data contained in large databases and analyze that data to derive meaningful information....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Engineer',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'Annapolis Junction, MD',\n",
       "  u'Work with team members to develop machine intelligence, data mining, statistical, and graph-based algorithms designed to analyze massive data sets....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist (Active Top Secret Clearance)',\n",
       "  u'Clarus Group',\n",
       "  u'Washington, DC',\n",
       "  u'Our Professional Services team is currently looking for a *Data Scientist*. Perform complex modeling, simulation and analysis of data and processes....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Analytics Engineer - Cybersecurity Data Scientist',\n",
       "  u'Fractal Industries',\n",
       "  u'Reston, VA',\n",
       "  u'Refactor algorithms created by our Data Scientists into production-quality and operational code. Data Analytics \\u2013 Cyber Team Lead....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Scientist I (WRAIR Entomology Branch)',\n",
       "  u'General Dynamics Information Technology',\n",
       "  u'Silver Spring, MD',\n",
       "  u'Provide and support a vector field data surveillance archival repository for WRBU partners and for DoD vector surveillance data worldwide....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Scientist',\n",
       "  u'ABS Consulting',\n",
       "  u'Arlington, VA',\n",
       "  u'Strong understanding of data. At ABS Consulting, risk analysis is our foundation....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'IT Specialist',\n",
       "  u'Draper',\n",
       "  u'Reston, VA',\n",
       "  u'Assist with the investigation of security incidents to include data spills, data integrity incidents, and malicious code incidents....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Associate Survey Research Analyst',\n",
       "  u'comScore',\n",
       "  u'Reston, VA',\n",
       "  u'Assist in analyzing data sets in order to communicate compelling insights to clients. Built on precision and innovation, our unmatched data footprint combines...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Engineer SME',\n",
       "  u'Vencore',\n",
       "  u'McLean, VA',\n",
       "  u'Demonstrated experience performing data assessment, data engineering, modeling and analytics to enable new methodologies for end user analysts, data scientists,...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Engineer',\n",
       "  u'Vencore',\n",
       "  u'McLean, VA',\n",
       "  u'Demonstrated experience performing data assessment, data engineering, modeling and analytics to enable new methodologies for end user analysts, data scientists,...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Clinical Project Coordinator',\n",
       "  u'The Henry M. Jackson Foundation',\n",
       "  u'Bethesda, MD 20817',\n",
       "  u'Assist Research Physicians and laboratory scientists with data review in preparation for further analyses and/or publications....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Software Developer',\n",
       "  u'Council on Dairy Cattle Breeding',\n",
       "  u'Bowie, MD',\n",
       "  u'Work closely with CDCB and AGIL scientists, data analysts and staff. Excellent Python programming skills aiming at data management of large datasets....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Machine Learning and Analytics Developer',\n",
       "  u'Varen Technologies',\n",
       "  u'Fort Meade, MD',\n",
       "  u'Overview: Varen Technologies is an Intelligence Services Provider focusing on information technology services and solutions for the Defense and Intelligence',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist/Intelligence Analyst',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'McLean, VA',\n",
       "  u'Data Scientist/Intelligence Analyst. Experience with SPSS, SAS, Python, and equivalent data science tools....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Architect',\n",
       "  u'Praescient Analytics',\n",
       "  u'Washington, DC',\n",
       "  u'Data Access On Demand (DAOD) experience. Architect additional capabilities in concert with data scientists/data analyst....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Data Analysis and Governance Analyst',\n",
       "  u'Capgemini Government Solutions',\n",
       "  u'Washington, DC',\n",
       "  u'Data quality, data cleansing, data tagging, and metadata management. Conduct and review work products involving data quality, data cleansing, data tagging, and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Business Development Research Analyst Manager',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'McLean, VA',\n",
       "  u'Develop new reports and tools, as needed and organize, analyze, and synthesize data and information using Excel and PowerPoint....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Acquisition Analyst',\n",
       "  u'Dynamo Technologies',\n",
       "  u'Tysons, VA',\n",
       "  u'Acquisition Analyst When you join Dynamo, you don\\u2019t just become another number, you become part of a family. A family who thrives to keep morale high and',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Coverent',\n",
       "  u'McLean, VA',\n",
       "  u'Experience supporting large-scale data manipulation, analytic tools, and data visualization operations. Prepare visual presentations of data and analysis....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Scientist/Engineer',\n",
       "  u'COMPASS',\n",
       "  u'Washington, DC',\n",
       "  u'Strong understanding of data acquisition and analysis. The Research Scientist/Engineer will serve on an integrated team of government and contractor personnel...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Scientist - Center for Sickle Cell Disease',\n",
       "  u'Howard University',\n",
       "  u'Washington, DC',\n",
       "  u'Howard University Mission Howard University is a comprehensive, research-oriented, historically Black private university providing an educational experience...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Statistician II',\n",
       "  u'National Opinion Research Center (NORC)',\n",
       "  u'Bethesda, MD',\n",
       "  u'Knowledge of quantitative methods of social science data analysis. Knowledge of weighting of various sampling and data collection designs....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'MOJA',\n",
       "  u'Chantilly, VA',\n",
       "  u'MOJA is seeking a Data Scientist. Getting data or proposing ways in which to measure or collect the data in the future....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Market Research Analyst, Mid',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'McLean, VA',\n",
       "  u'Experience in data visualization and transforming complex data into rich presentations with actionable and easy to read charts....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'NOA1773 Support Scientist -Global Ensemble Forecast System (...',\n",
       "  u'I.M. Systems Group (IMSG)',\n",
       "  u'College Park, MD',\n",
       "  u'Support Scientist \\u2013 Global Ensemble Forecast System (GEFS) reforecast and application. A candidate will be required to work closely with NCEP Central Operation...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Military Operations Research Analyst, Mid',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'Arlington, VA',\n",
       "  u'Possession of excellent data gathering, analytical, and problem\\u2013solving skills. Collect and format data to support M&S and other analysis efforts....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Central Intelligence Agency',\n",
       "  u'Washington, DC',\n",
       "  u'Data Scientists organize and interpret Big Data to inform US decision makers, drive successful operations and shape CIA technology and resource investments....',\n",
       "  91066.0],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Statistician/Data Scientist',\n",
       "  u'CACI',\n",
       "  u'Springfield, VA 22151',\n",
       "  u'Produces innovative solutions driven by exploratory data analysis from complex and high-dimensional datasets....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst III - Health Policy Research Center',\n",
       "  u'Optimal Solutions Group, LLC',\n",
       "  u'College Park, MD',\n",
       "  u'Real-Time Data Collection, Analysis, and Reporting More > Real-Time Data Collection, Analysis, and Reporting More > Real-Time Data Collection, Analysis, and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist (Active Top Secret Clearance)',\n",
       "  u'Clarus Group',\n",
       "  u'Washington, DC',\n",
       "  u'Our Professional Services team is currently looking for a *Data Scientist*. Perform complex modeling, simulation and analysis of data and processes....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Architect',\n",
       "  u'Praescient Analytics',\n",
       "  u'Washington, DC',\n",
       "  u'Data Access On Demand (DAOD) experience. Architect additional capabilities in concert with data scientists/data analyst....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Machine Learning and Analytics Developer',\n",
       "  u'Varen Technologies',\n",
       "  u'Fort Meade, MD',\n",
       "  u'Overview: Varen Technologies is an Intelligence Services Provider focusing on information technology services and solutions for the Defense and Intelligence',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Scientist, Subject Matter Expert in Infectious Diseas...',\n",
       "  u'The Henry M. Jackson Foundation',\n",
       "  u'Silver Spring, MD 20910',\n",
       "  u'Assists or leads quality assurance projects on maintaining the highest data quality. Government (AFHSC) in creating and validating assumptions and procedures...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Synthesis and Analysis Expert',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'Arlington, VA',\n",
       "  u'Data Synthesis and Analysis Expert. 5+ years of experience with operations research and data synthesis or analysis....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Engineer',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'Annapolis Junction, MD',\n",
       "  u'Work with team members to develop machine intelligence, data mining, statistical, and graph-based algorithms designed to analyze massive data sets....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Computer Science Data Scientist, Senior',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'Alexandria, VA',\n",
       "  u'Computer Science Data Scientist, Senior. Booz Allen Hamilton has been at the forefront of strategy and technology for more than 100 years Today, the firm...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Satellite Data Assimilation Scientist',\n",
       "  u'Earth Resources Technology, Inc',\n",
       "  u'College Park, MD',\n",
       "  u'Experience in running data assimilation systems of operational complexity on high-performance computers and experience with Fortran90....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Synthesis and Analysis Expert',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'Arlington, VA',\n",
       "  u'Data Synthesis and Analysis Expert. 5+ years of experience with operations research and data synthesis or analysis....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist IV',\n",
       "  u'Vencore',\n",
       "  u'Reston, VA',\n",
       "  u'Perform data migration activities to support transition of data between legacy and new systems through developing data migration strategies, logical data models...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist/Advanced Analytics and Modeling Consultant',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209 (Radnor-Ft Myer Heights area)',\n",
       "  u'4 + years of data mining and predictive modeling experience. Extensive knowledge of tools for data mining and statistics (SAS, R, SPSS, Matlab)....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Big Spatial Data Project',\n",
       "  u'Oak Ridge Associated Universities',\n",
       "  u'Springfield, VA',\n",
       "  u'Knowledge in high-dimensional data analysis, and/or machine learning will be a plus. NGA is interested in appointing one or more post-doctoral researchers with...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Scientist',\n",
       "  u'The Henry M. Jackson Foundation',\n",
       "  u'Silver Spring, MD 20910',\n",
       "  u'Performs data analysis using bioinformatics and statistical programs, prepares graphical representation of data, prepares paper manuscripts, prepare scientific...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Statistician',\n",
       "  u'General Dynamics Information Technology',\n",
       "  u'Washington, DC 20003 (Capitol Hill area)',\n",
       "  u'Plans data collection, and analyzes and interprets statistical data from surveys, experiments, studies, and other sources....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Policy Analyst I',\n",
       "  u'Axiologic Solutions',\n",
       "  u'Washington, DC',\n",
       "  u'Seven years or more years of specialized experience working on complex data/database projects as a data analyst, data architect, data scientist or database...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Statistician/ Imagery Science Support',\n",
       "  u'MacAulay-Brown, Inc. (MacB)',\n",
       "  u'Springfield, VA',\n",
       "  u'Maintains moves and manipulates data between applications, using appropriate software:. Analysts who use spectral data are usually not familiar with it, and the...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Lynch Consultants, LLC',\n",
       "  u'Rosslyn, VA',\n",
       "  u'Experience using data analytic software, such as Tableau and/or Alteryx. Experience with working with and extracting large data sets....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Operations Research Analyst (All Levels)',\n",
       "  u'Group W',\n",
       "  u'Vienna, VA',\n",
       "  u'DESCRIPTION: Looking for applicants to provide analytical support services to address PPBES issues at the mission or theater level to include but not limited',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Advisor Scientist/Engineer',\n",
       "  u'CSRA',\n",
       "  u'Arlington, VA',\n",
       "  u'CSRA is seeking a Research Scientist Advisor! Plans and conducts scientific testing and prepares comprehensive technical reports, data reports, and other...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist IV',\n",
       "  u'Vencore',\n",
       "  u'Reston, VA',\n",
       "  u'Perform data migration activities to support transition of data between legacy and new systems through developing data migration strategies, logical data models...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Statistician/ Imagery Science Support',\n",
       "  u'MacAulay-Brown, Inc. (MacB)',\n",
       "  u'Springfield, VA',\n",
       "  u'Maintains moves and manipulates data between applications, using appropriate software:. Analysts who use spectral data are usually not familiar with it, and the...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Financial Intelligence & Research Analyst',\n",
       "  u'Grant Thornton',\n",
       "  u'Washington, DC 20036 (Downtown area)',\n",
       "  u'Experience with data forensic tools and techniques, with large data sets. Analyze financial data systems for illicit finance activities to include money...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Statistician',\n",
       "  u'DataTEK, Inc.',\n",
       "  u'Fairfax, VA',\n",
       "  u'Create or provide specifications for analysis databases based on Data Management database. DOE*....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'MOJA',\n",
       "  u'Chantilly, VA',\n",
       "  u'MOJA is seeking a Data Scientist. Getting data or proposing ways in which to measure or collect the data in the future....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Academic Institution Research Analyst',\n",
       "  u'The Henry M. Jackson Foundation',\n",
       "  u'Bethesda, MD 20814',\n",
       "  u'Consistently audit data collection to ensure data integrity. Create efficient processes that support routinization of data management tasks and regular data...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Behavioral Science Researcher',\n",
       "  u'The Henry M. Jackson Foundation',\n",
       "  u'Bethesda, MD 20817',\n",
       "  u'Interpretation and application of data analyses.5. Performs basic behavioral science research and data analysis.4....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Director of Social Strategy',\n",
       "  u'Subject Matter',\n",
       "  u'Washington, DC',\n",
       "  u'Our full team is comprised of experienced writers, advertising experts, media relations pros, website designers, filmmakers, lobbyists \\u2014 even a certified data...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Operations Research Analyst, Mid',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'Arlington, VA',\n",
       "  u'Ability to lead analysis of budgetary and programmatic information, apply probability and statistical techniques to analyze large and complex data sets, and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Sr. Data Scientist',\n",
       "  u'CAVA',\n",
       "  u'Washington, DC 20001 (Shaw area)',\n",
       "  u'3+ years experience as a data scientist or data engineer a plus. Data Scientist to help implement our vision at our corporate headquarters in Washington, DC....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Jr. Space Vehicle Analyst',\n",
       "  u'The Aerospace Corporation',\n",
       "  u'Chantilly, VA 20151',\n",
       "  u'Our state-of-the-art laboratory facilities are staffed by some of the leading scientists in the world. Coursework or work experience in engineering modeling and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Program Scientist',\n",
       "  u'The Henry M. Jackson Foundation',\n",
       "  u'Silver Spring, MD 20910',\n",
       "  u'Coordinate the gathering and assembly of data related to specific projects and perform detailed scientific analysis;...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Research Analyst - Healthcare Actuary',\n",
       "  u'Truven Health Analytics, an IBM Company',\n",
       "  u'Washington, DC',\n",
       "  u'Synthesize data from a variety of public and proprietary data sources in an organized and accurate fashion. Validate data for accuracy and completeness, while...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Scientist/Engineer',\n",
       "  u'COMPASS',\n",
       "  u'Washington, DC',\n",
       "  u'Strong understanding of data acquisition and analysis. The Research Scientist/Engineer will serve on an integrated team of government and contractor personnel...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Web Based Research Analyst',\n",
       "  u'Foreground Security',\n",
       "  u'Herndon, VA',\n",
       "  u'Our expertise in cyber, analytics and automation allow us to reach beyond what others think is possible to underpin national security and give our global...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst',\n",
       "  u'Acuris',\n",
       "  u'Washington, DC',\n",
       "  u'PaRR is part of the Mergermarket Group, a media company that provides the advisory, corporate and financial communities with forward-looking intelligence,...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Analytics Data Scientist/Analyst',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'McLean, VA',\n",
       "  u'Analytics Data Scientist/Analyst. Experience with using R, Perl, Python, SAS, or SPSS for the analysis of data....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Scientist, Technical Services, Applied Bioinformatics',\n",
       "  u'QIAGEN',\n",
       "  u'Germantown, MD',\n",
       "  u'Knowledge and familiarity in analyzing and interpreting genomic data (and the clinical use of this data is a bonus)....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Visiting Scientist',\n",
       "  u'Universities Space Research Association',\n",
       "  u'Greenbelt, MD',\n",
       "  u'Perform experiments, collect and analyze data. The visiting scientist will assist in the design, development, execution and control of a scientific research...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Analytics Data Scientist/Analyst',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'McLean, VA',\n",
       "  u'Analytics Data Scientist/Analyst. Experience with using R, Perl, Python, SAS, or SPSS for the analysis of data....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Biostatistician',\n",
       "  u'Medical Science & Computing, Inc.',\n",
       "  u'Bethesda, MD',\n",
       "  u'Manipulating CMS Medicare claims data using SAS. Experience with analysis of clinical and medical record data....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Data Scientist',\n",
       "  u'Varen Technologies',\n",
       "  u'Fort Meade, MD',\n",
       "  u'Must have 6+ years of Data Scientist experience. The Senior Data Scientist will establish and implement end-to-end proof of concept for leading edge data mining...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Computer Scientist; Application Development and Cloud Migrat...',\n",
       "  u'Mitre Corporation',\n",
       "  u'McLean, VA',\n",
       "  u'Data Migration (Sqoop). Computer Scientist to develop and enhance applications and data as part of cloud migration....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Qualitative Researcher',\n",
       "  u'The Henry M. Jackson Foundation',\n",
       "  u'Bethesda, MD 20814',\n",
       "  u'Strength in acquiring and analyzing relevant data, collaborating where necessary with quantitative scientists (e.g....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'All-Source Intelligence Research Analyst (DM)',\n",
       "  u'Celestar Corporation',\n",
       "  u'Washington, DC',\n",
       "  u'The Celestar Corporation has an IMMEDIATE NEED to identify multiple All-Source Intelligence Research Analysts for an upcoming contract who will be seated in',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Operations Research Analyst, Mid',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'Arlington, VA',\n",
       "  u'Ability to lead analysis of budgetary and programmatic information, apply probability and statistical techniques to analyze large and complex data sets, and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'SOSi',\n",
       "  u'Reston, VA',\n",
       "  u'Retrieve, process and prepare a rich data variety of data sources such as social media, news, etc. Exovera, an SOS International LLC (SOSi) company, is seeking...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Research Analyst - Healthcare Actuary',\n",
       "  u'Truven Health Analytics, an IBM Company',\n",
       "  u'Washington, DC',\n",
       "  u'Synthesize data from a variety of public and proprietary data sources in an organized and accurate fashion. Validate data for accuracy and completeness, while...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Cubic Corporation',\n",
       "  u'McLean, VA',\n",
       "  u'Experience with large scale data manipulation, analytic tools, and data visualization. Ability to simultaneously understand computer science concepts, data...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Public Safety Analyst',\n",
       "  u'Corner Alliance',\n",
       "  u'Washington, DC 20036 (Downtown area)',\n",
       "  u'Evaluating and processing data; Review and analyze gathered qualitative data (i.e., theming, sorting, and categorizing information);...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Visionist, Inc.',\n",
       "  u'Columbia, MD 21046',\n",
       "  u'Visionist is currently seeking Data Scientists who will be responsible for data analytics support across a variety of areas, from the development of advanced...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Principal Data Scientist/Engineer',\n",
       "  u'Aptima',\n",
       "  u'Arlington, VA',\n",
       "  u'Aptima currently has an opening for a principal-level data scientist to help develop big-data applications in the DC Metro area....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Principal Statistician - Health Care and Pharma Data',\n",
       "  u'Can-Am Consultants, Inc.',\n",
       "  u'Gaithersburg, MD',\n",
       "  u'Experience of Development, program design and data analysis and interpretation. B&I drives good design to generate the data needed for quality decision making....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Junior SQL Developer & Report Writer',\n",
       "  u'Society for Neuroscience',\n",
       "  u'Washington, DC 20005 (Logan Circle area)',\n",
       "  u'Maintain data integrity in Personify. Preferably, in a data warehouse environment. Knowledge of SQL Server Analysis Services, dimensional table modeling,...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'ENVIRONMENTAL SCIENTIST',\n",
       "  u'VERSAR',\n",
       "  u'Germantown, MD 20874',\n",
       "  u'Strong analytical and data management skills; Proficiency with MS Office applications and ability to conduct data analysis (including simple statistical...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist/Operations Research Analyst',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'Annapolis Junction, MD',\n",
       "  u'Data Scientist/Operations Research Analyst. Apply expertise with and knowledge of analytics while working alongside industry\\u2013leading Cloud computing...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Advisor Scientist/Engineer',\n",
       "  u'CSRA',\n",
       "  u'Arlington, VA',\n",
       "  u'CSRA is seeking a Research Scientist Advisor! Plans and conducts scientific testing and prepares comprehensive technical reports, data reports, and other...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Oracle Database Engineer',\n",
       "  u'CACI',\n",
       "  u'Chantilly, VA 20153',\n",
       "  u'Work closely with system owners to comprehend the schema and format of authoritative data sources and data scientists to comprehend the schema of database for...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Spectral Scientist/ Software Engineer (Active TS)',\n",
       "  u'Harris IT Services',\n",
       "  u'Herndon, VA',\n",
       "  u'Spectral Scientist/ Software Engineer. The successful candidate will support a team of spectral scientists and engineers through software development and data...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Scientist I or II',\n",
       "  u'AstraZeneca',\n",
       "  u'Gaithersburg, MD',\n",
       "  u'The selected individual will be a well-organized and a highly productive bench scientist that can design and execute experiments efficiently and interpret data...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Machine Learning Specialist - Signals, Analysis and Controls',\n",
       "  u'Intelligent Automation',\n",
       "  u'Rockville, MD 20855',\n",
       "  u'The successful candidate will join a team of scientist, engineers, and data scientist in developing advance algorithms for time-series and time-frequency...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Lynch Consultants, LLC',\n",
       "  u'Rosslyn, VA',\n",
       "  u'Experience using data analytic software, such as Tableau and/or Alteryx. Experience with working with and extracting large data sets....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Bioinformatician',\n",
       "  u'NantWorks',\n",
       "  u'Rockville, MD 20850',\n",
       "  u'Maintain high-quality data entry of proteomics, genomics, and clinical data. Establishing a robust data analysis pipeline for discovery proteomics, automating...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Program Security/Cloud Security Analyst',\n",
       "  u'TDI',\n",
       "  u'Bethesda, MD',\n",
       "  u'TDI is currently looking for a Program Security/Cloud Security Analyst to support a federal research program at the National Institutes of Health (NIH), under',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Piper Companies',\n",
       "  u'Reston, VA 20190',\n",
       "  u'Responsibilities for the Lead Data Scientist include:. Work with Data Governance Board to create dataset requirements, manage data definitions and schemas and...',\n",
       "  210000.0],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Visionist, Inc.',\n",
       "  u'Columbia, MD 21046',\n",
       "  u'Visionist is currently seeking Data Scientists who will be responsible for data analytics support across a variety of areas, from the development of advanced...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Giant Oak',\n",
       "  u'Arlington, VA',\n",
       "  u'Experience with large-scale data manipulation, analytic tools, and data visualization. Giant Oak seeks full time data scientist with a passion for exploring...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Big Spatial Data Project',\n",
       "  u'Oak Ridge Associated Universities',\n",
       "  u'Springfield, VA',\n",
       "  u'Knowledge in high-dimensional data analysis, and/or machine learning will be a plus. NGA is interested in appointing one or more post-doctoral researchers with...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Operations Research Analyst (All Levels)',\n",
       "  u'Group W',\n",
       "  u'Vienna, VA',\n",
       "  u'DESCRIPTION: Looking for applicants to provide analytical support services to address PPBES issues at the mission or theater level to include but not limited',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Analystics Scientist',\n",
       "  u'MDA Information Systems LLC',\n",
       "  u'Reston, VA',\n",
       "  u'Has an immediate opening for a Data Analytics Scientist in Reston, VA. Develop, validate, and implement data models to solve problems/answer questions....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Operations Research Analyst (ORSA) Job',\n",
       "  u'SAIC',\n",
       "  u'Arlington, VA',\n",
       "  u'Experience incorporating data from modeling, simulations, and wargames into larger studies. This may include but is not limited to running excursions to...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst, Moscow Project, CAP Action Fund',\n",
       "  u'American Progress',\n",
       "  u'Washington, DC',\n",
       "  u'Collect, collate, and analyze data, and produce well-sourced written reports. Ability to analyze, graphically depict, and report data through technical...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Product Engineer',\n",
       "  u'TISTA Science and Technology Corporation',\n",
       "  u'Rockville, MD',\n",
       "  u'Strong quantitative background, with experience in data science or working with teams of data scientists. Data Product Engineer....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Software Developer (Python)',\n",
       "  u'Vencore',\n",
       "  u'College Park, MD',\n",
       "  u'From smart grid to smart phones, intelligent highways to intelligent battlefields, Vencore Labs\\u2019 200 scientists, engineers and analysts are consistently...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research & Content Analyst',\n",
       "  u'Envirosite Corporation',\n",
       "  u'Washington, DC',\n",
       "  u'Assist in testing technology to capture historical content and maintenance of associated meta data. Envirosite is committed to providing the highest quality...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Assoc, Lab I (Evenings) - Chantilly, VA',\n",
       "  u'Quest Diagnostics',\n",
       "  u'Chantilly, VA',\n",
       "  u\"Performs data entry or transfers data to computer for data reduction and prepares for clinical laboratory scientist's review....\",\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Operations Research Analyst, Senior',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'Arlington, VA',\n",
       "  u'Booz Allen Hamilton has been at the forefront of strategy and technology for more than 100 years Today, the firm provides management and technology consulting',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - OUSD(I)-HCMO-DCIPS',\n",
       "  u'Red Gate Group',\n",
       "  u'Arlington, VA',\n",
       "  u'Data Scientist (full-time contract). Under this task, the Data Scientist contractor shall:. Data Analysis / IT Requirements:....',\n",
       "  112500.0],\n",
       " ['Washington D.C.',\n",
       "  u'Intelligence Research Analyst',\n",
       "  u'ANSER',\n",
       "  u'Falls Church, VA',\n",
       "  u'SPECIFIC JOB DESCRIPTION The intelligence Research Analyst supports the Joint Requirements Office (JRO) for Chemical, Biological, Radiological and Nuclear',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Sr. Research Analyst',\n",
       "  u'TV One',\n",
       "  u'Silver Spring, MD 20910',\n",
       "  u'Advanced knowledge of PowerPoint and Excel (Macros, Vlookup, manipulate large data sets timely and effectively, etc.)....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Product Engineer',\n",
       "  u'TISTA Science and Technology Corporation',\n",
       "  u'Rockville, MD',\n",
       "  u'Strong quantitative background, with experience in data science or working with teams of data scientists. Data Product Engineer....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Apps Developer',\n",
       "  u'Central Intelligence Agency',\n",
       "  u'Washington, DC',\n",
       "  u'Big Data concepts and technologies such as Apache Hadoop, Apache Hive, Solr, Cloudera, MapReduce, R, Spark, Kafka, NiFi and the ELK(ElasticSearch, Logstash...',\n",
       "  90936.0],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Manager, ASH Registry Informatics',\n",
       "  u'American Society of Hematology',\n",
       "  u'Washington, DC 20036 (Downtown area)',\n",
       "  u'The American Society of Hematology (ASH), a Washington, DC-based association of physicians and scientists committed to promoting blood disease research and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Faculty-Information Systems Lab (Data)',\n",
       "  u'Virginia Tech',\n",
       "  u'Arlington, VA',\n",
       "  u'For the ranks of Senior Research Associate, Research Scientist and Senior Research Scientist:. For the ranks of Senior Research Associate and Senior Research...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Operations Research Analyst',\n",
       "  u'Vencore',\n",
       "  u'McLean, VA',\n",
       "  u'Gather, relate, and identify data with variables in models by applying personal judgment and subject matter expertise....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Geospatial Research Scientist',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'Springfield, VA',\n",
       "  u'Geospatial Research Scientist. Serve as an experienced, forward\\u2013thinking, and innovative scientist on an urban damage assessment research and development...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Assoc, Lab I (Evenings) - Chantilly, VA',\n",
       "  u'Quest Diagnostics',\n",
       "  u'Chantilly, VA',\n",
       "  u\"Performs data entry or transfers data to computer for data reduction and prepares for clinical laboratory scientist's review....\",\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst, Moscow Project, CAP Action Fund',\n",
       "  u'American Progress',\n",
       "  u'Washington, DC',\n",
       "  u'Collect, collate, and analyze data, and produce well-sourced written reports. Ability to analyze, graphically depict, and report data through technical...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Clinician',\n",
       "  u'Parsons Corporation',\n",
       "  u'Silver Spring, MD',\n",
       "  u'Collect and analyze human trial data to determine the efficacy of malaria vaccines; Serve as Principle or Associate Investigator and lead a team of clinicians...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'ASRC Federal',\n",
       "  u'Falls Church, VA',\n",
       "  u'Junior Data Scientist (Java and Python). Experience extracting data from websites using Python. Develop and deploy advanced scripting to integrate data across...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'UX Researcher',\n",
       "  u'Digital Axis, LLC',\n",
       "  u'Rockville, MD',\n",
       "  u'Engaging with project teams to determine needs and the best way to test for those needs (working with data scientists to test proposed care coordination use...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Oracle Financial Developer',\n",
       "  u'Dynamo Technologies',\n",
       "  u'Washington, DC',\n",
       "  u'Oracle Financial Devel o per When you join Dynamo, you don\\u2019t just become another number, you become part of a family. A family who thrives to keep morale high',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Program Security/Cloud Security Analyst',\n",
       "  u'TDI',\n",
       "  u'Bethesda, MD',\n",
       "  u'TDI is currently looking for a Program Security/Cloud Security Analyst to support a federal research program at the National Institutes of Health (NIH), under',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Open Source Research Analyst',\n",
       "  u'BAE Systems Applied Intelligence',\n",
       "  u'McLean, VA',\n",
       "  u'The Open Source Research Analyst position requires knowledge of and expertise with Open Source Intelligence (OSINT) tradecraft, processes, and tools in the',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Sotera Defense Solutions, Inc.',\n",
       "  u'McLean, VA',\n",
       "  u\"The Data Scientist will:. We're looking for a Data Scientist in McLean, VA . Computer science concepts and data content....\",\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Sr Statistical Analyst',\n",
       "  u'comScore',\n",
       "  u'Reston, VA',\n",
       "  u\"Experience working with Big Data Analytics (e.g. In this role, the successful candidate will analyze large amounts of comScore's data, design new methods to...\",\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Business & Quality Assurance Analyst',\n",
       "  u'Trout Unlimited',\n",
       "  u'Arlington, VA 22209 (Radnor-Ft Myer Heights area)',\n",
       "  u'Perform Data Analysis including data mapping, report analysis, interface definitions. Data conversions and migrations. A love of data feed integration....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Statistician',\n",
       "  u'RTI International',\n",
       "  u'Washington, DC',\n",
       "  u'Apply standard statistical and/or data management software package(s) to execute data processing and data analysis activities....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Staff Scientist - Physical Assessments - JUN17-01',\n",
       "  u'Human Resources Research Organization',\n",
       "  u'Alexandria, VA',\n",
       "  u'Experience collecting data and administering physical assessments. Conducting data collection of physical and physiological measures;...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Image Scientist / Phenomenologist Job',\n",
       "  u'SAIC',\n",
       "  u'Herndon, VA',\n",
       "  u'Image Scientist / Phenomenologist (Job Number:. Experience with design of multi- variable experiments and related statistical data analysis....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Customer Intelligence Product Manager',\n",
       "  u'Capital One',\n",
       "  u'McLean, VA',\n",
       "  u'Work deeply with internal customers, associates, designers, technologists and data scientists in building cutting edge solutions....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'ISR Cognitive Data Scientist',\n",
       "  u'IBM',\n",
       "  u'Arlington, VA 22203 (Bluemont area)',\n",
       "  u'Experience with ontology development, data labeling, and establishing training data for cognitive processes....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'CPIC Business Case Support Analyst',\n",
       "  u'xentity corporation',\n",
       "  u'Reston, VA',\n",
       "  u'We are a fast-growing data consulting and support services firm. He seeks projects in renewable energy, integrating geosciences, high performance computing, big...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Faculty-Information Systems Lab (Data)',\n",
       "  u'Virginia Tech',\n",
       "  u'Arlington, VA',\n",
       "  u'For the ranks of Senior Research Associate, Research Scientist and Senior Research Scientist:. For the ranks of Senior Research Associate and Senior Research...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Director of Social Strategy',\n",
       "  u'Subject Matter',\n",
       "  u'Washington, DC',\n",
       "  u'Our full team is comprised of experienced writers, advertising experts, media relations pros, website designers, filmmakers, lobbyists \\u2014 even a certified data...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Research Analyst',\n",
       "  u'George Mason University',\n",
       "  u'Fairfax, VA',\n",
       "  u'Independently manage day-to-day administration of data; Ability to work with data from multiple electronic sources;...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst',\n",
       "  u'Acuris',\n",
       "  u'Washington, DC',\n",
       "  u'PaRR is part of the Mergermarket Group, a media company that provides the advisory, corporate and financial communities with forward-looking intelligence,...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Scientist I',\n",
       "  u'Meso Scale Diagnostics',\n",
       "  u'Gaithersburg, MD 20877',\n",
       "  u'Analyzing resulting data and presenting findings in a clear and concise manner will be among the principle responsibilities a Scientist is accountable for....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Data Scientist',\n",
       "  u'Coverent',\n",
       "  u'Springfield, VA',\n",
       "  u'Coverent is seeking a Senior Data Scientist to work as part of a high performing, collaborative team providing support to critical, time sensitive assignments....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Sr Statistical Analyst',\n",
       "  u'comScore',\n",
       "  u'Reston, VA',\n",
       "  u\"Experience working with Big Data Analytics (e.g. In this role, the successful candidate will analyze large amounts of comScore's data, design new methods to...\",\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Expert Data Engineer',\n",
       "  u'Vencore',\n",
       "  u'McLean, VA',\n",
       "  u'Demonstrated experience performing data assessment, data engineering, modeling and analytics to enable new methodologies for end user analysts, data scientists,...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Staff Scientist - Physical Assessments - JUN17-01',\n",
       "  u'Human Resources Research Organization',\n",
       "  u'Alexandria, VA',\n",
       "  u'Experience collecting data and administering physical assessments. Conducting data collection of physical and physiological measures;...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Market Research Analyst, Senior',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'McLean, VA',\n",
       "  u'Experience in data visualization and transforming complex data into rich presentations with actionable and easy to read charts....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Research Assistant/Research Analyst',\n",
       "  u'IFPRI (International Food Policy Research Institut...',\n",
       "  u'Washington, DC',\n",
       "  u'Organization, cleaning, manipulation and analysis of large household data sets. Demonstrated experience working with large quantitative data sets (data cleaning...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Operations Research Systems Analyst (ORSA)',\n",
       "  u'Whitney, Bradley and Brown',\n",
       "  u'Reston, VA',\n",
       "  u'Operations Analysis, OA, Operations Research, OR, Modeling & Simulation, Data Mining, Data analytics, Statistical Analysis, Cost Estimating....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Software Engineer',\n",
       "  u'Sotera Defense Solutions, Inc.',\n",
       "  u'Arlington, VA',\n",
       "  u'Sotera delivers data fusion, data analytics, cyber and visualization solutions for U.S. Data wrangling / munging skills....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Account Executive',\n",
       "  u'Cambridge Social Science Decision Lab, Inc.',\n",
       "  u'Washington, DC',\n",
       "  u'To work in an intellectually stimulating environment alongside PhD scientists. KMD Scientifically Proven Data\\u2122 - Provides data on KPIs like foot traffic or...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Sr. Statistician Methodologist w/TS-SCI',\n",
       "  u'NuWave Solutions',\n",
       "  u'Springfield, VA',\n",
       "  u'Our team consists of experts in data transformation, data warehousing, business intelligence, data discovery, advanced analytics, web interfaces, and custom...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'ISR Cognitive Data Scientist',\n",
       "  u'IBM',\n",
       "  u'Arlington, VA 22203 (Bluemont area)',\n",
       "  u'Experience with ontology development, data labeling, and establishing training data for cognitive processes....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist | Software Developer (TS/SCI Required)',\n",
       "  u'ISPA Technology',\n",
       "  u'Washington, DC',\n",
       "  u'Seeking a Data Scientist to support the Intelligence Community and at Special Operations Command. Ability to merge data sources together, ensure consistency of...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Director of the Safe Drinking Water Research and Policy Prog...',\n",
       "  u'Northeast-Midwest Institute',\n",
       "  u'Washington, DC',\n",
       "  u'Three or more years of experience as a scientist conducting water quality research; To conduct scientific studies and policy analysis to provide data to inform...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Bioinformatics Scientist',\n",
       "  u'Macrogen Corp.',\n",
       "  u'Rockville, MD 20850',\n",
       "  u'Data Scientist I/II/III*. Strong interest in big data analysis and data mining. Prior experience analyzing high throughput sequencing data analysis (NGS data...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Expert Scientist, Preclinical Evidence Generation, R & D',\n",
       "  u'GlaxoSmithKline',\n",
       "  u'Rockville, MD',\n",
       "  u'Performs complex data management and data interpretation tasks/analysis. Performs complex data management tasks with minimal supervision....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Conference Manager - Technical Activities',\n",
       "  u'The National Academies',\n",
       "  u'Washington, DC',\n",
       "  u'Oversees and maintains meeting/conference data. Researches and compiles data for presentations and reports....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Asscociate Scientist',\n",
       "  u'it solutions inc',\n",
       "  u'Gaithersburg, MD',\n",
       "  u'High degree of skill in analyzing and processing information, time management, organization, data entry, and maintaining confidentiality;...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Bioanalytical Scientist',\n",
       "  u'The Henry M. Jackson Foundation',\n",
       "  u'Silver Spring, MD 20910',\n",
       "  u'The contractor shall maintain appropriate data records and QC data for incorporation into LIMs database....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Machine Learning Data Engineer',\n",
       "  u'Capital One',\n",
       "  u'McLean, VA',\n",
       "  u'Machine Learning Data Engineer. At Capital One, we have seas of big data and rivers of fast data. Enterprise Data Services- Machine Learning....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Social Scientist',\n",
       "  u'BLH Technologies, Inc.',\n",
       "  u'Rockville, MD 20850',\n",
       "  u'Possess basic working knowledge of statistics and/or data science. Collaborate with statisticians to develop data analysis plans for research efforts;...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Payroll Support Associate at EPA',\n",
       "  u'Oak Ridge Associated Universities',\n",
       "  u'Washington, DC',\n",
       "  u'Performing data entry in various ORD and Agency financial systems; Research is conducted in a broad range of environmental areas by scientists in EPA...',\n",
       "  35200.0],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Scientist I',\n",
       "  u'Meso Scale Diagnostics',\n",
       "  u'Gaithersburg, MD 20877',\n",
       "  u'Analyzing resulting data and presenting findings in a clear and concise manner will be among the principle responsibilities a Scientist is accountable for....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Grant Thornton',\n",
       "  u'Washington, DC 20036 (Downtown area)',\n",
       "  u'Query and mine large data sets to discover patterns, examine data and filter for targeted information using traditional/exploratory, as well as advanced...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Medical RDT&E Senior Scientist (Contingent)',\n",
       "  u'Strategic Analysis, Inc',\n",
       "  u'Alexandria, VA',\n",
       "  u'Task includes activities such as collecting data and conducting interviews, obtaining or developing related graphics, pictures, samples, devices, etc., and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist / Database Specialist',\n",
       "  u'STG, Inc.',\n",
       "  u'Washington, DC',\n",
       "  u'Experience supporting large-scale data manipulation, analytic tools, and data visualization operations. Has an immediate opportunity for various level Data...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Business Intelligence Developer and Data Scientist',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'Herndon, VA',\n",
       "  u'Business Intelligence Developer and Data Scientist. Work as a senior data visualization developer and data analyst responsible for creating enterprise-wide BI...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Geospatial Analyst',\n",
       "  u'BigBear, Inc.',\n",
       "  u'Washington, DC 20032 (Anacostia area)',\n",
       "  u'We are seeking to expand our top-notch team of forward thinking engineers, data scientists, analysts, and innovators to help our customers make sense of their...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Infrastructure Planning & Research Analyst',\n",
       "  u'Volkswagen Group of America, Inc.',\n",
       "  u'Herndon, VA 20171',\n",
       "  u'Gathering and analyzing voice of customer, market insights and other third party data exchange. Manage Plugshare and other research databases while providing...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Director of Membership',\n",
       "  u'Association for Psychological Science',\n",
       "  u'Washington, DC 20036 (Downtown area)',\n",
       "  u'Ability to analyze historical data for purposes of indentifying opportunities and informing trends. APS has 30,000 members from around the world and includes...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - OUSD(I)-HCMO-DCIPS',\n",
       "  u'Red Gate Group',\n",
       "  u'Arlington, VA',\n",
       "  u'Data Scientist (full-time contract). Under this task, the Data Scientist contractor shall:. Data Analysis / IT Requirements:....',\n",
       "  112500.0],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Program Assistant',\n",
       "  u'Howard Hughes Medical Institute',\n",
       "  u'Chevy Chase, MD 20815',\n",
       "  u'Enter and collate survey data; Use word processing, spreadsheet, and customized computer applications to generate program correspondence, reports, data analyses...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'CACI',\n",
       "  u'Reston, VA 20191',\n",
       "  u'Apply data science tradecraft to multi-INT big data sets (OSINT, GEOINT, SIGINT) to accomplish trend and pattern analysis, and where the data supports,...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Apps Developer',\n",
       "  u'Central Intelligence Agency',\n",
       "  u'Washington, DC',\n",
       "  u'Big Data concepts and technologies such as Apache Hadoop, Apache Hive, Solr, Cloudera, MapReduce, R, Spark, Kafka, NiFi and the ELK(ElasticSearch, Logstash...',\n",
       "  90936.0],\n",
       " ['Washington D.C.',\n",
       "  u'Medical RDT&E Senior Scientist (Contingent)',\n",
       "  u'Strategic Analysis, Inc',\n",
       "  u'Alexandria, VA',\n",
       "  u'Task includes activities such as collecting data and conducting interviews, obtaining or developing related graphics, pictures, samples, devices, etc., and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Infrastructure Planning & Research Analyst',\n",
       "  u'Volkswagen Group of America, Inc.',\n",
       "  u'Herndon, VA 20171',\n",
       "  u'Gathering and analyzing voice of customer, market insights and other third party data exchange. Manage Plugshare and other research databases while providing...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Lead Data Analyst',\n",
       "  u'Plus3 IT Systems',\n",
       "  u'Washington, DC',\n",
       "  u'Minimum 5 years\\u2019 experience working on complex data/database projects as a data analyst, data architect, data scientist or database engineer....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Bioanalytical Scientist',\n",
       "  u'The Henry M. Jackson Foundation',\n",
       "  u'Silver Spring, MD 20910',\n",
       "  u'The contractor shall maintain appropriate data records and QC data for incorporation into LIMs database....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Office of Naval Research STEM Program Analyst',\n",
       "  u'Greystones Group',\n",
       "  u'Ballston, VA',\n",
       "  u'Initiatives data, and provide analysis of this data to create summary reports and informational products, and for disseminating the data and analysis for...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Software Engineer I & II',\n",
       "  u'Knexus Research Corp.',\n",
       "  u'National Harbor, MD',\n",
       "  u'If you are an energetic, independent thinking individual who is passionate about coding, enjoys working in a small team, wants to learn about state of the art...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Federal - Operations Research Consultant',\n",
       "  u'Accenture',\n",
       "  u'Arlington, VA',\n",
       "  u'The Operations Research Consultant will support Analytic projects with data extraction, re-construction, integration and aggregation....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Market Research Analyst',\n",
       "  u'Penn Schoen Berland',\n",
       "  u'Washington, DC',\n",
       "  u'We are seeking qualified Analysts to join our team. Analysts work as part of a dynamic communications consulting/market research team conducting custom',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Project Coordinator',\n",
       "  u'Intrexon Corporation.',\n",
       "  u'Germantown, MD',\n",
       "  u'Collect and summarize laboratory data for reporting, planning, budgeting and production metrics. Ability to work collaboratively in a team setting with...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Software Engineer',\n",
       "  u'Giant Oak',\n",
       "  u'Arlington, VA',\n",
       "  u'This position will work closely with a dedicated group of social scientists, data scientists, engineers, technologists, and domain experts on implementing a...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Geospatial Analyst',\n",
       "  u'BigBear, Inc.',\n",
       "  u'Washington, DC 20032 (Anacostia area)',\n",
       "  u'We are seeking to expand our top-notch team of forward thinking engineers, data scientists, analysts, and innovators to help our customers make sense of their...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Payroll Support Associate at EPA',\n",
       "  u'Oak Ridge Associated Universities',\n",
       "  u'Washington, DC',\n",
       "  u'Performing data entry in various ORD and Agency financial systems; Research is conducted in a broad range of environmental areas by scientists in EPA...',\n",
       "  35200.0],\n",
       " ['Washington D.C.',\n",
       "  u'Statistician',\n",
       "  u'Simmons Research',\n",
       "  u'Washington, DC',\n",
       "  u'Manipulate data, code and prepare data for statistical analyses and modeling. Strong knowledge of statistical theory and methods generally, and particularly in...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Office Administrator',\n",
       "  u'BOEING',\n",
       "  u'Herndon, VA 20170',\n",
       "  u\"Skilled scientists and thinkers. Collects and compiles data to provide visibility of status for traveler's review and/or signature....\",\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Clinical Scientist',\n",
       "  u'AstraZeneca',\n",
       "  u'Gaithersburg, MD',\n",
       "  u'You will help drive study set-up with special focus on ensuring high quality data collection in the Web Based Data Capture system in line with the study...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - SME level',\n",
       "  u'Praxis Engineering',\n",
       "  u'Reston, VA',\n",
       "  u'Mentor other data scientists to support employee and product development. The SME-level Data Scientist will lead a team of data scientists in utilizing a broad...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Mid',\n",
       "  u'Praxis Engineering',\n",
       "  u'Reston, VA',\n",
       "  u'The mid-level Data Scientist will be working with established programmatic and quantitative methods to find patterns and relationships in large data sets;...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Manager, ASH Registry Informatics',\n",
       "  u'American Society of Hematology',\n",
       "  u'Washington, DC 20036 (Downtown area)',\n",
       "  u'The American Society of Hematology (ASH), a Washington, DC-based association of physicians and scientists committed to promoting blood disease research and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Image Scientist',\n",
       "  u'Booz Allen Hamilton',\n",
       "  u'Springfield, VA',\n",
       "  u'Apply knowledge of hyperspectral data processing to the detection of targets and anomalies. Experience with applying comprehension of hyperspectral data...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Project Coordinator',\n",
       "  u'Intrexon Corporation.',\n",
       "  u'Germantown, MD',\n",
       "  u'Collect and summarize laboratory data for reporting, planning, budgeting and production metrics. Ability to work collaboratively in a team setting with...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Office Administrator',\n",
       "  u'BOEING',\n",
       "  u'Herndon, VA 20170',\n",
       "  u\"Skilled scientists and thinkers. Collects and compiles data to provide visibility of status for traveler's review and/or signature....\",\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'GEOINT Program',\n",
       "  u'Leidos',\n",
       "  u'Springfield, VA 22151',\n",
       "  u\"Description: Leidos is excited to announce that we've been selected as a Prime for a large Geospatial Intelligence (GEOINT) Services contract! We will be\",\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Space Mission Analyst/Engineer',\n",
       "  u'Engility Corporation',\n",
       "  u'Chantilly, VA 20151',\n",
       "  u\"Engility's Space Systems Group is in need of entry/junior-level technical engineers and scientists to help us turn ideas into useable solutions for military and...\",\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Pharmaceutical Scientist',\n",
       "  u'Cherokee Nation Businesses',\n",
       "  u'Arlington, VA 22202 (Aurora Highlands area)',\n",
       "  u'Analyze and interpret data collected, including various prescription data sources and scientific research projects....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Market Research Analyst',\n",
       "  u'Penn Schoen Berland',\n",
       "  u'Washington, DC',\n",
       "  u'We are seeking qualified Analysts to join our team. Analysts work as part of a dynamic communications consulting/market research team conducting custom',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist Staff',\n",
       "  u'Leidos',\n",
       "  u'Fairfax, VA 22032',\n",
       "  u'This position is a part of the Data Services team providing integration and processing support of data to the applications....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Clinical Scientist',\n",
       "  u'AstraZeneca',\n",
       "  u'Gaithersburg, MD',\n",
       "  u'You will help drive study set-up with special focus on ensuring high quality data collection in the Web Based Data Capture system in line with the study...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Principal Statistician - Health Care and Pharma Data',\n",
       "  u'Can-Am Consultants, Inc.',\n",
       "  u'Gaithersburg, MD',\n",
       "  u'Experience of Development, program design and data analysis and interpretation. B&I drives good design to generate the data needed for quality decision making....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Graph Analytics/Machine Learning Senior Researcher',\n",
       "  u'Leidos',\n",
       "  u'Arlington, VA 22202 (Aurora Highlands area)',\n",
       "  u'Strong data analysis skills using R or a comparable platform, and one programming language, e.g. Python, Perl, C/C++, Java....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Scientist/Senior Scientist/Principal Scientist - Analytical',\n",
       "  u'Salubris Biotherapeutics, Inc.',\n",
       "  u'Gaithersburg, MD',\n",
       "  u'Scientist/Senior Scientist/Principal Scientist*. Compile analytical data, perform data analysis and interpretation, prepare technical report, present data to...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Geospatial Software Developer',\n",
       "  u'BigBear, Inc.',\n",
       "  u'Washington, DC 20032 (Anacostia area)',\n",
       "  u'We are seeking to expand our top-notch team of forward thinking engineers, data scientists, and innovators, to help our customers make sense of their data....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Image Scientist',\n",
       "  u'EOIR Technologies',\n",
       "  u'Suitland, MD',\n",
       "  u'Panchromatic, radar, infrared, multi-spectral, hyper-spectral, LIDAR, Overhead Persistent Infrared (OPIR), and other specialized collection systems or tactical...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'National Security Analyst',\n",
       "  u'The Johns Hopkins Applied Physics Laboratory',\n",
       "  u'Laurel, MD',\n",
       "  u'We seek scientists and engineers to support our efforts. Develop analysis plans, identify effectiveness measures and data requirements, craft analytic...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Network Operations Engineer (AWS, Linux/Unix,Active Director...',\n",
       "  u'Fractal Industries',\n",
       "  u'Reston, VA',\n",
       "  u'You will leverage your expertise as part of a growing multi-disciplinary team of Data Scientists, Engineers, and Solutions Experts with deep domain knowledge in...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Program Assistant',\n",
       "  u'Howard Hughes Medical Institute',\n",
       "  u'Chevy Chase, MD 20815',\n",
       "  u'Enter and collate survey data; Use word processing, spreadsheet, and customized computer applications to generate program correspondence, reports, data analyses...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Evaluation Scientist',\n",
       "  u'Aledade, Inc.',\n",
       "  u'Bethesda, MD',\n",
       "  u'Monitor study implementation and data collection. Design and oversee/execute rapid analysis of data. Provide consultation services to other scientists and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Bio-Security Scientist Job',\n",
       "  u'SAIC',\n",
       "  u'Fort Belvoir, VA',\n",
       "  u'Bio-Security Scientist (Job Number:. Expertise in sample transportation of toxic materials, data collecting and integration, biosafety and biosecurity...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Target Research and Methodology Development Analyst',\n",
       "  u'Core One',\n",
       "  u'McLean, VA',\n",
       "  u'Ability to employ data mining techniques and tools and data basing skills. Experience with sensitive data repositories....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Business Analyst / Project Coordinator',\n",
       "  u'OMNITEC Solutions, Inc.',\n",
       "  u'Rockville, MD 20850',\n",
       "  u'Writing requirements to improve system and data; Improve the infrastructure and help coordinate leading scientists from around the world in harmonizing and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist, Technical Director, IC',\n",
       "  u'GovHire',\n",
       "  u'Reston, VA',\n",
       "  u'Deliver DoDIIS and IC ITE data services which increase data enrichment, improve access to customer data sources and support data analytics and data science....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Bio-Security Scientist Job',\n",
       "  u'SAIC',\n",
       "  u'Fort Belvoir, VA',\n",
       "  u'Bio-Security Scientist (Job Number:. Expertise in sample transportation of toxic materials, data collecting and integration, biosafety and biosecurity...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - SME level',\n",
       "  u'Praxis Engineering',\n",
       "  u'Reston, VA',\n",
       "  u'Mentor other data scientists to support employee and product development. The SME-level Data Scientist will lead a team of data scientists in utilizing a broad...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Mid',\n",
       "  u'Praxis Engineering',\n",
       "  u'Reston, VA',\n",
       "  u'The mid-level Data Scientist will be working with established programmatic and quantitative methods to find patterns and relationships in large data sets;...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Sr Medicare/Medicaid Data Analyst',\n",
       "  u'General Dynamics Information Technology',\n",
       "  u'Falls Church, VA 22042',\n",
       "  u'Ensures the integrity of project data, including data extraction, storage, manipulation, processing and analysis....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Federal - Operations Research Consultant',\n",
       "  u'Accenture',\n",
       "  u'Arlington, VA',\n",
       "  u'The Operations Research Consultant will support Analytic projects with data extraction, re-construction, integration and aggregation....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Cell Sorter Operator',\n",
       "  u'Medical Science & Computing, Inc.',\n",
       "  u'Bethesda, MD',\n",
       "  u'The incumbent will assist and work closely with research scientists. Responsible for establishing and maintaining record keeping systems of instrument...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'NOA1769 Support Scientist Hurricane Weather Research-HMON Mo...',\n",
       "  u'IMSG, Inc.',\n",
       "  u'College Park, MD',\n",
       "  u'Advanced knowledge of data assimilation methods applicable to tropical storms. Developing advanced data assimilation and initialization methods for operational...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Evaluation Scientist',\n",
       "  u'Aledade, Inc.',\n",
       "  u'Bethesda, MD',\n",
       "  u'Monitor study implementation and data collection. Design and oversee/execute rapid analysis of data. Provide consultation services to other scientists and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist (VO)',\n",
       "  u'BrainTrust Holdings',\n",
       "  u'Annapolis Junction, MD 20701',\n",
       "  u'Proficiency in, at least, one modern programming language such as Java, C++, C, Python, or Scala Strong problem solving skills; adaptability, proactivity and',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Manager, Data Science',\n",
       "  u'MorganFranklin Consulting',\n",
       "  u'McLean, VA',\n",
       "  u'Leading a team of data scientists and technical resources. Data strategy, analytics, and data science/machine learning, including data architecture, technology...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Pharmaceutical Scientist',\n",
       "  u'Cherokee Nation Businesses',\n",
       "  u'Arlington, VA 22202 (Aurora Highlands area)',\n",
       "  u'Analyze and interpret data collected, including various prescription data sources and scientific research projects....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Scientist I, Translational Medicine',\n",
       "  u'AstraZeneca',\n",
       "  u'Gaithersburg, MD',\n",
       "  u'And experience in driving the publication of key data in top-tier scientific or technical journals. Ability to collaborate with scientists internally and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Praxis Engineering',\n",
       "  u'Reston, VA',\n",
       "  u'Mentor data scientists to support employee and product development. The Data Scientist will be developing highly complex programmatic and quantitative methods...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst -- Consumer Insights',\n",
       "  u'Hanover Research',\n",
       "  u'Arlington, VA 22203 (Bluemont area)',\n",
       "  u'Collect and analyze quantitative research data from surveys and other data sources; The core capabilities that drive Hanover\\u2019s research engine include primary...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Scientist/Senior Scientist - Down Stream Purification',\n",
       "  u'Salubris Biotherapeutics, Inc.',\n",
       "  u'Gaithersburg, MD',\n",
       "  u'Analyze, interpret, and present data to project teams. Knowledge in statistical design of experiment and data analysis....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Water Resources Engineer',\n",
       "  u'Brown and Caldwell',\n",
       "  u'Beltsville, MD 20705',\n",
       "  u'Lead or participate in field work, site visits, and data collection in a variety of areas and weather conditions....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Cell Sorter Operator',\n",
       "  u'Medical Science & Computing, Inc.',\n",
       "  u'Bethesda, MD',\n",
       "  u'The incumbent will assist and work closely with research scientists. Responsible for establishing and maintaining record keeping systems of instrument...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Health Care Payment Policy & Cost Analysis Expertise',\n",
       "  u'Social & Scientific Systems Inc.',\n",
       "  u'Silver Spring, MD 20910',\n",
       "  u'Familiarity with survey data and primary data collection is a plus. SSS is seeking a Principal Research Scientist with subject matter expertise in health care...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Scientist I, Translational Medicine',\n",
       "  u'AstraZeneca',\n",
       "  u'Gaithersburg, MD',\n",
       "  u'And experience in driving the publication of key data in top-tier scientific or technical journals. Ability to collaborate with scientists internally and...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Scientist/Senior Scientist - Down Stream Purification',\n",
       "  u'Salubris Biotherapeutics, Inc.',\n",
       "  u'Gaithersburg, MD',\n",
       "  u'Analyze, interpret, and present data to project teams. Knowledge in statistical design of experiment and data analysis....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior Manager, Data Science',\n",
       "  u'MorganFranklin Consulting',\n",
       "  u'McLean, VA',\n",
       "  u'Leading a team of data scientists and technical resources. Data strategy, analytics, and data science/machine learning, including data architecture, technology...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Analyst',\n",
       "  u'ANSER',\n",
       "  u'Falls Church, VA',\n",
       "  u'BASIC JOB DESCRIPTION The Analyst conducts organized analytical assessments and evaluations to understand and/or evaluate complex issues to inform decision',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Behavioral Scientist / Organizational Psychologist V',\n",
       "  u'TULK llc',\n",
       "  u'Alexandria, VA',\n",
       "  u'Analyzes data objectively and articulately communicates findings well-matched for different ends (e.g., to influence decisions, explain options)....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Human Resources Generalist',\n",
       "  u'Straughan Environmental Inc',\n",
       "  u'Columbia, MD 21046',\n",
       "  u'Our staff consists of environmental scientists; Ability to research, analyze, and interpret various data. Maintain data for Affirmative Action Plan (AAP), EEO-1...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Senior TechInt Fusion Analyst',\n",
       "  u'BAE Systems',\n",
       "  u'Reston, VA 20191',\n",
       "  u'Create data products and support/develop associated systems which heavily utilize technically-derived data from multiple sources to include MASINT, IMINT, OSINT...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Target Research and Methodology Development Analyst',\n",
       "  u'Core One',\n",
       "  u'McLean, VA',\n",
       "  u'Ability to employ data mining techniques and tools and data basing skills. Experience with sensitive data repositories....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Praxis Engineering',\n",
       "  u'Reston, VA',\n",
       "  u'Mentor data scientists to support employee and product development. The Data Scientist will be developing highly complex programmatic and quantitative methods...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'IFG Data Scientist Whiz!',\n",
       "  u'Interface Financial Group (IFG)',\n",
       "  u'Bethesda, MD',\n",
       "  u'Data Scientists need to analyze financial data, predict future trends, and isolate unexpected correlations. We have data and we need to identify key predictors....',\n",
       "  120000.0],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Novetta',\n",
       "  u'Crystal City, VA',\n",
       "  u'Collaborate with fellow technologists and contribute meaningfully in areas such as data sciences, data security, and architecture design....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Big Data',\n",
       "  u'The Washington Post',\n",
       "  u'Washington, DC',\n",
       "  u'Washington Post is looking for passionate Data Scientists to join our Big Data Analytics team. Data scientist will utilize the data from the platform and design...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Deloitte',\n",
       "  u'Arlington, VA 22209',\n",
       "  u'Gathering data from both information systems and personal interactions How you\\u2019ll grow At Deloitte, our professional development plan focuses on helping people...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'Riverside Research',\n",
       "  u'Washington, DC',\n",
       "  u'1 year practical work experience with geospatial data or imagery data. Identify data needs and methods for data gathering, extraction, integration, quality, etc...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist - Defense & Intelligence',\n",
       "  u'Elder Research Inc',\n",
       "  u'Linthicum, MD',\n",
       "  u'Data Scientist - Defense & Intelligence. We are looking to hire Data Scientists with at least 5 years of technical experience working with data and deploying...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Data Scientist',\n",
       "  u'National Geospatial-Intelligence Agency',\n",
       "  u'Springfield, VA',\n",
       "  u'Data Scientist **AMENDED**. Data Management, Data Engineering, Data Science, Computer Science, Software Engineering, Statistics, Applied Mathematics, Applied...',\n",
       "  90941.0],\n",
       " ['Washington D.C.',\n",
       "  u'Staff Fellow (Mathematical Statistician)',\n",
       "  u'Department of Health And Human Services',\n",
       "  u'Rockville, MD',\n",
       "  u'You will use statistical and mathematical methods to analyze and draw inferences from data submitted by animal drug applicants and to facilitate the Center...',\n",
       "  101477.0],\n",
       " ['Washington D.C.',\n",
       "  u'Graph Analytics/Machine Learning Senior Researcher',\n",
       "  u'Leidos',\n",
       "  u'Arlington, VA 22202 (Aurora Highlands area)',\n",
       "  u'Strong data analysis skills using R or a comparable platform, and one programming language, e.g. Python, Perl, C/C++, Java....',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Research Faculty-Information Systems Lab (Cyber)',\n",
       "  u'Virginia Tech',\n",
       "  u'Arlington, VA',\n",
       "  u'For the ranks of Senior Research Associate, Research Scientist and Senior Research Scientist:. Those appointed to the rank of Research Scientist or Senior...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Jr. Remote Sensing Scientist',\n",
       "  u'The Aerospace Corporation',\n",
       "  u'Chantilly, VA 20151',\n",
       "  u'Our state-of-the-art laboratory facilities are staffed by some of the leading scientists in the world. At least 2 years of experience with electro-optical...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'TECHINT Fusion Analyst \\u2013 Senior',\n",
       "  u'MDA Information Systems LLC',\n",
       "  u'Reston, VA',\n",
       "  u'Create data products and support/develop associated systems which heavily utilize technically-derived data from multiple sources to include MASINT, IMINT, OSINT...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'MedImmune Solution Delivery',\n",
       "  u'AstraZeneca',\n",
       "  u'Gaithersburg, MD',\n",
       "  u'Support Medimmune scientists use existing information systems with training and help solving issues. Prototype and part of the solution for data processing,...',\n",
       "  'NaN'],\n",
       " ['Washington D.C.',\n",
       "  u'Radar Image Analyst, Senior with TS/SCI/TK Security Clearanc...',\n",
       "  u'Imagitech',\n",
       "  u'Washington, DC 20375 (AU-Tenleytown area)',\n",
       "  u'The image scientist will collaborate with and provide scientific analysis support to full spectrum GEOINT (FSG) data to imagery and geospatial analysts, to add...',\n",
       "  'NaN'],\n",
       " ...]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_template = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l={cities}&start={0}\"\n",
    "max_results_per_city = 2750 # Set at high-value (2750) as two cities with most jobs are NYC and San Francisco both peak listings just below 2750. \n",
    "# Crawling more results, will also take much longer. First test your code on a small number of results and then expand.\n",
    "columns=['City','Title', 'Company', 'Location','Job Summary', 'Salary']\n",
    "cities = ['Washington D.C.', 'New York', 'San Francisco', 'Chicago', 'Austin', 'Jacksonville', 'Indianapolis'\\\n",
    "             'Seattle', 'Los Angeles', 'Philadelphia', 'Atlanta', 'Dallas', 'Columbus', 'Fort Worth', 'Charlotte' \\\n",
    "             'Pittsburgh', 'Portland', 'Phoenix', 'Denver', 'Houston', 'Miami', 'San Antonio', 'San Diego', 'San Jose'\\\n",
    "             'Nashville', 'El Paso', 'Boston', 'Detroit', 'Memphis', 'Oklahoma City', 'Baltimore', 'Las Vegas' \\\n",
    "             'Milwaukee', 'Albuquerque', 'Tucson', 'Fresno', 'Sacramento', 'Mesa', 'Kansas City', 'Raleigh']\n",
    "information = []\n",
    "for city in cities:\n",
    "    for start in range(0, max_results_per_city, 10):\n",
    "        html=requests.get(\"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=\" + str(city) + \"&start=\" + str(start))\n",
    "        sleep(0.5)\n",
    "        soup=BeautifulSoup(html.text,\"html.parser\", from_encoding='utf-8')\n",
    "        for div in soup.find_all(name='div', attrs={'class':'result'}):\n",
    "            #Indicate row # for index of posting in df\n",
    "            #row_index = (len(datajobs)+1)\n",
    "            #create emtpy list to hold all data\n",
    "            posting = []\n",
    "            #append city name to list\n",
    "            posting.append(city)\n",
    "        #Grab Job title\n",
    "            try:\n",
    "                posting.append(div.find('h2', class_='jobtitle').find('a').text)\n",
    "            except:\n",
    "                try:\n",
    "                    title2 = div.find('a', class_='turnstileLink')\n",
    "                    posting.append(title2.text)\n",
    "                except:\n",
    "                    posting.append('No Title')\n",
    "                #job = title.text\n",
    "        #Grab Company\n",
    "            #for b in div.find_all(name='span',attrs={'class':'company'}):\n",
    "            try:\n",
    "                posting.append(div.find(name='span',attrs={'class':'company'}).text.strip())\n",
    "            except:\n",
    "                posting.append('No Company')\n",
    "        #Grab Location\n",
    "            #for c in  div.find_all(name='span',attrs={'class':'location'}):\n",
    "            try:\n",
    "                posting.append(div.find(name='span',attrs={'class':'location'}).text)\n",
    "            except:\n",
    "                posting.append('No Location')\n",
    "        #Grab Job Description\n",
    "            #for d in div.find_all(name='span',attrs={'class':'summary'}):\n",
    "            try:\n",
    "                posting.append(div.find(name='span',attrs={'class':'summary'}).text.strip())\n",
    "            except:\n",
    "                posting.append('No Description')\n",
    "        # Grab Salary   \n",
    "            posting.append(salary(div))\n",
    "        #appending posting information to df\n",
    "            information.append(posting)\n",
    "            pass\n",
    "information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(information, columns=columns) #creating df2 dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Summary</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Riverside Research</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>1 year practical work experience with geospati...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist - Defense &amp; Intelligence</td>\n",
       "      <td>Elder Research Inc</td>\n",
       "      <td>Linthicum, MD</td>\n",
       "      <td>Data Scientist - Defense &amp; Intelligence. We ar...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Novetta</td>\n",
       "      <td>Crystal City, VA</td>\n",
       "      <td>Collaborate with fellow technologists and cont...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist_Entry Level</td>\n",
       "      <td>GS5</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>The Data Scientist_Entry Level is expected to:...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Junior Data Scientist / Visualist</td>\n",
       "      <td>Assured Consulting Solutions</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>We are seeking a highly motivated Junior Data ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist, Junior</td>\n",
       "      <td>Booz Allen Hamilton</td>\n",
       "      <td>Alexandria, VA</td>\n",
       "      <td>Data Scientist, Junior. Perform as a data scie...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Machine Learning Algorithm Developer - US Citi...</td>\n",
       "      <td>Naval Research Lab</td>\n",
       "      <td>Washington, DC 20375 (AU-Tenleytown area)</td>\n",
       "      <td>Develop machine learning algorithms for a vari...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Statistical Analyst</td>\n",
       "      <td>eGlobalTech</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Volumes of data (e.g. Coordinate with Data Ana...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist/Developer/Engineer</td>\n",
       "      <td>ByteCubed</td>\n",
       "      <td>Arlington, VA</td>\n",
       "      <td>ByteCubed is seeking a Data Scientist/Develope...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Statistician</td>\n",
       "      <td>Ukpeagvik IÃ±upiat Corporation/Bowhead Family o...</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>- Provide statistical support for sample desig...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Development Seed</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Remotely sensed data and associated libraries ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Statistician</td>\n",
       "      <td>International Cotton Advisory Committee</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Analysis, compilation, presentation and dissem...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Statistician</td>\n",
       "      <td>Leidos</td>\n",
       "      <td>Washington, DC 20001 (Shaw area)</td>\n",
       "      <td>Assist DEA statisticians and scientists in tra...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist - Big Data</td>\n",
       "      <td>The Washington Post</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Washington Post is looking for passionate Data...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Deloitte</td>\n",
       "      <td>Arlington, VA 22209</td>\n",
       "      <td>Gathering data from both information systems a...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Deloitte</td>\n",
       "      <td>Arlington, VA 22209</td>\n",
       "      <td>Gathering data from both information systems a...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist - Big Data</td>\n",
       "      <td>The Washington Post</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Washington Post is looking for passionate Data...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Novetta</td>\n",
       "      <td>Crystal City, VA</td>\n",
       "      <td>Collaborate with fellow technologists and cont...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist, Mid</td>\n",
       "      <td>Booz Allen Hamilton</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Data Scientist, Mid. Apply expertise in CS, so...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Federal - Business Analytics Consultant</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Washington, DC 20006 (Foggy Bottom area)</td>\n",
       "      <td>Individuals in this role are expected to work ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Analyst, Evaluation and Analysis</td>\n",
       "      <td>PCORI</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Demonstrated data cleaning, data management, a...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Intelligence Research Analyst</td>\n",
       "      <td>DAWSON</td>\n",
       "      <td>Washington, DC 20001 (Shaw area)</td>\n",
       "      <td>(Note: This position is contingent upon a succ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Undergraduate Internship/Co-op Program - Data ...</td>\n",
       "      <td>Central Intelligence Agency</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Students serving as Data Scientist interns wor...</td>\n",
       "      <td>36800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Public Affairs - Research Analyst, Public Poll...</td>\n",
       "      <td>Ipsos North America</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Data analysis planning and data verification i...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Statistician</td>\n",
       "      <td>Extreme Data Technologies</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>This type of study could involve data simulati...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Associate Research Scientist</td>\n",
       "      <td>Vencore</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>From smart grid to smart phones, intelligent h...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data and Policy Analyst - Statistical Programmer</td>\n",
       "      <td>Acumen LLC</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Data and Policy Analysts perform a wide array ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Business Analytics Consultant</td>\n",
       "      <td>PNC</td>\n",
       "      <td>Washington, DC 20022 (Brentwood area)</td>\n",
       "      <td>Providing business clients with detailed, acti...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist - Defense &amp; Intelligence</td>\n",
       "      <td>Elder Research Inc</td>\n",
       "      <td>Linthicum, MD</td>\n",
       "      <td>Data Scientist - Defense &amp; Intelligence. We ar...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Riverside Research</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>1 year practical work experience with geospati...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126650</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Research/Remediation Analyst 1</td>\n",
       "      <td>Wells Fargo</td>\n",
       "      <td>Raleigh, NC 27601</td>\n",
       "      <td>Strong data entry and attention to detail skil...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126651</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Analytical Scientist, Analytical R&amp;D</td>\n",
       "      <td>Tergus Pharma</td>\n",
       "      <td>Durham, NC 27713</td>\n",
       "      <td>Assist with assembling data summaries. Data en...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126652</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Scientist II, Cell Culture Development</td>\n",
       "      <td>FujiFilm Diosynth Biotechnologies</td>\n",
       "      <td>Morrisville, NC 27560</td>\n",
       "      <td>Experimental design, analysis of data, drawing...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126653</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Field Medical Regional Associate Director (Eas...</td>\n",
       "      <td>Bristol-Myers Squibb</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>Developing peer-to-peer relationships with TLs...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126654</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Development and Application of Quantitative Mo...</td>\n",
       "      <td>Oak Ridge Associated Universities</td>\n",
       "      <td>Durham, NC</td>\n",
       "      <td>The purpose of this project is to use existing...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126655</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Construction Engineering and Inspection (CEI) ...</td>\n",
       "      <td>Kleinfelder</td>\n",
       "      <td>Morrisville, NC 27560</td>\n",
       "      <td>We are engineers, scientists, and construction...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126656</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Senior Civil Designer - Water/Sewer</td>\n",
       "      <td>WK Dickson</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>Search, investigate, and select technical refe...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126657</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Immediately Need Sr. Tableau Developer</td>\n",
       "      <td>Intone Networks</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>The project would require interfacing with dat...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126658</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Software Engineer, Natural Language Processing...</td>\n",
       "      <td>Institute for Medical Research</td>\n",
       "      <td>Durham, NC 27701</td>\n",
       "      <td>Evaluate data efficacy and think critically ab...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126659</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Data Analyst, Natural Language Processing Special</td>\n",
       "      <td>Institute for Medical Research</td>\n",
       "      <td>Durham, NC 27701</td>\n",
       "      <td>Evaluate data efficacy and think critically ab...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126660</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Data Production Engineer</td>\n",
       "      <td>NJF Global Holdings</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>We are seeking Data Production Engineers for o...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126661</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Master Data Administrator Analyst SAP BI</td>\n",
       "      <td>Adecco: USA</td>\n",
       "      <td>Durham, NC</td>\n",
       "      <td>Prepare data summaries that are complete, accu...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126662</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Customer Research Analyst</td>\n",
       "      <td>Harte Hanks</td>\n",
       "      <td>Raleigh-Durham, NC</td>\n",
       "      <td>Understanding of the buyers journey, data driv...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126663</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Research Scientist/Engineer</td>\n",
       "      <td>Polarean, Inc.</td>\n",
       "      <td>Durham, NC</td>\n",
       "      <td>Numerical modeling and data analysis:. Data an...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126664</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Clinical Scientist</td>\n",
       "      <td>BiomÃ©rieux</td>\n",
       "      <td>Durham, NC</td>\n",
       "      <td>Conducts and monitors clinical trials, coordin...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126665</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Research/Remediation Analyst 1</td>\n",
       "      <td>Wells Fargo</td>\n",
       "      <td>Raleigh, NC 27601</td>\n",
       "      <td>Strong data entry and attention to detail skil...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126666</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Analytical Scientist, Analytical R&amp;D</td>\n",
       "      <td>Tergus Pharma</td>\n",
       "      <td>Durham, NC 27713</td>\n",
       "      <td>Assist with assembling data summaries. Data en...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126667</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Sr. Software Engineer \"Machine Learning Experi...</td>\n",
       "      <td>The Accuro Group, Inc.</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>Experience in Data science projects. 10 + year...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126668</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Senior Statistical Programmer Statistical Prog...</td>\n",
       "      <td>QuintilesIMS</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>(i) the programming, testing, and documentatio...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126669</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Construction Engineering and Inspection (CEI) ...</td>\n",
       "      <td>Kleinfelder</td>\n",
       "      <td>Morrisville, NC 27560</td>\n",
       "      <td>We are engineers, scientists, and construction...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126670</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Immediately Need Sr. Tableau Developer</td>\n",
       "      <td>Intone Networks</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>The project would require interfacing with dat...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126671</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Field Medical Regional Associate Director (Eas...</td>\n",
       "      <td>Bristol-Myers Squibb</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>Developing peer-to-peer relationships with TLs...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126672</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Software Engineer, Natural Language Processing...</td>\n",
       "      <td>Institute for Medical Research</td>\n",
       "      <td>Durham, NC 27701</td>\n",
       "      <td>Evaluate data efficacy and think critically ab...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126673</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Data Analyst, Natural Language Processing Special</td>\n",
       "      <td>Institute for Medical Research</td>\n",
       "      <td>Durham, NC 27701</td>\n",
       "      <td>Evaluate data efficacy and think critically ab...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126674</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Data Production Engineer</td>\n",
       "      <td>NJF Global Holdings</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>We are seeking Data Production Engineers for o...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126675</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Development and Application of Quantitative Mo...</td>\n",
       "      <td>Oak Ridge Associated Universities</td>\n",
       "      <td>Durham, NC</td>\n",
       "      <td>The purpose of this project is to use existing...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126676</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Master Data Administrator Analyst SAP BI</td>\n",
       "      <td>Adecco: USA</td>\n",
       "      <td>Durham, NC</td>\n",
       "      <td>Prepare data summaries that are complete, accu...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126677</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Customer Research Analyst</td>\n",
       "      <td>Harte Hanks</td>\n",
       "      <td>Raleigh-Durham, NC</td>\n",
       "      <td>Understanding of the buyers journey, data driv...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126678</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Research Scientist/Engineer</td>\n",
       "      <td>Polarean, Inc.</td>\n",
       "      <td>Durham, NC</td>\n",
       "      <td>Numerical modeling and data analysis:. Data an...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126679</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Clinical Scientist</td>\n",
       "      <td>BiomÃ©rieux</td>\n",
       "      <td>Durham, NC</td>\n",
       "      <td>Conducts and monitors clinical trials, coordin...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126680 rows Ã 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   City                                              Title  \\\n",
       "0       Washington D.C.                                     Data Scientist   \n",
       "1       Washington D.C.            Data Scientist - Defense & Intelligence   \n",
       "2       Washington D.C.                                     Data Scientist   \n",
       "3       Washington D.C.                         Data Scientist_Entry Level   \n",
       "4       Washington D.C.                  Junior Data Scientist / Visualist   \n",
       "5       Washington D.C.                             Data Scientist, Junior   \n",
       "6       Washington D.C.  Machine Learning Algorithm Developer - US Citi...   \n",
       "7       Washington D.C.                                Statistical Analyst   \n",
       "8       Washington D.C.                  Data Scientist/Developer/Engineer   \n",
       "9       Washington D.C.                                       Statistician   \n",
       "10      Washington D.C.                          Machine Learning Engineer   \n",
       "11      Washington D.C.                                       Statistician   \n",
       "12      Washington D.C.                                       Statistician   \n",
       "13      Washington D.C.                          Data Scientist - Big Data   \n",
       "14      Washington D.C.                                     Data Scientist   \n",
       "15      Washington D.C.                                     Data Scientist   \n",
       "16      Washington D.C.                          Data Scientist - Big Data   \n",
       "17      Washington D.C.                                     Data Scientist   \n",
       "18      Washington D.C.                                Data Scientist, Mid   \n",
       "19      Washington D.C.            Federal - Business Analytics Consultant   \n",
       "20      Washington D.C.              Data Analyst, Evaluation and Analysis   \n",
       "21      Washington D.C.                      Intelligence Research Analyst   \n",
       "22      Washington D.C.  Undergraduate Internship/Co-op Program - Data ...   \n",
       "23      Washington D.C.  Public Affairs - Research Analyst, Public Poll...   \n",
       "24      Washington D.C.                                       Statistician   \n",
       "25      Washington D.C.                       Associate Research Scientist   \n",
       "26      Washington D.C.   Data and Policy Analyst - Statistical Programmer   \n",
       "27      Washington D.C.                      Business Analytics Consultant   \n",
       "28      Washington D.C.            Data Scientist - Defense & Intelligence   \n",
       "29      Washington D.C.                                     Data Scientist   \n",
       "...                 ...                                                ...   \n",
       "126650          Raleigh                     Research/Remediation Analyst 1   \n",
       "126651          Raleigh               Analytical Scientist, Analytical R&D   \n",
       "126652          Raleigh             Scientist II, Cell Culture Development   \n",
       "126653          Raleigh  Field Medical Regional Associate Director (Eas...   \n",
       "126654          Raleigh  Development and Application of Quantitative Mo...   \n",
       "126655          Raleigh  Construction Engineering and Inspection (CEI) ...   \n",
       "126656          Raleigh                Senior Civil Designer - Water/Sewer   \n",
       "126657          Raleigh             Immediately Need Sr. Tableau Developer   \n",
       "126658          Raleigh  Software Engineer, Natural Language Processing...   \n",
       "126659          Raleigh  Data Analyst, Natural Language Processing Special   \n",
       "126660          Raleigh                           Data Production Engineer   \n",
       "126661          Raleigh           Master Data Administrator Analyst SAP BI   \n",
       "126662          Raleigh                          Customer Research Analyst   \n",
       "126663          Raleigh                        Research Scientist/Engineer   \n",
       "126664          Raleigh                                 Clinical Scientist   \n",
       "126665          Raleigh                     Research/Remediation Analyst 1   \n",
       "126666          Raleigh               Analytical Scientist, Analytical R&D   \n",
       "126667          Raleigh  Sr. Software Engineer \"Machine Learning Experi...   \n",
       "126668          Raleigh  Senior Statistical Programmer Statistical Prog...   \n",
       "126669          Raleigh  Construction Engineering and Inspection (CEI) ...   \n",
       "126670          Raleigh             Immediately Need Sr. Tableau Developer   \n",
       "126671          Raleigh  Field Medical Regional Associate Director (Eas...   \n",
       "126672          Raleigh  Software Engineer, Natural Language Processing...   \n",
       "126673          Raleigh  Data Analyst, Natural Language Processing Special   \n",
       "126674          Raleigh                           Data Production Engineer   \n",
       "126675          Raleigh  Development and Application of Quantitative Mo...   \n",
       "126676          Raleigh           Master Data Administrator Analyst SAP BI   \n",
       "126677          Raleigh                          Customer Research Analyst   \n",
       "126678          Raleigh                        Research Scientist/Engineer   \n",
       "126679          Raleigh                                 Clinical Scientist   \n",
       "\n",
       "                                                  Company  \\\n",
       "0                                      Riverside Research   \n",
       "1                                      Elder Research Inc   \n",
       "2                                                 Novetta   \n",
       "3                                                     GS5   \n",
       "4                            Assured Consulting Solutions   \n",
       "5                                     Booz Allen Hamilton   \n",
       "6                                      Naval Research Lab   \n",
       "7                                             eGlobalTech   \n",
       "8                                               ByteCubed   \n",
       "9       Ukpeagvik IÃ±upiat Corporation/Bowhead Family o...   \n",
       "10                                       Development Seed   \n",
       "11                International Cotton Advisory Committee   \n",
       "12                                                 Leidos   \n",
       "13                                    The Washington Post   \n",
       "14                                               Deloitte   \n",
       "15                                               Deloitte   \n",
       "16                                    The Washington Post   \n",
       "17                                                Novetta   \n",
       "18                                    Booz Allen Hamilton   \n",
       "19                                              Accenture   \n",
       "20                                                  PCORI   \n",
       "21                                                 DAWSON   \n",
       "22                            Central Intelligence Agency   \n",
       "23                                    Ipsos North America   \n",
       "24                              Extreme Data Technologies   \n",
       "25                                                Vencore   \n",
       "26                                             Acumen LLC   \n",
       "27                                                    PNC   \n",
       "28                                     Elder Research Inc   \n",
       "29                                     Riverside Research   \n",
       "...                                                   ...   \n",
       "126650                                        Wells Fargo   \n",
       "126651                                      Tergus Pharma   \n",
       "126652                  FujiFilm Diosynth Biotechnologies   \n",
       "126653                               Bristol-Myers Squibb   \n",
       "126654                  Oak Ridge Associated Universities   \n",
       "126655                                        Kleinfelder   \n",
       "126656                                         WK Dickson   \n",
       "126657                                    Intone Networks   \n",
       "126658                     Institute for Medical Research   \n",
       "126659                     Institute for Medical Research   \n",
       "126660                                NJF Global Holdings   \n",
       "126661                                        Adecco: USA   \n",
       "126662                                        Harte Hanks   \n",
       "126663                                     Polarean, Inc.   \n",
       "126664                                         BiomÃ©rieux   \n",
       "126665                                        Wells Fargo   \n",
       "126666                                      Tergus Pharma   \n",
       "126667                             The Accuro Group, Inc.   \n",
       "126668                                       QuintilesIMS   \n",
       "126669                                        Kleinfelder   \n",
       "126670                                    Intone Networks   \n",
       "126671                               Bristol-Myers Squibb   \n",
       "126672                     Institute for Medical Research   \n",
       "126673                     Institute for Medical Research   \n",
       "126674                                NJF Global Holdings   \n",
       "126675                  Oak Ridge Associated Universities   \n",
       "126676                                        Adecco: USA   \n",
       "126677                                        Harte Hanks   \n",
       "126678                                     Polarean, Inc.   \n",
       "126679                                         BiomÃ©rieux   \n",
       "\n",
       "                                         Location  \\\n",
       "0                                  Washington, DC   \n",
       "1                                   Linthicum, MD   \n",
       "2                                Crystal City, VA   \n",
       "3                                  Washington, DC   \n",
       "4                                  Washington, DC   \n",
       "5                                  Alexandria, VA   \n",
       "6       Washington, DC 20375 (AU-Tenleytown area)   \n",
       "7                                  Washington, DC   \n",
       "8                                   Arlington, VA   \n",
       "9                                  Washington, DC   \n",
       "10                                 Washington, DC   \n",
       "11                                 Washington, DC   \n",
       "12               Washington, DC 20001 (Shaw area)   \n",
       "13                                 Washington, DC   \n",
       "14                            Arlington, VA 22209   \n",
       "15                            Arlington, VA 22209   \n",
       "16                                 Washington, DC   \n",
       "17                               Crystal City, VA   \n",
       "18                                 Washington, DC   \n",
       "19       Washington, DC 20006 (Foggy Bottom area)   \n",
       "20                                 Washington, DC   \n",
       "21               Washington, DC 20001 (Shaw area)   \n",
       "22                                 Washington, DC   \n",
       "23                                 Washington, DC   \n",
       "24                                 Washington, DC   \n",
       "25                                 Washington, DC   \n",
       "26                                 Washington, DC   \n",
       "27          Washington, DC 20022 (Brentwood area)   \n",
       "28                                  Linthicum, MD   \n",
       "29                                 Washington, DC   \n",
       "...                                           ...   \n",
       "126650                          Raleigh, NC 27601   \n",
       "126651                           Durham, NC 27713   \n",
       "126652                      Morrisville, NC 27560   \n",
       "126653                                Raleigh, NC   \n",
       "126654                                 Durham, NC   \n",
       "126655                      Morrisville, NC 27560   \n",
       "126656                                Raleigh, NC   \n",
       "126657                                Raleigh, NC   \n",
       "126658                           Durham, NC 27701   \n",
       "126659                           Durham, NC 27701   \n",
       "126660                                Raleigh, NC   \n",
       "126661                                 Durham, NC   \n",
       "126662                         Raleigh-Durham, NC   \n",
       "126663                                 Durham, NC   \n",
       "126664                                 Durham, NC   \n",
       "126665                          Raleigh, NC 27601   \n",
       "126666                           Durham, NC 27713   \n",
       "126667                                Raleigh, NC   \n",
       "126668                                Raleigh, NC   \n",
       "126669                      Morrisville, NC 27560   \n",
       "126670                                Raleigh, NC   \n",
       "126671                                Raleigh, NC   \n",
       "126672                           Durham, NC 27701   \n",
       "126673                           Durham, NC 27701   \n",
       "126674                                Raleigh, NC   \n",
       "126675                                 Durham, NC   \n",
       "126676                                 Durham, NC   \n",
       "126677                         Raleigh-Durham, NC   \n",
       "126678                                 Durham, NC   \n",
       "126679                                 Durham, NC   \n",
       "\n",
       "                                              Job Summary Salary  \n",
       "0       1 year practical work experience with geospati...    NaN  \n",
       "1       Data Scientist - Defense & Intelligence. We ar...    NaN  \n",
       "2       Collaborate with fellow technologists and cont...    NaN  \n",
       "3       The Data Scientist_Entry Level is expected to:...    NaN  \n",
       "4       We are seeking a highly motivated Junior Data ...    NaN  \n",
       "5       Data Scientist, Junior. Perform as a data scie...    NaN  \n",
       "6       Develop machine learning algorithms for a vari...    NaN  \n",
       "7       Volumes of data (e.g. Coordinate with Data Ana...    NaN  \n",
       "8       ByteCubed is seeking a Data Scientist/Develope...    NaN  \n",
       "9       - Provide statistical support for sample desig...    NaN  \n",
       "10      Remotely sensed data and associated libraries ...    NaN  \n",
       "11      Analysis, compilation, presentation and dissem...    NaN  \n",
       "12      Assist DEA statisticians and scientists in tra...    NaN  \n",
       "13      Washington Post is looking for passionate Data...    NaN  \n",
       "14      Gathering data from both information systems a...    NaN  \n",
       "15      Gathering data from both information systems a...    NaN  \n",
       "16      Washington Post is looking for passionate Data...    NaN  \n",
       "17      Collaborate with fellow technologists and cont...    NaN  \n",
       "18      Data Scientist, Mid. Apply expertise in CS, so...    NaN  \n",
       "19      Individuals in this role are expected to work ...    NaN  \n",
       "20      Demonstrated data cleaning, data management, a...    NaN  \n",
       "21      (Note: This position is contingent upon a succ...    NaN  \n",
       "22      Students serving as Data Scientist interns wor...  36800  \n",
       "23      Data analysis planning and data verification i...    NaN  \n",
       "24      This type of study could involve data simulati...    NaN  \n",
       "25      From smart grid to smart phones, intelligent h...    NaN  \n",
       "26      Data and Policy Analysts perform a wide array ...    NaN  \n",
       "27      Providing business clients with detailed, acti...    NaN  \n",
       "28      Data Scientist - Defense & Intelligence. We ar...    NaN  \n",
       "29      1 year practical work experience with geospati...    NaN  \n",
       "...                                                   ...    ...  \n",
       "126650  Strong data entry and attention to detail skil...    NaN  \n",
       "126651  Assist with assembling data summaries. Data en...    NaN  \n",
       "126652  Experimental design, analysis of data, drawing...    NaN  \n",
       "126653  Developing peer-to-peer relationships with TLs...    NaN  \n",
       "126654  The purpose of this project is to use existing...    NaN  \n",
       "126655  We are engineers, scientists, and construction...    NaN  \n",
       "126656  Search, investigate, and select technical refe...    NaN  \n",
       "126657  The project would require interfacing with dat...    NaN  \n",
       "126658  Evaluate data efficacy and think critically ab...    NaN  \n",
       "126659  Evaluate data efficacy and think critically ab...    NaN  \n",
       "126660  We are seeking Data Production Engineers for o...    NaN  \n",
       "126661  Prepare data summaries that are complete, accu...    NaN  \n",
       "126662  Understanding of the buyers journey, data driv...    NaN  \n",
       "126663  Numerical modeling and data analysis:. Data an...    NaN  \n",
       "126664  Conducts and monitors clinical trials, coordin...    NaN  \n",
       "126665  Strong data entry and attention to detail skil...    NaN  \n",
       "126666  Assist with assembling data summaries. Data en...    NaN  \n",
       "126667  Experience in Data science projects. 10 + year...    NaN  \n",
       "126668  (i) the programming, testing, and documentatio...    NaN  \n",
       "126669  We are engineers, scientists, and construction...    NaN  \n",
       "126670  The project would require interfacing with dat...    NaN  \n",
       "126671  Developing peer-to-peer relationships with TLs...    NaN  \n",
       "126672  Evaluate data efficacy and think critically ab...    NaN  \n",
       "126673  Evaluate data efficacy and think critically ab...    NaN  \n",
       "126674  We are seeking Data Production Engineers for o...    NaN  \n",
       "126675  The purpose of this project is to use existing...    NaN  \n",
       "126676  Prepare data summaries that are complete, accu...    NaN  \n",
       "126677  Understanding of the buyers journey, data driv...    NaN  \n",
       "126678  Numerical modeling and data analysis:. Data an...    NaN  \n",
       "126679  Conducts and monitors clinical trials, coordin...    NaN  \n",
       "\n",
       "[126680 rows x 6 columns]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126680"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(information) #number of data rows collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## testing the company name\n",
    "\n",
    "\n",
    "#html2=requests.get(\"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=Washington+DC&start=10\")\n",
    "#soup2=BeautifulSoup(html2.text,\"html.parser\")\n",
    "#for obj in soup2.find_all(class_='result'):\n",
    "        #results.append(cities)\n",
    "    #Grab Job title\n",
    " #   try:\n",
    "  #      vale= obj.find('h2', class_='jobtitle')\n",
    "   #     print vale.text.strip()\n",
    "    #except AttributeError:\n",
    "     #   print 'unlisted'\n",
    "#     for title in div.find('h2', class_='jobtitle'):\n",
    "#         print title.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "20339c09-5032-4e27-91be-286e9b46cd13"
   },
   "source": [
    "#### Use the functions you wrote above to parse out the 4 fields - location, title, company and salary. Create a dataframe from the results with those 4 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "focus": false,
    "id": "6e259594-1c52-436b-ab9e-527e071941c1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# data_jobs = pd.DataFrame(columns=['Title','Company','Location','Salary','Job Description'])\n",
    "# # loop through each entry\n",
    "# for entry in soup.find_all('div', {'class':'row result'}):\n",
    "#     # grab Title\n",
    "#     Title = entry.find('a', {'data-tn-element':'jobtitle'})\n",
    "#     print entry\n",
    "#     # grab salary\n",
    "#     Salary = entry.find('span',{'class':'no-wrap'})\n",
    "#     # grab location\n",
    "#     Location = entry.find('span', {'class':'location'})\n",
    "#     #grab Company\n",
    "#     Company = entry.find('span', {'class':'company'})\n",
    "#     #grab Job Description\n",
    "#     Summary = entry.find('span', {'class':'summary'})\n",
    "#     # add to df\n",
    "#     data_jobs.loc[len(data_jobs)]=[Title, Company, Location, Salary, Summary]\n",
    "#     #where to put each data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save df as csv\n",
    "#data_jobs.to_csv('/Users/ThomasPLapinger/Documents/GA/Project3/Project_3.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#information_df = pd.DataFrame(np.array(information))\n",
    "#information_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#index = range(0,len(information))\n",
    "#pd.DataFrame(np.array(information),index = index, columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#datajobs = pd.DataFrame(information, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data=pd.DataFrame(information, columns=columns)\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#save df to csv\n",
    "#information_df.to_csv('../../Indeedinfo2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#data['0'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#index = range(0,len(data['0']))\n",
    "#pd.DataFrame(np.array(data),index = index, columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#data['0'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#index=data['0']\n",
    "#pd.DataFrame(data['0'].str.split(), columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "ff98ce64-78a7-441f-a675-63464e32c834"
   },
   "source": [
    "Lastly, we need to clean up salary data. \n",
    "\n",
    "1. Only a small number of the scraped results have salary information - only these will be used for modeling.\n",
    "1. Some of the salaries are not yearly but hourly or weekly, these will not be useful to us for now\n",
    "1. Some of the entries may be duplicated\n",
    "1. The salaries are given as text and usually with ranges.\n",
    "\n",
    "#### Find the entries with annual salary entries, by filtering the entries without salaries or salaries that are not yearly (filter those that refer to hour or week). Also, remove duplicate entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "focus": false,
    "id": "58533e57-f86b-494a-b841-e7b59c6229c6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Summary</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Riverside Research</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>1 year practical work experience with geospati...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist - Defense &amp; Intelligence</td>\n",
       "      <td>Elder Research Inc</td>\n",
       "      <td>Linthicum, MD</td>\n",
       "      <td>Data Scientist - Defense &amp; Intelligence. We ar...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Novetta</td>\n",
       "      <td>Crystal City, VA</td>\n",
       "      <td>Collaborate with fellow technologists and cont...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist_Entry Level</td>\n",
       "      <td>GS5</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>The Data Scientist_Entry Level is expected to:...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Junior Data Scientist / Visualist</td>\n",
       "      <td>Assured Consulting Solutions</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>We are seeking a highly motivated Junior Data ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              City                                    Title  \\\n",
       "0  Washington D.C.                           Data Scientist   \n",
       "1  Washington D.C.  Data Scientist - Defense & Intelligence   \n",
       "2  Washington D.C.                           Data Scientist   \n",
       "3  Washington D.C.               Data Scientist_Entry Level   \n",
       "4  Washington D.C.        Junior Data Scientist / Visualist   \n",
       "\n",
       "                        Company          Location  \\\n",
       "0            Riverside Research    Washington, DC   \n",
       "1            Elder Research Inc     Linthicum, MD   \n",
       "2                       Novetta  Crystal City, VA   \n",
       "3                           GS5    Washington, DC   \n",
       "4  Assured Consulting Solutions    Washington, DC   \n",
       "\n",
       "                                         Job Summary Salary  \n",
       "0  1 year practical work experience with geospati...    NaN  \n",
       "1  Data Scientist - Defense & Intelligence. We ar...    NaN  \n",
       "2  Collaborate with fellow technologists and cont...    NaN  \n",
       "3  The Data Scientist_Entry Level is expected to:...    NaN  \n",
       "4  We are seeking a highly motivated Junior Data ...    NaN  "
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## YOUR CODE HERE\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ritikas EDA function\n",
    "def eda(dataframe):\n",
    "    print \"Missing Values \\n \\n\", dataframe.isnull().sum(),\"\\n\" #find missing values\n",
    "    print \"Duplicate Rows \\n\", dataframe.duplicated().sum(),\"\\n\" #find duplicated values\n",
    "    print \"Dataframe Types \\n \\n\", dataframe.dtypes,\"\\n\" #datatypes of each column\n",
    "    print \"Dataframe Shape \\n\", dataframe.shape,\"\\n\" #number of rows and columns\n",
    "    print \"Dataframe Describe \\n \\n\", dataframe.describe(include='all'),\"\\n\" #Describe all columns\n",
    "    for feature in dataframe: # Prints unique values for each column \n",
    "        print feature\n",
    "        print dataframe[feature].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values \n",
      " \n",
      "City           0\n",
      "Title          0\n",
      "Company        0\n",
      "Location       0\n",
      "Job Summary    0\n",
      "Salary         0\n",
      "dtype: int64 \n",
      "\n",
      "Duplicate Rows \n",
      "119000 \n",
      "\n",
      "Dataframe Types \n",
      " \n",
      "City           object\n",
      "Title          object\n",
      "Company        object\n",
      "Location       object\n",
      "Job Summary    object\n",
      "Salary         object\n",
      "dtype: object \n",
      "\n",
      "Dataframe Shape \n",
      "(126680, 6) \n",
      "\n",
      "Dataframe Describe \n",
      " \n",
      "             City           Title Company       Location  \\\n",
      "count      126680          126680  126680         126680   \n",
      "unique         32            5651    2809           1053   \n",
      "top     Baltimore  Data Scientist  BOEING  United States   \n",
      "freq         4125            6255    4121           3629   \n",
      "\n",
      "                                              Job Summary  Salary  \n",
      "count                                              126680  126680  \n",
      "unique                                               6363     232  \n",
      "top     One year of clinical laboratory experienece as...     NaN  \n",
      "freq                                                 2101  115760   \n",
      "\n",
      "City\n",
      "32\n",
      "Title\n",
      "5651\n",
      "Company\n",
      "2809\n",
      "Location\n",
      "1053\n",
      "Job Summary\n",
      "6363\n",
      "Salary\n",
      "232\n"
     ]
    }
   ],
   "source": [
    "eda(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Summary</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Deloitte</td>\n",
       "      <td>Arlington, VA 22209</td>\n",
       "      <td>Gathering data from both information systems a...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist - Big Data</td>\n",
       "      <td>The Washington Post</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Washington Post is looking for passionate Data...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Novetta</td>\n",
       "      <td>Crystal City, VA</td>\n",
       "      <td>Collaborate with fellow technologists and cont...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist - Defense &amp; Intelligence</td>\n",
       "      <td>Elder Research Inc</td>\n",
       "      <td>Linthicum, MD</td>\n",
       "      <td>Data Scientist - Defense &amp; Intelligence. We ar...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Riverside Research</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>1 year practical work experience with geospati...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Deloitte</td>\n",
       "      <td>Arlington, VA 22209</td>\n",
       "      <td>Gathering data from both information systems a...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist - Big Data</td>\n",
       "      <td>The Washington Post</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Washington Post is looking for passionate Data...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Novetta</td>\n",
       "      <td>Crystal City, VA</td>\n",
       "      <td>Collaborate with fellow technologists and cont...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist - Defense &amp; Intelligence</td>\n",
       "      <td>Elder Research Inc</td>\n",
       "      <td>Linthicum, MD</td>\n",
       "      <td>Data Scientist - Defense &amp; Intelligence. We ar...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Riverside Research</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>1 year practical work experience with geospati...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Deloitte</td>\n",
       "      <td>Arlington, VA 22209</td>\n",
       "      <td>Gathering data from both information systems a...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Novetta</td>\n",
       "      <td>Crystal City, VA</td>\n",
       "      <td>Collaborate with fellow technologists and cont...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Big Data Architect (Manager, Sr. Manager)</td>\n",
       "      <td>Sumeru Solutions</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Experience working with Business Intelligence ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist - Big Data</td>\n",
       "      <td>The Washington Post</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Washington Post is looking for passionate Data...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist - Defense &amp; Intelligence</td>\n",
       "      <td>Elder Research Inc</td>\n",
       "      <td>Linthicum, MD</td>\n",
       "      <td>Data Scientist - Defense &amp; Intelligence. We ar...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Riverside Research</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>1 year practical work experience with geospati...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Deloitte</td>\n",
       "      <td>Arlington, VA 22209</td>\n",
       "      <td>Gathering data from both information systems a...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Novetta</td>\n",
       "      <td>Crystal City, VA</td>\n",
       "      <td>Collaborate with fellow technologists and cont...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist - Big Data</td>\n",
       "      <td>The Washington Post</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Washington Post is looking for passionate Data...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist - Defense &amp; Intelligence</td>\n",
       "      <td>Elder Research Inc</td>\n",
       "      <td>Linthicum, MD</td>\n",
       "      <td>Data Scientist - Defense &amp; Intelligence. We ar...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Riverside Research</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>1 year practical work experience with geospati...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Deloitte</td>\n",
       "      <td>Arlington, VA 22209</td>\n",
       "      <td>Gathering data from both information systems a...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Novetta</td>\n",
       "      <td>Crystal City, VA</td>\n",
       "      <td>Collaborate with fellow technologists and cont...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist - Big Data</td>\n",
       "      <td>The Washington Post</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Washington Post is looking for passionate Data...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist - Defense &amp; Intelligence</td>\n",
       "      <td>Elder Research Inc</td>\n",
       "      <td>Linthicum, MD</td>\n",
       "      <td>Data Scientist - Defense &amp; Intelligence. We ar...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Riverside Research</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>1 year practical work experience with geospati...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Deloitte</td>\n",
       "      <td>Arlington, VA 22209</td>\n",
       "      <td>Gathering data from both information systems a...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Novetta</td>\n",
       "      <td>Crystal City, VA</td>\n",
       "      <td>Collaborate with fellow technologists and cont...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist - Big Data</td>\n",
       "      <td>The Washington Post</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Washington Post is looking for passionate Data...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist - Defense &amp; Intelligence</td>\n",
       "      <td>Elder Research Inc</td>\n",
       "      <td>Linthicum, MD</td>\n",
       "      <td>Data Scientist - Defense &amp; Intelligence. We ar...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126650</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Research/Remediation Analyst 1</td>\n",
       "      <td>Wells Fargo</td>\n",
       "      <td>Raleigh, NC 27601</td>\n",
       "      <td>Strong data entry and attention to detail skil...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126651</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Analytical Scientist, Analytical R&amp;D</td>\n",
       "      <td>Tergus Pharma</td>\n",
       "      <td>Durham, NC 27713</td>\n",
       "      <td>Assist with assembling data summaries. Data en...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126652</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Scientist II, Cell Culture Development</td>\n",
       "      <td>FujiFilm Diosynth Biotechnologies</td>\n",
       "      <td>Morrisville, NC 27560</td>\n",
       "      <td>Experimental design, analysis of data, drawing...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126653</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Field Medical Regional Associate Director (Eas...</td>\n",
       "      <td>Bristol-Myers Squibb</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>Developing peer-to-peer relationships with TLs...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126654</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Development and Application of Quantitative Mo...</td>\n",
       "      <td>Oak Ridge Associated Universities</td>\n",
       "      <td>Durham, NC</td>\n",
       "      <td>The purpose of this project is to use existing...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126655</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Construction Engineering and Inspection (CEI) ...</td>\n",
       "      <td>Kleinfelder</td>\n",
       "      <td>Morrisville, NC 27560</td>\n",
       "      <td>We are engineers, scientists, and construction...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126656</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Senior Civil Designer - Water/Sewer</td>\n",
       "      <td>WK Dickson</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>Search, investigate, and select technical refe...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126657</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Immediately Need Sr. Tableau Developer</td>\n",
       "      <td>Intone Networks</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>The project would require interfacing with dat...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126658</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Software Engineer, Natural Language Processing...</td>\n",
       "      <td>Institute for Medical Research</td>\n",
       "      <td>Durham, NC 27701</td>\n",
       "      <td>Evaluate data efficacy and think critically ab...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126659</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Data Analyst, Natural Language Processing Special</td>\n",
       "      <td>Institute for Medical Research</td>\n",
       "      <td>Durham, NC 27701</td>\n",
       "      <td>Evaluate data efficacy and think critically ab...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126660</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Data Production Engineer</td>\n",
       "      <td>NJF Global Holdings</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>We are seeking Data Production Engineers for o...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126661</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Master Data Administrator Analyst SAP BI</td>\n",
       "      <td>Adecco: USA</td>\n",
       "      <td>Durham, NC</td>\n",
       "      <td>Prepare data summaries that are complete, accu...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126662</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Customer Research Analyst</td>\n",
       "      <td>Harte Hanks</td>\n",
       "      <td>Raleigh-Durham, NC</td>\n",
       "      <td>Understanding of the buyers journey, data driv...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126663</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Research Scientist/Engineer</td>\n",
       "      <td>Polarean, Inc.</td>\n",
       "      <td>Durham, NC</td>\n",
       "      <td>Numerical modeling and data analysis:. Data an...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126664</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Clinical Scientist</td>\n",
       "      <td>BiomÃ©rieux</td>\n",
       "      <td>Durham, NC</td>\n",
       "      <td>Conducts and monitors clinical trials, coordin...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126665</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Research/Remediation Analyst 1</td>\n",
       "      <td>Wells Fargo</td>\n",
       "      <td>Raleigh, NC 27601</td>\n",
       "      <td>Strong data entry and attention to detail skil...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126666</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Analytical Scientist, Analytical R&amp;D</td>\n",
       "      <td>Tergus Pharma</td>\n",
       "      <td>Durham, NC 27713</td>\n",
       "      <td>Assist with assembling data summaries. Data en...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126667</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Sr. Software Engineer \"Machine Learning Experi...</td>\n",
       "      <td>The Accuro Group, Inc.</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>Experience in Data science projects. 10 + year...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126668</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Senior Statistical Programmer Statistical Prog...</td>\n",
       "      <td>QuintilesIMS</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>(i) the programming, testing, and documentatio...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126669</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Construction Engineering and Inspection (CEI) ...</td>\n",
       "      <td>Kleinfelder</td>\n",
       "      <td>Morrisville, NC 27560</td>\n",
       "      <td>We are engineers, scientists, and construction...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126670</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Immediately Need Sr. Tableau Developer</td>\n",
       "      <td>Intone Networks</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>The project would require interfacing with dat...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126671</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Field Medical Regional Associate Director (Eas...</td>\n",
       "      <td>Bristol-Myers Squibb</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>Developing peer-to-peer relationships with TLs...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126672</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Software Engineer, Natural Language Processing...</td>\n",
       "      <td>Institute for Medical Research</td>\n",
       "      <td>Durham, NC 27701</td>\n",
       "      <td>Evaluate data efficacy and think critically ab...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126673</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Data Analyst, Natural Language Processing Special</td>\n",
       "      <td>Institute for Medical Research</td>\n",
       "      <td>Durham, NC 27701</td>\n",
       "      <td>Evaluate data efficacy and think critically ab...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126674</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Data Production Engineer</td>\n",
       "      <td>NJF Global Holdings</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>We are seeking Data Production Engineers for o...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126675</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Development and Application of Quantitative Mo...</td>\n",
       "      <td>Oak Ridge Associated Universities</td>\n",
       "      <td>Durham, NC</td>\n",
       "      <td>The purpose of this project is to use existing...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126676</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Master Data Administrator Analyst SAP BI</td>\n",
       "      <td>Adecco: USA</td>\n",
       "      <td>Durham, NC</td>\n",
       "      <td>Prepare data summaries that are complete, accu...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126677</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Customer Research Analyst</td>\n",
       "      <td>Harte Hanks</td>\n",
       "      <td>Raleigh-Durham, NC</td>\n",
       "      <td>Understanding of the buyers journey, data driv...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126678</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Research Scientist/Engineer</td>\n",
       "      <td>Polarean, Inc.</td>\n",
       "      <td>Durham, NC</td>\n",
       "      <td>Numerical modeling and data analysis:. Data an...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126679</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Clinical Scientist</td>\n",
       "      <td>BiomÃ©rieux</td>\n",
       "      <td>Durham, NC</td>\n",
       "      <td>Conducts and monitors clinical trials, coordin...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119000 rows Ã 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   City                                              Title  \\\n",
       "15      Washington D.C.                                     Data Scientist   \n",
       "16      Washington D.C.                          Data Scientist - Big Data   \n",
       "17      Washington D.C.                                     Data Scientist   \n",
       "28      Washington D.C.            Data Scientist - Defense & Intelligence   \n",
       "29      Washington D.C.                                     Data Scientist   \n",
       "30      Washington D.C.                                     Data Scientist   \n",
       "31      Washington D.C.                          Data Scientist - Big Data   \n",
       "42      Washington D.C.                                     Data Scientist   \n",
       "43      Washington D.C.            Data Scientist - Defense & Intelligence   \n",
       "44      Washington D.C.                                     Data Scientist   \n",
       "45      Washington D.C.                                     Data Scientist   \n",
       "46      Washington D.C.                                     Data Scientist   \n",
       "47      Washington D.C.          Big Data Architect (Manager, Sr. Manager)   \n",
       "57      Washington D.C.                          Data Scientist - Big Data   \n",
       "58      Washington D.C.            Data Scientist - Defense & Intelligence   \n",
       "59      Washington D.C.                                     Data Scientist   \n",
       "60      Washington D.C.                                     Data Scientist   \n",
       "61      Washington D.C.                                     Data Scientist   \n",
       "72      Washington D.C.                          Data Scientist - Big Data   \n",
       "73      Washington D.C.            Data Scientist - Defense & Intelligence   \n",
       "74      Washington D.C.                                     Data Scientist   \n",
       "75      Washington D.C.                                     Data Scientist   \n",
       "76      Washington D.C.                                     Data Scientist   \n",
       "87      Washington D.C.                          Data Scientist - Big Data   \n",
       "88      Washington D.C.            Data Scientist - Defense & Intelligence   \n",
       "89      Washington D.C.                                     Data Scientist   \n",
       "90      Washington D.C.                                     Data Scientist   \n",
       "91      Washington D.C.                                     Data Scientist   \n",
       "102     Washington D.C.                          Data Scientist - Big Data   \n",
       "103     Washington D.C.            Data Scientist - Defense & Intelligence   \n",
       "...                 ...                                                ...   \n",
       "126650          Raleigh                     Research/Remediation Analyst 1   \n",
       "126651          Raleigh               Analytical Scientist, Analytical R&D   \n",
       "126652          Raleigh             Scientist II, Cell Culture Development   \n",
       "126653          Raleigh  Field Medical Regional Associate Director (Eas...   \n",
       "126654          Raleigh  Development and Application of Quantitative Mo...   \n",
       "126655          Raleigh  Construction Engineering and Inspection (CEI) ...   \n",
       "126656          Raleigh                Senior Civil Designer - Water/Sewer   \n",
       "126657          Raleigh             Immediately Need Sr. Tableau Developer   \n",
       "126658          Raleigh  Software Engineer, Natural Language Processing...   \n",
       "126659          Raleigh  Data Analyst, Natural Language Processing Special   \n",
       "126660          Raleigh                           Data Production Engineer   \n",
       "126661          Raleigh           Master Data Administrator Analyst SAP BI   \n",
       "126662          Raleigh                          Customer Research Analyst   \n",
       "126663          Raleigh                        Research Scientist/Engineer   \n",
       "126664          Raleigh                                 Clinical Scientist   \n",
       "126665          Raleigh                     Research/Remediation Analyst 1   \n",
       "126666          Raleigh               Analytical Scientist, Analytical R&D   \n",
       "126667          Raleigh  Sr. Software Engineer \"Machine Learning Experi...   \n",
       "126668          Raleigh  Senior Statistical Programmer Statistical Prog...   \n",
       "126669          Raleigh  Construction Engineering and Inspection (CEI) ...   \n",
       "126670          Raleigh             Immediately Need Sr. Tableau Developer   \n",
       "126671          Raleigh  Field Medical Regional Associate Director (Eas...   \n",
       "126672          Raleigh  Software Engineer, Natural Language Processing...   \n",
       "126673          Raleigh  Data Analyst, Natural Language Processing Special   \n",
       "126674          Raleigh                           Data Production Engineer   \n",
       "126675          Raleigh  Development and Application of Quantitative Mo...   \n",
       "126676          Raleigh           Master Data Administrator Analyst SAP BI   \n",
       "126677          Raleigh                          Customer Research Analyst   \n",
       "126678          Raleigh                        Research Scientist/Engineer   \n",
       "126679          Raleigh                                 Clinical Scientist   \n",
       "\n",
       "                                  Company               Location  \\\n",
       "15                               Deloitte    Arlington, VA 22209   \n",
       "16                    The Washington Post         Washington, DC   \n",
       "17                                Novetta       Crystal City, VA   \n",
       "28                     Elder Research Inc          Linthicum, MD   \n",
       "29                     Riverside Research         Washington, DC   \n",
       "30                               Deloitte    Arlington, VA 22209   \n",
       "31                    The Washington Post         Washington, DC   \n",
       "42                                Novetta       Crystal City, VA   \n",
       "43                     Elder Research Inc          Linthicum, MD   \n",
       "44                     Riverside Research         Washington, DC   \n",
       "45                               Deloitte    Arlington, VA 22209   \n",
       "46                                Novetta       Crystal City, VA   \n",
       "47                       Sumeru Solutions         Washington, DC   \n",
       "57                    The Washington Post         Washington, DC   \n",
       "58                     Elder Research Inc          Linthicum, MD   \n",
       "59                     Riverside Research         Washington, DC   \n",
       "60                               Deloitte    Arlington, VA 22209   \n",
       "61                                Novetta       Crystal City, VA   \n",
       "72                    The Washington Post         Washington, DC   \n",
       "73                     Elder Research Inc          Linthicum, MD   \n",
       "74                     Riverside Research         Washington, DC   \n",
       "75                               Deloitte    Arlington, VA 22209   \n",
       "76                                Novetta       Crystal City, VA   \n",
       "87                    The Washington Post         Washington, DC   \n",
       "88                     Elder Research Inc          Linthicum, MD   \n",
       "89                     Riverside Research         Washington, DC   \n",
       "90                               Deloitte    Arlington, VA 22209   \n",
       "91                                Novetta       Crystal City, VA   \n",
       "102                   The Washington Post         Washington, DC   \n",
       "103                    Elder Research Inc          Linthicum, MD   \n",
       "...                                   ...                    ...   \n",
       "126650                        Wells Fargo      Raleigh, NC 27601   \n",
       "126651                      Tergus Pharma       Durham, NC 27713   \n",
       "126652  FujiFilm Diosynth Biotechnologies  Morrisville, NC 27560   \n",
       "126653               Bristol-Myers Squibb            Raleigh, NC   \n",
       "126654  Oak Ridge Associated Universities             Durham, NC   \n",
       "126655                        Kleinfelder  Morrisville, NC 27560   \n",
       "126656                         WK Dickson            Raleigh, NC   \n",
       "126657                    Intone Networks            Raleigh, NC   \n",
       "126658     Institute for Medical Research       Durham, NC 27701   \n",
       "126659     Institute for Medical Research       Durham, NC 27701   \n",
       "126660                NJF Global Holdings            Raleigh, NC   \n",
       "126661                        Adecco: USA             Durham, NC   \n",
       "126662                        Harte Hanks     Raleigh-Durham, NC   \n",
       "126663                     Polarean, Inc.             Durham, NC   \n",
       "126664                         BiomÃ©rieux             Durham, NC   \n",
       "126665                        Wells Fargo      Raleigh, NC 27601   \n",
       "126666                      Tergus Pharma       Durham, NC 27713   \n",
       "126667             The Accuro Group, Inc.            Raleigh, NC   \n",
       "126668                       QuintilesIMS            Raleigh, NC   \n",
       "126669                        Kleinfelder  Morrisville, NC 27560   \n",
       "126670                    Intone Networks            Raleigh, NC   \n",
       "126671               Bristol-Myers Squibb            Raleigh, NC   \n",
       "126672     Institute for Medical Research       Durham, NC 27701   \n",
       "126673     Institute for Medical Research       Durham, NC 27701   \n",
       "126674                NJF Global Holdings            Raleigh, NC   \n",
       "126675  Oak Ridge Associated Universities             Durham, NC   \n",
       "126676                        Adecco: USA             Durham, NC   \n",
       "126677                        Harte Hanks     Raleigh-Durham, NC   \n",
       "126678                     Polarean, Inc.             Durham, NC   \n",
       "126679                         BiomÃ©rieux             Durham, NC   \n",
       "\n",
       "                                              Job Summary Salary  \n",
       "15      Gathering data from both information systems a...    NaN  \n",
       "16      Washington Post is looking for passionate Data...    NaN  \n",
       "17      Collaborate with fellow technologists and cont...    NaN  \n",
       "28      Data Scientist - Defense & Intelligence. We ar...    NaN  \n",
       "29      1 year practical work experience with geospati...    NaN  \n",
       "30      Gathering data from both information systems a...    NaN  \n",
       "31      Washington Post is looking for passionate Data...    NaN  \n",
       "42      Collaborate with fellow technologists and cont...    NaN  \n",
       "43      Data Scientist - Defense & Intelligence. We ar...    NaN  \n",
       "44      1 year practical work experience with geospati...    NaN  \n",
       "45      Gathering data from both information systems a...    NaN  \n",
       "46      Collaborate with fellow technologists and cont...    NaN  \n",
       "47      Experience working with Business Intelligence ...    NaN  \n",
       "57      Washington Post is looking for passionate Data...    NaN  \n",
       "58      Data Scientist - Defense & Intelligence. We ar...    NaN  \n",
       "59      1 year practical work experience with geospati...    NaN  \n",
       "60      Gathering data from both information systems a...    NaN  \n",
       "61      Collaborate with fellow technologists and cont...    NaN  \n",
       "72      Washington Post is looking for passionate Data...    NaN  \n",
       "73      Data Scientist - Defense & Intelligence. We ar...    NaN  \n",
       "74      1 year practical work experience with geospati...    NaN  \n",
       "75      Gathering data from both information systems a...    NaN  \n",
       "76      Collaborate with fellow technologists and cont...    NaN  \n",
       "87      Washington Post is looking for passionate Data...    NaN  \n",
       "88      Data Scientist - Defense & Intelligence. We ar...    NaN  \n",
       "89      1 year practical work experience with geospati...    NaN  \n",
       "90      Gathering data from both information systems a...    NaN  \n",
       "91      Collaborate with fellow technologists and cont...    NaN  \n",
       "102     Washington Post is looking for passionate Data...    NaN  \n",
       "103     Data Scientist - Defense & Intelligence. We ar...    NaN  \n",
       "...                                                   ...    ...  \n",
       "126650  Strong data entry and attention to detail skil...    NaN  \n",
       "126651  Assist with assembling data summaries. Data en...    NaN  \n",
       "126652  Experimental design, analysis of data, drawing...    NaN  \n",
       "126653  Developing peer-to-peer relationships with TLs...    NaN  \n",
       "126654  The purpose of this project is to use existing...    NaN  \n",
       "126655  We are engineers, scientists, and construction...    NaN  \n",
       "126656  Search, investigate, and select technical refe...    NaN  \n",
       "126657  The project would require interfacing with dat...    NaN  \n",
       "126658  Evaluate data efficacy and think critically ab...    NaN  \n",
       "126659  Evaluate data efficacy and think critically ab...    NaN  \n",
       "126660  We are seeking Data Production Engineers for o...    NaN  \n",
       "126661  Prepare data summaries that are complete, accu...    NaN  \n",
       "126662  Understanding of the buyers journey, data driv...    NaN  \n",
       "126663  Numerical modeling and data analysis:. Data an...    NaN  \n",
       "126664  Conducts and monitors clinical trials, coordin...    NaN  \n",
       "126665  Strong data entry and attention to detail skil...    NaN  \n",
       "126666  Assist with assembling data summaries. Data en...    NaN  \n",
       "126667  Experience in Data science projects. 10 + year...    NaN  \n",
       "126668  (i) the programming, testing, and documentatio...    NaN  \n",
       "126669  We are engineers, scientists, and construction...    NaN  \n",
       "126670  The project would require interfacing with dat...    NaN  \n",
       "126671  Developing peer-to-peer relationships with TLs...    NaN  \n",
       "126672  Evaluate data efficacy and think critically ab...    NaN  \n",
       "126673  Evaluate data efficacy and think critically ab...    NaN  \n",
       "126674  We are seeking Data Production Engineers for o...    NaN  \n",
       "126675  The purpose of this project is to use existing...    NaN  \n",
       "126676  Prepare data summaries that are complete, accu...    NaN  \n",
       "126677  Understanding of the buyers journey, data driv...    NaN  \n",
       "126678  Numerical modeling and data analysis:. Data an...    NaN  \n",
       "126679  Conducts and monitors clinical trials, coordin...    NaN  \n",
       "\n",
       "[119000 rows x 6 columns]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2.duplicated()] #show duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop_duplicates(keep='first', inplace=True) #drop duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Summary</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Riverside Research</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>1 year practical work experience with geospati...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist - Defense &amp; Intelligence</td>\n",
       "      <td>Elder Research Inc</td>\n",
       "      <td>Linthicum, MD</td>\n",
       "      <td>Data Scientist - Defense &amp; Intelligence. We ar...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Novetta</td>\n",
       "      <td>Crystal City, VA</td>\n",
       "      <td>Collaborate with fellow technologists and cont...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist_Entry Level</td>\n",
       "      <td>GS5</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>The Data Scientist_Entry Level is expected to:...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Junior Data Scientist / Visualist</td>\n",
       "      <td>Assured Consulting Solutions</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>We are seeking a highly motivated Junior Data ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              City                                    Title  \\\n",
       "0  Washington D.C.                           Data Scientist   \n",
       "1  Washington D.C.  Data Scientist - Defense & Intelligence   \n",
       "2  Washington D.C.                           Data Scientist   \n",
       "3  Washington D.C.               Data Scientist_Entry Level   \n",
       "4  Washington D.C.        Junior Data Scientist / Visualist   \n",
       "\n",
       "                        Company          Location  \\\n",
       "0            Riverside Research    Washington, DC   \n",
       "1            Elder Research Inc     Linthicum, MD   \n",
       "2                       Novetta  Crystal City, VA   \n",
       "3                           GS5    Washington, DC   \n",
       "4  Assured Consulting Solutions    Washington, DC   \n",
       "\n",
       "                                         Job Summary Salary  \n",
       "0  1 year practical work experience with geospati...    NaN  \n",
       "1  Data Scientist - Defense & Intelligence. We ar...    NaN  \n",
       "2  Collaborate with fellow technologists and cont...    NaN  \n",
       "3  The Data Scientist_Entry Level is expected to:...    NaN  \n",
       "4  We are seeking a highly motivated Junior Data ...    NaN  "
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values \n",
      " \n",
      "City           0\n",
      "Title          0\n",
      "Company        0\n",
      "Location       0\n",
      "Job Summary    0\n",
      "Salary         0\n",
      "dtype: int64 \n",
      "\n",
      "Duplicate Rows \n",
      "0 \n",
      "\n",
      "Dataframe Types \n",
      " \n",
      "City           object\n",
      "Title          object\n",
      "Company        object\n",
      "Location       object\n",
      "Job Summary    object\n",
      "Salary         object\n",
      "dtype: object \n",
      "\n",
      "Dataframe Shape \n",
      "(7680, 6) \n",
      "\n",
      "Dataframe Describe \n",
      " \n",
      "                   City           Title         Company      Location  \\\n",
      "count              7680            7680            7680          7680   \n",
      "unique               32            5651            2809          1053   \n",
      "top     Washington D.C.  Data Scientist  Ball Aerospace  New York, NY   \n",
      "freq                825             361             132           432   \n",
      "\n",
      "                                              Job Summary Salary  \n",
      "count                                                7680   7680  \n",
      "unique                                               6363    232  \n",
      "top     Our team of more than 3,000 engineers, scienti...    NaN  \n",
      "freq                                                   76   7239   \n",
      "\n",
      "City\n",
      "32\n",
      "Title\n",
      "5651\n",
      "Company\n",
      "2809\n",
      "Location\n",
      "1053\n",
      "Job Summary\n",
      "6363\n",
      "Salary\n",
      "232\n"
     ]
    }
   ],
   "source": [
    "eda(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7680, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Summary</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Riverside Research</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>1 year practical work experience with geospati...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist - Defense &amp; Intelligence</td>\n",
       "      <td>Elder Research Inc</td>\n",
       "      <td>Linthicum, MD</td>\n",
       "      <td>Data Scientist - Defense &amp; Intelligence. We ar...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Novetta</td>\n",
       "      <td>Crystal City, VA</td>\n",
       "      <td>Collaborate with fellow technologists and cont...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist_Entry Level</td>\n",
       "      <td>GS5</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>The Data Scientist_Entry Level is expected to:...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Junior Data Scientist / Visualist</td>\n",
       "      <td>Assured Consulting Solutions</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>We are seeking a highly motivated Junior Data ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              City                                    Title  \\\n",
       "0  Washington D.C.                           Data Scientist   \n",
       "1  Washington D.C.  Data Scientist - Defense & Intelligence   \n",
       "2  Washington D.C.                           Data Scientist   \n",
       "3  Washington D.C.               Data Scientist_Entry Level   \n",
       "4  Washington D.C.        Junior Data Scientist / Visualist   \n",
       "\n",
       "                        Company          Location  \\\n",
       "0            Riverside Research    Washington, DC   \n",
       "1            Elder Research Inc     Linthicum, MD   \n",
       "2                       Novetta  Crystal City, VA   \n",
       "3                           GS5    Washington, DC   \n",
       "4  Assured Consulting Solutions    Washington, DC   \n",
       "\n",
       "                                         Job Summary Salary  \n",
       "0  1 year practical work experience with geospati...    NaN  \n",
       "1  Data Scientist - Defense & Intelligence. We ar...    NaN  \n",
       "2  Collaborate with fellow technologists and cont...    NaN  \n",
       "3  The Data Scientist_Entry Level is expected to:...    NaN  \n",
       "4  We are seeking a highly motivated Junior Data ...    NaN  "
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df2.dropna() #drop rows with value na\n",
    "print df2.shape\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Summary</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Undergraduate Internship/Co-op Program - Data ...</td>\n",
       "      <td>Central Intelligence Agency</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Students serving as Data Scientist interns wor...</td>\n",
       "      <td>36800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Supervisory Operations Research Analyst</td>\n",
       "      <td>Department of Health And Human Services</td>\n",
       "      <td>Silver Spring, MD</td>\n",
       "      <td>Develops alternative options to resolve comple...</td>\n",
       "      <td>146834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Metropolitan Police Department</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Or data visualization and interaction. The Dat...</td>\n",
       "      <td>86711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Facilities Intern</td>\n",
       "      <td>Natural Resources Defense Council</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Maintain data bases, paper and electronic fili...</td>\n",
       "      <td>24000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Research Physical Scientist, AST, Atmospheric ...</td>\n",
       "      <td>National Aeronautics and Space Administration</td>\n",
       "      <td>Greenbelt, MD</td>\n",
       "      <td>Utilization of satellite data to test existing...</td>\n",
       "      <td>120212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Real Estate and Urban Planning Research Analys...</td>\n",
       "      <td>The Maryland-National Capital Park and Plannin...</td>\n",
       "      <td>Silver Spring, MD 20902</td>\n",
       "      <td>Experience with Costar and other real estate d...</td>\n",
       "      <td>79475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Statistician - Healthcare or Pharma Industry</td>\n",
       "      <td>Contingent/Direct Consultants</td>\n",
       "      <td>Gaithersburg, MD 20877</td>\n",
       "      <td>Experience of Development, program design and ...</td>\n",
       "      <td>150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Central Intelligence Agency</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Data Scientists organize and interpret Big Dat...</td>\n",
       "      <td>91066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Piper Companies</td>\n",
       "      <td>Reston, VA 20190</td>\n",
       "      <td>Responsibilities for the Lead Data Scientist i...</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist - OUSD(I)-HCMO-DCIPS</td>\n",
       "      <td>Red Gate Group</td>\n",
       "      <td>Arlington, VA</td>\n",
       "      <td>Data Scientist (full-time contract). Under thi...</td>\n",
       "      <td>112500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Apps Developer</td>\n",
       "      <td>Central Intelligence Agency</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Big Data concepts and technologies such as Apa...</td>\n",
       "      <td>90936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Payroll Support Associate at EPA</td>\n",
       "      <td>Oak Ridge Associated Universities</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Performing data entry in various ORD and Agenc...</td>\n",
       "      <td>35200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>IFG Data Scientist Whiz!</td>\n",
       "      <td>Interface Financial Group (IFG)</td>\n",
       "      <td>Bethesda, MD</td>\n",
       "      <td>Data Scientists need to analyze financial data...</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>National Geospatial-Intelligence Agency</td>\n",
       "      <td>Springfield, VA</td>\n",
       "      <td>Data Scientist **AMENDED**. Data Management, D...</td>\n",
       "      <td>90941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Staff Fellow (Mathematical Statistician)</td>\n",
       "      <td>Department of Health And Human Services</td>\n",
       "      <td>Rockville, MD</td>\n",
       "      <td>You will use statistical and mathematical meth...</td>\n",
       "      <td>101477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Operations Research Analyst</td>\n",
       "      <td>Department of the Treasury</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Determining the types of data to be collected,...</td>\n",
       "      <td>109015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Mathematicians - Entry/Mid-Level</td>\n",
       "      <td>National Security Agency</td>\n",
       "      <td>Fort Meade, MD</td>\n",
       "      <td>These include, but are not limited to cryptogr...</td>\n",
       "      <td>77025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Mathematical Statisticians - Entry/Mid-Level</td>\n",
       "      <td>National Security Agency</td>\n",
       "      <td>Fort Meade, MD</td>\n",
       "      <td>These include, but are not limited to, problem...</td>\n",
       "      <td>77025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>2017-07-10 IT Program Manager Earning $$213,000</td>\n",
       "      <td>EMF Industries</td>\n",
       "      <td>McLean, VA</td>\n",
       "      <td>Our talented group of Data Scientists, Develop...</td>\n",
       "      <td>213000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Research Analyst (Vaccines)</td>\n",
       "      <td>Johnson Service Group Inc.</td>\n",
       "      <td>Rockville, MD 20850</td>\n",
       "      <td>Provide effort &amp; cost benchmarking &amp; insights ...</td>\n",
       "      <td>78400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Operations Research Analyst</td>\n",
       "      <td>Federal Aviation Administration</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Business Component: Associate Administrator fo...</td>\n",
       "      <td>97825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Piper Companies</td>\n",
       "      <td>Reston, VA 20190</td>\n",
       "      <td>Collaborate with a team of other data engineer...</td>\n",
       "      <td>195000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Interdisciplinary, GS-0101,0180,0801,1550-12/1...</td>\n",
       "      <td>Department of Commerce</td>\n",
       "      <td>Washington, DC 20230 (Downtown area)</td>\n",
       "      <td>Assisting with organizing and analyzing resear...</td>\n",
       "      <td>101477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Senior Product Manager</td>\n",
       "      <td>Catalist</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Conversant understanding of relational data an...</td>\n",
       "      <td>85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Piper Companies</td>\n",
       "      <td>Reston, VA 20190</td>\n",
       "      <td>Responsibilities for the Lead Data Scientist i...</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Recent Graduate Survey Statistician, GS-1530-7...</td>\n",
       "      <td>Department of Commerce</td>\n",
       "      <td>Washington, DC 20230 (Downtown area)</td>\n",
       "      <td>Analyze and evaluate data. Assist in data coll...</td>\n",
       "      <td>65700.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Environmental Scientist - Water Resources Mana...</td>\n",
       "      <td>WSSC</td>\n",
       "      <td>Laurel, MD 20707</td>\n",
       "      <td>Ability to plan and direct the work of profess...</td>\n",
       "      <td>95396.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist - Mid-Level</td>\n",
       "      <td>National Security Agency</td>\n",
       "      <td>Fort Meade, MD</td>\n",
       "      <td>Exploit, fuse and use data and data sources. A...</td>\n",
       "      <td>92498.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Operations Research Analyst</td>\n",
       "      <td>Department of Defense</td>\n",
       "      <td>Arlington, VA</td>\n",
       "      <td>Using statistical analysis techniques in order...</td>\n",
       "      <td>128825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Statistical Data Analyst - US Citizen</td>\n",
       "      <td>PeopleTek</td>\n",
       "      <td>Bethesda, MD</td>\n",
       "      <td>STATISTICAL DATA ANALYST*. ï· Extract insights ...</td>\n",
       "      <td>65000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114406</th>\n",
       "      <td>Mesa</td>\n",
       "      <td>Institutional Research Analyst (Open until Fil...</td>\n",
       "      <td>Maricopa County Community College District</td>\n",
       "      <td>Phoenix, AZ</td>\n",
       "      <td>Develops queries on data warehouses using data...</td>\n",
       "      <td>55735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114417</th>\n",
       "      <td>Mesa</td>\n",
       "      <td>Account Manager</td>\n",
       "      <td>The Creative Group</td>\n",
       "      <td>Phoenix, AZ 85016 (Camelback East area)</td>\n",
       "      <td>You're fascinated by data analytics:. You may ...</td>\n",
       "      <td>44000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114420</th>\n",
       "      <td>Mesa</td>\n",
       "      <td>Web Security Research Analyst</td>\n",
       "      <td>SiteLock</td>\n",
       "      <td>Scottsdale, AZ</td>\n",
       "      <td>About SiteLock: SiteLock is the global leader ...</td>\n",
       "      <td>52500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114421</th>\n",
       "      <td>Mesa</td>\n",
       "      <td>ENVIRONMENTAL OUTREACH SPECIALIST</td>\n",
       "      <td>State of Arizona</td>\n",
       "      <td>Phoenix, AZ</td>\n",
       "      <td>Analyze environmental data to determine validi...</td>\n",
       "      <td>55000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114422</th>\n",
       "      <td>Mesa</td>\n",
       "      <td>AIR QUALITY PLANNER 2-3</td>\n",
       "      <td>State of Arizona</td>\n",
       "      <td>Phoenix, AZ</td>\n",
       "      <td>Ability to present data and findings in public...</td>\n",
       "      <td>61000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118436</th>\n",
       "      <td>Kansas City</td>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>Jackson County, Missouri</td>\n",
       "      <td>Kansas City, MO 64106 (Downtown area)</td>\n",
       "      <td>Verifies and analyzes real estate sales, lease...</td>\n",
       "      <td>20800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118441</th>\n",
       "      <td>Kansas City</td>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>Jackson County Department of Corrections</td>\n",
       "      <td>Kansas City, MO</td>\n",
       "      <td>Verifies and analyzes real estate sales, lease...</td>\n",
       "      <td>20800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118452</th>\n",
       "      <td>Kansas City</td>\n",
       "      <td>Material Handler</td>\n",
       "      <td>Honeywell</td>\n",
       "      <td>Kansas City, MO 64147 (Richards Gebaur area)</td>\n",
       "      <td>Maintains inventory data bases. Completes pape...</td>\n",
       "      <td>25600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118486</th>\n",
       "      <td>Kansas City</td>\n",
       "      <td>Production Fabricator (Any Shift)</td>\n",
       "      <td>Honeywell</td>\n",
       "      <td>Kansas City, KS</td>\n",
       "      <td>Completes paperwork and computer data entries ...</td>\n",
       "      <td>25600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118498</th>\n",
       "      <td>Kansas City</td>\n",
       "      <td>Inspector, Tool &amp; Precision Gage (Any Shift)</td>\n",
       "      <td>Honeywell</td>\n",
       "      <td>Kansas City, KS</td>\n",
       "      <td>Ability to analyze and interpret data. Must be...</td>\n",
       "      <td>36800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118504</th>\n",
       "      <td>Kansas City</td>\n",
       "      <td>Tool &amp; Precision Gage Inspector (Any Shift)</td>\n",
       "      <td>Honeywell</td>\n",
       "      <td>Kansas City, KS</td>\n",
       "      <td>Ability to analyze and interpret data. Must be...</td>\n",
       "      <td>36800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118516</th>\n",
       "      <td>Kansas City</td>\n",
       "      <td>Electronics Test Inspector (Any Shift)</td>\n",
       "      <td>Honeywell</td>\n",
       "      <td>Kansas City, MO 64147 (Richards Gebaur area)</td>\n",
       "      <td>May be required to examine and evaluate test d...</td>\n",
       "      <td>33600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122561</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Piper Companies</td>\n",
       "      <td>Raleigh, NC 27607 (Northwest area)</td>\n",
       "      <td>The Data Scientist will be in charge of data m...</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122570</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Contract Statistician</td>\n",
       "      <td>Piper Companies</td>\n",
       "      <td>Research Triangle Park, NC 27709</td>\n",
       "      <td>Contract Statistician Statistician Description...</td>\n",
       "      <td>128000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122580</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>HPLC Scientist</td>\n",
       "      <td>Piper Companies</td>\n",
       "      <td>Durham, NC 27709</td>\n",
       "      <td>Responsibilities for the HPLC Scientist includ...</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122627</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>ITS Technologies</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>The *Senior Data Scientist*. Ability to collab...</td>\n",
       "      <td>150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122636</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Statistical Programmer</td>\n",
       "      <td>Piper Companies</td>\n",
       "      <td>Morrisville, NC 27560</td>\n",
       "      <td>Creation of macro programs, perform data check...</td>\n",
       "      <td>96000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122650</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Sente Data Science, LLC</td>\n",
       "      <td>Cary, NC</td>\n",
       "      <td>Sente Data Science is seeking a Data Scientist...</td>\n",
       "      <td>95000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122656</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Research/Remediation Analyst</td>\n",
       "      <td>DISYS (Digital Intelligence SYStems Pvt. Ltd.)</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>A large Financial Services Organization in Ral...</td>\n",
       "      <td>35200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122685</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Associate Scientist 3865</td>\n",
       "      <td>Hunter International</td>\n",
       "      <td>Research Triangle Park, NC</td>\n",
       "      <td>Analyzes data and prepares reports, upon reque...</td>\n",
       "      <td>46400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122696</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Bioinformatics Scientist</td>\n",
       "      <td>Hunter International</td>\n",
       "      <td>Research Triangle Park, NC</td>\n",
       "      <td>Phenotypic data analysis. The scientist will w...</td>\n",
       "      <td>54400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122701</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Piper Companies</td>\n",
       "      <td>Raleigh, NC 27617 (Central area)</td>\n",
       "      <td>Piper Enterprise Solutions is seeking Data Ana...</td>\n",
       "      <td>105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122747</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Biologist / Entomologist</td>\n",
       "      <td>Hunter International</td>\n",
       "      <td>Research Triangle Park, NC</td>\n",
       "      <td>Work will be conducted under direct supervisio...</td>\n",
       "      <td>32000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122763</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Soc/Clin Research Specialist</td>\n",
       "      <td>University of North Carolina</td>\n",
       "      <td>Chapel Hill, NC 27517</td>\n",
       "      <td>Radiation oncology is a highly-integrated, mul...</td>\n",
       "      <td>45734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122801</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Hadoop Integration Data Scientist</td>\n",
       "      <td>LifeScale Analytics</td>\n",
       "      <td>Raleigh-Durham, NC</td>\n",
       "      <td>Data Scientist with experience in experimental...</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122802</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Statistician II (Job Code: GR0218)</td>\n",
       "      <td>Seqirus A CSL Company</td>\n",
       "      <td>Holly Springs, NC</td>\n",
       "      <td>See below JOB TITLE: Statistician II (Job Code...</td>\n",
       "      <td>101830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122819</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Senior Data Scientist â Machine Learning</td>\n",
       "      <td>Strivector</td>\n",
       "      <td>Morrisville, NC</td>\n",
       "      <td>Senior Data Scientist â Machine Learning*. Men...</td>\n",
       "      <td>170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122821</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Research Assistant</td>\n",
       "      <td>University of North Carolina</td>\n",
       "      <td>Chapel Hill, NC 27517</td>\n",
       "      <td>Approximately 25% time will be spent coding an...</td>\n",
       "      <td>32603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122837</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Business Services Coordinator</td>\n",
       "      <td>North Carolina State University</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>Coordinate activities and logistics of visitin...</td>\n",
       "      <td>42945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122851</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Director Data Scientist, Product</td>\n",
       "      <td>All-In Analytics</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>Director Data Scientist, Product. Motivate, co...</td>\n",
       "      <td>185000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows Ã 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   City                                              Title  \\\n",
       "22      Washington D.C.  Undergraduate Internship/Co-op Program - Data ...   \n",
       "128     Washington D.C.            Supervisory Operations Research Analyst   \n",
       "242     Washington D.C.                                     Data Scientist   \n",
       "278     Washington D.C.                                  Facilities Intern   \n",
       "317     Washington D.C.  Research Physical Scientist, AST, Atmospheric ...   \n",
       "430     Washington D.C.  Real Estate and Urban Planning Research Analys...   \n",
       "442     Washington D.C.       Statistician - Healthcare or Pharma Industry   \n",
       "671     Washington D.C.                                     Data Scientist   \n",
       "773     Washington D.C.                                     Data Scientist   \n",
       "791     Washington D.C.                Data Scientist - OUSD(I)-HCMO-DCIPS   \n",
       "800     Washington D.C.                                     Apps Developer   \n",
       "866     Washington D.C.                   Payroll Support Associate at EPA   \n",
       "986     Washington D.C.                           IFG Data Scientist Whiz!   \n",
       "992     Washington D.C.                                     Data Scientist   \n",
       "993     Washington D.C.           Staff Fellow (Mathematical Statistician)   \n",
       "1025    Washington D.C.                        Operations Research Analyst   \n",
       "1072    Washington D.C.                   Mathematicians - Entry/Mid-Level   \n",
       "1073    Washington D.C.       Mathematical Statisticians - Entry/Mid-Level   \n",
       "1117    Washington D.C.    2017-07-10 IT Program Manager Earning $$213,000   \n",
       "1119    Washington D.C.                        Research Analyst (Vaccines)   \n",
       "1158    Washington D.C.                        Operations Research Analyst   \n",
       "1219    Washington D.C.                               Senior Data Engineer   \n",
       "1279    Washington D.C.  Interdisciplinary, GS-0101,0180,0801,1550-12/1...   \n",
       "1337    Washington D.C.                             Senior Product Manager   \n",
       "1344    Washington D.C.                              Senior Data Scientist   \n",
       "1399    Washington D.C.  Recent Graduate Survey Statistician, GS-1530-7...   \n",
       "1447    Washington D.C.  Environmental Scientist - Water Resources Mana...   \n",
       "1448    Washington D.C.                         Data Scientist - Mid-Level   \n",
       "1487    Washington D.C.                        Operations Research Analyst   \n",
       "1490    Washington D.C.              Statistical Data Analyst - US Citizen   \n",
       "...                 ...                                                ...   \n",
       "114406             Mesa  Institutional Research Analyst (Open until Fil...   \n",
       "114417             Mesa                                    Account Manager   \n",
       "114420             Mesa                      Web Security Research Analyst   \n",
       "114421             Mesa                  ENVIRONMENTAL OUTREACH SPECIALIST   \n",
       "114422             Mesa                            AIR QUALITY PLANNER 2-3   \n",
       "118436      Kansas City                                   Research Analyst   \n",
       "118441      Kansas City                                   Research Analyst   \n",
       "118452      Kansas City                                   Material Handler   \n",
       "118486      Kansas City                  Production Fabricator (Any Shift)   \n",
       "118498      Kansas City       Inspector, Tool & Precision Gage (Any Shift)   \n",
       "118504      Kansas City        Tool & Precision Gage Inspector (Any Shift)   \n",
       "118516      Kansas City             Electronics Test Inspector (Any Shift)   \n",
       "122561          Raleigh                                     Data Scientist   \n",
       "122570          Raleigh                              Contract Statistician   \n",
       "122580          Raleigh                                     HPLC Scientist   \n",
       "122627          Raleigh                                     Data Scientist   \n",
       "122636          Raleigh                             Statistical Programmer   \n",
       "122650          Raleigh                                     Data Scientist   \n",
       "122656          Raleigh                       Research/Remediation Analyst   \n",
       "122685          Raleigh                           Associate Scientist 3865   \n",
       "122696          Raleigh                           Bioinformatics Scientist   \n",
       "122701          Raleigh                                       Data Analyst   \n",
       "122747          Raleigh                           Biologist / Entomologist   \n",
       "122763          Raleigh                       Soc/Clin Research Specialist   \n",
       "122801          Raleigh                  Hadoop Integration Data Scientist   \n",
       "122802          Raleigh                 Statistician II (Job Code: GR0218)   \n",
       "122819          Raleigh           Senior Data Scientist â Machine Learning   \n",
       "122821          Raleigh                                 Research Assistant   \n",
       "122837          Raleigh                      Business Services Coordinator   \n",
       "122851          Raleigh                   Director Data Scientist, Product   \n",
       "\n",
       "                                                  Company  \\\n",
       "22                            Central Intelligence Agency   \n",
       "128               Department of Health And Human Services   \n",
       "242                        Metropolitan Police Department   \n",
       "278                     Natural Resources Defense Council   \n",
       "317         National Aeronautics and Space Administration   \n",
       "430     The Maryland-National Capital Park and Plannin...   \n",
       "442                         Contingent/Direct Consultants   \n",
       "671                           Central Intelligence Agency   \n",
       "773                                       Piper Companies   \n",
       "791                                        Red Gate Group   \n",
       "800                           Central Intelligence Agency   \n",
       "866                     Oak Ridge Associated Universities   \n",
       "986                       Interface Financial Group (IFG)   \n",
       "992               National Geospatial-Intelligence Agency   \n",
       "993               Department of Health And Human Services   \n",
       "1025                           Department of the Treasury   \n",
       "1072                             National Security Agency   \n",
       "1073                             National Security Agency   \n",
       "1117                                       EMF Industries   \n",
       "1119                           Johnson Service Group Inc.   \n",
       "1158                      Federal Aviation Administration   \n",
       "1219                                      Piper Companies   \n",
       "1279                               Department of Commerce   \n",
       "1337                                             Catalist   \n",
       "1344                                      Piper Companies   \n",
       "1399                               Department of Commerce   \n",
       "1447                                                 WSSC   \n",
       "1448                             National Security Agency   \n",
       "1487                                Department of Defense   \n",
       "1490                                            PeopleTek   \n",
       "...                                                   ...   \n",
       "114406         Maricopa County Community College District   \n",
       "114417                                 The Creative Group   \n",
       "114420                                           SiteLock   \n",
       "114421                                   State of Arizona   \n",
       "114422                                   State of Arizona   \n",
       "118436                           Jackson County, Missouri   \n",
       "118441           Jackson County Department of Corrections   \n",
       "118452                                          Honeywell   \n",
       "118486                                          Honeywell   \n",
       "118498                                          Honeywell   \n",
       "118504                                          Honeywell   \n",
       "118516                                          Honeywell   \n",
       "122561                                    Piper Companies   \n",
       "122570                                    Piper Companies   \n",
       "122580                                    Piper Companies   \n",
       "122627                                   ITS Technologies   \n",
       "122636                                    Piper Companies   \n",
       "122650                            Sente Data Science, LLC   \n",
       "122656     DISYS (Digital Intelligence SYStems Pvt. Ltd.)   \n",
       "122685                               Hunter International   \n",
       "122696                               Hunter International   \n",
       "122701                                    Piper Companies   \n",
       "122747                               Hunter International   \n",
       "122763                       University of North Carolina   \n",
       "122801                                LifeScale Analytics   \n",
       "122802                              Seqirus A CSL Company   \n",
       "122819                                         Strivector   \n",
       "122821                       University of North Carolina   \n",
       "122837                    North Carolina State University   \n",
       "122851                                   All-In Analytics   \n",
       "\n",
       "                                            Location  \\\n",
       "22                                    Washington, DC   \n",
       "128                                Silver Spring, MD   \n",
       "242                                   Washington, DC   \n",
       "278                                   Washington, DC   \n",
       "317                                    Greenbelt, MD   \n",
       "430                          Silver Spring, MD 20902   \n",
       "442                           Gaithersburg, MD 20877   \n",
       "671                                   Washington, DC   \n",
       "773                                 Reston, VA 20190   \n",
       "791                                    Arlington, VA   \n",
       "800                                   Washington, DC   \n",
       "866                                   Washington, DC   \n",
       "986                                     Bethesda, MD   \n",
       "992                                  Springfield, VA   \n",
       "993                                    Rockville, MD   \n",
       "1025                                  Washington, DC   \n",
       "1072                                  Fort Meade, MD   \n",
       "1073                                  Fort Meade, MD   \n",
       "1117                                      McLean, VA   \n",
       "1119                             Rockville, MD 20850   \n",
       "1158                                  Washington, DC   \n",
       "1219                                Reston, VA 20190   \n",
       "1279            Washington, DC 20230 (Downtown area)   \n",
       "1337                                  Washington, DC   \n",
       "1344                                Reston, VA 20190   \n",
       "1399            Washington, DC 20230 (Downtown area)   \n",
       "1447                                Laurel, MD 20707   \n",
       "1448                                  Fort Meade, MD   \n",
       "1487                                   Arlington, VA   \n",
       "1490                                    Bethesda, MD   \n",
       "...                                              ...   \n",
       "114406                                   Phoenix, AZ   \n",
       "114417       Phoenix, AZ 85016 (Camelback East area)   \n",
       "114420                                Scottsdale, AZ   \n",
       "114421                                   Phoenix, AZ   \n",
       "114422                                   Phoenix, AZ   \n",
       "118436         Kansas City, MO 64106 (Downtown area)   \n",
       "118441                               Kansas City, MO   \n",
       "118452  Kansas City, MO 64147 (Richards Gebaur area)   \n",
       "118486                               Kansas City, KS   \n",
       "118498                               Kansas City, KS   \n",
       "118504                               Kansas City, KS   \n",
       "118516  Kansas City, MO 64147 (Richards Gebaur area)   \n",
       "122561            Raleigh, NC 27607 (Northwest area)   \n",
       "122570              Research Triangle Park, NC 27709   \n",
       "122580                              Durham, NC 27709   \n",
       "122627                                   Raleigh, NC   \n",
       "122636                         Morrisville, NC 27560   \n",
       "122650                                      Cary, NC   \n",
       "122656                                   Raleigh, NC   \n",
       "122685                    Research Triangle Park, NC   \n",
       "122696                    Research Triangle Park, NC   \n",
       "122701              Raleigh, NC 27617 (Central area)   \n",
       "122747                    Research Triangle Park, NC   \n",
       "122763                         Chapel Hill, NC 27517   \n",
       "122801                            Raleigh-Durham, NC   \n",
       "122802                             Holly Springs, NC   \n",
       "122819                               Morrisville, NC   \n",
       "122821                         Chapel Hill, NC 27517   \n",
       "122837                                   Raleigh, NC   \n",
       "122851                                   Raleigh, NC   \n",
       "\n",
       "                                              Job Summary   Salary  \n",
       "22      Students serving as Data Scientist interns wor...    36800  \n",
       "128     Develops alternative options to resolve comple...   146834  \n",
       "242     Or data visualization and interaction. The Dat...    86711  \n",
       "278     Maintain data bases, paper and electronic fili...    24000  \n",
       "317     Utilization of satellite data to test existing...   120212  \n",
       "430     Experience with Costar and other real estate d...    79475  \n",
       "442     Experience of Development, program design and ...   150000  \n",
       "671     Data Scientists organize and interpret Big Dat...    91066  \n",
       "773     Responsibilities for the Lead Data Scientist i...   210000  \n",
       "791     Data Scientist (full-time contract). Under thi...   112500  \n",
       "800     Big Data concepts and technologies such as Apa...    90936  \n",
       "866     Performing data entry in various ORD and Agenc...    35200  \n",
       "986     Data Scientists need to analyze financial data...   120000  \n",
       "992     Data Scientist **AMENDED**. Data Management, D...    90941  \n",
       "993     You will use statistical and mathematical meth...   101477  \n",
       "1025    Determining the types of data to be collected,...   109015  \n",
       "1072    These include, but are not limited to cryptogr...    77025  \n",
       "1073    These include, but are not limited to, problem...    77025  \n",
       "1117    Our talented group of Data Scientists, Develop...   213000  \n",
       "1119    Provide effort & cost benchmarking & insights ...    78400  \n",
       "1158    Business Component: Associate Administrator fo...    97825  \n",
       "1219    Collaborate with a team of other data engineer...   195000  \n",
       "1279    Assisting with organizing and analyzing resear...   101477  \n",
       "1337    Conversant understanding of relational data an...    85000  \n",
       "1344    Responsibilities for the Lead Data Scientist i...   210000  \n",
       "1399    Analyze and evaluate data. Assist in data coll...  65700.5  \n",
       "1447    Ability to plan and direct the work of profess...  95396.5  \n",
       "1448    Exploit, fuse and use data and data sources. A...  92498.5  \n",
       "1487    Using statistical analysis techniques in order...   128825  \n",
       "1490    STATISTICAL DATA ANALYST*. ï· Extract insights ...    65000  \n",
       "...                                                   ...      ...  \n",
       "114406  Develops queries on data warehouses using data...    55735  \n",
       "114417  You're fascinated by data analytics:. You may ...    44000  \n",
       "114420  About SiteLock: SiteLock is the global leader ...    52500  \n",
       "114421  Analyze environmental data to determine validi...    55000  \n",
       "114422  Ability to present data and findings in public...    61000  \n",
       "118436  Verifies and analyzes real estate sales, lease...    20800  \n",
       "118441  Verifies and analyzes real estate sales, lease...    20800  \n",
       "118452  Maintains inventory data bases. Completes pape...    25600  \n",
       "118486  Completes paperwork and computer data entries ...    25600  \n",
       "118498  Ability to analyze and interpret data. Must be...    36800  \n",
       "118504  Ability to analyze and interpret data. Must be...    36800  \n",
       "118516  May be required to examine and evaluate test d...    33600  \n",
       "122561  The Data Scientist will be in charge of data m...   120000  \n",
       "122570  Contract Statistician Statistician Description...   128000  \n",
       "122580  Responsibilities for the HPLC Scientist includ...    48000  \n",
       "122627  The *Senior Data Scientist*. Ability to collab...   150000  \n",
       "122636  Creation of macro programs, perform data check...    96000  \n",
       "122650  Sente Data Science is seeking a Data Scientist...    95000  \n",
       "122656  A large Financial Services Organization in Ral...    35200  \n",
       "122685  Analyzes data and prepares reports, upon reque...    46400  \n",
       "122696  Phenotypic data analysis. The scientist will w...    54400  \n",
       "122701  Piper Enterprise Solutions is seeking Data Ana...   105000  \n",
       "122747  Work will be conducted under direct supervisio...    32000  \n",
       "122763  Radiation oncology is a highly-integrated, mul...    45734  \n",
       "122801  Data Scientist with experience in experimental...   140000  \n",
       "122802  See below JOB TITLE: Statistician II (Job Code...   101830  \n",
       "122819  Senior Data Scientist â Machine Learning*. Men...   170000  \n",
       "122821  Approximately 25% time will be spent coding an...    32603  \n",
       "122837  Coordinate activities and logistics of visitin...    42945  \n",
       "122851  Director Data Scientist, Product. Motivate, co...   185000  \n",
       "\n",
       "[441 rows x 6 columns]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df2[df2['Salary'] != 'NaN'] #drop rows with value NaN in Salary Column\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(441, 6)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values \n",
      " \n",
      "City           0\n",
      "Title          0\n",
      "Company        0\n",
      "Location       0\n",
      "Job Summary    0\n",
      "Salary         0\n",
      "dtype: int64 \n",
      "\n",
      "Duplicate Rows \n",
      "0 \n",
      "\n",
      "Dataframe Types \n",
      " \n",
      "City           object\n",
      "Title          object\n",
      "Company        object\n",
      "Location       object\n",
      "Job Summary    object\n",
      "Salary         object\n",
      "dtype: object \n",
      "\n",
      "Dataframe Shape \n",
      "(441, 6) \n",
      "\n",
      "Dataframe Describe \n",
      " \n",
      "            City           Title                Company     Location  \\\n",
      "count        441             441                    441          441   \n",
      "unique        31             369                    215          152   \n",
      "top     New York  Data Scientist  University of Arizona  Chicago, IL   \n",
      "freq          45              30                     19           28   \n",
      "\n",
      "                                              Job Summary    Salary  \n",
      "count                                                 441     441.0  \n",
      "unique                                                409     231.0  \n",
      "top     Salary 130K to 140K We are assisting our Clien...  120000.0  \n",
      "freq                                                    4      11.0   \n",
      "\n",
      "City\n",
      "31\n",
      "Title\n",
      "369\n",
      "Company\n",
      "215\n",
      "Location\n",
      "152\n",
      "Job Summary\n",
      "409\n",
      "Salary\n",
      "231\n"
     ]
    }
   ],
   "source": [
    "eda(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "New York           45\n",
       "Chicago            34\n",
       "Washington D.C.    31\n",
       "Los Angeles        25\n",
       "Atlanta            24\n",
       "Philadelphia       24\n",
       "Austin             23\n",
       "Houston            23\n",
       "Boston             22\n",
       "Baltimore          21\n",
       "Tucson             21\n",
       "Raleigh            18\n",
       "Miami              14\n",
       "San Fransisco      14\n",
       "Phoenix            12\n",
       "Mesa               12\n",
       "San Diego          11\n",
       "Sacramento         11\n",
       "Portland           10\n",
       "Kansas City         7\n",
       "Dallas              7\n",
       "Columbus            6\n",
       "Denver              6\n",
       "Detroit             5\n",
       "Albuquerque         5\n",
       "Fort Worth          3\n",
       "San Antonio         3\n",
       "Jacksonville        1\n",
       "El Paso             1\n",
       "Oklahoma City       1\n",
       "Memphis             1\n",
       "Name: City, dtype: int64"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['City'].value_counts() #confirm counts of salaries per city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "7d4bc860-b214-4f75-9cd0-b234830b1ec2"
   },
   "source": [
    "#### Write a function that takes a salary string and converts it to a number, averaging a salary range if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "a0f701e0-80bd-40ba-9101-4535860c0968"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "#refer to Baur function above that achieves this before the scrapping occurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "43e71edd-210e-42b1-9336-70a931f048af"
   },
   "source": [
    "### Save your results as a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "783fd153-28ac-47ab-bfca-27e7c1de95b4"
   },
   "outputs": [],
   "source": [
    "# Export to csv\n",
    "df2.to_csv('../../Indeedinfo5.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "04563b69-f7b6-466f-9d65-fc62c9ddee6a"
   },
   "source": [
    "## Predicting salaries using Random Forests + Another Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "243e949e-2742-40af-872e-fec475fd306c"
   },
   "source": [
    "#### Load in the the data of scraped salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "focus": false,
    "id": "588f9845-6143-4bcc-bfd1-85d45b79303d",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>City</th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Summary</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Undergraduate Internship/Co-op Program - Data ...</td>\n",
       "      <td>Central Intelligence Agency</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Students serving as Data Scientist interns wor...</td>\n",
       "      <td>36800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Supervisory Operations Research Analyst</td>\n",
       "      <td>Department of Health And Human Services</td>\n",
       "      <td>Silver Spring, MD</td>\n",
       "      <td>Develops alternative options to resolve comple...</td>\n",
       "      <td>146833.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>242</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Metropolitan Police Department</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Or data visualization and interaction. The Dat...</td>\n",
       "      <td>86711.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>278</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Facilities Intern</td>\n",
       "      <td>Natural Resources Defense Council</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Maintain data bases, paper and electronic fili...</td>\n",
       "      <td>24000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>317</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Research Physical Scientist, AST, Atmospheric ...</td>\n",
       "      <td>National Aeronautics and Space Administration</td>\n",
       "      <td>Greenbelt, MD</td>\n",
       "      <td>Utilization of satellite data to test existing...</td>\n",
       "      <td>120212.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             City  \\\n",
       "0          22  Washington D.C.   \n",
       "1         128  Washington D.C.   \n",
       "2         242  Washington D.C.   \n",
       "3         278  Washington D.C.   \n",
       "4         317  Washington D.C.   \n",
       "\n",
       "                                               Title  \\\n",
       "0  Undergraduate Internship/Co-op Program - Data ...   \n",
       "1            Supervisory Operations Research Analyst   \n",
       "2                                     Data Scientist   \n",
       "3                                  Facilities Intern   \n",
       "4  Research Physical Scientist, AST, Atmospheric ...   \n",
       "\n",
       "                                         Company           Location  \\\n",
       "0                    Central Intelligence Agency     Washington, DC   \n",
       "1        Department of Health And Human Services  Silver Spring, MD   \n",
       "2                 Metropolitan Police Department     Washington, DC   \n",
       "3              Natural Resources Defense Council     Washington, DC   \n",
       "4  National Aeronautics and Space Administration      Greenbelt, MD   \n",
       "\n",
       "                                         Job Summary    Salary  \n",
       "0  Students serving as Data Scientist interns wor...   36800.0  \n",
       "1  Develops alternative options to resolve comple...  146833.5  \n",
       "2  Or data visualization and interaction. The Dat...   86711.0  \n",
       "3  Maintain data bases, paper and electronic fili...   24000.0  \n",
       "4  Utilization of satellite data to test existing...  120212.5  "
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import csv\n",
    "data = pd.read_csv('../../Indeedinfo5.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Unnamed: 0', u'City', u'Title', u'Company', u'Location',\n",
       "       u'Job Summary', u'Salary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns #list columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Summary</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Undergraduate Internship/Co-op Program - Data ...</td>\n",
       "      <td>Central Intelligence Agency</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Students serving as Data Scientist interns wor...</td>\n",
       "      <td>36800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Supervisory Operations Research Analyst</td>\n",
       "      <td>Department of Health And Human Services</td>\n",
       "      <td>Silver Spring, MD</td>\n",
       "      <td>Develops alternative options to resolve comple...</td>\n",
       "      <td>146833.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Metropolitan Police Department</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Or data visualization and interaction. The Dat...</td>\n",
       "      <td>86711.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Facilities Intern</td>\n",
       "      <td>Natural Resources Defense Council</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Maintain data bases, paper and electronic fili...</td>\n",
       "      <td>24000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Research Physical Scientist, AST, Atmospheric ...</td>\n",
       "      <td>National Aeronautics and Space Administration</td>\n",
       "      <td>Greenbelt, MD</td>\n",
       "      <td>Utilization of satellite data to test existing...</td>\n",
       "      <td>120212.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              City                                              Title  \\\n",
       "0  Washington D.C.  Undergraduate Internship/Co-op Program - Data ...   \n",
       "1  Washington D.C.            Supervisory Operations Research Analyst   \n",
       "2  Washington D.C.                                     Data Scientist   \n",
       "3  Washington D.C.                                  Facilities Intern   \n",
       "4  Washington D.C.  Research Physical Scientist, AST, Atmospheric ...   \n",
       "\n",
       "                                         Company           Location  \\\n",
       "0                    Central Intelligence Agency     Washington, DC   \n",
       "1        Department of Health And Human Services  Silver Spring, MD   \n",
       "2                 Metropolitan Police Department     Washington, DC   \n",
       "3              Natural Resources Defense Council     Washington, DC   \n",
       "4  National Aeronautics and Space Administration      Greenbelt, MD   \n",
       "\n",
       "                                         Job Summary    Salary  \n",
       "0  Students serving as Data Scientist interns wor...   36800.0  \n",
       "1  Develops alternative options to resolve comple...  146833.5  \n",
       "2  Or data visualization and interaction. The Dat...   86711.0  \n",
       "3  Maintain data bases, paper and electronic fili...   24000.0  \n",
       "4  Utilization of satellite data to test existing...  120212.5  "
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop('Unnamed: 0', axis=1, inplace=True) #remove column Unamed: 0\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "c7631f51-07f2-4c79-a093-3e9bc7849a48"
   },
   "source": [
    "#### We want to predict a binary variable - whether the salary was low or high. Compute the median salary and create a new binary variable that is true when the salary is high (above the median)\n",
    "\n",
    "We could also perform Linear Regression (or any regression) to predict the salary value here. Instead, we are going to convert this into a _binary_ classification problem, by predicting two classes, HIGH vs LOW salary.\n",
    "\n",
    "While performing regression may be better, performing classification may help remove some of the noise of the extreme salaries. We don't _have_ to choose the `median` as the splitting point - we could also split on the 75th percentile or any other reasonable breaking point.\n",
    "\n",
    "In fact, the ideal scenario may be to predict many levels of salaries, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       441.000000\n",
       "mean      81176.054422\n",
       "std       42950.045585\n",
       "min       16000.000000\n",
       "25%       49992.000000\n",
       "50%       73860.000000\n",
       "75%      102498.000000\n",
       "max      300000.000000\n",
       "Name: Salary, dtype: float64"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Salary'].describe() #show descriptive statsitics about salary column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "focus": false,
    "id": "c20d2498-151c-44c3-a453-3a333c79a0ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73860.0"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compute Median Salary\n",
    "median = data['Salary'].median() #set median value as variable median\n",
    "median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Summary</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Undergraduate Internship/Co-op Program - Data ...</td>\n",
       "      <td>Central Intelligence Agency</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Students serving as Data Scientist interns wor...</td>\n",
       "      <td>36800.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Supervisory Operations Research Analyst</td>\n",
       "      <td>Department of Health And Human Services</td>\n",
       "      <td>Silver Spring, MD</td>\n",
       "      <td>Develops alternative options to resolve comple...</td>\n",
       "      <td>146833.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Metropolitan Police Department</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Or data visualization and interaction. The Dat...</td>\n",
       "      <td>86711.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Facilities Intern</td>\n",
       "      <td>Natural Resources Defense Council</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Maintain data bases, paper and electronic fili...</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Research Physical Scientist, AST, Atmospheric ...</td>\n",
       "      <td>National Aeronautics and Space Administration</td>\n",
       "      <td>Greenbelt, MD</td>\n",
       "      <td>Utilization of satellite data to test existing...</td>\n",
       "      <td>120212.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              City                                              Title  \\\n",
       "0  Washington D.C.  Undergraduate Internship/Co-op Program - Data ...   \n",
       "1  Washington D.C.            Supervisory Operations Research Analyst   \n",
       "2  Washington D.C.                                     Data Scientist   \n",
       "3  Washington D.C.                                  Facilities Intern   \n",
       "4  Washington D.C.  Research Physical Scientist, AST, Atmospheric ...   \n",
       "\n",
       "                                         Company           Location  \\\n",
       "0                    Central Intelligence Agency     Washington, DC   \n",
       "1        Department of Health And Human Services  Silver Spring, MD   \n",
       "2                 Metropolitan Police Department     Washington, DC   \n",
       "3              Natural Resources Defense Council     Washington, DC   \n",
       "4  National Aeronautics and Space Administration      Greenbelt, MD   \n",
       "\n",
       "                                         Job Summary    Salary  Binary  \n",
       "0  Students serving as Data Scientist interns wor...   36800.0   False  \n",
       "1  Develops alternative options to resolve comple...  146833.5    True  \n",
       "2  Or data visualization and interaction. The Dat...   86711.0    True  \n",
       "3  Maintain data bases, paper and electronic fili...   24000.0   False  \n",
       "4  Utilization of satellite data to test existing...  120212.5    True  "
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a Binary Variable that is true when salary is above median \n",
    "data['Binary'] = data['Salary'] > median\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    222\n",
       "True     219\n",
       "Name: Binary, dtype: int64"
      ]
     },
     "execution_count": 944,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Binary'].value_counts() #count number of True and Falses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Unicode from Job Summary Column\n",
    "data['Job Summary'] = data['Job Summary'].apply(lambda x: x.decode('unicode_escape').\\\n",
    "                                          encode('ascii', 'ignore').\\\n",
    "                                          strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Remove Unicode from Location Column\n",
    "data['Location'] = data['Location'].apply(lambda x: x.decode('unicode_escape').\\\n",
    "                                          encode('ascii', 'ignore').\\\n",
    "                                          strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Remove Unicode From Company Column\n",
    "data['Company'] = data['Company'].apply(lambda x: x.decode('unicode_escape').\\\n",
    "                                          encode('ascii', 'ignore').\\\n",
    "                                          strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Remove Unicode from Title Column\n",
    "data['Title'] = data['Title'].apply(lambda x: x.decode('unicode_escape').\\\n",
    "                                          encode('ascii', 'ignore').\\\n",
    "                                          strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Remove Unicode from City\n",
    "data['City'] = data['City'].apply(lambda x: x.decode('unicode_escape').\\\n",
    "                                          encode('ascii', 'ignore').\\\n",
    "                                          strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a7afb2c0-d41e-4779-8216-91cd8dd4473f"
   },
   "source": [
    "#### Thought experiment: What is the baseline accuracy for this model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "87a17d3d-b7f4-4747-9f75-f9af1d18a174"
   },
   "source": [
    "The baseline accuracy for this model is 50% becuase if we randomly selected a value from Binary(with only values True or False) it would be 50/50 random true false selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "4fb29de2-5b98-474c-a4ad-5170b72b9aea"
   },
   "source": [
    "#### Create a Random Forest model to predict High/Low salary using Sklearn. Start by ONLY using the location as a feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "metadata": {
    "focus": false,
    "id": "ddbc6159-6854-4ca7-857f-bfecdaf6d9c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132,) (132,)\n",
      "(309,) (309,)\n"
     ]
    }
   ],
   "source": [
    "## YOUR CODE HERE\n",
    "X = data['City'] #Feature #Using City over Location as they are both the general area Location of the job\n",
    "y = data['Binary'] #Aim of Predicting Binary T|F based on City \n",
    "#train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.3, random_state=3)\n",
    "print X_train.shape, y_train.shape\n",
    "print X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, test = data[data['Binary']==True], data[data['Binary']==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Number of observations in the training data:', len(train))\n",
    "#print('Number of observations in the test data:',len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#With data['Binary'] containing a string it needs to be converted to a digit\n",
    "#Since the column only has true or false it has been coded to 0 and 1 respectively\n",
    "#y2 = pd.factorize(y_train)\n",
    "#y2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = pd.factorize(y) #turn y into 0 and 1s\n",
    "X = pd.get_dummies(data['City']) #create dummy variables for City variable contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Albuquerque</th>\n",
       "      <th>Atlanta</th>\n",
       "      <th>Austin</th>\n",
       "      <th>Baltimore</th>\n",
       "      <th>Boston</th>\n",
       "      <th>Chicago</th>\n",
       "      <th>Columbus</th>\n",
       "      <th>Dallas</th>\n",
       "      <th>Denver</th>\n",
       "      <th>Detroit</th>\n",
       "      <th>...</th>\n",
       "      <th>Philadelphia</th>\n",
       "      <th>Phoenix</th>\n",
       "      <th>Portland</th>\n",
       "      <th>Raleigh</th>\n",
       "      <th>Sacramento</th>\n",
       "      <th>San Antonio</th>\n",
       "      <th>San Diego</th>\n",
       "      <th>San Fransisco</th>\n",
       "      <th>Tucson</th>\n",
       "      <th>Washington D.C.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows Ã 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Albuquerque  Atlanta  Austin  Baltimore  Boston  Chicago  Columbus  \\\n",
       "0              0        0       0          0       0        0         0   \n",
       "1              0        0       0          0       0        0         0   \n",
       "2              0        0       0          0       0        0         0   \n",
       "3              0        0       0          0       0        0         0   \n",
       "4              0        0       0          0       0        0         0   \n",
       "5              0        0       0          0       0        0         0   \n",
       "6              0        0       0          0       0        0         0   \n",
       "7              0        0       0          0       0        0         0   \n",
       "8              0        0       0          0       0        0         0   \n",
       "9              0        0       0          0       0        0         0   \n",
       "10             0        0       0          0       0        0         0   \n",
       "11             0        0       0          0       0        0         0   \n",
       "12             0        0       0          0       0        0         0   \n",
       "13             0        0       0          0       0        0         0   \n",
       "14             0        0       0          0       0        0         0   \n",
       "15             0        0       0          0       0        0         0   \n",
       "16             0        0       0          0       0        0         0   \n",
       "17             0        0       0          0       0        0         0   \n",
       "18             0        0       0          0       0        0         0   \n",
       "19             0        0       0          0       0        0         0   \n",
       "20             0        0       0          0       0        0         0   \n",
       "21             0        0       0          0       0        0         0   \n",
       "22             0        0       0          0       0        0         0   \n",
       "23             0        0       0          0       0        0         0   \n",
       "24             0        0       0          0       0        0         0   \n",
       "25             0        0       0          0       0        0         0   \n",
       "26             0        0       0          0       0        0         0   \n",
       "27             0        0       0          0       0        0         0   \n",
       "28             0        0       0          0       0        0         0   \n",
       "29             0        0       0          0       0        0         0   \n",
       "..           ...      ...     ...        ...     ...      ...       ...   \n",
       "411            0        0       0          0       0        0         0   \n",
       "412            0        0       0          0       0        0         0   \n",
       "413            0        0       0          0       0        0         0   \n",
       "414            0        0       0          0       0        0         0   \n",
       "415            0        0       0          0       0        0         0   \n",
       "416            0        0       0          0       0        0         0   \n",
       "417            0        0       0          0       0        0         0   \n",
       "418            0        0       0          0       0        0         0   \n",
       "419            0        0       0          0       0        0         0   \n",
       "420            0        0       0          0       0        0         0   \n",
       "421            0        0       0          0       0        0         0   \n",
       "422            0        0       0          0       0        0         0   \n",
       "423            0        0       0          0       0        0         0   \n",
       "424            0        0       0          0       0        0         0   \n",
       "425            0        0       0          0       0        0         0   \n",
       "426            0        0       0          0       0        0         0   \n",
       "427            0        0       0          0       0        0         0   \n",
       "428            0        0       0          0       0        0         0   \n",
       "429            0        0       0          0       0        0         0   \n",
       "430            0        0       0          0       0        0         0   \n",
       "431            0        0       0          0       0        0         0   \n",
       "432            0        0       0          0       0        0         0   \n",
       "433            0        0       0          0       0        0         0   \n",
       "434            0        0       0          0       0        0         0   \n",
       "435            0        0       0          0       0        0         0   \n",
       "436            0        0       0          0       0        0         0   \n",
       "437            0        0       0          0       0        0         0   \n",
       "438            0        0       0          0       0        0         0   \n",
       "439            0        0       0          0       0        0         0   \n",
       "440            0        0       0          0       0        0         0   \n",
       "\n",
       "     Dallas  Denver  Detroit       ...         Philadelphia  Phoenix  \\\n",
       "0         0       0        0       ...                    0        0   \n",
       "1         0       0        0       ...                    0        0   \n",
       "2         0       0        0       ...                    0        0   \n",
       "3         0       0        0       ...                    0        0   \n",
       "4         0       0        0       ...                    0        0   \n",
       "5         0       0        0       ...                    0        0   \n",
       "6         0       0        0       ...                    0        0   \n",
       "7         0       0        0       ...                    0        0   \n",
       "8         0       0        0       ...                    0        0   \n",
       "9         0       0        0       ...                    0        0   \n",
       "10        0       0        0       ...                    0        0   \n",
       "11        0       0        0       ...                    0        0   \n",
       "12        0       0        0       ...                    0        0   \n",
       "13        0       0        0       ...                    0        0   \n",
       "14        0       0        0       ...                    0        0   \n",
       "15        0       0        0       ...                    0        0   \n",
       "16        0       0        0       ...                    0        0   \n",
       "17        0       0        0       ...                    0        0   \n",
       "18        0       0        0       ...                    0        0   \n",
       "19        0       0        0       ...                    0        0   \n",
       "20        0       0        0       ...                    0        0   \n",
       "21        0       0        0       ...                    0        0   \n",
       "22        0       0        0       ...                    0        0   \n",
       "23        0       0        0       ...                    0        0   \n",
       "24        0       0        0       ...                    0        0   \n",
       "25        0       0        0       ...                    0        0   \n",
       "26        0       0        0       ...                    0        0   \n",
       "27        0       0        0       ...                    0        0   \n",
       "28        0       0        0       ...                    0        0   \n",
       "29        0       0        0       ...                    0        0   \n",
       "..      ...     ...      ...       ...                  ...      ...   \n",
       "411       0       0        0       ...                    0        0   \n",
       "412       0       0        0       ...                    0        0   \n",
       "413       0       0        0       ...                    0        0   \n",
       "414       0       0        0       ...                    0        0   \n",
       "415       0       0        0       ...                    0        0   \n",
       "416       0       0        0       ...                    0        0   \n",
       "417       0       0        0       ...                    0        0   \n",
       "418       0       0        0       ...                    0        0   \n",
       "419       0       0        0       ...                    0        0   \n",
       "420       0       0        0       ...                    0        0   \n",
       "421       0       0        0       ...                    0        0   \n",
       "422       0       0        0       ...                    0        0   \n",
       "423       0       0        0       ...                    0        0   \n",
       "424       0       0        0       ...                    0        0   \n",
       "425       0       0        0       ...                    0        0   \n",
       "426       0       0        0       ...                    0        0   \n",
       "427       0       0        0       ...                    0        0   \n",
       "428       0       0        0       ...                    0        0   \n",
       "429       0       0        0       ...                    0        0   \n",
       "430       0       0        0       ...                    0        0   \n",
       "431       0       0        0       ...                    0        0   \n",
       "432       0       0        0       ...                    0        0   \n",
       "433       0       0        0       ...                    0        0   \n",
       "434       0       0        0       ...                    0        0   \n",
       "435       0       0        0       ...                    0        0   \n",
       "436       0       0        0       ...                    0        0   \n",
       "437       0       0        0       ...                    0        0   \n",
       "438       0       0        0       ...                    0        0   \n",
       "439       0       0        0       ...                    0        0   \n",
       "440       0       0        0       ...                    0        0   \n",
       "\n",
       "     Portland  Raleigh  Sacramento  San Antonio  San Diego  San Fransisco  \\\n",
       "0           0        0           0            0          0              0   \n",
       "1           0        0           0            0          0              0   \n",
       "2           0        0           0            0          0              0   \n",
       "3           0        0           0            0          0              0   \n",
       "4           0        0           0            0          0              0   \n",
       "5           0        0           0            0          0              0   \n",
       "6           0        0           0            0          0              0   \n",
       "7           0        0           0            0          0              0   \n",
       "8           0        0           0            0          0              0   \n",
       "9           0        0           0            0          0              0   \n",
       "10          0        0           0            0          0              0   \n",
       "11          0        0           0            0          0              0   \n",
       "12          0        0           0            0          0              0   \n",
       "13          0        0           0            0          0              0   \n",
       "14          0        0           0            0          0              0   \n",
       "15          0        0           0            0          0              0   \n",
       "16          0        0           0            0          0              0   \n",
       "17          0        0           0            0          0              0   \n",
       "18          0        0           0            0          0              0   \n",
       "19          0        0           0            0          0              0   \n",
       "20          0        0           0            0          0              0   \n",
       "21          0        0           0            0          0              0   \n",
       "22          0        0           0            0          0              0   \n",
       "23          0        0           0            0          0              0   \n",
       "24          0        0           0            0          0              0   \n",
       "25          0        0           0            0          0              0   \n",
       "26          0        0           0            0          0              0   \n",
       "27          0        0           0            0          0              0   \n",
       "28          0        0           0            0          0              0   \n",
       "29          0        0           0            0          0              0   \n",
       "..        ...      ...         ...          ...        ...            ...   \n",
       "411         0        0           0            0          0              0   \n",
       "412         0        0           0            0          0              0   \n",
       "413         0        0           0            0          0              0   \n",
       "414         0        0           0            0          0              0   \n",
       "415         0        0           0            0          0              0   \n",
       "416         0        0           0            0          0              0   \n",
       "417         0        0           0            0          0              0   \n",
       "418         0        0           0            0          0              0   \n",
       "419         0        0           0            0          0              0   \n",
       "420         0        0           0            0          0              0   \n",
       "421         0        0           0            0          0              0   \n",
       "422         0        0           0            0          0              0   \n",
       "423         0        1           0            0          0              0   \n",
       "424         0        1           0            0          0              0   \n",
       "425         0        1           0            0          0              0   \n",
       "426         0        1           0            0          0              0   \n",
       "427         0        1           0            0          0              0   \n",
       "428         0        1           0            0          0              0   \n",
       "429         0        1           0            0          0              0   \n",
       "430         0        1           0            0          0              0   \n",
       "431         0        1           0            0          0              0   \n",
       "432         0        1           0            0          0              0   \n",
       "433         0        1           0            0          0              0   \n",
       "434         0        1           0            0          0              0   \n",
       "435         0        1           0            0          0              0   \n",
       "436         0        1           0            0          0              0   \n",
       "437         0        1           0            0          0              0   \n",
       "438         0        1           0            0          0              0   \n",
       "439         0        1           0            0          0              0   \n",
       "440         0        1           0            0          0              0   \n",
       "\n",
       "     Tucson  Washington D.C.  \n",
       "0         0                1  \n",
       "1         0                1  \n",
       "2         0                1  \n",
       "3         0                1  \n",
       "4         0                1  \n",
       "5         0                1  \n",
       "6         0                1  \n",
       "7         0                1  \n",
       "8         0                1  \n",
       "9         0                1  \n",
       "10        0                1  \n",
       "11        0                1  \n",
       "12        0                1  \n",
       "13        0                1  \n",
       "14        0                1  \n",
       "15        0                1  \n",
       "16        0                1  \n",
       "17        0                1  \n",
       "18        0                1  \n",
       "19        0                1  \n",
       "20        0                1  \n",
       "21        0                1  \n",
       "22        0                1  \n",
       "23        0                1  \n",
       "24        0                1  \n",
       "25        0                1  \n",
       "26        0                1  \n",
       "27        0                1  \n",
       "28        0                1  \n",
       "29        0                1  \n",
       "..      ...              ...  \n",
       "411       0                0  \n",
       "412       0                0  \n",
       "413       0                0  \n",
       "414       0                0  \n",
       "415       0                0  \n",
       "416       0                0  \n",
       "417       0                0  \n",
       "418       0                0  \n",
       "419       0                0  \n",
       "420       0                0  \n",
       "421       0                0  \n",
       "422       0                0  \n",
       "423       0                0  \n",
       "424       0                0  \n",
       "425       0                0  \n",
       "426       0                0  \n",
       "427       0                0  \n",
       "428       0                0  \n",
       "429       0                0  \n",
       "430       0                0  \n",
       "431       0                0  \n",
       "432       0                0  \n",
       "433       0                0  \n",
       "434       0                0  \n",
       "435       0                0  \n",
       "436       0                0  \n",
       "437       0                0  \n",
       "438       0                0  \n",
       "439       0                0  \n",
       "440       0                0  \n",
       "\n",
       "[441 rows x 31 columns]"
      ]
     },
     "execution_count": 953,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dummie variables for City\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, ..., 0, 1]), Index([False, True], dtype='object'))"
      ]
     },
     "execution_count": 954,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pd.Series(data['City']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Tree Score:\t0.608 Â± 0.076\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#Create a random forest classifier.\n",
    "#clf = RandomForestClassifier(n_jobs=-1)\n",
    "#Train Classifier to take training features,location, and how it realates to training y, binary\n",
    "#clf.fit(X, y2)\n",
    "cv = StratifiedKFold(y, n_folds=10, shuffle=True, random_state=35)\n",
    "dt = RandomForestClassifier(class_weight='balanced')\n",
    "s = cross_val_score(dt, X, y, cv=cv, n_jobs=-1)\n",
    "print \"{} Score:\\t{:0.3} Â± {:0.3}\".format(\"Random Forest Tree\", s.mean().round(3), s.std().round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 963,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=5, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 963,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apply the classifier we trained to the  data\n",
    "rf = RandomForestClassifier(class_weight='balanced', n_jobs=-1, max_depth=5)\n",
    "rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tucson</th>\n",
       "      <td>0.192040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mesa</th>\n",
       "      <td>0.138089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Washington D.C.</th>\n",
       "      <td>0.129968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Philadelphia</th>\n",
       "      <td>0.102299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chicago</th>\n",
       "      <td>0.088016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 City Importance\n",
       "Tucson                  0.192040\n",
       "Mesa                    0.138089\n",
       "Washington D.C.         0.129968\n",
       "Philadelphia            0.102299\n",
       "Chicago                 0.088016"
      ]
     },
     "execution_count": 965,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate importance of top five cities to a salary being above average\n",
    "importance = pd.DataFrame(zip(rf.feature_importances_,),\n",
    "                           index=X.columns,\n",
    "                           columns=['City Importance']).sort_values('City Importance',\n",
    "                                                                   ascending=False)\n",
    "importance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1, 31)"
      ]
     },
     "execution_count": 970,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(rf.feature_importances_ == np.mean([tree.feature_importances_ for tree in rf.estimators_], axis=0))\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "# calculate the standard deviation of feature importances by looping over the trees in the random forest\n",
    "# \n",
    "\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "feature_names = X.columns\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), feature_names[indices], rotation=90)\n",
    "plt.xlim([-1, X.shape[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "0ef04f32-419c-4bf2-baf7-48201f03df89"
   },
   "source": [
    "#### Create a few new variables in your dataframe to represent interesting features of a job title.\n",
    "- For example, create a feature that represents whether 'Senior' is in the title or whether 'Manager' is in the title. \n",
    "- Then build a new Random Forest with these features. Do they add any value?\n",
    "- After creating these variables, use count-vectorizer to create features based on the words in the job titles.\n",
    "- Build a new random forest model with location and these new features included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #function gathered from Nathan Mitchell blog to find words in title and turn into df\n",
    "# def count_results_by_keywords(query_string = None):\n",
    "\n",
    "#     # Ends the function if given invalid inputs\n",
    "#     if query_string == None:\n",
    "#         return (\"No keyword entered.\")\n",
    "\n",
    "#     # Format the keyword string in to URL query\n",
    "#     query = \"%20OR%20\".join(query_string.split(\", \"))\n",
    "#     query = query.replace(' ', '+')\n",
    "\n",
    "#     # Perform the search\n",
    "#     job_ids = count_results(\"%28{}%29\".format(query))\n",
    "\n",
    "#     # Rename job_ids's columns\n",
    "#     job_ids.columns = ['Title', 'job link', '{}'.format(\" OR \".join(query_string.split(\", \")))]\n",
    "\n",
    "#     return (job_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Summary</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Binary</th>\n",
       "      <th>Senior Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Undergraduate Internship/Co-op Program - Data ...</td>\n",
       "      <td>Central Intelligence Agency</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Students serving as Data Scientist interns wor...</td>\n",
       "      <td>36800.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Supervisory Operations Research Analyst</td>\n",
       "      <td>Department of Health And Human Services</td>\n",
       "      <td>Silver Spring, MD</td>\n",
       "      <td>Develops alternative options to resolve comple...</td>\n",
       "      <td>146833.5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Metropolitan Police Department</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Or data visualization and interaction. The Dat...</td>\n",
       "      <td>86711.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Facilities Intern</td>\n",
       "      <td>Natural Resources Defense Council</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Maintain data bases, paper and electronic fili...</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Research Physical Scientist, AST, Atmospheric ...</td>\n",
       "      <td>National Aeronautics and Space Administration</td>\n",
       "      <td>Greenbelt, MD</td>\n",
       "      <td>Utilization of satellite data to test existing...</td>\n",
       "      <td>120212.5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Real Estate and Urban Planning Research Analys...</td>\n",
       "      <td>The Maryland-National Capital Park and Plannin...</td>\n",
       "      <td>Silver Spring, MD 20902</td>\n",
       "      <td>Experience with Costar and other real estate d...</td>\n",
       "      <td>79475.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Statistician - Healthcare or Pharma Industry</td>\n",
       "      <td>Contingent/Direct Consultants</td>\n",
       "      <td>Gaithersburg, MD 20877</td>\n",
       "      <td>Experience of Development, program design and ...</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Central Intelligence Agency</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Data Scientists organize and interpret Big Dat...</td>\n",
       "      <td>91066.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Piper Companies</td>\n",
       "      <td>Reston, VA 20190</td>\n",
       "      <td>Responsibilities for the Lead Data Scientist i...</td>\n",
       "      <td>210000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist - OUSD(I)-HCMO-DCIPS</td>\n",
       "      <td>Red Gate Group</td>\n",
       "      <td>Arlington, VA</td>\n",
       "      <td>Data Scientist (full-time contract). Under thi...</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Apps Developer</td>\n",
       "      <td>Central Intelligence Agency</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Big Data concepts and technologies such as Apa...</td>\n",
       "      <td>90936.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Payroll Support Associate at EPA</td>\n",
       "      <td>Oak Ridge Associated Universities</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Performing data entry in various ORD and Agenc...</td>\n",
       "      <td>35200.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>IFG Data Scientist Whiz!</td>\n",
       "      <td>Interface Financial Group (IFG)</td>\n",
       "      <td>Bethesda, MD</td>\n",
       "      <td>Data Scientists need to analyze financial data...</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>National Geospatial-Intelligence Agency</td>\n",
       "      <td>Springfield, VA</td>\n",
       "      <td>Data Scientist **AMENDED**. Data Management, D...</td>\n",
       "      <td>90941.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Staff Fellow (Mathematical Statistician)</td>\n",
       "      <td>Department of Health And Human Services</td>\n",
       "      <td>Rockville, MD</td>\n",
       "      <td>You will use statistical and mathematical meth...</td>\n",
       "      <td>101477.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Operations Research Analyst</td>\n",
       "      <td>Department of the Treasury</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Determining the types of data to be collected,...</td>\n",
       "      <td>109015.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Mathematicians - Entry/Mid-Level</td>\n",
       "      <td>National Security Agency</td>\n",
       "      <td>Fort Meade, MD</td>\n",
       "      <td>These include, but are not limited to cryptogr...</td>\n",
       "      <td>77025.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Mathematical Statisticians - Entry/Mid-Level</td>\n",
       "      <td>National Security Agency</td>\n",
       "      <td>Fort Meade, MD</td>\n",
       "      <td>These include, but are not limited to, problem...</td>\n",
       "      <td>77025.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>2017-07-10 IT Program Manager Earning $$213,000</td>\n",
       "      <td>EMF Industries</td>\n",
       "      <td>McLean, VA</td>\n",
       "      <td>Our talented group of Data Scientists, Develop...</td>\n",
       "      <td>213000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Research Analyst (Vaccines)</td>\n",
       "      <td>Johnson Service Group Inc.</td>\n",
       "      <td>Rockville, MD 20850</td>\n",
       "      <td>Provide effort &amp; cost benchmarking &amp; insights ...</td>\n",
       "      <td>78400.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Operations Research Analyst</td>\n",
       "      <td>Federal Aviation Administration</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Business Component: Associate Administrator fo...</td>\n",
       "      <td>97825.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Piper Companies</td>\n",
       "      <td>Reston, VA 20190</td>\n",
       "      <td>Collaborate with a team of other data engineer...</td>\n",
       "      <td>195000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Interdisciplinary, GS-0101,0180,0801,1550-12/1...</td>\n",
       "      <td>Department of Commerce</td>\n",
       "      <td>Washington, DC 20230 (Downtown area)</td>\n",
       "      <td>Assisting with organizing and analyzing resear...</td>\n",
       "      <td>101477.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Senior Product Manager</td>\n",
       "      <td>Catalist</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Conversant understanding of relational data an...</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Piper Companies</td>\n",
       "      <td>Reston, VA 20190</td>\n",
       "      <td>Responsibilities for the Lead Data Scientist i...</td>\n",
       "      <td>210000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Recent Graduate Survey Statistician, GS-1530-7...</td>\n",
       "      <td>Department of Commerce</td>\n",
       "      <td>Washington, DC 20230 (Downtown area)</td>\n",
       "      <td>Analyze and evaluate data. Assist in data coll...</td>\n",
       "      <td>65700.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Environmental Scientist - Water Resources Mana...</td>\n",
       "      <td>WSSC</td>\n",
       "      <td>Laurel, MD 20707</td>\n",
       "      <td>Ability to plan and direct the work of profess...</td>\n",
       "      <td>95396.5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist - Mid-Level</td>\n",
       "      <td>National Security Agency</td>\n",
       "      <td>Fort Meade, MD</td>\n",
       "      <td>Exploit, fuse and use data and data sources. A...</td>\n",
       "      <td>92498.5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Operations Research Analyst</td>\n",
       "      <td>Department of Defense</td>\n",
       "      <td>Arlington, VA</td>\n",
       "      <td>Using statistical analysis techniques in order...</td>\n",
       "      <td>128825.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Statistical Data Analyst - US Citizen</td>\n",
       "      <td>PeopleTek</td>\n",
       "      <td>Bethesda, MD</td>\n",
       "      <td>STATISTICAL DATA ANALYST*. ï· Extract insights ...</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>Mesa</td>\n",
       "      <td>Institutional Research Analyst (Open until Fil...</td>\n",
       "      <td>Maricopa County Community College District</td>\n",
       "      <td>Phoenix, AZ</td>\n",
       "      <td>Develops queries on data warehouses using data...</td>\n",
       "      <td>55735.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>Mesa</td>\n",
       "      <td>Account Manager</td>\n",
       "      <td>The Creative Group</td>\n",
       "      <td>Phoenix, AZ 85016 (Camelback East area)</td>\n",
       "      <td>You're fascinated by data analytics:. You may ...</td>\n",
       "      <td>44000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>Mesa</td>\n",
       "      <td>Web Security Research Analyst</td>\n",
       "      <td>SiteLock</td>\n",
       "      <td>Scottsdale, AZ</td>\n",
       "      <td>About SiteLock: SiteLock is the global leader ...</td>\n",
       "      <td>52500.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>Mesa</td>\n",
       "      <td>ENVIRONMENTAL OUTREACH SPECIALIST</td>\n",
       "      <td>State of Arizona</td>\n",
       "      <td>Phoenix, AZ</td>\n",
       "      <td>Analyze environmental data to determine validi...</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>Mesa</td>\n",
       "      <td>AIR QUALITY PLANNER 2-3</td>\n",
       "      <td>State of Arizona</td>\n",
       "      <td>Phoenix, AZ</td>\n",
       "      <td>Ability to present data and findings in public...</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>Kansas City</td>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>Jackson County, Missouri</td>\n",
       "      <td>Kansas City, MO 64106 (Downtown area)</td>\n",
       "      <td>Verifies and analyzes real estate sales, lease...</td>\n",
       "      <td>20800.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>Kansas City</td>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>Jackson County Department of Corrections</td>\n",
       "      <td>Kansas City, MO</td>\n",
       "      <td>Verifies and analyzes real estate sales, lease...</td>\n",
       "      <td>20800.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>Kansas City</td>\n",
       "      <td>Material Handler</td>\n",
       "      <td>Honeywell</td>\n",
       "      <td>Kansas City, MO 64147 (Richards Gebaur area)</td>\n",
       "      <td>Maintains inventory data bases. Completes pape...</td>\n",
       "      <td>25600.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>Kansas City</td>\n",
       "      <td>Production Fabricator (Any Shift)</td>\n",
       "      <td>Honeywell</td>\n",
       "      <td>Kansas City, KS</td>\n",
       "      <td>Completes paperwork and computer data entries ...</td>\n",
       "      <td>25600.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>Kansas City</td>\n",
       "      <td>Inspector, Tool &amp; Precision Gage (Any Shift)</td>\n",
       "      <td>Honeywell</td>\n",
       "      <td>Kansas City, KS</td>\n",
       "      <td>Ability to analyze and interpret data. Must be...</td>\n",
       "      <td>36800.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>Kansas City</td>\n",
       "      <td>Tool &amp; Precision Gage Inspector (Any Shift)</td>\n",
       "      <td>Honeywell</td>\n",
       "      <td>Kansas City, KS</td>\n",
       "      <td>Ability to analyze and interpret data. Must be...</td>\n",
       "      <td>36800.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>Kansas City</td>\n",
       "      <td>Electronics Test Inspector (Any Shift)</td>\n",
       "      <td>Honeywell</td>\n",
       "      <td>Kansas City, MO 64147 (Richards Gebaur area)</td>\n",
       "      <td>May be required to examine and evaluate test d...</td>\n",
       "      <td>33600.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Piper Companies</td>\n",
       "      <td>Raleigh, NC 27607 (Northwest area)</td>\n",
       "      <td>The Data Scientist will be in charge of data m...</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Contract Statistician</td>\n",
       "      <td>Piper Companies</td>\n",
       "      <td>Research Triangle Park, NC 27709</td>\n",
       "      <td>Contract Statistician Statistician Description...</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>HPLC Scientist</td>\n",
       "      <td>Piper Companies</td>\n",
       "      <td>Durham, NC 27709</td>\n",
       "      <td>Responsibilities for the HPLC Scientist includ...</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>ITS Technologies</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>The *Senior Data Scientist*. Ability to collab...</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Statistical Programmer</td>\n",
       "      <td>Piper Companies</td>\n",
       "      <td>Morrisville, NC 27560</td>\n",
       "      <td>Creation of macro programs, perform data check...</td>\n",
       "      <td>96000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Sente Data Science, LLC</td>\n",
       "      <td>Cary, NC</td>\n",
       "      <td>Sente Data Science is seeking a Data Scientist...</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Research/Remediation Analyst</td>\n",
       "      <td>DISYS (Digital Intelligence SYStems Pvt. Ltd.)</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>A large Financial Services Organization in Ral...</td>\n",
       "      <td>35200.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Associate Scientist 3865</td>\n",
       "      <td>Hunter International</td>\n",
       "      <td>Research Triangle Park, NC</td>\n",
       "      <td>Analyzes data and prepares reports, upon reque...</td>\n",
       "      <td>46400.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Bioinformatics Scientist</td>\n",
       "      <td>Hunter International</td>\n",
       "      <td>Research Triangle Park, NC</td>\n",
       "      <td>Phenotypic data analysis. The scientist will w...</td>\n",
       "      <td>54400.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Piper Companies</td>\n",
       "      <td>Raleigh, NC 27617 (Central area)</td>\n",
       "      <td>Piper Enterprise Solutions is seeking Data Ana...</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Biologist / Entomologist</td>\n",
       "      <td>Hunter International</td>\n",
       "      <td>Research Triangle Park, NC</td>\n",
       "      <td>Work will be conducted under direct supervisio...</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Soc/Clin Research Specialist</td>\n",
       "      <td>University of North Carolina</td>\n",
       "      <td>Chapel Hill, NC 27517</td>\n",
       "      <td>Radiation oncology is a highly-integrated, mul...</td>\n",
       "      <td>45734.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Hadoop Integration Data Scientist</td>\n",
       "      <td>LifeScale Analytics</td>\n",
       "      <td>Raleigh-Durham, NC</td>\n",
       "      <td>Data Scientist with experience in experimental...</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Statistician II (Job Code: GR0218)</td>\n",
       "      <td>Seqirus A CSL Company</td>\n",
       "      <td>Holly Springs, NC</td>\n",
       "      <td>See below JOB TITLE: Statistician II (Job Code...</td>\n",
       "      <td>101830.5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Senior Data Scientist â Machine Learning</td>\n",
       "      <td>Strivector</td>\n",
       "      <td>Morrisville, NC</td>\n",
       "      <td>Senior Data Scientist â Machine Learning*. Men...</td>\n",
       "      <td>170000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Research Assistant</td>\n",
       "      <td>University of North Carolina</td>\n",
       "      <td>Chapel Hill, NC 27517</td>\n",
       "      <td>Approximately 25% time will be spent coding an...</td>\n",
       "      <td>32603.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Business Services Coordinator</td>\n",
       "      <td>North Carolina State University</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>Coordinate activities and logistics of visitin...</td>\n",
       "      <td>42945.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Director Data Scientist, Product</td>\n",
       "      <td>All-In Analytics</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>Director Data Scientist, Product. Motivate, co...</td>\n",
       "      <td>185000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows Ã 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                City                                              Title  \\\n",
       "0    Washington D.C.  Undergraduate Internship/Co-op Program - Data ...   \n",
       "1    Washington D.C.            Supervisory Operations Research Analyst   \n",
       "2    Washington D.C.                                     Data Scientist   \n",
       "3    Washington D.C.                                  Facilities Intern   \n",
       "4    Washington D.C.  Research Physical Scientist, AST, Atmospheric ...   \n",
       "5    Washington D.C.  Real Estate and Urban Planning Research Analys...   \n",
       "6    Washington D.C.       Statistician - Healthcare or Pharma Industry   \n",
       "7    Washington D.C.                                     Data Scientist   \n",
       "8    Washington D.C.                                     Data Scientist   \n",
       "9    Washington D.C.                Data Scientist - OUSD(I)-HCMO-DCIPS   \n",
       "10   Washington D.C.                                     Apps Developer   \n",
       "11   Washington D.C.                   Payroll Support Associate at EPA   \n",
       "12   Washington D.C.                           IFG Data Scientist Whiz!   \n",
       "13   Washington D.C.                                     Data Scientist   \n",
       "14   Washington D.C.           Staff Fellow (Mathematical Statistician)   \n",
       "15   Washington D.C.                        Operations Research Analyst   \n",
       "16   Washington D.C.                   Mathematicians - Entry/Mid-Level   \n",
       "17   Washington D.C.       Mathematical Statisticians - Entry/Mid-Level   \n",
       "18   Washington D.C.    2017-07-10 IT Program Manager Earning $$213,000   \n",
       "19   Washington D.C.                        Research Analyst (Vaccines)   \n",
       "20   Washington D.C.                        Operations Research Analyst   \n",
       "21   Washington D.C.                               Senior Data Engineer   \n",
       "22   Washington D.C.  Interdisciplinary, GS-0101,0180,0801,1550-12/1...   \n",
       "23   Washington D.C.                             Senior Product Manager   \n",
       "24   Washington D.C.                              Senior Data Scientist   \n",
       "25   Washington D.C.  Recent Graduate Survey Statistician, GS-1530-7...   \n",
       "26   Washington D.C.  Environmental Scientist - Water Resources Mana...   \n",
       "27   Washington D.C.                         Data Scientist - Mid-Level   \n",
       "28   Washington D.C.                        Operations Research Analyst   \n",
       "29   Washington D.C.              Statistical Data Analyst - US Citizen   \n",
       "..               ...                                                ...   \n",
       "411             Mesa  Institutional Research Analyst (Open until Fil...   \n",
       "412             Mesa                                    Account Manager   \n",
       "413             Mesa                      Web Security Research Analyst   \n",
       "414             Mesa                  ENVIRONMENTAL OUTREACH SPECIALIST   \n",
       "415             Mesa                            AIR QUALITY PLANNER 2-3   \n",
       "416      Kansas City                                   Research Analyst   \n",
       "417      Kansas City                                   Research Analyst   \n",
       "418      Kansas City                                   Material Handler   \n",
       "419      Kansas City                  Production Fabricator (Any Shift)   \n",
       "420      Kansas City       Inspector, Tool & Precision Gage (Any Shift)   \n",
       "421      Kansas City        Tool & Precision Gage Inspector (Any Shift)   \n",
       "422      Kansas City             Electronics Test Inspector (Any Shift)   \n",
       "423          Raleigh                                     Data Scientist   \n",
       "424          Raleigh                              Contract Statistician   \n",
       "425          Raleigh                                     HPLC Scientist   \n",
       "426          Raleigh                                     Data Scientist   \n",
       "427          Raleigh                             Statistical Programmer   \n",
       "428          Raleigh                                     Data Scientist   \n",
       "429          Raleigh                       Research/Remediation Analyst   \n",
       "430          Raleigh                           Associate Scientist 3865   \n",
       "431          Raleigh                           Bioinformatics Scientist   \n",
       "432          Raleigh                                       Data Analyst   \n",
       "433          Raleigh                           Biologist / Entomologist   \n",
       "434          Raleigh                       Soc/Clin Research Specialist   \n",
       "435          Raleigh                  Hadoop Integration Data Scientist   \n",
       "436          Raleigh                 Statistician II (Job Code: GR0218)   \n",
       "437          Raleigh           Senior Data Scientist â Machine Learning   \n",
       "438          Raleigh                                 Research Assistant   \n",
       "439          Raleigh                      Business Services Coordinator   \n",
       "440          Raleigh                   Director Data Scientist, Product   \n",
       "\n",
       "                                               Company  \\\n",
       "0                          Central Intelligence Agency   \n",
       "1              Department of Health And Human Services   \n",
       "2                       Metropolitan Police Department   \n",
       "3                    Natural Resources Defense Council   \n",
       "4        National Aeronautics and Space Administration   \n",
       "5    The Maryland-National Capital Park and Plannin...   \n",
       "6                        Contingent/Direct Consultants   \n",
       "7                          Central Intelligence Agency   \n",
       "8                                      Piper Companies   \n",
       "9                                       Red Gate Group   \n",
       "10                         Central Intelligence Agency   \n",
       "11                   Oak Ridge Associated Universities   \n",
       "12                     Interface Financial Group (IFG)   \n",
       "13             National Geospatial-Intelligence Agency   \n",
       "14             Department of Health And Human Services   \n",
       "15                          Department of the Treasury   \n",
       "16                            National Security Agency   \n",
       "17                            National Security Agency   \n",
       "18                                      EMF Industries   \n",
       "19                          Johnson Service Group Inc.   \n",
       "20                     Federal Aviation Administration   \n",
       "21                                     Piper Companies   \n",
       "22                              Department of Commerce   \n",
       "23                                            Catalist   \n",
       "24                                     Piper Companies   \n",
       "25                              Department of Commerce   \n",
       "26                                                WSSC   \n",
       "27                            National Security Agency   \n",
       "28                               Department of Defense   \n",
       "29                                           PeopleTek   \n",
       "..                                                 ...   \n",
       "411         Maricopa County Community College District   \n",
       "412                                 The Creative Group   \n",
       "413                                           SiteLock   \n",
       "414                                   State of Arizona   \n",
       "415                                   State of Arizona   \n",
       "416                           Jackson County, Missouri   \n",
       "417           Jackson County Department of Corrections   \n",
       "418                                          Honeywell   \n",
       "419                                          Honeywell   \n",
       "420                                          Honeywell   \n",
       "421                                          Honeywell   \n",
       "422                                          Honeywell   \n",
       "423                                    Piper Companies   \n",
       "424                                    Piper Companies   \n",
       "425                                    Piper Companies   \n",
       "426                                   ITS Technologies   \n",
       "427                                    Piper Companies   \n",
       "428                            Sente Data Science, LLC   \n",
       "429     DISYS (Digital Intelligence SYStems Pvt. Ltd.)   \n",
       "430                               Hunter International   \n",
       "431                               Hunter International   \n",
       "432                                    Piper Companies   \n",
       "433                               Hunter International   \n",
       "434                       University of North Carolina   \n",
       "435                                LifeScale Analytics   \n",
       "436                              Seqirus A CSL Company   \n",
       "437                                         Strivector   \n",
       "438                       University of North Carolina   \n",
       "439                    North Carolina State University   \n",
       "440                                   All-In Analytics   \n",
       "\n",
       "                                         Location  \\\n",
       "0                                  Washington, DC   \n",
       "1                               Silver Spring, MD   \n",
       "2                                  Washington, DC   \n",
       "3                                  Washington, DC   \n",
       "4                                   Greenbelt, MD   \n",
       "5                         Silver Spring, MD 20902   \n",
       "6                          Gaithersburg, MD 20877   \n",
       "7                                  Washington, DC   \n",
       "8                                Reston, VA 20190   \n",
       "9                                   Arlington, VA   \n",
       "10                                 Washington, DC   \n",
       "11                                 Washington, DC   \n",
       "12                                   Bethesda, MD   \n",
       "13                                Springfield, VA   \n",
       "14                                  Rockville, MD   \n",
       "15                                 Washington, DC   \n",
       "16                                 Fort Meade, MD   \n",
       "17                                 Fort Meade, MD   \n",
       "18                                     McLean, VA   \n",
       "19                            Rockville, MD 20850   \n",
       "20                                 Washington, DC   \n",
       "21                               Reston, VA 20190   \n",
       "22           Washington, DC 20230 (Downtown area)   \n",
       "23                                 Washington, DC   \n",
       "24                               Reston, VA 20190   \n",
       "25           Washington, DC 20230 (Downtown area)   \n",
       "26                               Laurel, MD 20707   \n",
       "27                                 Fort Meade, MD   \n",
       "28                                  Arlington, VA   \n",
       "29                                   Bethesda, MD   \n",
       "..                                            ...   \n",
       "411                                   Phoenix, AZ   \n",
       "412       Phoenix, AZ 85016 (Camelback East area)   \n",
       "413                                Scottsdale, AZ   \n",
       "414                                   Phoenix, AZ   \n",
       "415                                   Phoenix, AZ   \n",
       "416         Kansas City, MO 64106 (Downtown area)   \n",
       "417                               Kansas City, MO   \n",
       "418  Kansas City, MO 64147 (Richards Gebaur area)   \n",
       "419                               Kansas City, KS   \n",
       "420                               Kansas City, KS   \n",
       "421                               Kansas City, KS   \n",
       "422  Kansas City, MO 64147 (Richards Gebaur area)   \n",
       "423            Raleigh, NC 27607 (Northwest area)   \n",
       "424              Research Triangle Park, NC 27709   \n",
       "425                              Durham, NC 27709   \n",
       "426                                   Raleigh, NC   \n",
       "427                         Morrisville, NC 27560   \n",
       "428                                      Cary, NC   \n",
       "429                                   Raleigh, NC   \n",
       "430                    Research Triangle Park, NC   \n",
       "431                    Research Triangle Park, NC   \n",
       "432              Raleigh, NC 27617 (Central area)   \n",
       "433                    Research Triangle Park, NC   \n",
       "434                         Chapel Hill, NC 27517   \n",
       "435                            Raleigh-Durham, NC   \n",
       "436                             Holly Springs, NC   \n",
       "437                               Morrisville, NC   \n",
       "438                         Chapel Hill, NC 27517   \n",
       "439                                   Raleigh, NC   \n",
       "440                                   Raleigh, NC   \n",
       "\n",
       "                                           Job Summary    Salary  Binary  \\\n",
       "0    Students serving as Data Scientist interns wor...   36800.0   False   \n",
       "1    Develops alternative options to resolve comple...  146833.5    True   \n",
       "2    Or data visualization and interaction. The Dat...   86711.0    True   \n",
       "3    Maintain data bases, paper and electronic fili...   24000.0   False   \n",
       "4    Utilization of satellite data to test existing...  120212.5    True   \n",
       "5    Experience with Costar and other real estate d...   79475.0    True   \n",
       "6    Experience of Development, program design and ...  150000.0    True   \n",
       "7    Data Scientists organize and interpret Big Dat...   91066.0    True   \n",
       "8    Responsibilities for the Lead Data Scientist i...  210000.0    True   \n",
       "9    Data Scientist (full-time contract). Under thi...  112500.0    True   \n",
       "10   Big Data concepts and technologies such as Apa...   90936.0    True   \n",
       "11   Performing data entry in various ORD and Agenc...   35200.0   False   \n",
       "12   Data Scientists need to analyze financial data...  120000.0    True   \n",
       "13   Data Scientist **AMENDED**. Data Management, D...   90941.0    True   \n",
       "14   You will use statistical and mathematical meth...  101477.0    True   \n",
       "15   Determining the types of data to be collected,...  109015.0    True   \n",
       "16   These include, but are not limited to cryptogr...   77025.0    True   \n",
       "17   These include, but are not limited to, problem...   77025.0    True   \n",
       "18   Our talented group of Data Scientists, Develop...  213000.0    True   \n",
       "19   Provide effort & cost benchmarking & insights ...   78400.0    True   \n",
       "20   Business Component: Associate Administrator fo...   97825.0    True   \n",
       "21   Collaborate with a team of other data engineer...  195000.0    True   \n",
       "22   Assisting with organizing and analyzing resear...  101477.0    True   \n",
       "23   Conversant understanding of relational data an...   85000.0    True   \n",
       "24   Responsibilities for the Lead Data Scientist i...  210000.0    True   \n",
       "25   Analyze and evaluate data. Assist in data coll...   65700.5   False   \n",
       "26   Ability to plan and direct the work of profess...   95396.5    True   \n",
       "27   Exploit, fuse and use data and data sources. A...   92498.5    True   \n",
       "28   Using statistical analysis techniques in order...  128825.0    True   \n",
       "29   STATISTICAL DATA ANALYST*. ï· Extract insights ...   65000.0   False   \n",
       "..                                                 ...       ...     ...   \n",
       "411  Develops queries on data warehouses using data...   55735.0   False   \n",
       "412  You're fascinated by data analytics:. You may ...   44000.0   False   \n",
       "413  About SiteLock: SiteLock is the global leader ...   52500.0   False   \n",
       "414  Analyze environmental data to determine validi...   55000.0   False   \n",
       "415  Ability to present data and findings in public...   61000.0   False   \n",
       "416  Verifies and analyzes real estate sales, lease...   20800.0   False   \n",
       "417  Verifies and analyzes real estate sales, lease...   20800.0   False   \n",
       "418  Maintains inventory data bases. Completes pape...   25600.0   False   \n",
       "419  Completes paperwork and computer data entries ...   25600.0   False   \n",
       "420  Ability to analyze and interpret data. Must be...   36800.0   False   \n",
       "421  Ability to analyze and interpret data. Must be...   36800.0   False   \n",
       "422  May be required to examine and evaluate test d...   33600.0   False   \n",
       "423  The Data Scientist will be in charge of data m...  120000.0    True   \n",
       "424  Contract Statistician Statistician Description...  128000.0    True   \n",
       "425  Responsibilities for the HPLC Scientist includ...   48000.0   False   \n",
       "426  The *Senior Data Scientist*. Ability to collab...  150000.0    True   \n",
       "427  Creation of macro programs, perform data check...   96000.0    True   \n",
       "428  Sente Data Science is seeking a Data Scientist...   95000.0    True   \n",
       "429  A large Financial Services Organization in Ral...   35200.0   False   \n",
       "430  Analyzes data and prepares reports, upon reque...   46400.0   False   \n",
       "431  Phenotypic data analysis. The scientist will w...   54400.0   False   \n",
       "432  Piper Enterprise Solutions is seeking Data Ana...  105000.0    True   \n",
       "433  Work will be conducted under direct supervisio...   32000.0   False   \n",
       "434  Radiation oncology is a highly-integrated, mul...   45734.0   False   \n",
       "435  Data Scientist with experience in experimental...  140000.0    True   \n",
       "436  See below JOB TITLE: Statistician II (Job Code...  101830.5    True   \n",
       "437  Senior Data Scientist â Machine Learning*. Men...  170000.0    True   \n",
       "438  Approximately 25% time will be spent coding an...   32603.0   False   \n",
       "439  Coordinate activities and logistics of visitin...   42945.0   False   \n",
       "440  Director Data Scientist, Product. Motivate, co...  185000.0    True   \n",
       "\n",
       "     Senior Title  \n",
       "0           False  \n",
       "1           False  \n",
       "2           False  \n",
       "3           False  \n",
       "4           False  \n",
       "5           False  \n",
       "6           False  \n",
       "7           False  \n",
       "8           False  \n",
       "9           False  \n",
       "10          False  \n",
       "11          False  \n",
       "12          False  \n",
       "13          False  \n",
       "14          False  \n",
       "15          False  \n",
       "16          False  \n",
       "17          False  \n",
       "18          False  \n",
       "19          False  \n",
       "20          False  \n",
       "21           True  \n",
       "22          False  \n",
       "23           True  \n",
       "24           True  \n",
       "25          False  \n",
       "26          False  \n",
       "27          False  \n",
       "28          False  \n",
       "29          False  \n",
       "..            ...  \n",
       "411         False  \n",
       "412         False  \n",
       "413         False  \n",
       "414         False  \n",
       "415         False  \n",
       "416         False  \n",
       "417         False  \n",
       "418         False  \n",
       "419         False  \n",
       "420         False  \n",
       "421         False  \n",
       "422         False  \n",
       "423         False  \n",
       "424         False  \n",
       "425         False  \n",
       "426         False  \n",
       "427         False  \n",
       "428         False  \n",
       "429         False  \n",
       "430         False  \n",
       "431         False  \n",
       "432         False  \n",
       "433         False  \n",
       "434         False  \n",
       "435         False  \n",
       "436         False  \n",
       "437          True  \n",
       "438         False  \n",
       "439         False  \n",
       "440         False  \n",
       "\n",
       "[441 rows x 8 columns]"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Senior Title'] = data['Title'].str.contains('Senior') #create column that is T/F if title contains Senior\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Summary</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Binary</th>\n",
       "      <th>Senior Title</th>\n",
       "      <th>Manager Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Undergraduate Internship/Co-op Program - Data ...</td>\n",
       "      <td>Central Intelligence Agency</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Students serving as Data Scientist interns wor...</td>\n",
       "      <td>36800.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Supervisory Operations Research Analyst</td>\n",
       "      <td>Department of Health And Human Services</td>\n",
       "      <td>Silver Spring, MD</td>\n",
       "      <td>Develops alternative options to resolve comple...</td>\n",
       "      <td>146833.5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Metropolitan Police Department</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Or data visualization and interaction. The Dat...</td>\n",
       "      <td>86711.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Facilities Intern</td>\n",
       "      <td>Natural Resources Defense Council</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Maintain data bases, paper and electronic fili...</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Research Physical Scientist, AST, Atmospheric ...</td>\n",
       "      <td>National Aeronautics and Space Administration</td>\n",
       "      <td>Greenbelt, MD</td>\n",
       "      <td>Utilization of satellite data to test existing...</td>\n",
       "      <td>120212.5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Real Estate and Urban Planning Research Analys...</td>\n",
       "      <td>The Maryland-National Capital Park and Plannin...</td>\n",
       "      <td>Silver Spring, MD 20902</td>\n",
       "      <td>Experience with Costar and other real estate d...</td>\n",
       "      <td>79475.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Statistician - Healthcare or Pharma Industry</td>\n",
       "      <td>Contingent/Direct Consultants</td>\n",
       "      <td>Gaithersburg, MD 20877</td>\n",
       "      <td>Experience of Development, program design and ...</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Central Intelligence Agency</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Data Scientists organize and interpret Big Dat...</td>\n",
       "      <td>91066.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Piper Companies</td>\n",
       "      <td>Reston, VA 20190</td>\n",
       "      <td>Responsibilities for the Lead Data Scientist i...</td>\n",
       "      <td>210000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist - OUSD(I)-HCMO-DCIPS</td>\n",
       "      <td>Red Gate Group</td>\n",
       "      <td>Arlington, VA</td>\n",
       "      <td>Data Scientist (full-time contract). Under thi...</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Apps Developer</td>\n",
       "      <td>Central Intelligence Agency</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Big Data concepts and technologies such as Apa...</td>\n",
       "      <td>90936.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Payroll Support Associate at EPA</td>\n",
       "      <td>Oak Ridge Associated Universities</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Performing data entry in various ORD and Agenc...</td>\n",
       "      <td>35200.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>IFG Data Scientist Whiz!</td>\n",
       "      <td>Interface Financial Group (IFG)</td>\n",
       "      <td>Bethesda, MD</td>\n",
       "      <td>Data Scientists need to analyze financial data...</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>National Geospatial-Intelligence Agency</td>\n",
       "      <td>Springfield, VA</td>\n",
       "      <td>Data Scientist **AMENDED**. Data Management, D...</td>\n",
       "      <td>90941.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Staff Fellow (Mathematical Statistician)</td>\n",
       "      <td>Department of Health And Human Services</td>\n",
       "      <td>Rockville, MD</td>\n",
       "      <td>You will use statistical and mathematical meth...</td>\n",
       "      <td>101477.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Operations Research Analyst</td>\n",
       "      <td>Department of the Treasury</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Determining the types of data to be collected,...</td>\n",
       "      <td>109015.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Mathematicians - Entry/Mid-Level</td>\n",
       "      <td>National Security Agency</td>\n",
       "      <td>Fort Meade, MD</td>\n",
       "      <td>These include, but are not limited to cryptogr...</td>\n",
       "      <td>77025.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Mathematical Statisticians - Entry/Mid-Level</td>\n",
       "      <td>National Security Agency</td>\n",
       "      <td>Fort Meade, MD</td>\n",
       "      <td>These include, but are not limited to, problem...</td>\n",
       "      <td>77025.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>2017-07-10 IT Program Manager Earning $$213,000</td>\n",
       "      <td>EMF Industries</td>\n",
       "      <td>McLean, VA</td>\n",
       "      <td>Our talented group of Data Scientists, Develop...</td>\n",
       "      <td>213000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Research Analyst (Vaccines)</td>\n",
       "      <td>Johnson Service Group Inc.</td>\n",
       "      <td>Rockville, MD 20850</td>\n",
       "      <td>Provide effort &amp; cost benchmarking &amp; insights ...</td>\n",
       "      <td>78400.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Operations Research Analyst</td>\n",
       "      <td>Federal Aviation Administration</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Business Component: Associate Administrator fo...</td>\n",
       "      <td>97825.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Piper Companies</td>\n",
       "      <td>Reston, VA 20190</td>\n",
       "      <td>Collaborate with a team of other data engineer...</td>\n",
       "      <td>195000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Interdisciplinary, GS-0101,0180,0801,1550-12/1...</td>\n",
       "      <td>Department of Commerce</td>\n",
       "      <td>Washington, DC 20230 (Downtown area)</td>\n",
       "      <td>Assisting with organizing and analyzing resear...</td>\n",
       "      <td>101477.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Senior Product Manager</td>\n",
       "      <td>Catalist</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Conversant understanding of relational data an...</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Piper Companies</td>\n",
       "      <td>Reston, VA 20190</td>\n",
       "      <td>Responsibilities for the Lead Data Scientist i...</td>\n",
       "      <td>210000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Recent Graduate Survey Statistician, GS-1530-7...</td>\n",
       "      <td>Department of Commerce</td>\n",
       "      <td>Washington, DC 20230 (Downtown area)</td>\n",
       "      <td>Analyze and evaluate data. Assist in data coll...</td>\n",
       "      <td>65700.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Environmental Scientist - Water Resources Mana...</td>\n",
       "      <td>WSSC</td>\n",
       "      <td>Laurel, MD 20707</td>\n",
       "      <td>Ability to plan and direct the work of profess...</td>\n",
       "      <td>95396.5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist - Mid-Level</td>\n",
       "      <td>National Security Agency</td>\n",
       "      <td>Fort Meade, MD</td>\n",
       "      <td>Exploit, fuse and use data and data sources. A...</td>\n",
       "      <td>92498.5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Operations Research Analyst</td>\n",
       "      <td>Department of Defense</td>\n",
       "      <td>Arlington, VA</td>\n",
       "      <td>Using statistical analysis techniques in order...</td>\n",
       "      <td>128825.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Statistical Data Analyst - US Citizen</td>\n",
       "      <td>PeopleTek</td>\n",
       "      <td>Bethesda, MD</td>\n",
       "      <td>STATISTICAL DATA ANALYST*. ï· Extract insights ...</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City                                              Title  \\\n",
       "0   Washington D.C.  Undergraduate Internship/Co-op Program - Data ...   \n",
       "1   Washington D.C.            Supervisory Operations Research Analyst   \n",
       "2   Washington D.C.                                     Data Scientist   \n",
       "3   Washington D.C.                                  Facilities Intern   \n",
       "4   Washington D.C.  Research Physical Scientist, AST, Atmospheric ...   \n",
       "5   Washington D.C.  Real Estate and Urban Planning Research Analys...   \n",
       "6   Washington D.C.       Statistician - Healthcare or Pharma Industry   \n",
       "7   Washington D.C.                                     Data Scientist   \n",
       "8   Washington D.C.                                     Data Scientist   \n",
       "9   Washington D.C.                Data Scientist - OUSD(I)-HCMO-DCIPS   \n",
       "10  Washington D.C.                                     Apps Developer   \n",
       "11  Washington D.C.                   Payroll Support Associate at EPA   \n",
       "12  Washington D.C.                           IFG Data Scientist Whiz!   \n",
       "13  Washington D.C.                                     Data Scientist   \n",
       "14  Washington D.C.           Staff Fellow (Mathematical Statistician)   \n",
       "15  Washington D.C.                        Operations Research Analyst   \n",
       "16  Washington D.C.                   Mathematicians - Entry/Mid-Level   \n",
       "17  Washington D.C.       Mathematical Statisticians - Entry/Mid-Level   \n",
       "18  Washington D.C.    2017-07-10 IT Program Manager Earning $$213,000   \n",
       "19  Washington D.C.                        Research Analyst (Vaccines)   \n",
       "20  Washington D.C.                        Operations Research Analyst   \n",
       "21  Washington D.C.                               Senior Data Engineer   \n",
       "22  Washington D.C.  Interdisciplinary, GS-0101,0180,0801,1550-12/1...   \n",
       "23  Washington D.C.                             Senior Product Manager   \n",
       "24  Washington D.C.                              Senior Data Scientist   \n",
       "25  Washington D.C.  Recent Graduate Survey Statistician, GS-1530-7...   \n",
       "26  Washington D.C.  Environmental Scientist - Water Resources Mana...   \n",
       "27  Washington D.C.                         Data Scientist - Mid-Level   \n",
       "28  Washington D.C.                        Operations Research Analyst   \n",
       "29  Washington D.C.              Statistical Data Analyst - US Citizen   \n",
       "\n",
       "                                              Company  \\\n",
       "0                         Central Intelligence Agency   \n",
       "1             Department of Health And Human Services   \n",
       "2                      Metropolitan Police Department   \n",
       "3                   Natural Resources Defense Council   \n",
       "4       National Aeronautics and Space Administration   \n",
       "5   The Maryland-National Capital Park and Plannin...   \n",
       "6                       Contingent/Direct Consultants   \n",
       "7                         Central Intelligence Agency   \n",
       "8                                     Piper Companies   \n",
       "9                                      Red Gate Group   \n",
       "10                        Central Intelligence Agency   \n",
       "11                  Oak Ridge Associated Universities   \n",
       "12                    Interface Financial Group (IFG)   \n",
       "13            National Geospatial-Intelligence Agency   \n",
       "14            Department of Health And Human Services   \n",
       "15                         Department of the Treasury   \n",
       "16                           National Security Agency   \n",
       "17                           National Security Agency   \n",
       "18                                     EMF Industries   \n",
       "19                         Johnson Service Group Inc.   \n",
       "20                    Federal Aviation Administration   \n",
       "21                                    Piper Companies   \n",
       "22                             Department of Commerce   \n",
       "23                                           Catalist   \n",
       "24                                    Piper Companies   \n",
       "25                             Department of Commerce   \n",
       "26                                               WSSC   \n",
       "27                           National Security Agency   \n",
       "28                              Department of Defense   \n",
       "29                                          PeopleTek   \n",
       "\n",
       "                                Location  \\\n",
       "0                         Washington, DC   \n",
       "1                      Silver Spring, MD   \n",
       "2                         Washington, DC   \n",
       "3                         Washington, DC   \n",
       "4                          Greenbelt, MD   \n",
       "5                Silver Spring, MD 20902   \n",
       "6                 Gaithersburg, MD 20877   \n",
       "7                         Washington, DC   \n",
       "8                       Reston, VA 20190   \n",
       "9                          Arlington, VA   \n",
       "10                        Washington, DC   \n",
       "11                        Washington, DC   \n",
       "12                          Bethesda, MD   \n",
       "13                       Springfield, VA   \n",
       "14                         Rockville, MD   \n",
       "15                        Washington, DC   \n",
       "16                        Fort Meade, MD   \n",
       "17                        Fort Meade, MD   \n",
       "18                            McLean, VA   \n",
       "19                   Rockville, MD 20850   \n",
       "20                        Washington, DC   \n",
       "21                      Reston, VA 20190   \n",
       "22  Washington, DC 20230 (Downtown area)   \n",
       "23                        Washington, DC   \n",
       "24                      Reston, VA 20190   \n",
       "25  Washington, DC 20230 (Downtown area)   \n",
       "26                      Laurel, MD 20707   \n",
       "27                        Fort Meade, MD   \n",
       "28                         Arlington, VA   \n",
       "29                          Bethesda, MD   \n",
       "\n",
       "                                          Job Summary    Salary  Binary  \\\n",
       "0   Students serving as Data Scientist interns wor...   36800.0   False   \n",
       "1   Develops alternative options to resolve comple...  146833.5    True   \n",
       "2   Or data visualization and interaction. The Dat...   86711.0    True   \n",
       "3   Maintain data bases, paper and electronic fili...   24000.0   False   \n",
       "4   Utilization of satellite data to test existing...  120212.5    True   \n",
       "5   Experience with Costar and other real estate d...   79475.0    True   \n",
       "6   Experience of Development, program design and ...  150000.0    True   \n",
       "7   Data Scientists organize and interpret Big Dat...   91066.0    True   \n",
       "8   Responsibilities for the Lead Data Scientist i...  210000.0    True   \n",
       "9   Data Scientist (full-time contract). Under thi...  112500.0    True   \n",
       "10  Big Data concepts and technologies such as Apa...   90936.0    True   \n",
       "11  Performing data entry in various ORD and Agenc...   35200.0   False   \n",
       "12  Data Scientists need to analyze financial data...  120000.0    True   \n",
       "13  Data Scientist **AMENDED**. Data Management, D...   90941.0    True   \n",
       "14  You will use statistical and mathematical meth...  101477.0    True   \n",
       "15  Determining the types of data to be collected,...  109015.0    True   \n",
       "16  These include, but are not limited to cryptogr...   77025.0    True   \n",
       "17  These include, but are not limited to, problem...   77025.0    True   \n",
       "18  Our talented group of Data Scientists, Develop...  213000.0    True   \n",
       "19  Provide effort & cost benchmarking & insights ...   78400.0    True   \n",
       "20  Business Component: Associate Administrator fo...   97825.0    True   \n",
       "21  Collaborate with a team of other data engineer...  195000.0    True   \n",
       "22  Assisting with organizing and analyzing resear...  101477.0    True   \n",
       "23  Conversant understanding of relational data an...   85000.0    True   \n",
       "24  Responsibilities for the Lead Data Scientist i...  210000.0    True   \n",
       "25  Analyze and evaluate data. Assist in data coll...   65700.5   False   \n",
       "26  Ability to plan and direct the work of profess...   95396.5    True   \n",
       "27  Exploit, fuse and use data and data sources. A...   92498.5    True   \n",
       "28  Using statistical analysis techniques in order...  128825.0    True   \n",
       "29  STATISTICAL DATA ANALYST*. ï· Extract insights ...   65000.0   False   \n",
       "\n",
       "    Senior Title  Manager Title  \n",
       "0          False          False  \n",
       "1          False          False  \n",
       "2          False          False  \n",
       "3          False          False  \n",
       "4          False          False  \n",
       "5          False          False  \n",
       "6          False          False  \n",
       "7          False          False  \n",
       "8          False          False  \n",
       "9          False          False  \n",
       "10         False          False  \n",
       "11         False          False  \n",
       "12         False          False  \n",
       "13         False          False  \n",
       "14         False          False  \n",
       "15         False          False  \n",
       "16         False          False  \n",
       "17         False          False  \n",
       "18         False           True  \n",
       "19         False          False  \n",
       "20         False          False  \n",
       "21          True          False  \n",
       "22         False          False  \n",
       "23          True           True  \n",
       "24          True          False  \n",
       "25         False          False  \n",
       "26         False          False  \n",
       "27         False          False  \n",
       "28         False          False  \n",
       "29         False          False  "
      ]
     },
     "execution_count": 641,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Manager Title']=  data['Title'].str.contains('Manager') #create column that is T/F if title contains Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 971,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 2) (132,)\n",
      "(309, 2) (309,)\n"
     ]
    }
   ],
   "source": [
    "X = data[['Manager Title', 'Senior Title']] #Feature \n",
    "y = data['Binary'] #Aim of Predicting Binary T|F based on Title containing Manager and/or Senior \n",
    "#train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.3, random_state=3)\n",
    "print X_train.shape, y_train.shape\n",
    "print X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 972,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y2 = pd.factorize(y)\n",
    "X = pd.get_dummies(data[['Manager Title', 'Senior Title']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 973,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, ..., 0, 1]), Index([False, True], dtype='object'))"
      ]
     },
     "execution_count": 973,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 974,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Manager Title</th>\n",
       "      <th>Senior Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows Ã 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Manager Title  Senior Title\n",
       "0            False         False\n",
       "1            False         False\n",
       "2            False         False\n",
       "3            False         False\n",
       "4            False         False\n",
       "5            False         False\n",
       "6            False         False\n",
       "7            False         False\n",
       "8            False         False\n",
       "9            False         False\n",
       "10           False         False\n",
       "11           False         False\n",
       "12           False         False\n",
       "13           False         False\n",
       "14           False         False\n",
       "15           False         False\n",
       "16           False         False\n",
       "17           False         False\n",
       "18            True         False\n",
       "19           False         False\n",
       "20           False         False\n",
       "21           False          True\n",
       "22           False         False\n",
       "23            True          True\n",
       "24           False          True\n",
       "25           False         False\n",
       "26           False         False\n",
       "27           False         False\n",
       "28           False         False\n",
       "29           False         False\n",
       "..             ...           ...\n",
       "411          False         False\n",
       "412           True         False\n",
       "413          False         False\n",
       "414          False         False\n",
       "415          False         False\n",
       "416          False         False\n",
       "417          False         False\n",
       "418          False         False\n",
       "419          False         False\n",
       "420          False         False\n",
       "421          False         False\n",
       "422          False         False\n",
       "423          False         False\n",
       "424          False         False\n",
       "425          False         False\n",
       "426          False         False\n",
       "427          False         False\n",
       "428          False         False\n",
       "429          False         False\n",
       "430          False         False\n",
       "431          False         False\n",
       "432          False         False\n",
       "433          False         False\n",
       "434          False         False\n",
       "435          False         False\n",
       "436          False         False\n",
       "437          False          True\n",
       "438          False         False\n",
       "439          False         False\n",
       "440          False         False\n",
       "\n",
       "[441 rows x 2 columns]"
      ]
     },
     "execution_count": 974,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 975,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=5, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 975,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apply the classifier we trained to the  data\n",
    "rf = RandomForestClassifier(class_weight='balanced', n_jobs=-1, max_depth=5)\n",
    "rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Tree Score:\t0.56 Â± 0.039\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#Create a random forest classifier.\n",
    "#clf = RandomForestClassifier(n_jobs=-1)\n",
    "#Train Classifier to take training features,location, and how it realates to training y, binary\n",
    "#clf.fit(X, y2)\n",
    "cv = StratifiedKFold(y, n_folds=10, shuffle=True, random_state=35)\n",
    "dt = RandomForestClassifier(class_weight='balanced')\n",
    "s = cross_val_score(dt, X, y, cv=cv, n_jobs=-1)\n",
    "print \"{} Score:\\t{:0.3} Â± {:0.3}\".format(\"Random Forest Tree\", s.mean().round(3), s.std().round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Senior Title</th>\n",
       "      <td>0.906731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manager Title</th>\n",
       "      <td>0.093269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Title Importance\n",
       "Senior Title           0.906731\n",
       "Manager Title          0.093269"
      ]
     },
     "execution_count": 977,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = pd.DataFrame(zip(rf.feature_importances_,),\n",
    "                           index=X.columns,\n",
    "                           columns=['Title Importance']).sort_values('Title Importance',\n",
    "                                                                   ascending=False)\n",
    "importance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAKJCAYAAAB5zWflAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2mNA8igiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13ad64890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "all(rf.feature_importances_ == np.mean([tree.feature_importances_ for tree in rf.estimators_], axis=0))\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "# calculate the standard deviation of feature importances by looping over the trees in the random forest\n",
    "# \n",
    "\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "feature_names = X.columns\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), feature_names[indices], rotation=90)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "# senior_dataframe = count_results_by_keywords('Senior', 'Manager','')\n",
    "# senior_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = StratifiedKFold(y, n_folds=3, shuffle=True, random_state=41)\n",
    "# dt = DecisionTreeClassifier(class_weight='balanced')\n",
    "# s = cross_val_score(dt, X, y, cv=cv, n_jobs=-1)\n",
    "# print \"{} Score:\\t{:0.3} Â± {:0.3}\".format(\"Decision Tree\", s.mean().round(3), s.std().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COUNT VECTORIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NLP analysis using function created in 5.04 NLP-2\n",
    "#Initialize the BeautifulSoup object on a single Job Description \n",
    "# title = BeautifulSoup(data['Title'][0])\n",
    "# #Remove Html\n",
    "# html_remove = title.get_text()\n",
    "# html_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Punctuation\n",
    "# letters_only = re.sub(\"[^a-zA-Z]\", \" \", title.get_text())  \n",
    "# lower_case = letters_only.lower() #Convert to lowercase\n",
    "# words = lower_case.split()      #Split into words\n",
    "# print letters_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "#import stopword list\n",
    "# stopwords.words('english') \n",
    "# #Remove Stop words\n",
    "# words = [w for w in words if not w in stopwords.words(\"english\")]\n",
    "# print words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def title_words(title):\n",
    "    #Remove Html\n",
    "    html_remove = BeautifulSoup(title).get_text()\n",
    "    #Remove Non-Letters\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", html_remove) \n",
    "    #Convert to Lower case and split individual words\n",
    "    words = letters_only.lower().split()\n",
    "    #import english words as set\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    #Remove Stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]\n",
    "    # 6. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return(\" \".join( meaningful_words )) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "441"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_titles=data['Title'].size\n",
    "clean_titles = []\n",
    "num_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clean_titles = []\n",
    "for i in xrange(0, num_titles):\n",
    "    if ( (i+1)%1000 == 0):\n",
    "        print \"Title %d of %d\\n\" % (i+1, num_titles)\n",
    "    clean_titles.append( title_words(data['Title'][i] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "441"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiliazie CountVectorizer to create vocabulary list.\n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = 'english',   \\\n",
    "                             max_features = 25) \n",
    "#fit_transform() first the model and learns the vocab\n",
    "#transforms data into feature vectors\n",
    "#becomes list of strings\n",
    "#.transform counts everything and turns it into a feature matrix\n",
    "train_data_features = vectorizer.fit_transform(clean_titles)\n",
    "\n",
    "#Convert result to numpy array\n",
    "data_features = train_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441, 25)\n"
     ]
    }
   ],
   "source": [
    "print data_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, ..., 0, 0],\n",
       "       [1, 0, ..., 0, 0],\n",
       "       ..., \n",
       "       [0, 0, ..., 0, 0],\n",
       "       [0, 0, ..., 0, 0]])"
      ]
     },
     "execution_count": 796,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_features #show data_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'analyst', u'analytics', u'assistant', u'associate', u'bureau', u'clinical', u'data', u'developer', u'engineer', u'engineering', u'environmental', u'health', u'laboratory', u'learning', u'machine', u'manager', u'medical', u'program', u'research', u'scientist', u'senior', u'software', u'specialist', u'sr', u'statistical']\n"
     ]
    }
   ],
   "source": [
    "vocab = vectorizer.get_feature_names() #define vocab as vectorizer feature names\n",
    "print vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analyst</th>\n",
       "      <th>analytics</th>\n",
       "      <th>assistant</th>\n",
       "      <th>associate</th>\n",
       "      <th>bureau</th>\n",
       "      <th>clinical</th>\n",
       "      <th>data</th>\n",
       "      <th>developer</th>\n",
       "      <th>engineer</th>\n",
       "      <th>engineering</th>\n",
       "      <th>...</th>\n",
       "      <th>manager</th>\n",
       "      <th>medical</th>\n",
       "      <th>program</th>\n",
       "      <th>research</th>\n",
       "      <th>scientist</th>\n",
       "      <th>senior</th>\n",
       "      <th>software</th>\n",
       "      <th>specialist</th>\n",
       "      <th>sr</th>\n",
       "      <th>statistical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows Ã 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     analyst  analytics  assistant  associate  bureau  clinical  data  \\\n",
       "0          0          0          0          0       0         0     1   \n",
       "1          1          0          0          0       0         0     0   \n",
       "2          0          0          0          0       0         0     1   \n",
       "3          0          0          0          0       0         0     0   \n",
       "4          0          0          0          0       0         0     0   \n",
       "5          1          0          0          0       0         0     0   \n",
       "6          0          0          0          0       0         0     0   \n",
       "7          0          0          0          0       0         0     1   \n",
       "8          0          0          0          0       0         0     1   \n",
       "9          0          0          0          0       0         0     1   \n",
       "10         0          0          0          0       0         0     0   \n",
       "11         0          0          0          1       0         0     0   \n",
       "12         0          0          0          0       0         0     1   \n",
       "13         0          0          0          0       0         0     1   \n",
       "14         0          0          0          0       0         0     0   \n",
       "15         1          0          0          0       0         0     0   \n",
       "16         0          0          0          0       0         0     0   \n",
       "17         0          0          0          0       0         0     0   \n",
       "18         0          0          0          0       0         0     0   \n",
       "19         1          0          0          0       0         0     0   \n",
       "20         1          0          0          0       0         0     0   \n",
       "21         0          0          0          0       0         0     1   \n",
       "22         0          0          0          0       0         0     0   \n",
       "23         0          0          0          0       0         0     0   \n",
       "24         0          0          0          0       0         0     1   \n",
       "25         0          0          0          0       0         0     0   \n",
       "26         0          0          0          0       0         0     0   \n",
       "27         0          0          0          0       0         0     1   \n",
       "28         1          0          0          0       0         0     0   \n",
       "29         1          0          0          0       0         0     1   \n",
       "..       ...        ...        ...        ...     ...       ...   ...   \n",
       "411        1          0          0          0       0         0     0   \n",
       "412        0          0          0          0       0         0     0   \n",
       "413        1          0          0          0       0         0     0   \n",
       "414        0          0          0          0       0         0     0   \n",
       "415        0          0          0          0       0         0     0   \n",
       "416        1          0          0          0       0         0     0   \n",
       "417        1          0          0          0       0         0     0   \n",
       "418        0          0          0          0       0         0     0   \n",
       "419        0          0          0          0       0         0     0   \n",
       "420        0          0          0          0       0         0     0   \n",
       "421        0          0          0          0       0         0     0   \n",
       "422        0          0          0          0       0         0     0   \n",
       "423        0          0          0          0       0         0     1   \n",
       "424        0          0          0          0       0         0     0   \n",
       "425        0          0          0          0       0         0     0   \n",
       "426        0          0          0          0       0         0     1   \n",
       "427        0          0          0          0       0         0     0   \n",
       "428        0          0          0          0       0         0     1   \n",
       "429        1          0          0          0       0         0     0   \n",
       "430        0          0          0          1       0         0     0   \n",
       "431        0          0          0          0       0         0     0   \n",
       "432        1          0          0          0       0         0     1   \n",
       "433        0          0          0          0       0         0     0   \n",
       "434        0          0          0          0       0         0     0   \n",
       "435        0          0          0          0       0         0     1   \n",
       "436        0          0          0          0       0         0     0   \n",
       "437        0          0          0          0       0         0     1   \n",
       "438        0          0          1          0       0         0     0   \n",
       "439        0          0          0          0       0         0     0   \n",
       "440        0          0          0          0       0         0     1   \n",
       "\n",
       "     developer  engineer  engineering     ...       manager  medical  program  \\\n",
       "0            0         0            0     ...             0        0        1   \n",
       "1            0         0            0     ...             0        0        0   \n",
       "2            0         0            0     ...             0        0        0   \n",
       "3            0         0            0     ...             0        0        0   \n",
       "4            0         0            0     ...             0        0        0   \n",
       "5            0         0            0     ...             0        0        0   \n",
       "6            0         0            0     ...             0        0        0   \n",
       "7            0         0            0     ...             0        0        0   \n",
       "8            0         0            0     ...             0        0        0   \n",
       "9            0         0            0     ...             0        0        0   \n",
       "10           1         0            0     ...             0        0        0   \n",
       "11           0         0            0     ...             0        0        0   \n",
       "12           0         0            0     ...             0        0        0   \n",
       "13           0         0            0     ...             0        0        0   \n",
       "14           0         0            0     ...             0        0        0   \n",
       "15           0         0            0     ...             0        0        0   \n",
       "16           0         0            0     ...             0        0        0   \n",
       "17           0         0            0     ...             0        0        0   \n",
       "18           0         0            0     ...             1        0        1   \n",
       "19           0         0            0     ...             0        0        0   \n",
       "20           0         0            0     ...             0        0        0   \n",
       "21           0         1            0     ...             0        0        0   \n",
       "22           0         0            0     ...             0        0        0   \n",
       "23           0         0            0     ...             1        0        0   \n",
       "24           0         0            0     ...             0        0        0   \n",
       "25           0         0            0     ...             0        0        0   \n",
       "26           0         0            0     ...             0        0        0   \n",
       "27           0         0            0     ...             0        0        0   \n",
       "28           0         0            0     ...             0        0        0   \n",
       "29           0         0            0     ...             0        0        0   \n",
       "..         ...       ...          ...     ...           ...      ...      ...   \n",
       "411          0         0            0     ...             0        0        0   \n",
       "412          0         0            0     ...             1        0        0   \n",
       "413          0         0            0     ...             0        0        0   \n",
       "414          0         0            0     ...             0        0        0   \n",
       "415          0         0            0     ...             0        0        0   \n",
       "416          0         0            0     ...             0        0        0   \n",
       "417          0         0            0     ...             0        0        0   \n",
       "418          0         0            0     ...             0        0        0   \n",
       "419          0         0            0     ...             0        0        0   \n",
       "420          0         0            0     ...             0        0        0   \n",
       "421          0         0            0     ...             0        0        0   \n",
       "422          0         0            0     ...             0        0        0   \n",
       "423          0         0            0     ...             0        0        0   \n",
       "424          0         0            0     ...             0        0        0   \n",
       "425          0         0            0     ...             0        0        0   \n",
       "426          0         0            0     ...             0        0        0   \n",
       "427          0         0            0     ...             0        0        0   \n",
       "428          0         0            0     ...             0        0        0   \n",
       "429          0         0            0     ...             0        0        0   \n",
       "430          0         0            0     ...             0        0        0   \n",
       "431          0         0            0     ...             0        0        0   \n",
       "432          0         0            0     ...             0        0        0   \n",
       "433          0         0            0     ...             0        0        0   \n",
       "434          0         0            0     ...             0        0        0   \n",
       "435          0         0            0     ...             0        0        0   \n",
       "436          0         0            0     ...             0        0        0   \n",
       "437          0         0            0     ...             0        0        0   \n",
       "438          0         0            0     ...             0        0        0   \n",
       "439          0         0            0     ...             0        0        0   \n",
       "440          0         0            0     ...             0        0        0   \n",
       "\n",
       "     research  scientist  senior  software  specialist  sr  statistical  \n",
       "0           0          1       0         0           0   0            0  \n",
       "1           1          0       0         0           0   0            0  \n",
       "2           0          1       0         0           0   0            0  \n",
       "3           0          0       0         0           0   0            0  \n",
       "4           1          1       0         0           0   0            0  \n",
       "5           1          0       0         0           0   0            0  \n",
       "6           0          0       0         0           0   0            0  \n",
       "7           0          1       0         0           0   0            0  \n",
       "8           0          1       0         0           0   0            0  \n",
       "9           0          1       0         0           0   0            0  \n",
       "10          0          0       0         0           0   0            0  \n",
       "11          0          0       0         0           0   0            0  \n",
       "12          0          1       0         0           0   0            0  \n",
       "13          0          1       0         0           0   0            0  \n",
       "14          0          0       0         0           0   0            0  \n",
       "15          1          0       0         0           0   0            0  \n",
       "16          0          0       0         0           0   0            0  \n",
       "17          0          0       0         0           0   0            0  \n",
       "18          0          0       0         0           0   0            0  \n",
       "19          1          0       0         0           0   0            0  \n",
       "20          1          0       0         0           0   0            0  \n",
       "21          0          0       1         0           0   0            0  \n",
       "22          0          0       0         0           0   0            0  \n",
       "23          0          0       1         0           0   0            0  \n",
       "24          0          1       1         0           0   0            0  \n",
       "25          0          0       0         0           0   0            0  \n",
       "26          0          1       0         0           0   0            0  \n",
       "27          0          1       0         0           0   0            0  \n",
       "28          1          0       0         0           0   0            0  \n",
       "29          0          0       0         0           0   0            1  \n",
       "..        ...        ...     ...       ...         ...  ..          ...  \n",
       "411         1          0       0         0           0   0            0  \n",
       "412         0          0       0         0           0   0            0  \n",
       "413         1          0       0         0           0   0            0  \n",
       "414         0          0       0         0           1   0            0  \n",
       "415         0          0       0         0           0   0            0  \n",
       "416         1          0       0         0           0   0            0  \n",
       "417         1          0       0         0           0   0            0  \n",
       "418         0          0       0         0           0   0            0  \n",
       "419         0          0       0         0           0   0            0  \n",
       "420         0          0       0         0           0   0            0  \n",
       "421         0          0       0         0           0   0            0  \n",
       "422         0          0       0         0           0   0            0  \n",
       "423         0          1       0         0           0   0            0  \n",
       "424         0          0       0         0           0   0            0  \n",
       "425         0          1       0         0           0   0            0  \n",
       "426         0          1       0         0           0   0            0  \n",
       "427         0          0       0         0           0   0            1  \n",
       "428         0          1       0         0           0   0            0  \n",
       "429         1          0       0         0           0   0            0  \n",
       "430         0          1       0         0           0   0            0  \n",
       "431         0          1       0         0           0   0            0  \n",
       "432         0          0       0         0           0   0            0  \n",
       "433         0          0       0         0           0   0            0  \n",
       "434         1          0       0         0           1   0            0  \n",
       "435         0          1       0         0           0   0            0  \n",
       "436         0          0       0         0           0   0            0  \n",
       "437         0          1       1         0           0   0            0  \n",
       "438         1          0       0         0           0   0            0  \n",
       "439         0          0       0         0           0   0            0  \n",
       "440         0          1       0         0           0   0            0  \n",
       "\n",
       "[441 rows x 25 columns]"
      ]
     },
     "execution_count": 798,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab2 = pd.DataFrame(data_features, columns=vocab) #create vectorizer df\n",
    "vocab2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Summary</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Binary</th>\n",
       "      <th>Senior Title</th>\n",
       "      <th>Manager Title</th>\n",
       "      <th>analyst</th>\n",
       "      <th>...</th>\n",
       "      <th>manager</th>\n",
       "      <th>medical</th>\n",
       "      <th>program</th>\n",
       "      <th>research</th>\n",
       "      <th>scientist</th>\n",
       "      <th>senior</th>\n",
       "      <th>software</th>\n",
       "      <th>specialist</th>\n",
       "      <th>sr</th>\n",
       "      <th>statistical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Undergraduate Internship/Co-op Program - Data ...</td>\n",
       "      <td>Central Intelligence Agency</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Students serving as Data Scientist interns wor...</td>\n",
       "      <td>36800.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Supervisory Operations Research Analyst</td>\n",
       "      <td>Department of Health And Human Services</td>\n",
       "      <td>Silver Spring, MD</td>\n",
       "      <td>Develops alternative options to resolve comple...</td>\n",
       "      <td>146833.5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Metropolitan Police Department</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Or data visualization and interaction. The Dat...</td>\n",
       "      <td>86711.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Facilities Intern</td>\n",
       "      <td>Natural Resources Defense Council</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Maintain data bases, paper and electronic fili...</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Research Physical Scientist, AST, Atmospheric ...</td>\n",
       "      <td>National Aeronautics and Space Administration</td>\n",
       "      <td>Greenbelt, MD</td>\n",
       "      <td>Utilization of satellite data to test existing...</td>\n",
       "      <td>120212.5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Real Estate and Urban Planning Research Analys...</td>\n",
       "      <td>The Maryland-National Capital Park and Plannin...</td>\n",
       "      <td>Silver Spring, MD 20902</td>\n",
       "      <td>Experience with Costar and other real estate d...</td>\n",
       "      <td>79475.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Statistician - Healthcare or Pharma Industry</td>\n",
       "      <td>Contingent/Direct Consultants</td>\n",
       "      <td>Gaithersburg, MD 20877</td>\n",
       "      <td>Experience of Development, program design and ...</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Central Intelligence Agency</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Data Scientists organize and interpret Big Dat...</td>\n",
       "      <td>91066.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Piper Companies</td>\n",
       "      <td>Reston, VA 20190</td>\n",
       "      <td>Responsibilities for the Lead Data Scientist i...</td>\n",
       "      <td>210000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist - OUSD(I)-HCMO-DCIPS</td>\n",
       "      <td>Red Gate Group</td>\n",
       "      <td>Arlington, VA</td>\n",
       "      <td>Data Scientist (full-time contract). Under thi...</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Apps Developer</td>\n",
       "      <td>Central Intelligence Agency</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Big Data concepts and technologies such as Apa...</td>\n",
       "      <td>90936.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Payroll Support Associate at EPA</td>\n",
       "      <td>Oak Ridge Associated Universities</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Performing data entry in various ORD and Agenc...</td>\n",
       "      <td>35200.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>IFG Data Scientist Whiz!</td>\n",
       "      <td>Interface Financial Group (IFG)</td>\n",
       "      <td>Bethesda, MD</td>\n",
       "      <td>Data Scientists need to analyze financial data...</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>National Geospatial-Intelligence Agency</td>\n",
       "      <td>Springfield, VA</td>\n",
       "      <td>Data Scientist **AMENDED**. Data Management, D...</td>\n",
       "      <td>90941.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Staff Fellow (Mathematical Statistician)</td>\n",
       "      <td>Department of Health And Human Services</td>\n",
       "      <td>Rockville, MD</td>\n",
       "      <td>You will use statistical and mathematical meth...</td>\n",
       "      <td>101477.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Operations Research Analyst</td>\n",
       "      <td>Department of the Treasury</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Determining the types of data to be collected,...</td>\n",
       "      <td>109015.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Mathematicians - Entry/Mid-Level</td>\n",
       "      <td>National Security Agency</td>\n",
       "      <td>Fort Meade, MD</td>\n",
       "      <td>These include, but are not limited to cryptogr...</td>\n",
       "      <td>77025.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Mathematical Statisticians - Entry/Mid-Level</td>\n",
       "      <td>National Security Agency</td>\n",
       "      <td>Fort Meade, MD</td>\n",
       "      <td>These include, but are not limited to, problem...</td>\n",
       "      <td>77025.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>2017-07-10 IT Program Manager Earning $$213,000</td>\n",
       "      <td>EMF Industries</td>\n",
       "      <td>McLean, VA</td>\n",
       "      <td>Our talented group of Data Scientists, Develop...</td>\n",
       "      <td>213000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Research Analyst (Vaccines)</td>\n",
       "      <td>Johnson Service Group Inc.</td>\n",
       "      <td>Rockville, MD 20850</td>\n",
       "      <td>Provide effort &amp; cost benchmarking &amp; insights ...</td>\n",
       "      <td>78400.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Operations Research Analyst</td>\n",
       "      <td>Federal Aviation Administration</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Business Component: Associate Administrator fo...</td>\n",
       "      <td>97825.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Piper Companies</td>\n",
       "      <td>Reston, VA 20190</td>\n",
       "      <td>Collaborate with a team of other data engineer...</td>\n",
       "      <td>195000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Interdisciplinary, GS-0101,0180,0801,1550-12/1...</td>\n",
       "      <td>Department of Commerce</td>\n",
       "      <td>Washington, DC 20230 (Downtown area)</td>\n",
       "      <td>Assisting with organizing and analyzing resear...</td>\n",
       "      <td>101477.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Senior Product Manager</td>\n",
       "      <td>Catalist</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Conversant understanding of relational data an...</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Piper Companies</td>\n",
       "      <td>Reston, VA 20190</td>\n",
       "      <td>Responsibilities for the Lead Data Scientist i...</td>\n",
       "      <td>210000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Recent Graduate Survey Statistician, GS-1530-7...</td>\n",
       "      <td>Department of Commerce</td>\n",
       "      <td>Washington, DC 20230 (Downtown area)</td>\n",
       "      <td>Analyze and evaluate data. Assist in data coll...</td>\n",
       "      <td>65700.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Environmental Scientist - Water Resources Mana...</td>\n",
       "      <td>WSSC</td>\n",
       "      <td>Laurel, MD 20707</td>\n",
       "      <td>Ability to plan and direct the work of profess...</td>\n",
       "      <td>95396.5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Data Scientist - Mid-Level</td>\n",
       "      <td>National Security Agency</td>\n",
       "      <td>Fort Meade, MD</td>\n",
       "      <td>Exploit, fuse and use data and data sources. A...</td>\n",
       "      <td>92498.5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Operations Research Analyst</td>\n",
       "      <td>Department of Defense</td>\n",
       "      <td>Arlington, VA</td>\n",
       "      <td>Using statistical analysis techniques in order...</td>\n",
       "      <td>128825.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Statistical Data Analyst - US Citizen</td>\n",
       "      <td>PeopleTek</td>\n",
       "      <td>Bethesda, MD</td>\n",
       "      <td>STATISTICAL DATA ANALYST*. ï· Extract insights ...</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>Mesa</td>\n",
       "      <td>Institutional Research Analyst (Open until Fil...</td>\n",
       "      <td>Maricopa County Community College District</td>\n",
       "      <td>Phoenix, AZ</td>\n",
       "      <td>Develops queries on data warehouses using data...</td>\n",
       "      <td>55735.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>Mesa</td>\n",
       "      <td>Account Manager</td>\n",
       "      <td>The Creative Group</td>\n",
       "      <td>Phoenix, AZ 85016 (Camelback East area)</td>\n",
       "      <td>You're fascinated by data analytics:. You may ...</td>\n",
       "      <td>44000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>Mesa</td>\n",
       "      <td>Web Security Research Analyst</td>\n",
       "      <td>SiteLock</td>\n",
       "      <td>Scottsdale, AZ</td>\n",
       "      <td>About SiteLock: SiteLock is the global leader ...</td>\n",
       "      <td>52500.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>Mesa</td>\n",
       "      <td>ENVIRONMENTAL OUTREACH SPECIALIST</td>\n",
       "      <td>State of Arizona</td>\n",
       "      <td>Phoenix, AZ</td>\n",
       "      <td>Analyze environmental data to determine validi...</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>Mesa</td>\n",
       "      <td>AIR QUALITY PLANNER 2-3</td>\n",
       "      <td>State of Arizona</td>\n",
       "      <td>Phoenix, AZ</td>\n",
       "      <td>Ability to present data and findings in public...</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>Kansas City</td>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>Jackson County, Missouri</td>\n",
       "      <td>Kansas City, MO 64106 (Downtown area)</td>\n",
       "      <td>Verifies and analyzes real estate sales, lease...</td>\n",
       "      <td>20800.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>Kansas City</td>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>Jackson County Department of Corrections</td>\n",
       "      <td>Kansas City, MO</td>\n",
       "      <td>Verifies and analyzes real estate sales, lease...</td>\n",
       "      <td>20800.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>Kansas City</td>\n",
       "      <td>Material Handler</td>\n",
       "      <td>Honeywell</td>\n",
       "      <td>Kansas City, MO 64147 (Richards Gebaur area)</td>\n",
       "      <td>Maintains inventory data bases. Completes pape...</td>\n",
       "      <td>25600.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>Kansas City</td>\n",
       "      <td>Production Fabricator (Any Shift)</td>\n",
       "      <td>Honeywell</td>\n",
       "      <td>Kansas City, KS</td>\n",
       "      <td>Completes paperwork and computer data entries ...</td>\n",
       "      <td>25600.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>Kansas City</td>\n",
       "      <td>Inspector, Tool &amp; Precision Gage (Any Shift)</td>\n",
       "      <td>Honeywell</td>\n",
       "      <td>Kansas City, KS</td>\n",
       "      <td>Ability to analyze and interpret data. Must be...</td>\n",
       "      <td>36800.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>Kansas City</td>\n",
       "      <td>Tool &amp; Precision Gage Inspector (Any Shift)</td>\n",
       "      <td>Honeywell</td>\n",
       "      <td>Kansas City, KS</td>\n",
       "      <td>Ability to analyze and interpret data. Must be...</td>\n",
       "      <td>36800.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>Kansas City</td>\n",
       "      <td>Electronics Test Inspector (Any Shift)</td>\n",
       "      <td>Honeywell</td>\n",
       "      <td>Kansas City, MO 64147 (Richards Gebaur area)</td>\n",
       "      <td>May be required to examine and evaluate test d...</td>\n",
       "      <td>33600.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Piper Companies</td>\n",
       "      <td>Raleigh, NC 27607 (Northwest area)</td>\n",
       "      <td>The Data Scientist will be in charge of data m...</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Contract Statistician</td>\n",
       "      <td>Piper Companies</td>\n",
       "      <td>Research Triangle Park, NC 27709</td>\n",
       "      <td>Contract Statistician Statistician Description...</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>HPLC Scientist</td>\n",
       "      <td>Piper Companies</td>\n",
       "      <td>Durham, NC 27709</td>\n",
       "      <td>Responsibilities for the HPLC Scientist includ...</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>ITS Technologies</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>The *Senior Data Scientist*. Ability to collab...</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Statistical Programmer</td>\n",
       "      <td>Piper Companies</td>\n",
       "      <td>Morrisville, NC 27560</td>\n",
       "      <td>Creation of macro programs, perform data check...</td>\n",
       "      <td>96000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Sente Data Science, LLC</td>\n",
       "      <td>Cary, NC</td>\n",
       "      <td>Sente Data Science is seeking a Data Scientist...</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Research/Remediation Analyst</td>\n",
       "      <td>DISYS (Digital Intelligence SYStems Pvt. Ltd.)</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>A large Financial Services Organization in Ral...</td>\n",
       "      <td>35200.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Associate Scientist 3865</td>\n",
       "      <td>Hunter International</td>\n",
       "      <td>Research Triangle Park, NC</td>\n",
       "      <td>Analyzes data and prepares reports, upon reque...</td>\n",
       "      <td>46400.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Bioinformatics Scientist</td>\n",
       "      <td>Hunter International</td>\n",
       "      <td>Research Triangle Park, NC</td>\n",
       "      <td>Phenotypic data analysis. The scientist will w...</td>\n",
       "      <td>54400.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Piper Companies</td>\n",
       "      <td>Raleigh, NC 27617 (Central area)</td>\n",
       "      <td>Piper Enterprise Solutions is seeking Data Ana...</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Biologist / Entomologist</td>\n",
       "      <td>Hunter International</td>\n",
       "      <td>Research Triangle Park, NC</td>\n",
       "      <td>Work will be conducted under direct supervisio...</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Soc/Clin Research Specialist</td>\n",
       "      <td>University of North Carolina</td>\n",
       "      <td>Chapel Hill, NC 27517</td>\n",
       "      <td>Radiation oncology is a highly-integrated, mul...</td>\n",
       "      <td>45734.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Hadoop Integration Data Scientist</td>\n",
       "      <td>LifeScale Analytics</td>\n",
       "      <td>Raleigh-Durham, NC</td>\n",
       "      <td>Data Scientist with experience in experimental...</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Statistician II (Job Code: GR0218)</td>\n",
       "      <td>Seqirus A CSL Company</td>\n",
       "      <td>Holly Springs, NC</td>\n",
       "      <td>See below JOB TITLE: Statistician II (Job Code...</td>\n",
       "      <td>101830.5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Senior Data Scientist â Machine Learning</td>\n",
       "      <td>Strivector</td>\n",
       "      <td>Morrisville, NC</td>\n",
       "      <td>Senior Data Scientist â Machine Learning*. Men...</td>\n",
       "      <td>170000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Research Assistant</td>\n",
       "      <td>University of North Carolina</td>\n",
       "      <td>Chapel Hill, NC 27517</td>\n",
       "      <td>Approximately 25% time will be spent coding an...</td>\n",
       "      <td>32603.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Business Services Coordinator</td>\n",
       "      <td>North Carolina State University</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>Coordinate activities and logistics of visitin...</td>\n",
       "      <td>42945.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Director Data Scientist, Product</td>\n",
       "      <td>All-In Analytics</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>Director Data Scientist, Product. Motivate, co...</td>\n",
       "      <td>185000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows Ã 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                City                                              Title  \\\n",
       "0    Washington D.C.  Undergraduate Internship/Co-op Program - Data ...   \n",
       "1    Washington D.C.            Supervisory Operations Research Analyst   \n",
       "2    Washington D.C.                                     Data Scientist   \n",
       "3    Washington D.C.                                  Facilities Intern   \n",
       "4    Washington D.C.  Research Physical Scientist, AST, Atmospheric ...   \n",
       "5    Washington D.C.  Real Estate and Urban Planning Research Analys...   \n",
       "6    Washington D.C.       Statistician - Healthcare or Pharma Industry   \n",
       "7    Washington D.C.                                     Data Scientist   \n",
       "8    Washington D.C.                                     Data Scientist   \n",
       "9    Washington D.C.                Data Scientist - OUSD(I)-HCMO-DCIPS   \n",
       "10   Washington D.C.                                     Apps Developer   \n",
       "11   Washington D.C.                   Payroll Support Associate at EPA   \n",
       "12   Washington D.C.                           IFG Data Scientist Whiz!   \n",
       "13   Washington D.C.                                     Data Scientist   \n",
       "14   Washington D.C.           Staff Fellow (Mathematical Statistician)   \n",
       "15   Washington D.C.                        Operations Research Analyst   \n",
       "16   Washington D.C.                   Mathematicians - Entry/Mid-Level   \n",
       "17   Washington D.C.       Mathematical Statisticians - Entry/Mid-Level   \n",
       "18   Washington D.C.    2017-07-10 IT Program Manager Earning $$213,000   \n",
       "19   Washington D.C.                        Research Analyst (Vaccines)   \n",
       "20   Washington D.C.                        Operations Research Analyst   \n",
       "21   Washington D.C.                               Senior Data Engineer   \n",
       "22   Washington D.C.  Interdisciplinary, GS-0101,0180,0801,1550-12/1...   \n",
       "23   Washington D.C.                             Senior Product Manager   \n",
       "24   Washington D.C.                              Senior Data Scientist   \n",
       "25   Washington D.C.  Recent Graduate Survey Statistician, GS-1530-7...   \n",
       "26   Washington D.C.  Environmental Scientist - Water Resources Mana...   \n",
       "27   Washington D.C.                         Data Scientist - Mid-Level   \n",
       "28   Washington D.C.                        Operations Research Analyst   \n",
       "29   Washington D.C.              Statistical Data Analyst - US Citizen   \n",
       "..               ...                                                ...   \n",
       "411             Mesa  Institutional Research Analyst (Open until Fil...   \n",
       "412             Mesa                                    Account Manager   \n",
       "413             Mesa                      Web Security Research Analyst   \n",
       "414             Mesa                  ENVIRONMENTAL OUTREACH SPECIALIST   \n",
       "415             Mesa                            AIR QUALITY PLANNER 2-3   \n",
       "416      Kansas City                                   Research Analyst   \n",
       "417      Kansas City                                   Research Analyst   \n",
       "418      Kansas City                                   Material Handler   \n",
       "419      Kansas City                  Production Fabricator (Any Shift)   \n",
       "420      Kansas City       Inspector, Tool & Precision Gage (Any Shift)   \n",
       "421      Kansas City        Tool & Precision Gage Inspector (Any Shift)   \n",
       "422      Kansas City             Electronics Test Inspector (Any Shift)   \n",
       "423          Raleigh                                     Data Scientist   \n",
       "424          Raleigh                              Contract Statistician   \n",
       "425          Raleigh                                     HPLC Scientist   \n",
       "426          Raleigh                                     Data Scientist   \n",
       "427          Raleigh                             Statistical Programmer   \n",
       "428          Raleigh                                     Data Scientist   \n",
       "429          Raleigh                       Research/Remediation Analyst   \n",
       "430          Raleigh                           Associate Scientist 3865   \n",
       "431          Raleigh                           Bioinformatics Scientist   \n",
       "432          Raleigh                                       Data Analyst   \n",
       "433          Raleigh                           Biologist / Entomologist   \n",
       "434          Raleigh                       Soc/Clin Research Specialist   \n",
       "435          Raleigh                  Hadoop Integration Data Scientist   \n",
       "436          Raleigh                 Statistician II (Job Code: GR0218)   \n",
       "437          Raleigh           Senior Data Scientist â Machine Learning   \n",
       "438          Raleigh                                 Research Assistant   \n",
       "439          Raleigh                      Business Services Coordinator   \n",
       "440          Raleigh                   Director Data Scientist, Product   \n",
       "\n",
       "                                               Company  \\\n",
       "0                          Central Intelligence Agency   \n",
       "1              Department of Health And Human Services   \n",
       "2                       Metropolitan Police Department   \n",
       "3                    Natural Resources Defense Council   \n",
       "4        National Aeronautics and Space Administration   \n",
       "5    The Maryland-National Capital Park and Plannin...   \n",
       "6                        Contingent/Direct Consultants   \n",
       "7                          Central Intelligence Agency   \n",
       "8                                      Piper Companies   \n",
       "9                                       Red Gate Group   \n",
       "10                         Central Intelligence Agency   \n",
       "11                   Oak Ridge Associated Universities   \n",
       "12                     Interface Financial Group (IFG)   \n",
       "13             National Geospatial-Intelligence Agency   \n",
       "14             Department of Health And Human Services   \n",
       "15                          Department of the Treasury   \n",
       "16                            National Security Agency   \n",
       "17                            National Security Agency   \n",
       "18                                      EMF Industries   \n",
       "19                          Johnson Service Group Inc.   \n",
       "20                     Federal Aviation Administration   \n",
       "21                                     Piper Companies   \n",
       "22                              Department of Commerce   \n",
       "23                                            Catalist   \n",
       "24                                     Piper Companies   \n",
       "25                              Department of Commerce   \n",
       "26                                                WSSC   \n",
       "27                            National Security Agency   \n",
       "28                               Department of Defense   \n",
       "29                                           PeopleTek   \n",
       "..                                                 ...   \n",
       "411         Maricopa County Community College District   \n",
       "412                                 The Creative Group   \n",
       "413                                           SiteLock   \n",
       "414                                   State of Arizona   \n",
       "415                                   State of Arizona   \n",
       "416                           Jackson County, Missouri   \n",
       "417           Jackson County Department of Corrections   \n",
       "418                                          Honeywell   \n",
       "419                                          Honeywell   \n",
       "420                                          Honeywell   \n",
       "421                                          Honeywell   \n",
       "422                                          Honeywell   \n",
       "423                                    Piper Companies   \n",
       "424                                    Piper Companies   \n",
       "425                                    Piper Companies   \n",
       "426                                   ITS Technologies   \n",
       "427                                    Piper Companies   \n",
       "428                            Sente Data Science, LLC   \n",
       "429     DISYS (Digital Intelligence SYStems Pvt. Ltd.)   \n",
       "430                               Hunter International   \n",
       "431                               Hunter International   \n",
       "432                                    Piper Companies   \n",
       "433                               Hunter International   \n",
       "434                       University of North Carolina   \n",
       "435                                LifeScale Analytics   \n",
       "436                              Seqirus A CSL Company   \n",
       "437                                         Strivector   \n",
       "438                       University of North Carolina   \n",
       "439                    North Carolina State University   \n",
       "440                                   All-In Analytics   \n",
       "\n",
       "                                         Location  \\\n",
       "0                                  Washington, DC   \n",
       "1                               Silver Spring, MD   \n",
       "2                                  Washington, DC   \n",
       "3                                  Washington, DC   \n",
       "4                                   Greenbelt, MD   \n",
       "5                         Silver Spring, MD 20902   \n",
       "6                          Gaithersburg, MD 20877   \n",
       "7                                  Washington, DC   \n",
       "8                                Reston, VA 20190   \n",
       "9                                   Arlington, VA   \n",
       "10                                 Washington, DC   \n",
       "11                                 Washington, DC   \n",
       "12                                   Bethesda, MD   \n",
       "13                                Springfield, VA   \n",
       "14                                  Rockville, MD   \n",
       "15                                 Washington, DC   \n",
       "16                                 Fort Meade, MD   \n",
       "17                                 Fort Meade, MD   \n",
       "18                                     McLean, VA   \n",
       "19                            Rockville, MD 20850   \n",
       "20                                 Washington, DC   \n",
       "21                               Reston, VA 20190   \n",
       "22           Washington, DC 20230 (Downtown area)   \n",
       "23                                 Washington, DC   \n",
       "24                               Reston, VA 20190   \n",
       "25           Washington, DC 20230 (Downtown area)   \n",
       "26                               Laurel, MD 20707   \n",
       "27                                 Fort Meade, MD   \n",
       "28                                  Arlington, VA   \n",
       "29                                   Bethesda, MD   \n",
       "..                                            ...   \n",
       "411                                   Phoenix, AZ   \n",
       "412       Phoenix, AZ 85016 (Camelback East area)   \n",
       "413                                Scottsdale, AZ   \n",
       "414                                   Phoenix, AZ   \n",
       "415                                   Phoenix, AZ   \n",
       "416         Kansas City, MO 64106 (Downtown area)   \n",
       "417                               Kansas City, MO   \n",
       "418  Kansas City, MO 64147 (Richards Gebaur area)   \n",
       "419                               Kansas City, KS   \n",
       "420                               Kansas City, KS   \n",
       "421                               Kansas City, KS   \n",
       "422  Kansas City, MO 64147 (Richards Gebaur area)   \n",
       "423            Raleigh, NC 27607 (Northwest area)   \n",
       "424              Research Triangle Park, NC 27709   \n",
       "425                              Durham, NC 27709   \n",
       "426                                   Raleigh, NC   \n",
       "427                         Morrisville, NC 27560   \n",
       "428                                      Cary, NC   \n",
       "429                                   Raleigh, NC   \n",
       "430                    Research Triangle Park, NC   \n",
       "431                    Research Triangle Park, NC   \n",
       "432              Raleigh, NC 27617 (Central area)   \n",
       "433                    Research Triangle Park, NC   \n",
       "434                         Chapel Hill, NC 27517   \n",
       "435                            Raleigh-Durham, NC   \n",
       "436                             Holly Springs, NC   \n",
       "437                               Morrisville, NC   \n",
       "438                         Chapel Hill, NC 27517   \n",
       "439                                   Raleigh, NC   \n",
       "440                                   Raleigh, NC   \n",
       "\n",
       "                                           Job Summary    Salary  Binary  \\\n",
       "0    Students serving as Data Scientist interns wor...   36800.0   False   \n",
       "1    Develops alternative options to resolve comple...  146833.5    True   \n",
       "2    Or data visualization and interaction. The Dat...   86711.0    True   \n",
       "3    Maintain data bases, paper and electronic fili...   24000.0   False   \n",
       "4    Utilization of satellite data to test existing...  120212.5    True   \n",
       "5    Experience with Costar and other real estate d...   79475.0    True   \n",
       "6    Experience of Development, program design and ...  150000.0    True   \n",
       "7    Data Scientists organize and interpret Big Dat...   91066.0    True   \n",
       "8    Responsibilities for the Lead Data Scientist i...  210000.0    True   \n",
       "9    Data Scientist (full-time contract). Under thi...  112500.0    True   \n",
       "10   Big Data concepts and technologies such as Apa...   90936.0    True   \n",
       "11   Performing data entry in various ORD and Agenc...   35200.0   False   \n",
       "12   Data Scientists need to analyze financial data...  120000.0    True   \n",
       "13   Data Scientist **AMENDED**. Data Management, D...   90941.0    True   \n",
       "14   You will use statistical and mathematical meth...  101477.0    True   \n",
       "15   Determining the types of data to be collected,...  109015.0    True   \n",
       "16   These include, but are not limited to cryptogr...   77025.0    True   \n",
       "17   These include, but are not limited to, problem...   77025.0    True   \n",
       "18   Our talented group of Data Scientists, Develop...  213000.0    True   \n",
       "19   Provide effort & cost benchmarking & insights ...   78400.0    True   \n",
       "20   Business Component: Associate Administrator fo...   97825.0    True   \n",
       "21   Collaborate with a team of other data engineer...  195000.0    True   \n",
       "22   Assisting with organizing and analyzing resear...  101477.0    True   \n",
       "23   Conversant understanding of relational data an...   85000.0    True   \n",
       "24   Responsibilities for the Lead Data Scientist i...  210000.0    True   \n",
       "25   Analyze and evaluate data. Assist in data coll...   65700.5   False   \n",
       "26   Ability to plan and direct the work of profess...   95396.5    True   \n",
       "27   Exploit, fuse and use data and data sources. A...   92498.5    True   \n",
       "28   Using statistical analysis techniques in order...  128825.0    True   \n",
       "29   STATISTICAL DATA ANALYST*. ï· Extract insights ...   65000.0   False   \n",
       "..                                                 ...       ...     ...   \n",
       "411  Develops queries on data warehouses using data...   55735.0   False   \n",
       "412  You're fascinated by data analytics:. You may ...   44000.0   False   \n",
       "413  About SiteLock: SiteLock is the global leader ...   52500.0   False   \n",
       "414  Analyze environmental data to determine validi...   55000.0   False   \n",
       "415  Ability to present data and findings in public...   61000.0   False   \n",
       "416  Verifies and analyzes real estate sales, lease...   20800.0   False   \n",
       "417  Verifies and analyzes real estate sales, lease...   20800.0   False   \n",
       "418  Maintains inventory data bases. Completes pape...   25600.0   False   \n",
       "419  Completes paperwork and computer data entries ...   25600.0   False   \n",
       "420  Ability to analyze and interpret data. Must be...   36800.0   False   \n",
       "421  Ability to analyze and interpret data. Must be...   36800.0   False   \n",
       "422  May be required to examine and evaluate test d...   33600.0   False   \n",
       "423  The Data Scientist will be in charge of data m...  120000.0    True   \n",
       "424  Contract Statistician Statistician Description...  128000.0    True   \n",
       "425  Responsibilities for the HPLC Scientist includ...   48000.0   False   \n",
       "426  The *Senior Data Scientist*. Ability to collab...  150000.0    True   \n",
       "427  Creation of macro programs, perform data check...   96000.0    True   \n",
       "428  Sente Data Science is seeking a Data Scientist...   95000.0    True   \n",
       "429  A large Financial Services Organization in Ral...   35200.0   False   \n",
       "430  Analyzes data and prepares reports, upon reque...   46400.0   False   \n",
       "431  Phenotypic data analysis. The scientist will w...   54400.0   False   \n",
       "432  Piper Enterprise Solutions is seeking Data Ana...  105000.0    True   \n",
       "433  Work will be conducted under direct supervisio...   32000.0   False   \n",
       "434  Radiation oncology is a highly-integrated, mul...   45734.0   False   \n",
       "435  Data Scientist with experience in experimental...  140000.0    True   \n",
       "436  See below JOB TITLE: Statistician II (Job Code...  101830.5    True   \n",
       "437  Senior Data Scientist â Machine Learning*. Men...  170000.0    True   \n",
       "438  Approximately 25% time will be spent coding an...   32603.0   False   \n",
       "439  Coordinate activities and logistics of visitin...   42945.0   False   \n",
       "440  Director Data Scientist, Product. Motivate, co...  185000.0    True   \n",
       "\n",
       "     Senior Title  Manager Title  analyst     ...       manager  medical  \\\n",
       "0           False          False        0     ...             0        0   \n",
       "1           False          False        1     ...             0        0   \n",
       "2           False          False        0     ...             0        0   \n",
       "3           False          False        0     ...             0        0   \n",
       "4           False          False        0     ...             0        0   \n",
       "5           False          False        1     ...             0        0   \n",
       "6           False          False        0     ...             0        0   \n",
       "7           False          False        0     ...             0        0   \n",
       "8           False          False        0     ...             0        0   \n",
       "9           False          False        0     ...             0        0   \n",
       "10          False          False        0     ...             0        0   \n",
       "11          False          False        0     ...             0        0   \n",
       "12          False          False        0     ...             0        0   \n",
       "13          False          False        0     ...             0        0   \n",
       "14          False          False        0     ...             0        0   \n",
       "15          False          False        1     ...             0        0   \n",
       "16          False          False        0     ...             0        0   \n",
       "17          False          False        0     ...             0        0   \n",
       "18          False           True        0     ...             1        0   \n",
       "19          False          False        1     ...             0        0   \n",
       "20          False          False        1     ...             0        0   \n",
       "21           True          False        0     ...             0        0   \n",
       "22          False          False        0     ...             0        0   \n",
       "23           True           True        0     ...             1        0   \n",
       "24           True          False        0     ...             0        0   \n",
       "25          False          False        0     ...             0        0   \n",
       "26          False          False        0     ...             0        0   \n",
       "27          False          False        0     ...             0        0   \n",
       "28          False          False        1     ...             0        0   \n",
       "29          False          False        1     ...             0        0   \n",
       "..            ...            ...      ...     ...           ...      ...   \n",
       "411         False          False        1     ...             0        0   \n",
       "412         False           True        0     ...             1        0   \n",
       "413         False          False        1     ...             0        0   \n",
       "414         False          False        0     ...             0        0   \n",
       "415         False          False        0     ...             0        0   \n",
       "416         False          False        1     ...             0        0   \n",
       "417         False          False        1     ...             0        0   \n",
       "418         False          False        0     ...             0        0   \n",
       "419         False          False        0     ...             0        0   \n",
       "420         False          False        0     ...             0        0   \n",
       "421         False          False        0     ...             0        0   \n",
       "422         False          False        0     ...             0        0   \n",
       "423         False          False        0     ...             0        0   \n",
       "424         False          False        0     ...             0        0   \n",
       "425         False          False        0     ...             0        0   \n",
       "426         False          False        0     ...             0        0   \n",
       "427         False          False        0     ...             0        0   \n",
       "428         False          False        0     ...             0        0   \n",
       "429         False          False        1     ...             0        0   \n",
       "430         False          False        0     ...             0        0   \n",
       "431         False          False        0     ...             0        0   \n",
       "432         False          False        1     ...             0        0   \n",
       "433         False          False        0     ...             0        0   \n",
       "434         False          False        0     ...             0        0   \n",
       "435         False          False        0     ...             0        0   \n",
       "436         False          False        0     ...             0        0   \n",
       "437          True          False        0     ...             0        0   \n",
       "438         False          False        0     ...             0        0   \n",
       "439         False          False        0     ...             0        0   \n",
       "440         False          False        0     ...             0        0   \n",
       "\n",
       "     program  research  scientist  senior  software  specialist  sr  \\\n",
       "0          1         0          1       0         0           0   0   \n",
       "1          0         1          0       0         0           0   0   \n",
       "2          0         0          1       0         0           0   0   \n",
       "3          0         0          0       0         0           0   0   \n",
       "4          0         1          1       0         0           0   0   \n",
       "5          0         1          0       0         0           0   0   \n",
       "6          0         0          0       0         0           0   0   \n",
       "7          0         0          1       0         0           0   0   \n",
       "8          0         0          1       0         0           0   0   \n",
       "9          0         0          1       0         0           0   0   \n",
       "10         0         0          0       0         0           0   0   \n",
       "11         0         0          0       0         0           0   0   \n",
       "12         0         0          1       0         0           0   0   \n",
       "13         0         0          1       0         0           0   0   \n",
       "14         0         0          0       0         0           0   0   \n",
       "15         0         1          0       0         0           0   0   \n",
       "16         0         0          0       0         0           0   0   \n",
       "17         0         0          0       0         0           0   0   \n",
       "18         1         0          0       0         0           0   0   \n",
       "19         0         1          0       0         0           0   0   \n",
       "20         0         1          0       0         0           0   0   \n",
       "21         0         0          0       1         0           0   0   \n",
       "22         0         0          0       0         0           0   0   \n",
       "23         0         0          0       1         0           0   0   \n",
       "24         0         0          1       1         0           0   0   \n",
       "25         0         0          0       0         0           0   0   \n",
       "26         0         0          1       0         0           0   0   \n",
       "27         0         0          1       0         0           0   0   \n",
       "28         0         1          0       0         0           0   0   \n",
       "29         0         0          0       0         0           0   0   \n",
       "..       ...       ...        ...     ...       ...         ...  ..   \n",
       "411        0         1          0       0         0           0   0   \n",
       "412        0         0          0       0         0           0   0   \n",
       "413        0         1          0       0         0           0   0   \n",
       "414        0         0          0       0         0           1   0   \n",
       "415        0         0          0       0         0           0   0   \n",
       "416        0         1          0       0         0           0   0   \n",
       "417        0         1          0       0         0           0   0   \n",
       "418        0         0          0       0         0           0   0   \n",
       "419        0         0          0       0         0           0   0   \n",
       "420        0         0          0       0         0           0   0   \n",
       "421        0         0          0       0         0           0   0   \n",
       "422        0         0          0       0         0           0   0   \n",
       "423        0         0          1       0         0           0   0   \n",
       "424        0         0          0       0         0           0   0   \n",
       "425        0         0          1       0         0           0   0   \n",
       "426        0         0          1       0         0           0   0   \n",
       "427        0         0          0       0         0           0   0   \n",
       "428        0         0          1       0         0           0   0   \n",
       "429        0         1          0       0         0           0   0   \n",
       "430        0         0          1       0         0           0   0   \n",
       "431        0         0          1       0         0           0   0   \n",
       "432        0         0          0       0         0           0   0   \n",
       "433        0         0          0       0         0           0   0   \n",
       "434        0         1          0       0         0           1   0   \n",
       "435        0         0          1       0         0           0   0   \n",
       "436        0         0          0       0         0           0   0   \n",
       "437        0         0          1       1         0           0   0   \n",
       "438        0         1          0       0         0           0   0   \n",
       "439        0         0          0       0         0           0   0   \n",
       "440        0         0          1       0         0           0   0   \n",
       "\n",
       "     statistical  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "5              0  \n",
       "6              0  \n",
       "7              0  \n",
       "8              0  \n",
       "9              0  \n",
       "10             0  \n",
       "11             0  \n",
       "12             0  \n",
       "13             0  \n",
       "14             0  \n",
       "15             0  \n",
       "16             0  \n",
       "17             0  \n",
       "18             0  \n",
       "19             0  \n",
       "20             0  \n",
       "21             0  \n",
       "22             0  \n",
       "23             0  \n",
       "24             0  \n",
       "25             0  \n",
       "26             0  \n",
       "27             0  \n",
       "28             0  \n",
       "29             1  \n",
       "..           ...  \n",
       "411            0  \n",
       "412            0  \n",
       "413            0  \n",
       "414            0  \n",
       "415            0  \n",
       "416            0  \n",
       "417            0  \n",
       "418            0  \n",
       "419            0  \n",
       "420            0  \n",
       "421            0  \n",
       "422            0  \n",
       "423            0  \n",
       "424            0  \n",
       "425            0  \n",
       "426            0  \n",
       "427            1  \n",
       "428            0  \n",
       "429            0  \n",
       "430            0  \n",
       "431            0  \n",
       "432            0  \n",
       "433            0  \n",
       "434            0  \n",
       "435            0  \n",
       "436            0  \n",
       "437            0  \n",
       "438            0  \n",
       "439            0  \n",
       "440            0  \n",
       "\n",
       "[441 rows x 34 columns]"
      ]
     },
     "execution_count": 799,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Large_df = pd.concat([data, vocab2], axis=1) #concatenate data df and vocab df\n",
    "Large_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Large_df.loc[:,'academic':'youth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Salary</th>\n",
       "      <th>Binary</th>\n",
       "      <th>City</th>\n",
       "      <th>analyst</th>\n",
       "      <th>analytics</th>\n",
       "      <th>assistant</th>\n",
       "      <th>associate</th>\n",
       "      <th>bureau</th>\n",
       "      <th>clinical</th>\n",
       "      <th>data</th>\n",
       "      <th>...</th>\n",
       "      <th>manager</th>\n",
       "      <th>medical</th>\n",
       "      <th>program</th>\n",
       "      <th>research</th>\n",
       "      <th>scientist</th>\n",
       "      <th>senior</th>\n",
       "      <th>software</th>\n",
       "      <th>specialist</th>\n",
       "      <th>sr</th>\n",
       "      <th>statistical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36800.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>146833.5</td>\n",
       "      <td>True</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86711.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120212.5</td>\n",
       "      <td>True</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>79475.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>91066.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>210000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>112500.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>90936.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>35200.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>120000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>90941.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>101477.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>109015.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>77025.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>77025.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>213000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>78400.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>97825.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>195000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>101477.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>85000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>210000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>65700.5</td>\n",
       "      <td>False</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>95396.5</td>\n",
       "      <td>True</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>92498.5</td>\n",
       "      <td>True</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>128825.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>65000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>55735.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Mesa</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>44000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Mesa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>52500.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Mesa</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>55000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Mesa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>61000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Mesa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>20800.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Kansas City</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>20800.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Kansas City</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>25600.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Kansas City</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>25600.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Kansas City</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>36800.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Kansas City</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>36800.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Kansas City</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>33600.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Kansas City</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>120000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Raleigh</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>128000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Raleigh</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>48000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Raleigh</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Raleigh</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>96000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Raleigh</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>95000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Raleigh</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>35200.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Raleigh</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>46400.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Raleigh</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>54400.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Raleigh</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>105000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Raleigh</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>32000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Raleigh</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>45734.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Raleigh</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>140000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Raleigh</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>101830.5</td>\n",
       "      <td>True</td>\n",
       "      <td>Raleigh</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>170000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Raleigh</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>32603.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Raleigh</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>42945.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Raleigh</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>185000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Raleigh</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows Ã 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Salary  Binary             City  analyst  analytics  assistant  \\\n",
       "0     36800.0   False  Washington D.C.        0          0          0   \n",
       "1    146833.5    True  Washington D.C.        1          0          0   \n",
       "2     86711.0    True  Washington D.C.        0          0          0   \n",
       "3     24000.0   False  Washington D.C.        0          0          0   \n",
       "4    120212.5    True  Washington D.C.        0          0          0   \n",
       "5     79475.0    True  Washington D.C.        1          0          0   \n",
       "6    150000.0    True  Washington D.C.        0          0          0   \n",
       "7     91066.0    True  Washington D.C.        0          0          0   \n",
       "8    210000.0    True  Washington D.C.        0          0          0   \n",
       "9    112500.0    True  Washington D.C.        0          0          0   \n",
       "10    90936.0    True  Washington D.C.        0          0          0   \n",
       "11    35200.0   False  Washington D.C.        0          0          0   \n",
       "12   120000.0    True  Washington D.C.        0          0          0   \n",
       "13    90941.0    True  Washington D.C.        0          0          0   \n",
       "14   101477.0    True  Washington D.C.        0          0          0   \n",
       "15   109015.0    True  Washington D.C.        1          0          0   \n",
       "16    77025.0    True  Washington D.C.        0          0          0   \n",
       "17    77025.0    True  Washington D.C.        0          0          0   \n",
       "18   213000.0    True  Washington D.C.        0          0          0   \n",
       "19    78400.0    True  Washington D.C.        1          0          0   \n",
       "20    97825.0    True  Washington D.C.        1          0          0   \n",
       "21   195000.0    True  Washington D.C.        0          0          0   \n",
       "22   101477.0    True  Washington D.C.        0          0          0   \n",
       "23    85000.0    True  Washington D.C.        0          0          0   \n",
       "24   210000.0    True  Washington D.C.        0          0          0   \n",
       "25    65700.5   False  Washington D.C.        0          0          0   \n",
       "26    95396.5    True  Washington D.C.        0          0          0   \n",
       "27    92498.5    True  Washington D.C.        0          0          0   \n",
       "28   128825.0    True  Washington D.C.        1          0          0   \n",
       "29    65000.0   False  Washington D.C.        1          0          0   \n",
       "..        ...     ...              ...      ...        ...        ...   \n",
       "411   55735.0   False             Mesa        1          0          0   \n",
       "412   44000.0   False             Mesa        0          0          0   \n",
       "413   52500.0   False             Mesa        1          0          0   \n",
       "414   55000.0   False             Mesa        0          0          0   \n",
       "415   61000.0   False             Mesa        0          0          0   \n",
       "416   20800.0   False      Kansas City        1          0          0   \n",
       "417   20800.0   False      Kansas City        1          0          0   \n",
       "418   25600.0   False      Kansas City        0          0          0   \n",
       "419   25600.0   False      Kansas City        0          0          0   \n",
       "420   36800.0   False      Kansas City        0          0          0   \n",
       "421   36800.0   False      Kansas City        0          0          0   \n",
       "422   33600.0   False      Kansas City        0          0          0   \n",
       "423  120000.0    True          Raleigh        0          0          0   \n",
       "424  128000.0    True          Raleigh        0          0          0   \n",
       "425   48000.0   False          Raleigh        0          0          0   \n",
       "426  150000.0    True          Raleigh        0          0          0   \n",
       "427   96000.0    True          Raleigh        0          0          0   \n",
       "428   95000.0    True          Raleigh        0          0          0   \n",
       "429   35200.0   False          Raleigh        1          0          0   \n",
       "430   46400.0   False          Raleigh        0          0          0   \n",
       "431   54400.0   False          Raleigh        0          0          0   \n",
       "432  105000.0    True          Raleigh        1          0          0   \n",
       "433   32000.0   False          Raleigh        0          0          0   \n",
       "434   45734.0   False          Raleigh        0          0          0   \n",
       "435  140000.0    True          Raleigh        0          0          0   \n",
       "436  101830.5    True          Raleigh        0          0          0   \n",
       "437  170000.0    True          Raleigh        0          0          0   \n",
       "438   32603.0   False          Raleigh        0          0          1   \n",
       "439   42945.0   False          Raleigh        0          0          0   \n",
       "440  185000.0    True          Raleigh        0          0          0   \n",
       "\n",
       "     associate  bureau  clinical  data     ...       manager  medical  \\\n",
       "0            0       0         0     1     ...             0        0   \n",
       "1            0       0         0     0     ...             0        0   \n",
       "2            0       0         0     1     ...             0        0   \n",
       "3            0       0         0     0     ...             0        0   \n",
       "4            0       0         0     0     ...             0        0   \n",
       "5            0       0         0     0     ...             0        0   \n",
       "6            0       0         0     0     ...             0        0   \n",
       "7            0       0         0     1     ...             0        0   \n",
       "8            0       0         0     1     ...             0        0   \n",
       "9            0       0         0     1     ...             0        0   \n",
       "10           0       0         0     0     ...             0        0   \n",
       "11           1       0         0     0     ...             0        0   \n",
       "12           0       0         0     1     ...             0        0   \n",
       "13           0       0         0     1     ...             0        0   \n",
       "14           0       0         0     0     ...             0        0   \n",
       "15           0       0         0     0     ...             0        0   \n",
       "16           0       0         0     0     ...             0        0   \n",
       "17           0       0         0     0     ...             0        0   \n",
       "18           0       0         0     0     ...             1        0   \n",
       "19           0       0         0     0     ...             0        0   \n",
       "20           0       0         0     0     ...             0        0   \n",
       "21           0       0         0     1     ...             0        0   \n",
       "22           0       0         0     0     ...             0        0   \n",
       "23           0       0         0     0     ...             1        0   \n",
       "24           0       0         0     1     ...             0        0   \n",
       "25           0       0         0     0     ...             0        0   \n",
       "26           0       0         0     0     ...             0        0   \n",
       "27           0       0         0     1     ...             0        0   \n",
       "28           0       0         0     0     ...             0        0   \n",
       "29           0       0         0     1     ...             0        0   \n",
       "..         ...     ...       ...   ...     ...           ...      ...   \n",
       "411          0       0         0     0     ...             0        0   \n",
       "412          0       0         0     0     ...             1        0   \n",
       "413          0       0         0     0     ...             0        0   \n",
       "414          0       0         0     0     ...             0        0   \n",
       "415          0       0         0     0     ...             0        0   \n",
       "416          0       0         0     0     ...             0        0   \n",
       "417          0       0         0     0     ...             0        0   \n",
       "418          0       0         0     0     ...             0        0   \n",
       "419          0       0         0     0     ...             0        0   \n",
       "420          0       0         0     0     ...             0        0   \n",
       "421          0       0         0     0     ...             0        0   \n",
       "422          0       0         0     0     ...             0        0   \n",
       "423          0       0         0     1     ...             0        0   \n",
       "424          0       0         0     0     ...             0        0   \n",
       "425          0       0         0     0     ...             0        0   \n",
       "426          0       0         0     1     ...             0        0   \n",
       "427          0       0         0     0     ...             0        0   \n",
       "428          0       0         0     1     ...             0        0   \n",
       "429          0       0         0     0     ...             0        0   \n",
       "430          1       0         0     0     ...             0        0   \n",
       "431          0       0         0     0     ...             0        0   \n",
       "432          0       0         0     1     ...             0        0   \n",
       "433          0       0         0     0     ...             0        0   \n",
       "434          0       0         0     0     ...             0        0   \n",
       "435          0       0         0     1     ...             0        0   \n",
       "436          0       0         0     0     ...             0        0   \n",
       "437          0       0         0     1     ...             0        0   \n",
       "438          0       0         0     0     ...             0        0   \n",
       "439          0       0         0     0     ...             0        0   \n",
       "440          0       0         0     1     ...             0        0   \n",
       "\n",
       "     program  research  scientist  senior  software  specialist  sr  \\\n",
       "0          1         0          1       0         0           0   0   \n",
       "1          0         1          0       0         0           0   0   \n",
       "2          0         0          1       0         0           0   0   \n",
       "3          0         0          0       0         0           0   0   \n",
       "4          0         1          1       0         0           0   0   \n",
       "5          0         1          0       0         0           0   0   \n",
       "6          0         0          0       0         0           0   0   \n",
       "7          0         0          1       0         0           0   0   \n",
       "8          0         0          1       0         0           0   0   \n",
       "9          0         0          1       0         0           0   0   \n",
       "10         0         0          0       0         0           0   0   \n",
       "11         0         0          0       0         0           0   0   \n",
       "12         0         0          1       0         0           0   0   \n",
       "13         0         0          1       0         0           0   0   \n",
       "14         0         0          0       0         0           0   0   \n",
       "15         0         1          0       0         0           0   0   \n",
       "16         0         0          0       0         0           0   0   \n",
       "17         0         0          0       0         0           0   0   \n",
       "18         1         0          0       0         0           0   0   \n",
       "19         0         1          0       0         0           0   0   \n",
       "20         0         1          0       0         0           0   0   \n",
       "21         0         0          0       1         0           0   0   \n",
       "22         0         0          0       0         0           0   0   \n",
       "23         0         0          0       1         0           0   0   \n",
       "24         0         0          1       1         0           0   0   \n",
       "25         0         0          0       0         0           0   0   \n",
       "26         0         0          1       0         0           0   0   \n",
       "27         0         0          1       0         0           0   0   \n",
       "28         0         1          0       0         0           0   0   \n",
       "29         0         0          0       0         0           0   0   \n",
       "..       ...       ...        ...     ...       ...         ...  ..   \n",
       "411        0         1          0       0         0           0   0   \n",
       "412        0         0          0       0         0           0   0   \n",
       "413        0         1          0       0         0           0   0   \n",
       "414        0         0          0       0         0           1   0   \n",
       "415        0         0          0       0         0           0   0   \n",
       "416        0         1          0       0         0           0   0   \n",
       "417        0         1          0       0         0           0   0   \n",
       "418        0         0          0       0         0           0   0   \n",
       "419        0         0          0       0         0           0   0   \n",
       "420        0         0          0       0         0           0   0   \n",
       "421        0         0          0       0         0           0   0   \n",
       "422        0         0          0       0         0           0   0   \n",
       "423        0         0          1       0         0           0   0   \n",
       "424        0         0          0       0         0           0   0   \n",
       "425        0         0          1       0         0           0   0   \n",
       "426        0         0          1       0         0           0   0   \n",
       "427        0         0          0       0         0           0   0   \n",
       "428        0         0          1       0         0           0   0   \n",
       "429        0         1          0       0         0           0   0   \n",
       "430        0         0          1       0         0           0   0   \n",
       "431        0         0          1       0         0           0   0   \n",
       "432        0         0          0       0         0           0   0   \n",
       "433        0         0          0       0         0           0   0   \n",
       "434        0         1          0       0         0           1   0   \n",
       "435        0         0          1       0         0           0   0   \n",
       "436        0         0          0       0         0           0   0   \n",
       "437        0         0          1       1         0           0   0   \n",
       "438        0         1          0       0         0           0   0   \n",
       "439        0         0          0       0         0           0   0   \n",
       "440        0         0          1       0         0           0   0   \n",
       "\n",
       "     statistical  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "5              0  \n",
       "6              0  \n",
       "7              0  \n",
       "8              0  \n",
       "9              0  \n",
       "10             0  \n",
       "11             0  \n",
       "12             0  \n",
       "13             0  \n",
       "14             0  \n",
       "15             0  \n",
       "16             0  \n",
       "17             0  \n",
       "18             0  \n",
       "19             0  \n",
       "20             0  \n",
       "21             0  \n",
       "22             0  \n",
       "23             0  \n",
       "24             0  \n",
       "25             0  \n",
       "26             0  \n",
       "27             0  \n",
       "28             0  \n",
       "29             1  \n",
       "..           ...  \n",
       "411            0  \n",
       "412            0  \n",
       "413            0  \n",
       "414            0  \n",
       "415            0  \n",
       "416            0  \n",
       "417            0  \n",
       "418            0  \n",
       "419            0  \n",
       "420            0  \n",
       "421            0  \n",
       "422            0  \n",
       "423            0  \n",
       "424            0  \n",
       "425            0  \n",
       "426            0  \n",
       "427            1  \n",
       "428            0  \n",
       "429            0  \n",
       "430            0  \n",
       "431            0  \n",
       "432            0  \n",
       "433            0  \n",
       "434            0  \n",
       "435            0  \n",
       "436            0  \n",
       "437            0  \n",
       "438            0  \n",
       "439            0  \n",
       "440            0  \n",
       "\n",
       "[441 rows x 28 columns]"
      ]
     },
     "execution_count": 801,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df =  Large_df[['Salary','Binary','City']] #create df containing vocab df and relevant columns for model form Large_df\n",
    "City_words = pd.concat([temp_df, vocab2], axis=1)\n",
    "City_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 26) (132,)\n",
      "(309, 26) (309,)\n"
     ]
    }
   ],
   "source": [
    "X = City_words.loc[:,'City':'statistical'] #Feature #Using City over Location as they are both the general area Location of the job\n",
    "y = City_words['Binary'] #Aim of Predicting Binary T|F based on City \n",
    "#train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.3, random_state=3)\n",
    "print X_train.shape, y_train.shape\n",
    "print X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analyst</th>\n",
       "      <th>analytics</th>\n",
       "      <th>assistant</th>\n",
       "      <th>associate</th>\n",
       "      <th>bureau</th>\n",
       "      <th>clinical</th>\n",
       "      <th>data</th>\n",
       "      <th>developer</th>\n",
       "      <th>engineer</th>\n",
       "      <th>engineering</th>\n",
       "      <th>...</th>\n",
       "      <th>manager</th>\n",
       "      <th>medical</th>\n",
       "      <th>program</th>\n",
       "      <th>research</th>\n",
       "      <th>scientist</th>\n",
       "      <th>senior</th>\n",
       "      <th>software</th>\n",
       "      <th>specialist</th>\n",
       "      <th>sr</th>\n",
       "      <th>statistical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows Ã 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     analyst  analytics  assistant  associate  bureau  clinical  data  \\\n",
       "264        0          0          0          0       0         0     0   \n",
       "276        1          0          0          0       0         0     0   \n",
       "8          0          0          0          0       0         0     1   \n",
       "309        0          0          0          0       0         0     0   \n",
       "283        0          0          0          0       0         0     0   \n",
       "92         0          1          0          0       0         0     1   \n",
       "252        0          0          0          0       0         0     0   \n",
       "32         0          0          0          0       0         0     1   \n",
       "135        0          0          0          0       0         0     0   \n",
       "22         0          0          0          0       0         0     0   \n",
       "62         0          0          0          0       0         0     0   \n",
       "426        0          0          0          0       0         0     1   \n",
       "215        0          0          0          0       0         0     0   \n",
       "440        0          0          0          0       0         0     1   \n",
       "389        0          0          0          0       0         1     0   \n",
       "257        0          0          0          0       0         0     0   \n",
       "52         1          0          0          0       1         0     0   \n",
       "432        1          0          0          0       0         0     1   \n",
       "173        0          0          0          0       0         0     1   \n",
       "35         1          0          0          0       1         0     1   \n",
       "178        1          0          0          0       0         0     0   \n",
       "167        0          0          0          0       0         1     0   \n",
       "226        0          0          0          0       0         1     0   \n",
       "120        0          0          0          0       0         0     0   \n",
       "275        1          0          0          0       0         0     0   \n",
       "44         0          0          0          0       0         0     1   \n",
       "300        1          0          0          0       0         0     0   \n",
       "324        0          0          0          0       0         0     0   \n",
       "76         0          0          0          0       0         0     1   \n",
       "208        0          0          0          0       0         0     0   \n",
       "..       ...        ...        ...        ...     ...       ...   ...   \n",
       "97         0          0          0          0       0         0     0   \n",
       "110        0          0          0          0       0         0     1   \n",
       "360        0          0          0          0       0         0     0   \n",
       "69         0          0          0          0       0         0     1   \n",
       "346        1          0          0          0       0         0     0   \n",
       "129        0          0          0          1       0         0     0   \n",
       "316        0          0          0          0       0         0     0   \n",
       "258        0          0          0          0       0         0     0   \n",
       "322        0          0          0          0       0         0     0   \n",
       "150        1          0          0          0       0         0     0   \n",
       "337        0          0          0          0       0         0     0   \n",
       "26         0          0          0          0       0         0     0   \n",
       "398        0          0          1          0       0         0     0   \n",
       "423        0          0          0          0       0         0     1   \n",
       "93         0          0          0          0       0         0     1   \n",
       "148        1          0          0          0       0         0     0   \n",
       "422        0          0          0          0       0         0     0   \n",
       "119        1          0          0          0       0         0     0   \n",
       "405        0          0          1          0       0         0     0   \n",
       "138        0          0          0          0       0         0     0   \n",
       "169        0          0          0          0       0         0     0   \n",
       "363        0          0          0          0       0         0     0   \n",
       "202        0          0          0          0       0         0     0   \n",
       "147        1          0          0          0       0         0     0   \n",
       "277        0          0          0          0       0         0     0   \n",
       "256        1          0          0          0       0         0     0   \n",
       "131        0          0          0          1       0         0     0   \n",
       "249        1          0          0          0       0         0     0   \n",
       "152        0          0          0          0       0         1     0   \n",
       "362        1          0          0          0       0         0     0   \n",
       "\n",
       "     developer  engineer  engineering     ...       manager  medical  program  \\\n",
       "264          0         0            0     ...             0        0        0   \n",
       "276          0         0            0     ...             0        0        0   \n",
       "8            0         0            0     ...             0        0        0   \n",
       "309          0         0            0     ...             0        0        0   \n",
       "283          0         0            0     ...             0        1        0   \n",
       "92           0         0            0     ...             0        0        0   \n",
       "252          0         0            0     ...             1        0        0   \n",
       "32           0         0            0     ...             1        0        0   \n",
       "135          0         0            1     ...             0        0        0   \n",
       "22           0         0            0     ...             0        0        0   \n",
       "62           0         0            0     ...             0        0        0   \n",
       "426          0         0            0     ...             0        0        0   \n",
       "215          0         0            0     ...             0        0        0   \n",
       "440          0         0            0     ...             0        0        0   \n",
       "389          0         0            0     ...             0        0        0   \n",
       "257          0         0            0     ...             0        0        0   \n",
       "52           0         0            0     ...             0        0        0   \n",
       "432          0         0            0     ...             0        0        0   \n",
       "173          0         0            0     ...             0        0        0   \n",
       "35           0         0            0     ...             0        0        0   \n",
       "178          0         0            0     ...             0        0        0   \n",
       "167          0         0            0     ...             0        0        0   \n",
       "226          0         0            0     ...             0        0        0   \n",
       "120          0         1            0     ...             0        0        0   \n",
       "275          0         0            0     ...             0        0        0   \n",
       "44           0         0            0     ...             0        0        0   \n",
       "300          0         0            0     ...             0        0        0   \n",
       "324          0         0            0     ...             0        0        0   \n",
       "76           0         0            0     ...             0        0        0   \n",
       "208          0         0            0     ...             0        0        1   \n",
       "..         ...       ...          ...     ...           ...      ...      ...   \n",
       "97           0         0            0     ...             0        1        0   \n",
       "110          0         0            0     ...             0        0        0   \n",
       "360          0         0            0     ...             0        0        0   \n",
       "69           1         1            0     ...             0        0        0   \n",
       "346          0         0            0     ...             0        0        0   \n",
       "129          0         0            1     ...             0        0        0   \n",
       "316          0         0            0     ...             1        0        0   \n",
       "258          0         0            0     ...             0        0        0   \n",
       "322          0         0            0     ...             0        0        0   \n",
       "150          0         0            0     ...             0        0        0   \n",
       "337          0         0            0     ...             1        0        1   \n",
       "26           0         0            0     ...             0        0        0   \n",
       "398          0         0            0     ...             0        0        0   \n",
       "423          0         0            0     ...             0        0        0   \n",
       "93           0         0            0     ...             0        0        0   \n",
       "148          0         0            0     ...             0        0        0   \n",
       "422          0         0            0     ...             0        0        0   \n",
       "119          0         0            0     ...             0        0        0   \n",
       "405          0         0            0     ...             0        0        0   \n",
       "138          0         1            1     ...             0        0        0   \n",
       "169          1         0            0     ...             0        0        0   \n",
       "363          0         1            0     ...             0        0        0   \n",
       "202          0         0            0     ...             0        0        0   \n",
       "147          0         0            0     ...             0        0        0   \n",
       "277          0         0            0     ...             0        0        0   \n",
       "256          0         0            0     ...             0        0        0   \n",
       "131          0         0            1     ...             0        0        0   \n",
       "249          0         0            0     ...             0        0        0   \n",
       "152          0         0            0     ...             0        0        0   \n",
       "362          0         0            0     ...             0        0        0   \n",
       "\n",
       "     research  scientist  senior  software  specialist  sr  statistical  \n",
       "264         0          0       1         1           0   0            0  \n",
       "276         1          0       0         0           0   0            1  \n",
       "8           0          1       0         0           0   0            0  \n",
       "309         0          0       0         0           0   0            0  \n",
       "283         0          1       0         0           0   0            0  \n",
       "92          0          1       0         0           0   0            0  \n",
       "252         0          0       0         0           0   0            0  \n",
       "32          0          0       0         0           0   0            0  \n",
       "135         0          1       0         0           0   0            0  \n",
       "22          0          0       0         0           0   0            0  \n",
       "62          1          1       0         0           0   0            0  \n",
       "426         0          1       0         0           0   0            0  \n",
       "215         0          0       0         0           0   0            0  \n",
       "440         0          1       0         0           0   0            0  \n",
       "389         1          0       1         0           0   0            0  \n",
       "257         0          0       0         0           1   0            0  \n",
       "52          0          0       1         0           0   0            0  \n",
       "432         0          0       0         0           0   0            0  \n",
       "173         0          1       0         0           0   0            0  \n",
       "35          0          0       0         0           0   0            0  \n",
       "178         0          0       0         0           0   0            0  \n",
       "167         0          1       0         0           0   0            0  \n",
       "226         0          0       0         0           0   0            0  \n",
       "120         0          0       0         0           0   0            0  \n",
       "275         1          0       0         0           0   0            1  \n",
       "44          0          1       0         0           0   0            0  \n",
       "300         1          0       0         0           0   0            0  \n",
       "324         0          0       0         0           0   0            0  \n",
       "76          0          1       0         0           0   0            0  \n",
       "208         0          0       0         0           0   0            0  \n",
       "..        ...        ...     ...       ...         ...  ..          ...  \n",
       "97          0          0       0         0           0   0            0  \n",
       "110         0          1       0         0           0   0            0  \n",
       "360         0          0       0         0           0   0            0  \n",
       "69          0          0       0         0           0   1            0  \n",
       "346         1          0       0         0           0   0            0  \n",
       "129         1          1       0         0           0   0            0  \n",
       "316         0          0       0         0           0   0            0  \n",
       "258         0          0       0         0           0   0            0  \n",
       "322         0          1       0         0           0   0            0  \n",
       "150         1          0       0         0           0   0            0  \n",
       "337         0          1       0         0           0   0            0  \n",
       "26          0          1       0         0           0   0            0  \n",
       "398         0          0       0         0           0   0            0  \n",
       "423         0          1       0         0           0   0            0  \n",
       "93          0          1       0         0           0   0            0  \n",
       "148         1          0       0         0           0   0            0  \n",
       "422         0          0       0         0           0   0            0  \n",
       "119         0          0       0         0           0   1            1  \n",
       "405         0          0       0         0           0   1            0  \n",
       "138         1          1       1         1           0   0            0  \n",
       "169         1          0       0         0           0   0            0  \n",
       "363         0          0       0         0           0   0            0  \n",
       "202         0          1       0         0           0   0            0  \n",
       "147         1          0       0         0           0   0            0  \n",
       "277         1          1       0         0           0   0            0  \n",
       "256         1          0       0         0           0   0            0  \n",
       "131         0          1       0         0           0   0            0  \n",
       "249         1          0       0         0           0   0            1  \n",
       "152         0          1       0         0           0   0            0  \n",
       "362         1          0       0         0           0   0            0  \n",
       "\n",
       "[132 rows x 25 columns]"
      ]
     },
     "execution_count": 817,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_words = X_train.loc[:,'analyst':'statistical']\n",
    "X_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Atlanta</th>\n",
       "      <th>Austin</th>\n",
       "      <th>Baltimore</th>\n",
       "      <th>Boston</th>\n",
       "      <th>Chicago</th>\n",
       "      <th>Columbus</th>\n",
       "      <th>Dallas</th>\n",
       "      <th>Denver</th>\n",
       "      <th>Detroit</th>\n",
       "      <th>El Paso</th>\n",
       "      <th>...</th>\n",
       "      <th>New York</th>\n",
       "      <th>Philadelphia</th>\n",
       "      <th>Phoenix</th>\n",
       "      <th>Portland</th>\n",
       "      <th>Raleigh</th>\n",
       "      <th>Sacramento</th>\n",
       "      <th>San Diego</th>\n",
       "      <th>San Fransisco</th>\n",
       "      <th>Tucson</th>\n",
       "      <th>Washington D.C.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows Ã 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Atlanta  Austin  Baltimore  Boston  Chicago  Columbus  Dallas  Denver  \\\n",
       "264        0       0          0       0        0         0       0       1   \n",
       "276        0       0          0       0        0         0       0       0   \n",
       "8          0       0          0       0        0         0       0       0   \n",
       "309        0       0          0       0        0         0       0       0   \n",
       "283        0       0          0       0        0         0       0       0   \n",
       "92         0       0          0       0        1         0       0       0   \n",
       "252        0       0          0       0        0         0       0       0   \n",
       "32         0       0          0       0        0         0       0       0   \n",
       "135        0       1          0       0        0         0       0       0   \n",
       "22         0       0          0       0        0         0       0       0   \n",
       "62         0       0          0       0        0         0       0       0   \n",
       "426        0       0          0       0        0         0       0       0   \n",
       "215        1       0          0       0        0         0       0       0   \n",
       "440        0       0          0       0        0         0       0       0   \n",
       "389        0       0          0       0        0         0       0       0   \n",
       "257        0       0          0       0        0         0       0       0   \n",
       "52         0       0          0       0        0         0       0       0   \n",
       "432        0       0          0       0        0         0       0       0   \n",
       "173        0       0          0       0        0         0       0       0   \n",
       "35         0       0          0       0        0         0       0       0   \n",
       "178        0       0          0       0        0         0       0       0   \n",
       "167        0       0          0       0        0         0       0       0   \n",
       "226        0       0          0       0        0         0       1       0   \n",
       "120        0       0          0       0        1         0       0       0   \n",
       "275        0       0          0       0        0         0       0       0   \n",
       "44         0       0          0       0        0         0       0       0   \n",
       "300        0       0          0       0        0         0       0       0   \n",
       "324        0       0          0       1        0         0       0       0   \n",
       "76         0       0          0       0        0         0       0       0   \n",
       "208        1       0          0       0        0         0       0       0   \n",
       "..       ...     ...        ...     ...      ...       ...     ...     ...   \n",
       "97         0       0          0       0        1         0       0       0   \n",
       "110        0       0          0       0        1         0       0       0   \n",
       "360        0       0          1       0        0         0       0       0   \n",
       "69         0       0          0       0        0         0       0       0   \n",
       "346        0       0          1       0        0         0       0       0   \n",
       "129        0       1          0       0        0         0       0       0   \n",
       "316        0       0          0       0        0         0       0       0   \n",
       "258        0       0          0       0        0         0       0       0   \n",
       "322        0       0          0       1        0         0       0       0   \n",
       "150        0       0          0       0        0         0       0       0   \n",
       "337        0       0          0       1        0         0       0       0   \n",
       "26         0       0          0       0        0         0       0       0   \n",
       "398        0       0          0       0        0         0       0       0   \n",
       "423        0       0          0       0        0         0       0       0   \n",
       "93         0       0          0       0        1         0       0       0   \n",
       "148        0       0          0       0        0         0       0       0   \n",
       "422        0       0          0       0        0         0       0       0   \n",
       "119        0       0          0       0        1         0       0       0   \n",
       "405        0       0          0       0        0         0       0       0   \n",
       "138        0       1          0       0        0         0       0       0   \n",
       "169        0       0          0       0        0         0       0       0   \n",
       "363        0       0          1       0        0         0       0       0   \n",
       "202        1       0          0       0        0         0       0       0   \n",
       "147        0       0          0       0        0         0       0       0   \n",
       "277        0       0          0       0        0         0       0       0   \n",
       "256        0       0          0       0        0         0       0       0   \n",
       "131        0       1          0       0        0         0       0       0   \n",
       "249        0       0          0       0        0         0       0       0   \n",
       "152        0       0          0       0        0         0       0       0   \n",
       "362        0       0          1       0        0         0       0       0   \n",
       "\n",
       "     Detroit  El Paso       ...         New York  Philadelphia  Phoenix  \\\n",
       "264        0        0       ...                0             0        0   \n",
       "276        0        0       ...                0             0        0   \n",
       "8          0        0       ...                0             0        0   \n",
       "309        0        0       ...                0             0        0   \n",
       "283        0        0       ...                0             0        0   \n",
       "92         0        0       ...                0             0        0   \n",
       "252        0        0       ...                0             0        1   \n",
       "32         0        0       ...                1             0        0   \n",
       "135        0        0       ...                0             0        0   \n",
       "22         0        0       ...                0             0        0   \n",
       "62         0        0       ...                1             0        0   \n",
       "426        0        0       ...                0             0        0   \n",
       "215        0        0       ...                0             0        0   \n",
       "440        0        0       ...                0             0        0   \n",
       "389        0        0       ...                0             0        0   \n",
       "257        0        0       ...                0             0        1   \n",
       "52         0        0       ...                1             0        0   \n",
       "432        0        0       ...                0             0        0   \n",
       "173        0        0       ...                0             1        0   \n",
       "35         0        0       ...                1             0        0   \n",
       "178        0        0       ...                0             1        0   \n",
       "167        0        0       ...                0             0        0   \n",
       "226        0        0       ...                0             0        0   \n",
       "120        0        0       ...                0             0        0   \n",
       "275        0        0       ...                0             0        0   \n",
       "44         0        0       ...                1             0        0   \n",
       "300        0        0       ...                0             0        0   \n",
       "324        0        0       ...                0             0        0   \n",
       "76         0        0       ...                0             0        0   \n",
       "208        0        0       ...                0             0        0   \n",
       "..       ...      ...       ...              ...           ...      ...   \n",
       "97         0        0       ...                0             0        0   \n",
       "110        0        0       ...                0             0        0   \n",
       "360        0        0       ...                0             0        0   \n",
       "69         0        0       ...                1             0        0   \n",
       "346        0        0       ...                0             0        0   \n",
       "129        0        0       ...                0             0        0   \n",
       "316        0        1       ...                0             0        0   \n",
       "258        0        0       ...                0             0        1   \n",
       "322        0        0       ...                0             0        0   \n",
       "150        0        0       ...                0             0        0   \n",
       "337        0        0       ...                0             0        0   \n",
       "26         0        0       ...                0             0        0   \n",
       "398        0        0       ...                0             0        0   \n",
       "423        0        0       ...                0             0        0   \n",
       "93         0        0       ...                0             0        0   \n",
       "148        0        0       ...                0             0        0   \n",
       "422        0        0       ...                0             0        0   \n",
       "119        0        0       ...                0             0        0   \n",
       "405        0        0       ...                0             0        0   \n",
       "138        0        0       ...                0             0        0   \n",
       "169        0        0       ...                0             0        0   \n",
       "363        0        0       ...                0             0        0   \n",
       "202        0        0       ...                0             0        0   \n",
       "147        0        0       ...                0             0        0   \n",
       "277        0        0       ...                0             0        0   \n",
       "256        0        0       ...                0             0        1   \n",
       "131        0        0       ...                0             0        0   \n",
       "249        0        0       ...                0             0        1   \n",
       "152        0        0       ...                0             0        0   \n",
       "362        0        0       ...                0             0        0   \n",
       "\n",
       "     Portland  Raleigh  Sacramento  San Diego  San Fransisco  Tucson  \\\n",
       "264         0        0           0          0              0       0   \n",
       "276         0        0           0          0              0       0   \n",
       "8           0        0           0          0              0       0   \n",
       "309         0        0           0          1              0       0   \n",
       "283         0        0           0          0              0       0   \n",
       "92          0        0           0          0              0       0   \n",
       "252         0        0           0          0              0       0   \n",
       "32          0        0           0          0              0       0   \n",
       "135         0        0           0          0              0       0   \n",
       "22          0        0           0          0              0       0   \n",
       "62          0        0           0          0              0       0   \n",
       "426         0        1           0          0              0       0   \n",
       "215         0        0           0          0              0       0   \n",
       "440         0        1           0          0              0       0   \n",
       "389         0        0           0          0              0       1   \n",
       "257         0        0           0          0              0       0   \n",
       "52          0        0           0          0              0       0   \n",
       "432         0        1           0          0              0       0   \n",
       "173         0        0           0          0              0       0   \n",
       "35          0        0           0          0              0       0   \n",
       "178         0        0           0          0              0       0   \n",
       "167         0        0           0          0              0       0   \n",
       "226         0        0           0          0              0       0   \n",
       "120         0        0           0          0              0       0   \n",
       "275         0        0           0          0              0       0   \n",
       "44          0        0           0          0              0       0   \n",
       "300         0        0           0          0              0       0   \n",
       "324         0        0           0          0              0       0   \n",
       "76          0        0           0          0              1       0   \n",
       "208         0        0           0          0              0       0   \n",
       "..        ...      ...         ...        ...            ...     ...   \n",
       "97          0        0           0          0              0       0   \n",
       "110         0        0           0          0              0       0   \n",
       "360         0        0           0          0              0       0   \n",
       "69          0        0           0          0              0       0   \n",
       "346         0        0           0          0              0       0   \n",
       "129         0        0           0          0              0       0   \n",
       "316         0        0           0          0              0       0   \n",
       "258         0        0           0          0              0       0   \n",
       "322         0        0           0          0              0       0   \n",
       "150         0        0           0          0              0       0   \n",
       "337         0        0           0          0              0       0   \n",
       "26          0        0           0          0              0       0   \n",
       "398         0        0           1          0              0       0   \n",
       "423         0        1           0          0              0       0   \n",
       "93          0        0           0          0              0       0   \n",
       "148         0        0           0          0              0       0   \n",
       "422         0        0           0          0              0       0   \n",
       "119         0        0           0          0              0       0   \n",
       "405         0        0           0          0              0       0   \n",
       "138         0        0           0          0              0       0   \n",
       "169         0        0           0          0              0       0   \n",
       "363         0        0           0          0              0       0   \n",
       "202         0        0           0          0              0       0   \n",
       "147         0        0           0          0              0       0   \n",
       "277         0        0           0          0              0       0   \n",
       "256         0        0           0          0              0       0   \n",
       "131         0        0           0          0              0       0   \n",
       "249         0        0           0          0              0       0   \n",
       "152         0        0           0          0              0       0   \n",
       "362         0        0           0          0              0       0   \n",
       "\n",
       "     Washington D.C.  \n",
       "264                0  \n",
       "276                0  \n",
       "8                  1  \n",
       "309                0  \n",
       "283                0  \n",
       "92                 0  \n",
       "252                0  \n",
       "32                 0  \n",
       "135                0  \n",
       "22                 1  \n",
       "62                 0  \n",
       "426                0  \n",
       "215                0  \n",
       "440                0  \n",
       "389                0  \n",
       "257                0  \n",
       "52                 0  \n",
       "432                0  \n",
       "173                0  \n",
       "35                 0  \n",
       "178                0  \n",
       "167                0  \n",
       "226                0  \n",
       "120                0  \n",
       "275                0  \n",
       "44                 0  \n",
       "300                0  \n",
       "324                0  \n",
       "76                 0  \n",
       "208                0  \n",
       "..               ...  \n",
       "97                 0  \n",
       "110                0  \n",
       "360                0  \n",
       "69                 0  \n",
       "346                0  \n",
       "129                0  \n",
       "316                0  \n",
       "258                0  \n",
       "322                0  \n",
       "150                0  \n",
       "337                0  \n",
       "26                 1  \n",
       "398                0  \n",
       "423                0  \n",
       "93                 0  \n",
       "148                0  \n",
       "422                0  \n",
       "119                0  \n",
       "405                0  \n",
       "138                0  \n",
       "169                0  \n",
       "363                0  \n",
       "202                0  \n",
       "147                0  \n",
       "277                0  \n",
       "256                0  \n",
       "131                0  \n",
       "249                0  \n",
       "152                0  \n",
       "362                0  \n",
       "\n",
       "[132 rows x 27 columns]"
      ]
     },
     "execution_count": 818,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2= pd.get_dummies(X_train['City']) #create dummy variables for city\n",
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Atlanta</th>\n",
       "      <th>Austin</th>\n",
       "      <th>Baltimore</th>\n",
       "      <th>Boston</th>\n",
       "      <th>Chicago</th>\n",
       "      <th>Columbus</th>\n",
       "      <th>Dallas</th>\n",
       "      <th>Denver</th>\n",
       "      <th>Detroit</th>\n",
       "      <th>El Paso</th>\n",
       "      <th>...</th>\n",
       "      <th>manager</th>\n",
       "      <th>medical</th>\n",
       "      <th>program</th>\n",
       "      <th>research</th>\n",
       "      <th>scientist</th>\n",
       "      <th>senior</th>\n",
       "      <th>software</th>\n",
       "      <th>specialist</th>\n",
       "      <th>sr</th>\n",
       "      <th>statistical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows Ã 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Atlanta  Austin  Baltimore  Boston  Chicago  Columbus  Dallas  Denver  \\\n",
       "264        0       0          0       0        0         0       0       1   \n",
       "276        0       0          0       0        0         0       0       0   \n",
       "8          0       0          0       0        0         0       0       0   \n",
       "309        0       0          0       0        0         0       0       0   \n",
       "283        0       0          0       0        0         0       0       0   \n",
       "92         0       0          0       0        1         0       0       0   \n",
       "252        0       0          0       0        0         0       0       0   \n",
       "32         0       0          0       0        0         0       0       0   \n",
       "135        0       1          0       0        0         0       0       0   \n",
       "22         0       0          0       0        0         0       0       0   \n",
       "62         0       0          0       0        0         0       0       0   \n",
       "426        0       0          0       0        0         0       0       0   \n",
       "215        1       0          0       0        0         0       0       0   \n",
       "440        0       0          0       0        0         0       0       0   \n",
       "389        0       0          0       0        0         0       0       0   \n",
       "257        0       0          0       0        0         0       0       0   \n",
       "52         0       0          0       0        0         0       0       0   \n",
       "432        0       0          0       0        0         0       0       0   \n",
       "173        0       0          0       0        0         0       0       0   \n",
       "35         0       0          0       0        0         0       0       0   \n",
       "178        0       0          0       0        0         0       0       0   \n",
       "167        0       0          0       0        0         0       0       0   \n",
       "226        0       0          0       0        0         0       1       0   \n",
       "120        0       0          0       0        1         0       0       0   \n",
       "275        0       0          0       0        0         0       0       0   \n",
       "44         0       0          0       0        0         0       0       0   \n",
       "300        0       0          0       0        0         0       0       0   \n",
       "324        0       0          0       1        0         0       0       0   \n",
       "76         0       0          0       0        0         0       0       0   \n",
       "208        1       0          0       0        0         0       0       0   \n",
       "..       ...     ...        ...     ...      ...       ...     ...     ...   \n",
       "97         0       0          0       0        1         0       0       0   \n",
       "110        0       0          0       0        1         0       0       0   \n",
       "360        0       0          1       0        0         0       0       0   \n",
       "69         0       0          0       0        0         0       0       0   \n",
       "346        0       0          1       0        0         0       0       0   \n",
       "129        0       1          0       0        0         0       0       0   \n",
       "316        0       0          0       0        0         0       0       0   \n",
       "258        0       0          0       0        0         0       0       0   \n",
       "322        0       0          0       1        0         0       0       0   \n",
       "150        0       0          0       0        0         0       0       0   \n",
       "337        0       0          0       1        0         0       0       0   \n",
       "26         0       0          0       0        0         0       0       0   \n",
       "398        0       0          0       0        0         0       0       0   \n",
       "423        0       0          0       0        0         0       0       0   \n",
       "93         0       0          0       0        1         0       0       0   \n",
       "148        0       0          0       0        0         0       0       0   \n",
       "422        0       0          0       0        0         0       0       0   \n",
       "119        0       0          0       0        1         0       0       0   \n",
       "405        0       0          0       0        0         0       0       0   \n",
       "138        0       1          0       0        0         0       0       0   \n",
       "169        0       0          0       0        0         0       0       0   \n",
       "363        0       0          1       0        0         0       0       0   \n",
       "202        1       0          0       0        0         0       0       0   \n",
       "147        0       0          0       0        0         0       0       0   \n",
       "277        0       0          0       0        0         0       0       0   \n",
       "256        0       0          0       0        0         0       0       0   \n",
       "131        0       1          0       0        0         0       0       0   \n",
       "249        0       0          0       0        0         0       0       0   \n",
       "152        0       0          0       0        0         0       0       0   \n",
       "362        0       0          1       0        0         0       0       0   \n",
       "\n",
       "     Detroit  El Paso     ...       manager  medical  program  research  \\\n",
       "264        0        0     ...             0        0        0         0   \n",
       "276        0        0     ...             0        0        0         1   \n",
       "8          0        0     ...             0        0        0         0   \n",
       "309        0        0     ...             0        0        0         0   \n",
       "283        0        0     ...             0        1        0         0   \n",
       "92         0        0     ...             0        0        0         0   \n",
       "252        0        0     ...             1        0        0         0   \n",
       "32         0        0     ...             1        0        0         0   \n",
       "135        0        0     ...             0        0        0         0   \n",
       "22         0        0     ...             0        0        0         0   \n",
       "62         0        0     ...             0        0        0         1   \n",
       "426        0        0     ...             0        0        0         0   \n",
       "215        0        0     ...             0        0        0         0   \n",
       "440        0        0     ...             0        0        0         0   \n",
       "389        0        0     ...             0        0        0         1   \n",
       "257        0        0     ...             0        0        0         0   \n",
       "52         0        0     ...             0        0        0         0   \n",
       "432        0        0     ...             0        0        0         0   \n",
       "173        0        0     ...             0        0        0         0   \n",
       "35         0        0     ...             0        0        0         0   \n",
       "178        0        0     ...             0        0        0         0   \n",
       "167        0        0     ...             0        0        0         0   \n",
       "226        0        0     ...             0        0        0         0   \n",
       "120        0        0     ...             0        0        0         0   \n",
       "275        0        0     ...             0        0        0         1   \n",
       "44         0        0     ...             0        0        0         0   \n",
       "300        0        0     ...             0        0        0         1   \n",
       "324        0        0     ...             0        0        0         0   \n",
       "76         0        0     ...             0        0        0         0   \n",
       "208        0        0     ...             0        0        1         0   \n",
       "..       ...      ...     ...           ...      ...      ...       ...   \n",
       "97         0        0     ...             0        1        0         0   \n",
       "110        0        0     ...             0        0        0         0   \n",
       "360        0        0     ...             0        0        0         0   \n",
       "69         0        0     ...             0        0        0         0   \n",
       "346        0        0     ...             0        0        0         1   \n",
       "129        0        0     ...             0        0        0         1   \n",
       "316        0        1     ...             1        0        0         0   \n",
       "258        0        0     ...             0        0        0         0   \n",
       "322        0        0     ...             0        0        0         0   \n",
       "150        0        0     ...             0        0        0         1   \n",
       "337        0        0     ...             1        0        1         0   \n",
       "26         0        0     ...             0        0        0         0   \n",
       "398        0        0     ...             0        0        0         0   \n",
       "423        0        0     ...             0        0        0         0   \n",
       "93         0        0     ...             0        0        0         0   \n",
       "148        0        0     ...             0        0        0         1   \n",
       "422        0        0     ...             0        0        0         0   \n",
       "119        0        0     ...             0        0        0         0   \n",
       "405        0        0     ...             0        0        0         0   \n",
       "138        0        0     ...             0        0        0         1   \n",
       "169        0        0     ...             0        0        0         1   \n",
       "363        0        0     ...             0        0        0         0   \n",
       "202        0        0     ...             0        0        0         0   \n",
       "147        0        0     ...             0        0        0         1   \n",
       "277        0        0     ...             0        0        0         1   \n",
       "256        0        0     ...             0        0        0         1   \n",
       "131        0        0     ...             0        0        0         0   \n",
       "249        0        0     ...             0        0        0         1   \n",
       "152        0        0     ...             0        0        0         0   \n",
       "362        0        0     ...             0        0        0         1   \n",
       "\n",
       "     scientist  senior  software  specialist  sr  statistical  \n",
       "264          0       1         1           0   0            0  \n",
       "276          0       0         0           0   0            1  \n",
       "8            1       0         0           0   0            0  \n",
       "309          0       0         0           0   0            0  \n",
       "283          1       0         0           0   0            0  \n",
       "92           1       0         0           0   0            0  \n",
       "252          0       0         0           0   0            0  \n",
       "32           0       0         0           0   0            0  \n",
       "135          1       0         0           0   0            0  \n",
       "22           0       0         0           0   0            0  \n",
       "62           1       0         0           0   0            0  \n",
       "426          1       0         0           0   0            0  \n",
       "215          0       0         0           0   0            0  \n",
       "440          1       0         0           0   0            0  \n",
       "389          0       1         0           0   0            0  \n",
       "257          0       0         0           1   0            0  \n",
       "52           0       1         0           0   0            0  \n",
       "432          0       0         0           0   0            0  \n",
       "173          1       0         0           0   0            0  \n",
       "35           0       0         0           0   0            0  \n",
       "178          0       0         0           0   0            0  \n",
       "167          1       0         0           0   0            0  \n",
       "226          0       0         0           0   0            0  \n",
       "120          0       0         0           0   0            0  \n",
       "275          0       0         0           0   0            1  \n",
       "44           1       0         0           0   0            0  \n",
       "300          0       0         0           0   0            0  \n",
       "324          0       0         0           0   0            0  \n",
       "76           1       0         0           0   0            0  \n",
       "208          0       0         0           0   0            0  \n",
       "..         ...     ...       ...         ...  ..          ...  \n",
       "97           0       0         0           0   0            0  \n",
       "110          1       0         0           0   0            0  \n",
       "360          0       0         0           0   0            0  \n",
       "69           0       0         0           0   1            0  \n",
       "346          0       0         0           0   0            0  \n",
       "129          1       0         0           0   0            0  \n",
       "316          0       0         0           0   0            0  \n",
       "258          0       0         0           0   0            0  \n",
       "322          1       0         0           0   0            0  \n",
       "150          0       0         0           0   0            0  \n",
       "337          1       0         0           0   0            0  \n",
       "26           1       0         0           0   0            0  \n",
       "398          0       0         0           0   0            0  \n",
       "423          1       0         0           0   0            0  \n",
       "93           1       0         0           0   0            0  \n",
       "148          0       0         0           0   0            0  \n",
       "422          0       0         0           0   0            0  \n",
       "119          0       0         0           0   1            1  \n",
       "405          0       0         0           0   1            0  \n",
       "138          1       1         1           0   0            0  \n",
       "169          0       0         0           0   0            0  \n",
       "363          0       0         0           0   0            0  \n",
       "202          1       0         0           0   0            0  \n",
       "147          0       0         0           0   0            0  \n",
       "277          1       0         0           0   0            0  \n",
       "256          0       0         0           0   0            0  \n",
       "131          1       0         0           0   0            0  \n",
       "249          0       0         0           0   0            1  \n",
       "152          1       0         0           0   0            0  \n",
       "362          0       0         0           0   0            0  \n",
       "\n",
       "[132 rows x 52 columns]"
      ]
     },
     "execution_count": 819,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3 = pd.concat([X2,X_words], axis=1) #concat 0, 1rows of job titles and cities\n",
    "X3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 25)\n",
      "(132, 27)\n",
      "(132,)\n",
      "(132, 52)\n"
     ]
    }
   ],
   "source": [
    "print X_words.shape #vectorizer df\n",
    "print X2.shape #City dummies\n",
    "print y_train.shape\n",
    "print X3.shape #concat df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 820,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apply the classifier we trained to the  data\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X3, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City/Title Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>research</th>\n",
       "      <td>0.094524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>0.092410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scientist</th>\n",
       "      <td>0.066537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Washington D.C.</th>\n",
       "      <td>0.055777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>statistical</th>\n",
       "      <td>0.044784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Houston</th>\n",
       "      <td>0.041874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>program</th>\n",
       "      <td>0.041808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Boston</th>\n",
       "      <td>0.039343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tucson</th>\n",
       "      <td>0.033460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phoenix</th>\n",
       "      <td>0.033382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>software</th>\n",
       "      <td>0.032202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>manager</th>\n",
       "      <td>0.025546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analyst</th>\n",
       "      <td>0.024172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>San Diego</th>\n",
       "      <td>0.021546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>0.020711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engineer</th>\n",
       "      <td>0.019860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bureau</th>\n",
       "      <td>0.019379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baltimore</th>\n",
       "      <td>0.019007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>associate</th>\n",
       "      <td>0.018085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laboratory</th>\n",
       "      <td>0.016361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atlanta</th>\n",
       "      <td>0.016295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raleigh</th>\n",
       "      <td>0.015191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>senior</th>\n",
       "      <td>0.014492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engineering</th>\n",
       "      <td>0.014350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assistant</th>\n",
       "      <td>0.013903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chicago</th>\n",
       "      <td>0.012907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Philadelphia</th>\n",
       "      <td>0.012894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health</th>\n",
       "      <td>0.012313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Portland</th>\n",
       "      <td>0.012078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sr</th>\n",
       "      <td>0.012040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 City/Title Importance\n",
       "research                      0.094524\n",
       "data                          0.092410\n",
       "scientist                     0.066537\n",
       "Washington D.C.               0.055777\n",
       "statistical                   0.044784\n",
       "Houston                       0.041874\n",
       "program                       0.041808\n",
       "Boston                        0.039343\n",
       "Tucson                        0.033460\n",
       "Phoenix                       0.033382\n",
       "software                      0.032202\n",
       "manager                       0.025546\n",
       "analyst                       0.024172\n",
       "San Diego                     0.021546\n",
       "New York                      0.020711\n",
       "engineer                      0.019860\n",
       "bureau                        0.019379\n",
       "Baltimore                     0.019007\n",
       "associate                     0.018085\n",
       "laboratory                    0.016361\n",
       "Atlanta                       0.016295\n",
       "Raleigh                       0.015191\n",
       "senior                        0.014492\n",
       "engineering                   0.014350\n",
       "assistant                     0.013903\n",
       "Chicago                       0.012907\n",
       "Philadelphia                  0.012894\n",
       "health                        0.012313\n",
       "Portland                      0.012078\n",
       "sr                            0.012040"
      ]
     },
     "execution_count": 821,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = pd.DataFrame(zip(rf.feature_importances_,),\n",
    "                           index=X3.columns,\n",
    "                           columns=['City/Title Importance']).sort_values('City/Title Importance',\n",
    "                                                                   ascending=False)\n",
    "importance.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "9367beff-72ba-4768-a0ba-a50b335de61d"
   },
   "source": [
    "#### Use cross-validation in scikit-learn to evaluate the model above. \n",
    "- Evaluate the accuracy of the model, as well as any other metrics you feel are appropriate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cv = StratifiedKFold(y_train, n_folds=10, shuffle=True, random_state=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dt = RandomForestClassifier(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.6      0.59091  0.62791]\n"
     ]
    }
   ],
   "source": [
    "# s = cross_val_score(dt, X3, y_train)\n",
    "# print s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {
    "focus": false,
    "id": "269b9e7c-60b5-4a06-8255-881d7395bc1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Tree Score:\t0.705 Â± 0.115\n"
     ]
    }
   ],
   "source": [
    "#cross validate model \n",
    "cv = StratifiedKFold(y_train, n_folds=10, shuffle=True, random_state=35)\n",
    "dt = RandomForestClassifier(class_weight='balanced')\n",
    "s = cross_val_score(dt, X3, y_train, cv=cv, n_jobs=-1)\n",
    "print \"{} Score:\\t{:0.3} Â± {:0.3}\".format(\"Random Forest Tree\", s.mean().round(3), s.std().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeat the model-building process with a non-tree-based method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Binary</th>\n",
       "      <th>research</th>\n",
       "      <th>data</th>\n",
       "      <th>scientist</th>\n",
       "      <th>statistical</th>\n",
       "      <th>program</th>\n",
       "      <th>software</th>\n",
       "      <th>manager</th>\n",
       "      <th>analyst</th>\n",
       "      <th>Washington D.C.</th>\n",
       "      <th>Houston</th>\n",
       "      <th>Boston</th>\n",
       "      <th>Tucson</th>\n",
       "      <th>Phoenix</th>\n",
       "      <th>San Diego</th>\n",
       "      <th>New York</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows Ã 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Binary  research  data  scientist  statistical  program  software  \\\n",
       "0     False         0     1          1            0        1         0   \n",
       "1      True         1     0          0            0        0         0   \n",
       "2      True         0     1          1            0        0         0   \n",
       "3     False         0     0          0            0        0         0   \n",
       "4      True         1     0          1            0        0         0   \n",
       "5      True         1     0          0            0        0         0   \n",
       "6      True         0     0          0            0        0         0   \n",
       "7      True         0     1          1            0        0         0   \n",
       "8      True         0     1          1            0        0         0   \n",
       "9      True         0     1          1            0        0         0   \n",
       "10     True         0     0          0            0        0         0   \n",
       "11    False         0     0          0            0        0         0   \n",
       "12     True         0     1          1            0        0         0   \n",
       "13     True         0     1          1            0        0         0   \n",
       "14     True         0     0          0            0        0         0   \n",
       "15     True         1     0          0            0        0         0   \n",
       "16     True         0     0          0            0        0         0   \n",
       "17     True         0     0          0            0        0         0   \n",
       "18     True         0     0          0            0        1         0   \n",
       "19     True         1     0          0            0        0         0   \n",
       "20     True         1     0          0            0        0         0   \n",
       "21     True         0     1          0            0        0         0   \n",
       "22     True         0     0          0            0        0         0   \n",
       "23     True         0     0          0            0        0         0   \n",
       "24     True         0     1          1            0        0         0   \n",
       "25    False         0     0          0            0        0         0   \n",
       "26     True         0     0          1            0        0         0   \n",
       "27     True         0     1          1            0        0         0   \n",
       "28     True         1     0          0            0        0         0   \n",
       "29    False         0     1          0            1        0         0   \n",
       "..      ...       ...   ...        ...          ...      ...       ...   \n",
       "411   False         1     0          0            0        0         0   \n",
       "412   False         0     0          0            0        0         0   \n",
       "413   False         1     0          0            0        0         0   \n",
       "414   False         0     0          0            0        0         0   \n",
       "415   False         0     0          0            0        0         0   \n",
       "416   False         1     0          0            0        0         0   \n",
       "417   False         1     0          0            0        0         0   \n",
       "418   False         0     0          0            0        0         0   \n",
       "419   False         0     0          0            0        0         0   \n",
       "420   False         0     0          0            0        0         0   \n",
       "421   False         0     0          0            0        0         0   \n",
       "422   False         0     0          0            0        0         0   \n",
       "423    True         0     1          1            0        0         0   \n",
       "424    True         0     0          0            0        0         0   \n",
       "425   False         0     0          1            0        0         0   \n",
       "426    True         0     1          1            0        0         0   \n",
       "427    True         0     0          0            1        0         0   \n",
       "428    True         0     1          1            0        0         0   \n",
       "429   False         1     0          0            0        0         0   \n",
       "430   False         0     0          1            0        0         0   \n",
       "431   False         0     0          1            0        0         0   \n",
       "432    True         0     1          0            0        0         0   \n",
       "433   False         0     0          0            0        0         0   \n",
       "434   False         1     0          0            0        0         0   \n",
       "435    True         0     1          1            0        0         0   \n",
       "436    True         0     0          0            0        0         0   \n",
       "437    True         0     1          1            0        0         0   \n",
       "438   False         1     0          0            0        0         0   \n",
       "439   False         0     0          0            0        0         0   \n",
       "440    True         0     1          1            0        0         0   \n",
       "\n",
       "     manager  analyst  Washington D.C.  Houston  Boston  Tucson  Phoenix  \\\n",
       "0          0        0                1        0       0       0        0   \n",
       "1          0        1                1        0       0       0        0   \n",
       "2          0        0                1        0       0       0        0   \n",
       "3          0        0                1        0       0       0        0   \n",
       "4          0        0                1        0       0       0        0   \n",
       "5          0        1                1        0       0       0        0   \n",
       "6          0        0                1        0       0       0        0   \n",
       "7          0        0                1        0       0       0        0   \n",
       "8          0        0                1        0       0       0        0   \n",
       "9          0        0                1        0       0       0        0   \n",
       "10         0        0                1        0       0       0        0   \n",
       "11         0        0                1        0       0       0        0   \n",
       "12         0        0                1        0       0       0        0   \n",
       "13         0        0                1        0       0       0        0   \n",
       "14         0        0                1        0       0       0        0   \n",
       "15         0        1                1        0       0       0        0   \n",
       "16         0        0                1        0       0       0        0   \n",
       "17         0        0                1        0       0       0        0   \n",
       "18         1        0                1        0       0       0        0   \n",
       "19         0        1                1        0       0       0        0   \n",
       "20         0        1                1        0       0       0        0   \n",
       "21         0        0                1        0       0       0        0   \n",
       "22         0        0                1        0       0       0        0   \n",
       "23         1        0                1        0       0       0        0   \n",
       "24         0        0                1        0       0       0        0   \n",
       "25         0        0                1        0       0       0        0   \n",
       "26         0        0                1        0       0       0        0   \n",
       "27         0        0                1        0       0       0        0   \n",
       "28         0        1                1        0       0       0        0   \n",
       "29         0        1                1        0       0       0        0   \n",
       "..       ...      ...              ...      ...     ...     ...      ...   \n",
       "411        0        1                0        0       0       0        0   \n",
       "412        1        0                0        0       0       0        0   \n",
       "413        0        1                0        0       0       0        0   \n",
       "414        0        0                0        0       0       0        0   \n",
       "415        0        0                0        0       0       0        0   \n",
       "416        0        1                0        0       0       0        0   \n",
       "417        0        1                0        0       0       0        0   \n",
       "418        0        0                0        0       0       0        0   \n",
       "419        0        0                0        0       0       0        0   \n",
       "420        0        0                0        0       0       0        0   \n",
       "421        0        0                0        0       0       0        0   \n",
       "422        0        0                0        0       0       0        0   \n",
       "423        0        0                0        0       0       0        0   \n",
       "424        0        0                0        0       0       0        0   \n",
       "425        0        0                0        0       0       0        0   \n",
       "426        0        0                0        0       0       0        0   \n",
       "427        0        0                0        0       0       0        0   \n",
       "428        0        0                0        0       0       0        0   \n",
       "429        0        1                0        0       0       0        0   \n",
       "430        0        0                0        0       0       0        0   \n",
       "431        0        0                0        0       0       0        0   \n",
       "432        0        1                0        0       0       0        0   \n",
       "433        0        0                0        0       0       0        0   \n",
       "434        0        0                0        0       0       0        0   \n",
       "435        0        0                0        0       0       0        0   \n",
       "436        0        0                0        0       0       0        0   \n",
       "437        0        0                0        0       0       0        0   \n",
       "438        0        0                0        0       0       0        0   \n",
       "439        0        0                0        0       0       0        0   \n",
       "440        0        0                0        0       0       0        0   \n",
       "\n",
       "     San Diego  New York  \n",
       "0            0         0  \n",
       "1            0         0  \n",
       "2            0         0  \n",
       "3            0         0  \n",
       "4            0         0  \n",
       "5            0         0  \n",
       "6            0         0  \n",
       "7            0         0  \n",
       "8            0         0  \n",
       "9            0         0  \n",
       "10           0         0  \n",
       "11           0         0  \n",
       "12           0         0  \n",
       "13           0         0  \n",
       "14           0         0  \n",
       "15           0         0  \n",
       "16           0         0  \n",
       "17           0         0  \n",
       "18           0         0  \n",
       "19           0         0  \n",
       "20           0         0  \n",
       "21           0         0  \n",
       "22           0         0  \n",
       "23           0         0  \n",
       "24           0         0  \n",
       "25           0         0  \n",
       "26           0         0  \n",
       "27           0         0  \n",
       "28           0         0  \n",
       "29           0         0  \n",
       "..         ...       ...  \n",
       "411          0         0  \n",
       "412          0         0  \n",
       "413          0         0  \n",
       "414          0         0  \n",
       "415          0         0  \n",
       "416          0         0  \n",
       "417          0         0  \n",
       "418          0         0  \n",
       "419          0         0  \n",
       "420          0         0  \n",
       "421          0         0  \n",
       "422          0         0  \n",
       "423          0         0  \n",
       "424          0         0  \n",
       "425          0         0  \n",
       "426          0         0  \n",
       "427          0         0  \n",
       "428          0         0  \n",
       "429          0         0  \n",
       "430          0         0  \n",
       "431          0         0  \n",
       "432          0         0  \n",
       "433          0         0  \n",
       "434          0         0  \n",
       "435          0         0  \n",
       "436          0         0  \n",
       "437          0         0  \n",
       "438          0         0  \n",
       "439          0         0  \n",
       "440          0         0  \n",
       "\n",
       "[441 rows x 16 columns]"
      ]
     },
     "execution_count": 897,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe with y variable and high importance variables from previous model\n",
    "temp_df3 =  Large_df[['Binary']]\n",
    "temp_df2 =  vocab2[['research','data','scientist', 'statistical', 'program','software','manager','analyst']]\n",
    "X4 = pd.get_dummies(data['City'])\n",
    "temp_df4 =  X4[['Washington D.C.', 'Houston','Boston', 'Tucson', 'Phoenix', 'San Diego', 'New York']]\n",
    "logit_df = pd.concat([temp_df3, temp_df2, temp_df4], axis=1)\n",
    "logit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Binary</th>\n",
       "      <th>research</th>\n",
       "      <th>data</th>\n",
       "      <th>scientist</th>\n",
       "      <th>statistical</th>\n",
       "      <th>program</th>\n",
       "      <th>software</th>\n",
       "      <th>manager</th>\n",
       "      <th>analyst</th>\n",
       "      <th>Washington D.C.</th>\n",
       "      <th>Houston</th>\n",
       "      <th>Boston</th>\n",
       "      <th>Tucson</th>\n",
       "      <th>Phoenix</th>\n",
       "      <th>San Diego</th>\n",
       "      <th>New York</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows Ã 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Binary  research  data  scientist  statistical  program  software  \\\n",
       "0         0         0     1          1            0        1         0   \n",
       "1         1         1     0          0            0        0         0   \n",
       "2         1         0     1          1            0        0         0   \n",
       "3         0         0     0          0            0        0         0   \n",
       "4         1         1     0          1            0        0         0   \n",
       "5         1         1     0          0            0        0         0   \n",
       "6         1         0     0          0            0        0         0   \n",
       "7         1         0     1          1            0        0         0   \n",
       "8         1         0     1          1            0        0         0   \n",
       "9         1         0     1          1            0        0         0   \n",
       "10        1         0     0          0            0        0         0   \n",
       "11        0         0     0          0            0        0         0   \n",
       "12        1         0     1          1            0        0         0   \n",
       "13        1         0     1          1            0        0         0   \n",
       "14        1         0     0          0            0        0         0   \n",
       "15        1         1     0          0            0        0         0   \n",
       "16        1         0     0          0            0        0         0   \n",
       "17        1         0     0          0            0        0         0   \n",
       "18        1         0     0          0            0        1         0   \n",
       "19        1         1     0          0            0        0         0   \n",
       "20        1         1     0          0            0        0         0   \n",
       "21        1         0     1          0            0        0         0   \n",
       "22        1         0     0          0            0        0         0   \n",
       "23        1         0     0          0            0        0         0   \n",
       "24        1         0     1          1            0        0         0   \n",
       "25        0         0     0          0            0        0         0   \n",
       "26        1         0     0          1            0        0         0   \n",
       "27        1         0     1          1            0        0         0   \n",
       "28        1         1     0          0            0        0         0   \n",
       "29        0         0     1          0            1        0         0   \n",
       "..      ...       ...   ...        ...          ...      ...       ...   \n",
       "411       0         1     0          0            0        0         0   \n",
       "412       0         0     0          0            0        0         0   \n",
       "413       0         1     0          0            0        0         0   \n",
       "414       0         0     0          0            0        0         0   \n",
       "415       0         0     0          0            0        0         0   \n",
       "416       0         1     0          0            0        0         0   \n",
       "417       0         1     0          0            0        0         0   \n",
       "418       0         0     0          0            0        0         0   \n",
       "419       0         0     0          0            0        0         0   \n",
       "420       0         0     0          0            0        0         0   \n",
       "421       0         0     0          0            0        0         0   \n",
       "422       0         0     0          0            0        0         0   \n",
       "423       1         0     1          1            0        0         0   \n",
       "424       1         0     0          0            0        0         0   \n",
       "425       0         0     0          1            0        0         0   \n",
       "426       1         0     1          1            0        0         0   \n",
       "427       1         0     0          0            1        0         0   \n",
       "428       1         0     1          1            0        0         0   \n",
       "429       0         1     0          0            0        0         0   \n",
       "430       0         0     0          1            0        0         0   \n",
       "431       0         0     0          1            0        0         0   \n",
       "432       1         0     1          0            0        0         0   \n",
       "433       0         0     0          0            0        0         0   \n",
       "434       0         1     0          0            0        0         0   \n",
       "435       1         0     1          1            0        0         0   \n",
       "436       1         0     0          0            0        0         0   \n",
       "437       1         0     1          1            0        0         0   \n",
       "438       0         1     0          0            0        0         0   \n",
       "439       0         0     0          0            0        0         0   \n",
       "440       1         0     1          1            0        0         0   \n",
       "\n",
       "     manager  analyst  Washington D.C.  Houston  Boston  Tucson  Phoenix  \\\n",
       "0          0        0                1        0       0       0        0   \n",
       "1          0        1                1        0       0       0        0   \n",
       "2          0        0                1        0       0       0        0   \n",
       "3          0        0                1        0       0       0        0   \n",
       "4          0        0                1        0       0       0        0   \n",
       "5          0        1                1        0       0       0        0   \n",
       "6          0        0                1        0       0       0        0   \n",
       "7          0        0                1        0       0       0        0   \n",
       "8          0        0                1        0       0       0        0   \n",
       "9          0        0                1        0       0       0        0   \n",
       "10         0        0                1        0       0       0        0   \n",
       "11         0        0                1        0       0       0        0   \n",
       "12         0        0                1        0       0       0        0   \n",
       "13         0        0                1        0       0       0        0   \n",
       "14         0        0                1        0       0       0        0   \n",
       "15         0        1                1        0       0       0        0   \n",
       "16         0        0                1        0       0       0        0   \n",
       "17         0        0                1        0       0       0        0   \n",
       "18         1        0                1        0       0       0        0   \n",
       "19         0        1                1        0       0       0        0   \n",
       "20         0        1                1        0       0       0        0   \n",
       "21         0        0                1        0       0       0        0   \n",
       "22         0        0                1        0       0       0        0   \n",
       "23         1        0                1        0       0       0        0   \n",
       "24         0        0                1        0       0       0        0   \n",
       "25         0        0                1        0       0       0        0   \n",
       "26         0        0                1        0       0       0        0   \n",
       "27         0        0                1        0       0       0        0   \n",
       "28         0        1                1        0       0       0        0   \n",
       "29         0        1                1        0       0       0        0   \n",
       "..       ...      ...              ...      ...     ...     ...      ...   \n",
       "411        0        1                0        0       0       0        0   \n",
       "412        1        0                0        0       0       0        0   \n",
       "413        0        1                0        0       0       0        0   \n",
       "414        0        0                0        0       0       0        0   \n",
       "415        0        0                0        0       0       0        0   \n",
       "416        0        1                0        0       0       0        0   \n",
       "417        0        1                0        0       0       0        0   \n",
       "418        0        0                0        0       0       0        0   \n",
       "419        0        0                0        0       0       0        0   \n",
       "420        0        0                0        0       0       0        0   \n",
       "421        0        0                0        0       0       0        0   \n",
       "422        0        0                0        0       0       0        0   \n",
       "423        0        0                0        0       0       0        0   \n",
       "424        0        0                0        0       0       0        0   \n",
       "425        0        0                0        0       0       0        0   \n",
       "426        0        0                0        0       0       0        0   \n",
       "427        0        0                0        0       0       0        0   \n",
       "428        0        0                0        0       0       0        0   \n",
       "429        0        1                0        0       0       0        0   \n",
       "430        0        0                0        0       0       0        0   \n",
       "431        0        0                0        0       0       0        0   \n",
       "432        0        1                0        0       0       0        0   \n",
       "433        0        0                0        0       0       0        0   \n",
       "434        0        0                0        0       0       0        0   \n",
       "435        0        0                0        0       0       0        0   \n",
       "436        0        0                0        0       0       0        0   \n",
       "437        0        0                0        0       0       0        0   \n",
       "438        0        0                0        0       0       0        0   \n",
       "439        0        0                0        0       0       0        0   \n",
       "440        0        0                0        0       0       0        0   \n",
       "\n",
       "     San Diego  New York  \n",
       "0            0         0  \n",
       "1            0         0  \n",
       "2            0         0  \n",
       "3            0         0  \n",
       "4            0         0  \n",
       "5            0         0  \n",
       "6            0         0  \n",
       "7            0         0  \n",
       "8            0         0  \n",
       "9            0         0  \n",
       "10           0         0  \n",
       "11           0         0  \n",
       "12           0         0  \n",
       "13           0         0  \n",
       "14           0         0  \n",
       "15           0         0  \n",
       "16           0         0  \n",
       "17           0         0  \n",
       "18           0         0  \n",
       "19           0         0  \n",
       "20           0         0  \n",
       "21           0         0  \n",
       "22           0         0  \n",
       "23           0         0  \n",
       "24           0         0  \n",
       "25           0         0  \n",
       "26           0         0  \n",
       "27           0         0  \n",
       "28           0         0  \n",
       "29           0         0  \n",
       "..         ...       ...  \n",
       "411          0         0  \n",
       "412          0         0  \n",
       "413          0         0  \n",
       "414          0         0  \n",
       "415          0         0  \n",
       "416          0         0  \n",
       "417          0         0  \n",
       "418          0         0  \n",
       "419          0         0  \n",
       "420          0         0  \n",
       "421          0         0  \n",
       "422          0         0  \n",
       "423          0         0  \n",
       "424          0         0  \n",
       "425          0         0  \n",
       "426          0         0  \n",
       "427          0         0  \n",
       "428          0         0  \n",
       "429          0         0  \n",
       "430          0         0  \n",
       "431          0         0  \n",
       "432          0         0  \n",
       "433          0         0  \n",
       "434          0         0  \n",
       "435          0         0  \n",
       "436          0         0  \n",
       "437          0         0  \n",
       "438          0         0  \n",
       "439          0         0  \n",
       "440          0         0  \n",
       "\n",
       "[441 rows x 16 columns]"
      ]
     },
     "execution_count": 914,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_df['Binary'] = logit_df['Binary'].astype(int) #turning Binary into 0, false, and 1, True\n",
    "logit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#renaming df names so patsy can understand(it does not lik spaces or .'s)\n",
    "logit_df.rename(columns={'Washington D.C.':'WashingtonDC','San Diego':'SanDiego','New York':'NewYork'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([      u'Binary',     u'research',         u'data',    u'scientist',\n",
       "        u'statistical',      u'program',     u'software',      u'manager',\n",
       "            u'analyst', u'WashingtonDC',      u'Houston',       u'Boston',\n",
       "             u'Tucson',      u'Phoenix',     u'SanDiego',      u'NewYork'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 942,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.549199\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>Binary</td>      <th>  No. Observations:  </th>  <td>   441</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   427</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>    13</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Thu, 27 Jul 2017</td> <th>  Pseudo R-squ.:     </th>  <td>0.2076</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>22:20:47</td>     <th>  Log-Likelihood:    </th> <td> -242.20</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -305.67</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>8.482e-21</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>    <td>   -0.4264</td> <td>    0.194</td> <td>   -2.199</td> <td> 0.028</td> <td>   -0.806</td> <td>   -0.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>research</th>     <td>   -1.2055</td> <td>    0.277</td> <td>   -4.360</td> <td> 0.000</td> <td>   -1.747</td> <td>   -0.664</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>data</th>         <td>    1.6847</td> <td>    0.314</td> <td>    5.361</td> <td> 0.000</td> <td>    1.069</td> <td>    2.301</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scientist</th>    <td>    0.3972</td> <td>    0.264</td> <td>    1.504</td> <td> 0.132</td> <td>   -0.120</td> <td>    0.915</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>statistical</th>  <td>    1.3976</td> <td>    0.619</td> <td>    2.256</td> <td> 0.024</td> <td>    0.183</td> <td>    2.612</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>program</th>      <td>   -0.5626</td> <td>    0.739</td> <td>   -0.761</td> <td> 0.447</td> <td>   -2.012</td> <td>    0.886</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>software</th>     <td>    2.0956</td> <td>    0.813</td> <td>    2.576</td> <td> 0.010</td> <td>    0.501</td> <td>    3.690</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>manager</th>      <td>   -0.2314</td> <td>    0.527</td> <td>   -0.439</td> <td> 0.661</td> <td>   -1.264</td> <td>    0.801</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>analyst</th>      <td>   -0.1870</td> <td>    0.331</td> <td>   -0.565</td> <td> 0.572</td> <td>   -0.835</td> <td>    0.461</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>WashingtonDC</th> <td>    1.9245</td> <td>    0.523</td> <td>    3.677</td> <td> 0.000</td> <td>    0.899</td> <td>    2.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Houston</th>      <td>    0.9606</td> <td>    0.504</td> <td>    1.905</td> <td> 0.057</td> <td>   -0.028</td> <td>    1.949</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Boston</th>       <td>    0.0210</td> <td>    0.521</td> <td>    0.040</td> <td> 0.968</td> <td>   -1.000</td> <td>    1.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SanDiego</th>     <td>    0.5982</td> <td>    0.685</td> <td>    0.873</td> <td> 0.383</td> <td>   -0.745</td> <td>    1.941</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NewYork</th>      <td>    0.5570</td> <td>    0.372</td> <td>    1.497</td> <td> 0.134</td> <td>   -0.172</td> <td>    1.286</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                 Binary   No. Observations:                  441\n",
       "Model:                          Logit   Df Residuals:                      427\n",
       "Method:                           MLE   Df Model:                           13\n",
       "Date:                Thu, 27 Jul 2017   Pseudo R-squ.:                  0.2076\n",
       "Time:                        22:20:47   Log-Likelihood:                -242.20\n",
       "converged:                       True   LL-Null:                       -305.67\n",
       "                                        LLR p-value:                 8.482e-21\n",
       "================================================================================\n",
       "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "Intercept       -0.4264      0.194     -2.199      0.028      -0.806      -0.046\n",
       "research        -1.2055      0.277     -4.360      0.000      -1.747      -0.664\n",
       "data             1.6847      0.314      5.361      0.000       1.069       2.301\n",
       "scientist        0.3972      0.264      1.504      0.132      -0.120       0.915\n",
       "statistical      1.3976      0.619      2.256      0.024       0.183       2.612\n",
       "program         -0.5626      0.739     -0.761      0.447      -2.012       0.886\n",
       "software         2.0956      0.813      2.576      0.010       0.501       3.690\n",
       "manager         -0.2314      0.527     -0.439      0.661      -1.264       0.801\n",
       "analyst         -0.1870      0.331     -0.565      0.572      -0.835       0.461\n",
       "WashingtonDC     1.9245      0.523      3.677      0.000       0.899       2.950\n",
       "Houston          0.9606      0.504      1.905      0.057      -0.028       1.949\n",
       "Boston           0.0210      0.521      0.040      0.968      -1.000       1.042\n",
       "SanDiego         0.5982      0.685      0.873      0.383      -0.745       1.941\n",
       "NewYork          0.5570      0.372      1.497      0.134      -0.172       1.286\n",
       "================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 946,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#logisitic regression model\n",
    "import statsmodels.formula.api as sm\n",
    "model = sm.logit(\"Binary ~ research + data + scientist + statistical + program + software + manager + analyst + WashingtonDC + Houston + Boston + SanDiego + NewYork\"\n",
    "                 ,data=logit_df).fit()\n",
    "#model summary\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "3be94357-e551-4094-b784-2df039216d33"
   },
   "source": [
    "### BONUS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "db045898-1d2d-4af2-8e79-437c4c7546b4"
   },
   "source": [
    "#### Bonus: Use Count Vectorizer from scikit-learn to create features from the job descriptions. \n",
    "- Examine using count or binary features in the model\n",
    "- Re-evaluate your models using these. Does this improve the model performance? \n",
    "- What text features are the most valuable? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "4239e458-28bd-4675-8db3-c1d9c02b9854"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
